
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
  <title>MemoryManager.cpp</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">/*</a>
<a name="ln2"> * Copyright 2010, Ingo Weinhold &lt;ingo_weinhold@gmx.de&gt;.</a>
<a name="ln3"> * Distributed under the terms of the MIT License.</a>
<a name="ln4"> */</a>
<a name="ln5"> </a>
<a name="ln6"> </a>
<a name="ln7">#include &quot;MemoryManager.h&quot;</a>
<a name="ln8"> </a>
<a name="ln9">#include &lt;algorithm&gt;</a>
<a name="ln10"> </a>
<a name="ln11">#include &lt;debug.h&gt;</a>
<a name="ln12">#include &lt;tracing.h&gt;</a>
<a name="ln13">#include &lt;util/AutoLock.h&gt;</a>
<a name="ln14">#include &lt;vm/vm.h&gt;</a>
<a name="ln15">#include &lt;vm/vm_page.h&gt;</a>
<a name="ln16">#include &lt;vm/vm_priv.h&gt;</a>
<a name="ln17">#include &lt;vm/VMAddressSpace.h&gt;</a>
<a name="ln18">#include &lt;vm/VMArea.h&gt;</a>
<a name="ln19">#include &lt;vm/VMCache.h&gt;</a>
<a name="ln20">#include &lt;vm/VMTranslationMap.h&gt;</a>
<a name="ln21"> </a>
<a name="ln22">#include &quot;kernel_debug_config.h&quot;</a>
<a name="ln23"> </a>
<a name="ln24">#include &quot;ObjectCache.h&quot;</a>
<a name="ln25"> </a>
<a name="ln26"> </a>
<a name="ln27">//#define TRACE_MEMORY_MANAGER</a>
<a name="ln28">#ifdef TRACE_MEMORY_MANAGER</a>
<a name="ln29">#	define TRACE(x...)	dprintf(x)</a>
<a name="ln30">#else</a>
<a name="ln31">#	define TRACE(x...)	do {} while (false)</a>
<a name="ln32">#endif</a>
<a name="ln33"> </a>
<a name="ln34">#if DEBUG_SLAB_MEMORY_MANAGER_PARANOID_CHECKS</a>
<a name="ln35">#	define PARANOID_CHECKS_ONLY(x)	x</a>
<a name="ln36">#else</a>
<a name="ln37">#	define PARANOID_CHECKS_ONLY(x)</a>
<a name="ln38">#endif</a>
<a name="ln39"> </a>
<a name="ln40"> </a>
<a name="ln41">static const char* const kSlabAreaName = &quot;slab area&quot;;</a>
<a name="ln42"> </a>
<a name="ln43">static void* sAreaTableBuffer[1024];</a>
<a name="ln44"> </a>
<a name="ln45">mutex MemoryManager::sLock;</a>
<a name="ln46">rw_lock MemoryManager::sAreaTableLock;</a>
<a name="ln47">kernel_args* MemoryManager::sKernelArgs;</a>
<a name="ln48">MemoryManager::AreaTable MemoryManager::sAreaTable;</a>
<a name="ln49">MemoryManager::Area* MemoryManager::sFreeAreas;</a>
<a name="ln50">int MemoryManager::sFreeAreaCount;</a>
<a name="ln51">MemoryManager::MetaChunkList MemoryManager::sFreeCompleteMetaChunks;</a>
<a name="ln52">MemoryManager::MetaChunkList MemoryManager::sFreeShortMetaChunks;</a>
<a name="ln53">MemoryManager::MetaChunkList MemoryManager::sPartialMetaChunksSmall;</a>
<a name="ln54">MemoryManager::MetaChunkList MemoryManager::sPartialMetaChunksMedium;</a>
<a name="ln55">MemoryManager::AllocationEntry* MemoryManager::sAllocationEntryCanWait;</a>
<a name="ln56">MemoryManager::AllocationEntry* MemoryManager::sAllocationEntryDontWait;</a>
<a name="ln57">bool MemoryManager::sMaintenanceNeeded;</a>
<a name="ln58"> </a>
<a name="ln59"> </a>
<a name="ln60">RANGE_MARKER_FUNCTION_BEGIN(SlabMemoryManager)</a>
<a name="ln61"> </a>
<a name="ln62"> </a>
<a name="ln63">// #pragma mark - kernel tracing</a>
<a name="ln64"> </a>
<a name="ln65"> </a>
<a name="ln66">#if SLAB_MEMORY_MANAGER_TRACING</a>
<a name="ln67"> </a>
<a name="ln68"> </a>
<a name="ln69">//namespace SlabMemoryManagerCacheTracing {</a>
<a name="ln70">struct MemoryManager::Tracing {</a>
<a name="ln71"> </a>
<a name="ln72">class MemoryManagerTraceEntry</a>
<a name="ln73">	: public TRACE_ENTRY_SELECTOR(SLAB_MEMORY_MANAGER_TRACING_STACK_TRACE) {</a>
<a name="ln74">public:</a>
<a name="ln75">	MemoryManagerTraceEntry()</a>
<a name="ln76">		:</a>
<a name="ln77">		TraceEntryBase(SLAB_MEMORY_MANAGER_TRACING_STACK_TRACE, 0, true)</a>
<a name="ln78">	{</a>
<a name="ln79">	}</a>
<a name="ln80">};</a>
<a name="ln81"> </a>
<a name="ln82"> </a>
<a name="ln83">class Allocate : public MemoryManagerTraceEntry {</a>
<a name="ln84">public:</a>
<a name="ln85">	Allocate(ObjectCache* cache, uint32 flags)</a>
<a name="ln86">		:</a>
<a name="ln87">		MemoryManagerTraceEntry(),</a>
<a name="ln88">		fCache(cache),</a>
<a name="ln89">		fFlags(flags)</a>
<a name="ln90">	{</a>
<a name="ln91">		Initialized();</a>
<a name="ln92">	}</a>
<a name="ln93"> </a>
<a name="ln94">	virtual void AddDump(TraceOutput&amp; out)</a>
<a name="ln95">	{</a>
<a name="ln96">		out.Print(&quot;slab memory manager alloc: cache: %p, flags: %#&quot; B_PRIx32,</a>
<a name="ln97">			fCache, fFlags);</a>
<a name="ln98">	}</a>
<a name="ln99"> </a>
<a name="ln100">private:</a>
<a name="ln101">	ObjectCache*	fCache;</a>
<a name="ln102">	uint32			fFlags;</a>
<a name="ln103">};</a>
<a name="ln104"> </a>
<a name="ln105"> </a>
<a name="ln106">class Free : public MemoryManagerTraceEntry {</a>
<a name="ln107">public:</a>
<a name="ln108">	Free(void* address, uint32 flags)</a>
<a name="ln109">		:</a>
<a name="ln110">		MemoryManagerTraceEntry(),</a>
<a name="ln111">		fAddress(address),</a>
<a name="ln112">		fFlags(flags)</a>
<a name="ln113">	{</a>
<a name="ln114">		Initialized();</a>
<a name="ln115">	}</a>
<a name="ln116"> </a>
<a name="ln117">	virtual void AddDump(TraceOutput&amp; out)</a>
<a name="ln118">	{</a>
<a name="ln119">		out.Print(&quot;slab memory manager free: address: %p, flags: %#&quot; B_PRIx32,</a>
<a name="ln120">			fAddress, fFlags);</a>
<a name="ln121">	}</a>
<a name="ln122"> </a>
<a name="ln123">private:</a>
<a name="ln124">	void*	fAddress;</a>
<a name="ln125">	uint32	fFlags;</a>
<a name="ln126">};</a>
<a name="ln127"> </a>
<a name="ln128"> </a>
<a name="ln129">class AllocateRaw : public MemoryManagerTraceEntry {</a>
<a name="ln130">public:</a>
<a name="ln131">	AllocateRaw(size_t size, uint32 flags)</a>
<a name="ln132">		:</a>
<a name="ln133">		MemoryManagerTraceEntry(),</a>
<a name="ln134">		fSize(size),</a>
<a name="ln135">		fFlags(flags)</a>
<a name="ln136">	{</a>
<a name="ln137">		Initialized();</a>
<a name="ln138">	}</a>
<a name="ln139"> </a>
<a name="ln140">	virtual void AddDump(TraceOutput&amp; out)</a>
<a name="ln141">	{</a>
<a name="ln142">		out.Print(&quot;slab memory manager alloc raw: size: %&quot; B_PRIuSIZE</a>
<a name="ln143">			&quot;, flags: %#&quot; B_PRIx32, fSize, fFlags);</a>
<a name="ln144">	}</a>
<a name="ln145"> </a>
<a name="ln146">private:</a>
<a name="ln147">	size_t	fSize;</a>
<a name="ln148">	uint32	fFlags;</a>
<a name="ln149">};</a>
<a name="ln150"> </a>
<a name="ln151"> </a>
<a name="ln152">class FreeRawOrReturnCache : public MemoryManagerTraceEntry {</a>
<a name="ln153">public:</a>
<a name="ln154">	FreeRawOrReturnCache(void* address, uint32 flags)</a>
<a name="ln155">		:</a>
<a name="ln156">		MemoryManagerTraceEntry(),</a>
<a name="ln157">		fAddress(address),</a>
<a name="ln158">		fFlags(flags)</a>
<a name="ln159">	{</a>
<a name="ln160">		Initialized();</a>
<a name="ln161">	}</a>
<a name="ln162"> </a>
<a name="ln163">	virtual void AddDump(TraceOutput&amp; out)</a>
<a name="ln164">	{</a>
<a name="ln165">		out.Print(&quot;slab memory manager free raw/return: address: %p, flags: %#&quot;</a>
<a name="ln166">			B_PRIx32, fAddress, fFlags);</a>
<a name="ln167">	}</a>
<a name="ln168"> </a>
<a name="ln169">private:</a>
<a name="ln170">	void*	fAddress;</a>
<a name="ln171">	uint32	fFlags;</a>
<a name="ln172">};</a>
<a name="ln173"> </a>
<a name="ln174"> </a>
<a name="ln175">class AllocateArea : public MemoryManagerTraceEntry {</a>
<a name="ln176">public:</a>
<a name="ln177">	AllocateArea(Area* area, uint32 flags)</a>
<a name="ln178">		:</a>
<a name="ln179">		MemoryManagerTraceEntry(),</a>
<a name="ln180">		fArea(area),</a>
<a name="ln181">		fFlags(flags)</a>
<a name="ln182">	{</a>
<a name="ln183">		Initialized();</a>
<a name="ln184">	}</a>
<a name="ln185"> </a>
<a name="ln186">	virtual void AddDump(TraceOutput&amp; out)</a>
<a name="ln187">	{</a>
<a name="ln188">		out.Print(&quot;slab memory manager alloc area: flags: %#&quot; B_PRIx32</a>
<a name="ln189">			&quot; -&gt; %p&quot;, fFlags, fArea);</a>
<a name="ln190">	}</a>
<a name="ln191"> </a>
<a name="ln192">private:</a>
<a name="ln193">	Area*	fArea;</a>
<a name="ln194">	uint32	fFlags;</a>
<a name="ln195">};</a>
<a name="ln196"> </a>
<a name="ln197"> </a>
<a name="ln198">class AddArea : public MemoryManagerTraceEntry {</a>
<a name="ln199">public:</a>
<a name="ln200">	AddArea(Area* area)</a>
<a name="ln201">		:</a>
<a name="ln202">		MemoryManagerTraceEntry(),</a>
<a name="ln203">		fArea(area)</a>
<a name="ln204">	{</a>
<a name="ln205">		Initialized();</a>
<a name="ln206">	}</a>
<a name="ln207"> </a>
<a name="ln208">	virtual void AddDump(TraceOutput&amp; out)</a>
<a name="ln209">	{</a>
<a name="ln210">		out.Print(&quot;slab memory manager add area: %p&quot;, fArea);</a>
<a name="ln211">	}</a>
<a name="ln212"> </a>
<a name="ln213">private:</a>
<a name="ln214">	Area*	fArea;</a>
<a name="ln215">};</a>
<a name="ln216"> </a>
<a name="ln217"> </a>
<a name="ln218">class FreeArea : public MemoryManagerTraceEntry {</a>
<a name="ln219">public:</a>
<a name="ln220">	FreeArea(Area* area, bool areaRemoved, uint32 flags)</a>
<a name="ln221">		:</a>
<a name="ln222">		MemoryManagerTraceEntry(),</a>
<a name="ln223">		fArea(area),</a>
<a name="ln224">		fFlags(flags),</a>
<a name="ln225">		fRemoved(areaRemoved)</a>
<a name="ln226">	{</a>
<a name="ln227">		Initialized();</a>
<a name="ln228">	}</a>
<a name="ln229"> </a>
<a name="ln230">	virtual void AddDump(TraceOutput&amp; out)</a>
<a name="ln231">	{</a>
<a name="ln232">		out.Print(&quot;slab memory manager free area: %p%s, flags: %#&quot; B_PRIx32,</a>
<a name="ln233">			fArea, fRemoved ? &quot; (removed)&quot; : &quot;&quot;, fFlags);</a>
<a name="ln234">	}</a>
<a name="ln235"> </a>
<a name="ln236">private:</a>
<a name="ln237">	Area*	fArea;</a>
<a name="ln238">	uint32	fFlags;</a>
<a name="ln239">	bool	fRemoved;</a>
<a name="ln240">};</a>
<a name="ln241"> </a>
<a name="ln242"> </a>
<a name="ln243">class AllocateMetaChunk : public MemoryManagerTraceEntry {</a>
<a name="ln244">public:</a>
<a name="ln245">	AllocateMetaChunk(MetaChunk* metaChunk)</a>
<a name="ln246">		:</a>
<a name="ln247">		MemoryManagerTraceEntry(),</a>
<a name="ln248">		fMetaChunk(metaChunk-&gt;chunkBase)</a>
<a name="ln249">	{</a>
<a name="ln250">		Initialized();</a>
<a name="ln251">	}</a>
<a name="ln252"> </a>
<a name="ln253">	virtual void AddDump(TraceOutput&amp; out)</a>
<a name="ln254">	{</a>
<a name="ln255">		out.Print(&quot;slab memory manager alloc meta chunk: %#&quot; B_PRIxADDR,</a>
<a name="ln256">			fMetaChunk);</a>
<a name="ln257">	}</a>
<a name="ln258"> </a>
<a name="ln259">private:</a>
<a name="ln260">	addr_t	fMetaChunk;</a>
<a name="ln261">};</a>
<a name="ln262"> </a>
<a name="ln263"> </a>
<a name="ln264">class FreeMetaChunk : public MemoryManagerTraceEntry {</a>
<a name="ln265">public:</a>
<a name="ln266">	FreeMetaChunk(MetaChunk* metaChunk)</a>
<a name="ln267">		:</a>
<a name="ln268">		MemoryManagerTraceEntry(),</a>
<a name="ln269">		fMetaChunk(metaChunk-&gt;chunkBase)</a>
<a name="ln270">	{</a>
<a name="ln271">		Initialized();</a>
<a name="ln272">	}</a>
<a name="ln273"> </a>
<a name="ln274">	virtual void AddDump(TraceOutput&amp; out)</a>
<a name="ln275">	{</a>
<a name="ln276">		out.Print(&quot;slab memory manager free meta chunk: %#&quot; B_PRIxADDR,</a>
<a name="ln277">			fMetaChunk);</a>
<a name="ln278">	}</a>
<a name="ln279"> </a>
<a name="ln280">private:</a>
<a name="ln281">	addr_t	fMetaChunk;</a>
<a name="ln282">};</a>
<a name="ln283"> </a>
<a name="ln284"> </a>
<a name="ln285">class AllocateChunk : public MemoryManagerTraceEntry {</a>
<a name="ln286">public:</a>
<a name="ln287">	AllocateChunk(size_t chunkSize, MetaChunk* metaChunk, Chunk* chunk)</a>
<a name="ln288">		:</a>
<a name="ln289">		MemoryManagerTraceEntry(),</a>
<a name="ln290">		fChunkSize(chunkSize),</a>
<a name="ln291">		fMetaChunk(metaChunk-&gt;chunkBase),</a>
<a name="ln292">		fChunk(chunk - metaChunk-&gt;chunks)</a>
<a name="ln293">	{</a>
<a name="ln294">		Initialized();</a>
<a name="ln295">	}</a>
<a name="ln296"> </a>
<a name="ln297">	virtual void AddDump(TraceOutput&amp; out)</a>
<a name="ln298">	{</a>
<a name="ln299">		out.Print(&quot;slab memory manager alloc chunk: size: %&quot; B_PRIuSIZE</a>
<a name="ln300">			&quot; -&gt; meta chunk: %#&quot; B_PRIxADDR &quot;, chunk: %&quot; B_PRIu32, fChunkSize,</a>
<a name="ln301">			fMetaChunk, fChunk);</a>
<a name="ln302">	}</a>
<a name="ln303"> </a>
<a name="ln304">private:</a>
<a name="ln305">	size_t	fChunkSize;</a>
<a name="ln306">	addr_t	fMetaChunk;</a>
<a name="ln307">	uint32	fChunk;</a>
<a name="ln308">};</a>
<a name="ln309"> </a>
<a name="ln310"> </a>
<a name="ln311">class AllocateChunks : public MemoryManagerTraceEntry {</a>
<a name="ln312">public:</a>
<a name="ln313">	AllocateChunks(size_t chunkSize, uint32 chunkCount, MetaChunk* metaChunk,</a>
<a name="ln314">		Chunk* chunk)</a>
<a name="ln315">		:</a>
<a name="ln316">		MemoryManagerTraceEntry(),</a>
<a name="ln317">		fMetaChunk(metaChunk-&gt;chunkBase),</a>
<a name="ln318">		fChunkSize(chunkSize),</a>
<a name="ln319">		fChunkCount(chunkCount),</a>
<a name="ln320">		fChunk(chunk - metaChunk-&gt;chunks)</a>
<a name="ln321">	{</a>
<a name="ln322">		Initialized();</a>
<a name="ln323">	}</a>
<a name="ln324"> </a>
<a name="ln325">	virtual void AddDump(TraceOutput&amp; out)</a>
<a name="ln326">	{</a>
<a name="ln327">		out.Print(&quot;slab memory manager alloc chunks: size: %&quot; B_PRIuSIZE</a>
<a name="ln328">			&quot;, count %&quot; B_PRIu32 &quot; -&gt; meta chunk: %#&quot; B_PRIxADDR &quot;, chunk: %&quot;</a>
<a name="ln329">			B_PRIu32, fChunkSize, fChunkCount, fMetaChunk, fChunk);</a>
<a name="ln330">	}</a>
<a name="ln331"> </a>
<a name="ln332">private:</a>
<a name="ln333">	addr_t	fMetaChunk;</a>
<a name="ln334">	size_t	fChunkSize;</a>
<a name="ln335">	uint32	fChunkCount;</a>
<a name="ln336">	uint32	fChunk;</a>
<a name="ln337">};</a>
<a name="ln338"> </a>
<a name="ln339"> </a>
<a name="ln340">class FreeChunk : public MemoryManagerTraceEntry {</a>
<a name="ln341">public:</a>
<a name="ln342">	FreeChunk(MetaChunk* metaChunk, Chunk* chunk)</a>
<a name="ln343">		:</a>
<a name="ln344">		MemoryManagerTraceEntry(),</a>
<a name="ln345">		fMetaChunk(metaChunk-&gt;chunkBase),</a>
<a name="ln346">		fChunk(chunk - metaChunk-&gt;chunks)</a>
<a name="ln347">	{</a>
<a name="ln348">		Initialized();</a>
<a name="ln349">	}</a>
<a name="ln350"> </a>
<a name="ln351">	virtual void AddDump(TraceOutput&amp; out)</a>
<a name="ln352">	{</a>
<a name="ln353">		out.Print(&quot;slab memory manager free chunk: meta chunk: %#&quot; B_PRIxADDR</a>
<a name="ln354">			&quot;, chunk: %&quot; B_PRIu32, fMetaChunk, fChunk);</a>
<a name="ln355">	}</a>
<a name="ln356"> </a>
<a name="ln357">private:</a>
<a name="ln358">	addr_t	fMetaChunk;</a>
<a name="ln359">	uint32	fChunk;</a>
<a name="ln360">};</a>
<a name="ln361"> </a>
<a name="ln362"> </a>
<a name="ln363">class Map : public MemoryManagerTraceEntry {</a>
<a name="ln364">public:</a>
<a name="ln365">	Map(addr_t address, size_t size, uint32 flags)</a>
<a name="ln366">		:</a>
<a name="ln367">		MemoryManagerTraceEntry(),</a>
<a name="ln368">		fAddress(address),</a>
<a name="ln369">		fSize(size),</a>
<a name="ln370">		fFlags(flags)</a>
<a name="ln371">	{</a>
<a name="ln372">		Initialized();</a>
<a name="ln373">	}</a>
<a name="ln374"> </a>
<a name="ln375">	virtual void AddDump(TraceOutput&amp; out)</a>
<a name="ln376">	{</a>
<a name="ln377">		out.Print(&quot;slab memory manager map: %#&quot; B_PRIxADDR &quot;, size: %&quot;</a>
<a name="ln378">			B_PRIuSIZE &quot;, flags: %#&quot; B_PRIx32, fAddress, fSize, fFlags);</a>
<a name="ln379">	}</a>
<a name="ln380"> </a>
<a name="ln381">private:</a>
<a name="ln382">	addr_t	fAddress;</a>
<a name="ln383">	size_t	fSize;</a>
<a name="ln384">	uint32	fFlags;</a>
<a name="ln385">};</a>
<a name="ln386"> </a>
<a name="ln387"> </a>
<a name="ln388">class Unmap : public MemoryManagerTraceEntry {</a>
<a name="ln389">public:</a>
<a name="ln390">	Unmap(addr_t address, size_t size, uint32 flags)</a>
<a name="ln391">		:</a>
<a name="ln392">		MemoryManagerTraceEntry(),</a>
<a name="ln393">		fAddress(address),</a>
<a name="ln394">		fSize(size),</a>
<a name="ln395">		fFlags(flags)</a>
<a name="ln396">	{</a>
<a name="ln397">		Initialized();</a>
<a name="ln398">	}</a>
<a name="ln399"> </a>
<a name="ln400">	virtual void AddDump(TraceOutput&amp; out)</a>
<a name="ln401">	{</a>
<a name="ln402">		out.Print(&quot;slab memory manager unmap: %#&quot; B_PRIxADDR &quot;, size: %&quot;</a>
<a name="ln403">			B_PRIuSIZE &quot;, flags: %#&quot; B_PRIx32, fAddress, fSize, fFlags);</a>
<a name="ln404">	}</a>
<a name="ln405"> </a>
<a name="ln406">private:</a>
<a name="ln407">	addr_t	fAddress;</a>
<a name="ln408">	size_t	fSize;</a>
<a name="ln409">	uint32	fFlags;</a>
<a name="ln410">};</a>
<a name="ln411"> </a>
<a name="ln412"> </a>
<a name="ln413">//}	// namespace SlabMemoryManagerCacheTracing</a>
<a name="ln414">};	// struct MemoryManager::Tracing</a>
<a name="ln415"> </a>
<a name="ln416"> </a>
<a name="ln417">//#	define T(x)	new(std::nothrow) SlabMemoryManagerCacheTracing::x</a>
<a name="ln418">#	define T(x)	new(std::nothrow) MemoryManager::Tracing::x</a>
<a name="ln419"> </a>
<a name="ln420">#else</a>
<a name="ln421">#	define T(x)</a>
<a name="ln422">#endif	// SLAB_MEMORY_MANAGER_TRACING</a>
<a name="ln423"> </a>
<a name="ln424"> </a>
<a name="ln425">// #pragma mark - MemoryManager</a>
<a name="ln426"> </a>
<a name="ln427"> </a>
<a name="ln428">/*static*/ void</a>
<a name="ln429">MemoryManager::Init(kernel_args* args)</a>
<a name="ln430">{</a>
<a name="ln431">	mutex_init(&amp;sLock, &quot;slab memory manager&quot;);</a>
<a name="ln432">	rw_lock_init(&amp;sAreaTableLock, &quot;slab memory manager area table&quot;);</a>
<a name="ln433">	sKernelArgs = args;</a>
<a name="ln434"> </a>
<a name="ln435">	new(&amp;sFreeCompleteMetaChunks) MetaChunkList;</a>
<a name="ln436">	new(&amp;sFreeShortMetaChunks) MetaChunkList;</a>
<a name="ln437">	new(&amp;sPartialMetaChunksSmall) MetaChunkList;</a>
<a name="ln438">	new(&amp;sPartialMetaChunksMedium) MetaChunkList;</a>
<a name="ln439"> </a>
<a name="ln440">	new(&amp;sAreaTable) AreaTable;</a>
<a name="ln441">	sAreaTable.Resize(sAreaTableBuffer, sizeof(sAreaTableBuffer), true);</a>
<a name="ln442">		// A bit hacky: The table now owns the memory. Since we never resize or</a>
<a name="ln443">		// free it, that's not a problem, though.</a>
<a name="ln444"> </a>
<a name="ln445">	sFreeAreas = NULL;</a>
<a name="ln446">	sFreeAreaCount = 0;</a>
<a name="ln447">	sMaintenanceNeeded = false;</a>
<a name="ln448">}</a>
<a name="ln449"> </a>
<a name="ln450"> </a>
<a name="ln451">/*static*/ void</a>
<a name="ln452">MemoryManager::InitPostArea()</a>
<a name="ln453">{</a>
<a name="ln454">	sKernelArgs = NULL;</a>
<a name="ln455"> </a>
<a name="ln456">	// Convert all areas to actual areas. This loop might look a bit weird, but</a>
<a name="ln457">	// is necessary since creating the actual area involves memory allocations,</a>
<a name="ln458">	// which in turn can change the situation.</a>
<a name="ln459">	bool done;</a>
<a name="ln460">	do {</a>
<a name="ln461">		done = true;</a>
<a name="ln462"> </a>
<a name="ln463">		for (AreaTable::Iterator it = sAreaTable.GetIterator();</a>
<a name="ln464">				Area* area = it.Next();) {</a>
<a name="ln465">			if (area-&gt;vmArea == NULL) {</a>
<a name="ln466">				_ConvertEarlyArea(area);</a>
<a name="ln467">				done = false;</a>
<a name="ln468">				break;</a>
<a name="ln469">			}</a>
<a name="ln470">		}</a>
<a name="ln471">	} while (!done);</a>
<a name="ln472"> </a>
<a name="ln473">	// unmap and free unused pages</a>
<a name="ln474">	if (sFreeAreas != NULL) {</a>
<a name="ln475">		// Just &quot;leak&quot; all but the first of the free areas -- the VM will</a>
<a name="ln476">		// automatically free all unclaimed memory.</a>
<a name="ln477">		sFreeAreas-&gt;next = NULL;</a>
<a name="ln478">		sFreeAreaCount = 1;</a>
<a name="ln479"> </a>
<a name="ln480">		Area* area = sFreeAreas;</a>
<a name="ln481">		_ConvertEarlyArea(area);</a>
<a name="ln482">		_UnmapFreeChunksEarly(area);</a>
<a name="ln483">	}</a>
<a name="ln484"> </a>
<a name="ln485">	for (AreaTable::Iterator it = sAreaTable.GetIterator();</a>
<a name="ln486">			Area* area = it.Next();) {</a>
<a name="ln487">		_UnmapFreeChunksEarly(area);</a>
<a name="ln488">	}</a>
<a name="ln489"> </a>
<a name="ln490">	sMaintenanceNeeded = true;</a>
<a name="ln491">		// might not be necessary, but doesn't harm</a>
<a name="ln492"> </a>
<a name="ln493">	add_debugger_command_etc(&quot;slab_area&quot;, &amp;_DumpArea,</a>
<a name="ln494">		&quot;Dump information on a given slab area&quot;,</a>
<a name="ln495">		&quot;[ -c ] &lt;area&gt;\n&quot;</a>
<a name="ln496">		&quot;Dump information on a given slab area specified by its base &quot;</a>
<a name="ln497">			&quot;address.\n&quot;</a>
<a name="ln498">		&quot;If \&quot;-c\&quot; is given, the chunks of all meta chunks area printed as &quot;</a>
<a name="ln499">			&quot;well.\n&quot;, 0);</a>
<a name="ln500">	add_debugger_command_etc(&quot;slab_areas&quot;, &amp;_DumpAreas,</a>
<a name="ln501">		&quot;List all slab areas&quot;,</a>
<a name="ln502">		&quot;\n&quot;</a>
<a name="ln503">		&quot;Lists all slab areas.\n&quot;, 0);</a>
<a name="ln504">	add_debugger_command_etc(&quot;slab_meta_chunk&quot;, &amp;_DumpMetaChunk,</a>
<a name="ln505">		&quot;Dump information on a given slab meta chunk&quot;,</a>
<a name="ln506">		&quot;&lt;meta chunk&gt;\n&quot;</a>
<a name="ln507">		&quot;Dump information on a given slab meta chunk specified by its base &quot;</a>
<a name="ln508">			&quot;or object address.\n&quot;, 0);</a>
<a name="ln509">	add_debugger_command_etc(&quot;slab_meta_chunks&quot;, &amp;_DumpMetaChunks,</a>
<a name="ln510">		&quot;List all non-full slab meta chunks&quot;,</a>
<a name="ln511">		&quot;[ -c ]\n&quot;</a>
<a name="ln512">		&quot;Lists all non-full slab meta chunks.\n&quot;</a>
<a name="ln513">		&quot;If \&quot;-c\&quot; is given, the chunks of all meta chunks area printed as &quot;</a>
<a name="ln514">			&quot;well.\n&quot;, 0);</a>
<a name="ln515">	add_debugger_command_etc(&quot;slab_raw_allocations&quot;, &amp;_DumpRawAllocations,</a>
<a name="ln516">		&quot;List all raw allocations in slab areas&quot;,</a>
<a name="ln517">		&quot;\n&quot;</a>
<a name="ln518">		&quot;Lists all raw allocations in slab areas.\n&quot;, 0);</a>
<a name="ln519">}</a>
<a name="ln520"> </a>
<a name="ln521"> </a>
<a name="ln522">/*static*/ status_t</a>
<a name="ln523">MemoryManager::Allocate(ObjectCache* cache, uint32 flags, void*&amp; _pages)</a>
<a name="ln524">{</a>
<a name="ln525">	// TODO: Support CACHE_UNLOCKED_PAGES!</a>
<a name="ln526"> </a>
<a name="ln527">	T(Allocate(cache, flags));</a>
<a name="ln528"> </a>
<a name="ln529">	size_t chunkSize = cache-&gt;slab_size;</a>
<a name="ln530"> </a>
<a name="ln531">	TRACE(&quot;MemoryManager::Allocate(%p, %#&quot; B_PRIx32 &quot;): chunkSize: %&quot;</a>
<a name="ln532">		B_PRIuSIZE &quot;\n&quot;, cache, flags, chunkSize);</a>
<a name="ln533"> </a>
<a name="ln534">	MutexLocker locker(sLock);</a>
<a name="ln535"> </a>
<a name="ln536">	// allocate a chunk</a>
<a name="ln537">	MetaChunk* metaChunk;</a>
<a name="ln538">	Chunk* chunk;</a>
<a name="ln539">	status_t error = _AllocateChunks(chunkSize, 1, flags, metaChunk, chunk);</a>
<a name="ln540">	if (error != B_OK)</a>
<a name="ln541">		return error;</a>
<a name="ln542"> </a>
<a name="ln543">	// map the chunk</a>
<a name="ln544">	Area* area = metaChunk-&gt;GetArea();</a>
<a name="ln545">	addr_t chunkAddress = _ChunkAddress(metaChunk, chunk);</a>
<a name="ln546"> </a>
<a name="ln547">	locker.Unlock();</a>
<a name="ln548">	error = _MapChunk(area-&gt;vmArea, chunkAddress, chunkSize, 0, flags);</a>
<a name="ln549">	locker.Lock();</a>
<a name="ln550">	if (error != B_OK) {</a>
<a name="ln551">		// something failed -- free the chunk</a>
<a name="ln552">		_FreeChunk(area, metaChunk, chunk, chunkAddress, true, flags);</a>
<a name="ln553">		return error;</a>
<a name="ln554">	}</a>
<a name="ln555"> </a>
<a name="ln556">	chunk-&gt;reference = (addr_t)cache;</a>
<a name="ln557">	_pages = (void*)chunkAddress;</a>
<a name="ln558"> </a>
<a name="ln559">	TRACE(&quot;MemoryManager::Allocate() done: %p (meta chunk: %d, chunk %d)\n&quot;,</a>
<a name="ln560">		_pages, int(metaChunk - area-&gt;metaChunks),</a>
<a name="ln561">		int(chunk - metaChunk-&gt;chunks));</a>
<a name="ln562">	return B_OK;</a>
<a name="ln563">}</a>
<a name="ln564"> </a>
<a name="ln565"> </a>
<a name="ln566">/*static*/ void</a>
<a name="ln567">MemoryManager::Free(void* pages, uint32 flags)</a>
<a name="ln568">{</a>
<a name="ln569">	TRACE(&quot;MemoryManager::Free(%p, %#&quot; B_PRIx32 &quot;)\n&quot;, pages, flags);</a>
<a name="ln570"> </a>
<a name="ln571">	T(Free(pages, flags));</a>
<a name="ln572"> </a>
<a name="ln573">	// get the area and the meta chunk</a>
<a name="ln574">	Area* area = _AreaForAddress((addr_t)pages);</a>
<a name="ln575">	MetaChunk* metaChunk = &amp;area-&gt;metaChunks[</a>
<a name="ln576">		((addr_t)pages % SLAB_AREA_SIZE) / SLAB_CHUNK_SIZE_LARGE];</a>
<a name="ln577"> </a>
<a name="ln578">	ASSERT(metaChunk-&gt;chunkSize &gt; 0);</a>
<a name="ln579">	ASSERT((addr_t)pages &gt;= metaChunk-&gt;chunkBase);</a>
<a name="ln580">	ASSERT(((addr_t)pages % metaChunk-&gt;chunkSize) == 0);</a>
<a name="ln581"> </a>
<a name="ln582">	// get the chunk</a>
<a name="ln583">	uint16 chunkIndex = _ChunkIndexForAddress(metaChunk, (addr_t)pages);</a>
<a name="ln584">	Chunk* chunk = &amp;metaChunk-&gt;chunks[chunkIndex];</a>
<a name="ln585"> </a>
<a name="ln586">	ASSERT(chunk-&gt;next != NULL);</a>
<a name="ln587">	ASSERT(chunk-&gt;next &lt; metaChunk-&gt;chunks</a>
<a name="ln588">		|| chunk-&gt;next</a>
<a name="ln589">			&gt;= metaChunk-&gt;chunks + SLAB_SMALL_CHUNKS_PER_META_CHUNK);</a>
<a name="ln590"> </a>
<a name="ln591">	// and free it</a>
<a name="ln592">	MutexLocker locker(sLock);</a>
<a name="ln593">	_FreeChunk(area, metaChunk, chunk, (addr_t)pages, false, flags);</a>
<a name="ln594">}</a>
<a name="ln595"> </a>
<a name="ln596"> </a>
<a name="ln597">/*static*/ status_t</a>
<a name="ln598">MemoryManager::AllocateRaw(size_t size, uint32 flags, void*&amp; _pages)</a>
<a name="ln599">{</a>
<a name="ln600">#if SLAB_MEMORY_MANAGER_TRACING</a>
<a name="ln601">#if SLAB_MEMORY_MANAGER_ALLOCATION_TRACKING</a>
<a name="ln602">	AbstractTraceEntryWithStackTrace* traceEntry = T(AllocateRaw(size, flags));</a>
<a name="ln603">	size += sizeof(AllocationTrackingInfo);</a>
<a name="ln604">#else</a>
<a name="ln605">	T(AllocateRaw(size, flags));</a>
<a name="ln606">#endif</a>
<a name="ln607">#endif</a>
<a name="ln608"> </a>
<a name="ln609">	size = ROUNDUP(size, SLAB_CHUNK_SIZE_SMALL);</a>
<a name="ln610"> </a>
<a name="ln611">	TRACE(&quot;MemoryManager::AllocateRaw(%&quot; B_PRIuSIZE &quot;, %#&quot; B_PRIx32 &quot;)\n&quot;, size,</a>
<a name="ln612">		  flags);</a>
<a name="ln613"> </a>
<a name="ln614">	if (size &gt; SLAB_CHUNK_SIZE_LARGE || (flags &amp; CACHE_ALIGN_ON_SIZE) != 0) {</a>
<a name="ln615">		// Requested size greater than a large chunk or an aligned allocation.</a>
<a name="ln616">		// Allocate as an area.</a>
<a name="ln617">		if ((flags &amp; CACHE_DONT_LOCK_KERNEL_SPACE) != 0)</a>
<a name="ln618">			return B_WOULD_BLOCK;</a>
<a name="ln619"> </a>
<a name="ln620">		virtual_address_restrictions virtualRestrictions = {};</a>
<a name="ln621">		virtualRestrictions.address_specification</a>
<a name="ln622">			= (flags &amp; CACHE_ALIGN_ON_SIZE) != 0</a>
<a name="ln623">				? B_ANY_KERNEL_BLOCK_ADDRESS : B_ANY_KERNEL_ADDRESS;</a>
<a name="ln624">		physical_address_restrictions physicalRestrictions = {};</a>
<a name="ln625">		area_id area = create_area_etc(VMAddressSpace::KernelID(),</a>
<a name="ln626">			&quot;slab large raw allocation&quot;, size, B_FULL_LOCK,</a>
<a name="ln627">			B_KERNEL_READ_AREA | B_KERNEL_WRITE_AREA,</a>
<a name="ln628">			((flags &amp; CACHE_DONT_WAIT_FOR_MEMORY) != 0</a>
<a name="ln629">					? CREATE_AREA_DONT_WAIT : 0)</a>
<a name="ln630">				| CREATE_AREA_DONT_CLEAR, 0,</a>
<a name="ln631">			&amp;virtualRestrictions, &amp;physicalRestrictions, &amp;_pages);</a>
<a name="ln632"> </a>
<a name="ln633">		status_t result = area &gt;= 0 ? B_OK : area;</a>
<a name="ln634">		if (result == B_OK) {</a>
<a name="ln635">			fill_allocated_block(_pages, size);</a>
<a name="ln636">#if SLAB_MEMORY_MANAGER_ALLOCATION_TRACKING</a>
<a name="ln637">			_AddTrackingInfo(_pages, size, traceEntry);</a>
<a name="ln638">#endif</a>
<a name="ln639">		}</a>
<a name="ln640"> </a>
<a name="ln641">		return result;</a>
<a name="ln642">	}</a>
<a name="ln643"> </a>
<a name="ln644">	// determine chunk size (small or medium)</a>
<a name="ln645">	size_t chunkSize = SLAB_CHUNK_SIZE_SMALL;</a>
<a name="ln646">	uint32 chunkCount = size / SLAB_CHUNK_SIZE_SMALL;</a>
<a name="ln647"> </a>
<a name="ln648">	if (size % SLAB_CHUNK_SIZE_MEDIUM == 0) {</a>
<a name="ln649">		chunkSize = SLAB_CHUNK_SIZE_MEDIUM;</a>
<a name="ln650">		chunkCount = size / SLAB_CHUNK_SIZE_MEDIUM;</a>
<a name="ln651">	}</a>
<a name="ln652"> </a>
<a name="ln653">	MutexLocker locker(sLock);</a>
<a name="ln654"> </a>
<a name="ln655">	// allocate the chunks</a>
<a name="ln656">	MetaChunk* metaChunk;</a>
<a name="ln657">	Chunk* chunk;</a>
<a name="ln658">	status_t error = _AllocateChunks(chunkSize, chunkCount, flags, metaChunk,</a>
<a name="ln659">		chunk);</a>
<a name="ln660">	if (error != B_OK)</a>
<a name="ln661">		return error;</a>
<a name="ln662"> </a>
<a name="ln663">	// map the chunks</a>
<a name="ln664">	Area* area = metaChunk-&gt;GetArea();</a>
<a name="ln665">	addr_t chunkAddress = _ChunkAddress(metaChunk, chunk);</a>
<a name="ln666"> </a>
<a name="ln667">	locker.Unlock();</a>
<a name="ln668">	error = _MapChunk(area-&gt;vmArea, chunkAddress, size, 0, flags);</a>
<a name="ln669">	locker.Lock();</a>
<a name="ln670">	if (error != B_OK) {</a>
<a name="ln671">		// something failed -- free the chunks</a>
<a name="ln672">		for (uint32 i = 0; i &lt; chunkCount; i++)</a>
<a name="ln673">			_FreeChunk(area, metaChunk, chunk + i, chunkAddress, true, flags);</a>
<a name="ln674">		return error;</a>
<a name="ln675">	}</a>
<a name="ln676"> </a>
<a name="ln677">	chunk-&gt;reference = (addr_t)chunkAddress + size - 1;</a>
<a name="ln678">	_pages = (void*)chunkAddress;</a>
<a name="ln679"> </a>
<a name="ln680">	fill_allocated_block(_pages, size);</a>
<a name="ln681">#if SLAB_MEMORY_MANAGER_ALLOCATION_TRACKING</a>
<a name="ln682">	_AddTrackingInfo(_pages, size, traceEntry);</a>
<a name="ln683">#endif</a>
<a name="ln684"> </a>
<a name="ln685">	TRACE(&quot;MemoryManager::AllocateRaw() done: %p (meta chunk: %d, chunk %d)\n&quot;,</a>
<a name="ln686">		_pages, int(metaChunk - area-&gt;metaChunks),</a>
<a name="ln687">		int(chunk - metaChunk-&gt;chunks));</a>
<a name="ln688">	return B_OK;</a>
<a name="ln689">}</a>
<a name="ln690"> </a>
<a name="ln691"> </a>
<a name="ln692">/*static*/ ObjectCache*</a>
<a name="ln693">MemoryManager::FreeRawOrReturnCache(void* pages, uint32 flags)</a>
<a name="ln694">{</a>
<a name="ln695">	TRACE(&quot;MemoryManager::FreeRawOrReturnCache(%p, %#&quot; B_PRIx32 &quot;)\n&quot;, pages,</a>
<a name="ln696">		flags);</a>
<a name="ln697"> </a>
<a name="ln698">	T(FreeRawOrReturnCache(pages, flags));</a>
<a name="ln699"> </a>
<a name="ln700">	// get the area</a>
<a name="ln701">	addr_t areaBase = _AreaBaseAddressForAddress((addr_t)pages);</a>
<a name="ln702"> </a>
<a name="ln703">	ReadLocker readLocker(sAreaTableLock);</a>
<a name="ln704">	Area* area = sAreaTable.Lookup(areaBase);</a>
<a name="ln705">	readLocker.Unlock();</a>
<a name="ln706"> </a>
<a name="ln707">	if (area == NULL) {</a>
<a name="ln708">		// Probably a large allocation. Look up the VM area.</a>
<a name="ln709">		VMAddressSpace* addressSpace = VMAddressSpace::Kernel();</a>
<a name="ln710">		addressSpace-&gt;ReadLock();</a>
<a name="ln711">		VMArea* area = addressSpace-&gt;LookupArea((addr_t)pages);</a>
<a name="ln712">		addressSpace-&gt;ReadUnlock();</a>
<a name="ln713"> </a>
<a name="ln714">		if (area != NULL &amp;&amp; (addr_t)pages == area-&gt;Base())</a>
<a name="ln715">			delete_area(area-&gt;id);</a>
<a name="ln716">		else</a>
<a name="ln717">			panic(&quot;freeing unknown block %p from area %p&quot;, pages, area);</a>
<a name="ln718"> </a>
<a name="ln719">		return NULL;</a>
<a name="ln720">	}</a>
<a name="ln721"> </a>
<a name="ln722">	MetaChunk* metaChunk = &amp;area-&gt;metaChunks[</a>
<a name="ln723">		((addr_t)pages % SLAB_AREA_SIZE) / SLAB_CHUNK_SIZE_LARGE];</a>
<a name="ln724"> </a>
<a name="ln725">	// get the chunk</a>
<a name="ln726">	ASSERT(metaChunk-&gt;chunkSize &gt; 0);</a>
<a name="ln727">	ASSERT((addr_t)pages &gt;= metaChunk-&gt;chunkBase);</a>
<a name="ln728">	uint16 chunkIndex = _ChunkIndexForAddress(metaChunk, (addr_t)pages);</a>
<a name="ln729">	Chunk* chunk = &amp;metaChunk-&gt;chunks[chunkIndex];</a>
<a name="ln730"> </a>
<a name="ln731">	addr_t reference = chunk-&gt;reference;</a>
<a name="ln732">	if ((reference &amp; 1) == 0)</a>
<a name="ln733">		return (ObjectCache*)reference;</a>
<a name="ln734"> </a>
<a name="ln735">	// Seems we have a raw chunk allocation.</a>
<a name="ln736">	ASSERT((addr_t)pages == _ChunkAddress(metaChunk, chunk));</a>
<a name="ln737">	ASSERT(reference &gt; (addr_t)pages);</a>
<a name="ln738">	ASSERT(reference &lt;= areaBase + SLAB_AREA_SIZE - 1);</a>
<a name="ln739">	size_t size = reference - (addr_t)pages + 1;</a>
<a name="ln740">	ASSERT((size % SLAB_CHUNK_SIZE_SMALL) == 0);</a>
<a name="ln741"> </a>
<a name="ln742">	// unmap the chunks</a>
<a name="ln743">	_UnmapChunk(area-&gt;vmArea, (addr_t)pages, size, flags);</a>
<a name="ln744"> </a>
<a name="ln745">	// and free them</a>
<a name="ln746">	MutexLocker locker(sLock);</a>
<a name="ln747">	uint32 chunkCount = size / metaChunk-&gt;chunkSize;</a>
<a name="ln748">	for (uint32 i = 0; i &lt; chunkCount; i++)</a>
<a name="ln749">		_FreeChunk(area, metaChunk, chunk + i, (addr_t)pages, true, flags);</a>
<a name="ln750"> </a>
<a name="ln751">	return NULL;</a>
<a name="ln752">}</a>
<a name="ln753"> </a>
<a name="ln754"> </a>
<a name="ln755">/*static*/ size_t</a>
<a name="ln756">MemoryManager::AcceptableChunkSize(size_t size)</a>
<a name="ln757">{</a>
<a name="ln758">	if (size &lt;= SLAB_CHUNK_SIZE_SMALL)</a>
<a name="ln759">		return SLAB_CHUNK_SIZE_SMALL;</a>
<a name="ln760">	if (size &lt;= SLAB_CHUNK_SIZE_MEDIUM)</a>
<a name="ln761">		return SLAB_CHUNK_SIZE_MEDIUM;</a>
<a name="ln762">	return SLAB_CHUNK_SIZE_LARGE;</a>
<a name="ln763">}</a>
<a name="ln764"> </a>
<a name="ln765"> </a>
<a name="ln766">/*static*/ ObjectCache*</a>
<a name="ln767">MemoryManager::GetAllocationInfo(void* address, size_t&amp; _size)</a>
<a name="ln768">{</a>
<a name="ln769">	// get the area</a>
<a name="ln770">	ReadLocker readLocker(sAreaTableLock);</a>
<a name="ln771">	Area* area = sAreaTable.Lookup(_AreaBaseAddressForAddress((addr_t)address));</a>
<a name="ln772">	readLocker.Unlock();</a>
<a name="ln773"> </a>
<a name="ln774">	if (area == NULL) {</a>
<a name="ln775">		VMAddressSpace* addressSpace = VMAddressSpace::Kernel();</a>
<a name="ln776">		addressSpace-&gt;ReadLock();</a>
<a name="ln777">		VMArea* area = addressSpace-&gt;LookupArea((addr_t)address);</a>
<a name="ln778">		if (area != NULL &amp;&amp; (addr_t)address == area-&gt;Base())</a>
<a name="ln779">			_size = area-&gt;Size();</a>
<a name="ln780">		else</a>
<a name="ln781">			_size = 0;</a>
<a name="ln782">		addressSpace-&gt;ReadUnlock();</a>
<a name="ln783"> </a>
<a name="ln784">		return NULL;</a>
<a name="ln785">	}</a>
<a name="ln786"> </a>
<a name="ln787">	MetaChunk* metaChunk = &amp;area-&gt;metaChunks[</a>
<a name="ln788">		((addr_t)address % SLAB_AREA_SIZE) / SLAB_CHUNK_SIZE_LARGE];</a>
<a name="ln789"> </a>
<a name="ln790">	// get the chunk</a>
<a name="ln791">	ASSERT(metaChunk-&gt;chunkSize &gt; 0);</a>
<a name="ln792">	ASSERT((addr_t)address &gt;= metaChunk-&gt;chunkBase);</a>
<a name="ln793">	uint16 chunkIndex = _ChunkIndexForAddress(metaChunk, (addr_t)address);</a>
<a name="ln794"> </a>
<a name="ln795">	addr_t reference = metaChunk-&gt;chunks[chunkIndex].reference;</a>
<a name="ln796">	if ((reference &amp; 1) == 0) {</a>
<a name="ln797">		ObjectCache* cache = (ObjectCache*)reference;</a>
<a name="ln798">		_size = cache-&gt;object_size;</a>
<a name="ln799">		return cache;</a>
<a name="ln800">	}</a>
<a name="ln801"> </a>
<a name="ln802">	_size = reference - (addr_t)address + 1;</a>
<a name="ln803">	return NULL;</a>
<a name="ln804">}</a>
<a name="ln805"> </a>
<a name="ln806"> </a>
<a name="ln807">/*static*/ ObjectCache*</a>
<a name="ln808">MemoryManager::CacheForAddress(void* address)</a>
<a name="ln809">{</a>
<a name="ln810">	// get the area</a>
<a name="ln811">	ReadLocker readLocker(sAreaTableLock);</a>
<a name="ln812">	Area* area = sAreaTable.Lookup(_AreaBaseAddressForAddress((addr_t)address));</a>
<a name="ln813">	readLocker.Unlock();</a>
<a name="ln814"> </a>
<a name="ln815">	if (area == NULL)</a>
<a name="ln816">		return NULL;</a>
<a name="ln817"> </a>
<a name="ln818">	MetaChunk* metaChunk = &amp;area-&gt;metaChunks[</a>
<a name="ln819">		((addr_t)address % SLAB_AREA_SIZE) / SLAB_CHUNK_SIZE_LARGE];</a>
<a name="ln820"> </a>
<a name="ln821">	// get the chunk</a>
<a name="ln822">	ASSERT(metaChunk-&gt;chunkSize &gt; 0);</a>
<a name="ln823">	ASSERT((addr_t)address &gt;= metaChunk-&gt;chunkBase);</a>
<a name="ln824">	uint16 chunkIndex = _ChunkIndexForAddress(metaChunk, (addr_t)address);</a>
<a name="ln825"> </a>
<a name="ln826">	addr_t reference = metaChunk-&gt;chunks[chunkIndex].reference;</a>
<a name="ln827">	return (reference &amp; 1) == 0 ? (ObjectCache*)reference : NULL;</a>
<a name="ln828">}</a>
<a name="ln829"> </a>
<a name="ln830"> </a>
<a name="ln831">/*static*/ void</a>
<a name="ln832">MemoryManager::PerformMaintenance()</a>
<a name="ln833">{</a>
<a name="ln834">	MutexLocker locker(sLock);</a>
<a name="ln835"> </a>
<a name="ln836">	while (sMaintenanceNeeded) {</a>
<a name="ln837">		sMaintenanceNeeded = false;</a>
<a name="ln838"> </a>
<a name="ln839">		// We want to keep one or two areas as a reserve. This way we have at</a>
<a name="ln840">		// least one area to use in situations when we aren't allowed to</a>
<a name="ln841">		// allocate one and also avoid ping-pong effects.</a>
<a name="ln842">		if (sFreeAreaCount &gt; 0 &amp;&amp; sFreeAreaCount &lt;= 2)</a>
<a name="ln843">			return;</a>
<a name="ln844"> </a>
<a name="ln845">		if (sFreeAreaCount == 0) {</a>
<a name="ln846">			// try to allocate one</a>
<a name="ln847">			Area* area;</a>
<a name="ln848">			if (_AllocateArea(0, area) != B_OK)</a>
<a name="ln849">				return;</a>
<a name="ln850"> </a>
<a name="ln851">			_PushFreeArea(area);</a>
<a name="ln852">			if (sFreeAreaCount &gt; 2)</a>
<a name="ln853">				sMaintenanceNeeded = true;</a>
<a name="ln854">		} else {</a>
<a name="ln855">			// free until we only have two free ones</a>
<a name="ln856">			while (sFreeAreaCount &gt; 2)</a>
<a name="ln857">				_FreeArea(_PopFreeArea(), true, 0);</a>
<a name="ln858"> </a>
<a name="ln859">			if (sFreeAreaCount == 0)</a>
<a name="ln860">				sMaintenanceNeeded = true;</a>
<a name="ln861">		}</a>
<a name="ln862">	}</a>
<a name="ln863">}</a>
<a name="ln864"> </a>
<a name="ln865"> </a>
<a name="ln866">#if SLAB_MEMORY_MANAGER_ALLOCATION_TRACKING</a>
<a name="ln867"> </a>
<a name="ln868">/*static*/ bool</a>
<a name="ln869">MemoryManager::AnalyzeAllocationCallers(AllocationTrackingCallback&amp; callback)</a>
<a name="ln870">{</a>
<a name="ln871">	for (AreaTable::Iterator it = sAreaTable.GetIterator();</a>
<a name="ln872">			Area* area = it.Next();) {</a>
<a name="ln873">		for (int32 i = 0; i &lt; SLAB_META_CHUNKS_PER_AREA; i++) {</a>
<a name="ln874">			MetaChunk* metaChunk = area-&gt;metaChunks + i;</a>
<a name="ln875">			if (metaChunk-&gt;chunkSize == 0)</a>
<a name="ln876">				continue;</a>
<a name="ln877"> </a>
<a name="ln878">			for (uint32 k = 0; k &lt; metaChunk-&gt;chunkCount; k++) {</a>
<a name="ln879">				Chunk* chunk = metaChunk-&gt;chunks + k;</a>
<a name="ln880"> </a>
<a name="ln881">				// skip free chunks</a>
<a name="ln882">				if (_IsChunkFree(metaChunk, chunk))</a>
<a name="ln883">					continue;</a>
<a name="ln884"> </a>
<a name="ln885">				addr_t reference = chunk-&gt;reference;</a>
<a name="ln886">				if ((reference &amp; 1) == 0 || reference == 1)</a>
<a name="ln887">					continue;</a>
<a name="ln888"> </a>
<a name="ln889">				addr_t chunkAddress = _ChunkAddress(metaChunk, chunk);</a>
<a name="ln890">				size_t size = reference - chunkAddress + 1;</a>
<a name="ln891"> </a>
<a name="ln892">				if (!callback.ProcessTrackingInfo(</a>
<a name="ln893">						_TrackingInfoFor((void*)chunkAddress, size),</a>
<a name="ln894">						(void*)chunkAddress, size)) {</a>
<a name="ln895">					return false;</a>
<a name="ln896">				}</a>
<a name="ln897">			}</a>
<a name="ln898">		}</a>
<a name="ln899">	}</a>
<a name="ln900"> </a>
<a name="ln901">	return true;</a>
<a name="ln902">}</a>
<a name="ln903"> </a>
<a name="ln904">#endif	// SLAB_MEMORY_MANAGER_ALLOCATION_TRACKING</a>
<a name="ln905"> </a>
<a name="ln906"> </a>
<a name="ln907">/*static*/ ObjectCache*</a>
<a name="ln908">MemoryManager::DebugObjectCacheForAddress(void* address)</a>
<a name="ln909">{</a>
<a name="ln910">	// get the area</a>
<a name="ln911">	addr_t areaBase = _AreaBaseAddressForAddress((addr_t)address);</a>
<a name="ln912">	Area* area = sAreaTable.Lookup(areaBase);</a>
<a name="ln913"> </a>
<a name="ln914">	if (area == NULL)</a>
<a name="ln915">		return NULL;</a>
<a name="ln916"> </a>
<a name="ln917">	MetaChunk* metaChunk = &amp;area-&gt;metaChunks[</a>
<a name="ln918">		((addr_t)address % SLAB_AREA_SIZE) / SLAB_CHUNK_SIZE_LARGE];</a>
<a name="ln919"> </a>
<a name="ln920">	// get the chunk</a>
<a name="ln921">	if (metaChunk-&gt;chunkSize == 0)</a>
<a name="ln922">		return NULL;</a>
<a name="ln923">	if ((addr_t)address &lt; metaChunk-&gt;chunkBase)</a>
<a name="ln924">		return NULL;</a>
<a name="ln925"> </a>
<a name="ln926">	uint16 chunkIndex = _ChunkIndexForAddress(metaChunk, (addr_t)address);</a>
<a name="ln927">	Chunk* chunk = &amp;metaChunk-&gt;chunks[chunkIndex];</a>
<a name="ln928"> </a>
<a name="ln929">	addr_t reference = chunk-&gt;reference;</a>
<a name="ln930">	if ((reference &amp; 1) == 0)</a>
<a name="ln931">		return (ObjectCache*)reference;</a>
<a name="ln932"> </a>
<a name="ln933">	return NULL;</a>
<a name="ln934">}</a>
<a name="ln935"> </a>
<a name="ln936"> </a>
<a name="ln937">/*static*/ status_t</a>
<a name="ln938">MemoryManager::_AllocateChunks(size_t chunkSize, uint32 chunkCount,</a>
<a name="ln939">	uint32 flags, MetaChunk*&amp; _metaChunk, Chunk*&amp; _chunk)</a>
<a name="ln940">{</a>
<a name="ln941">	MetaChunkList* metaChunkList = NULL;</a>
<a name="ln942">	if (chunkSize == SLAB_CHUNK_SIZE_SMALL) {</a>
<a name="ln943">		metaChunkList = &amp;sPartialMetaChunksSmall;</a>
<a name="ln944">	} else if (chunkSize == SLAB_CHUNK_SIZE_MEDIUM) {</a>
<a name="ln945">		metaChunkList = &amp;sPartialMetaChunksMedium;</a>
<a name="ln946">	} else if (chunkSize != SLAB_CHUNK_SIZE_LARGE) {</a>
<a name="ln947">		panic(&quot;MemoryManager::_AllocateChunks(): Unsupported chunk size: %&quot;</a>
<a name="ln948">			B_PRIuSIZE, chunkSize);</a>
<a name="ln949">		return B_BAD_VALUE;</a>
<a name="ln950">	}</a>
<a name="ln951"> </a>
<a name="ln952">	if (_GetChunks(metaChunkList, chunkSize, chunkCount, _metaChunk, _chunk))</a>
<a name="ln953">		return B_OK;</a>
<a name="ln954"> </a>
<a name="ln955">	if (sFreeAreas != NULL) {</a>
<a name="ln956">		_AddArea(_PopFreeArea());</a>
<a name="ln957">		_RequestMaintenance();</a>
<a name="ln958"> </a>
<a name="ln959">		_GetChunks(metaChunkList, chunkSize, chunkCount, _metaChunk, _chunk);</a>
<a name="ln960">		return B_OK;</a>
<a name="ln961">	}</a>
<a name="ln962"> </a>
<a name="ln963">	if ((flags &amp; CACHE_DONT_LOCK_KERNEL_SPACE) != 0) {</a>
<a name="ln964">		// We can't create an area with this limitation and we must not wait for</a>
<a name="ln965">		// someone else doing that.</a>
<a name="ln966">		return B_WOULD_BLOCK;</a>
<a name="ln967">	}</a>
<a name="ln968"> </a>
<a name="ln969">	// We need to allocate a new area. Wait, if someone else is trying to do</a>
<a name="ln970">	// the same.</a>
<a name="ln971">	while (true) {</a>
<a name="ln972">		AllocationEntry* allocationEntry = NULL;</a>
<a name="ln973">		if (sAllocationEntryDontWait != NULL) {</a>
<a name="ln974">			allocationEntry = sAllocationEntryDontWait;</a>
<a name="ln975">		} else if (sAllocationEntryCanWait != NULL</a>
<a name="ln976">				&amp;&amp; (flags &amp; CACHE_DONT_WAIT_FOR_MEMORY) == 0) {</a>
<a name="ln977">			allocationEntry = sAllocationEntryCanWait;</a>
<a name="ln978">		} else</a>
<a name="ln979">			break;</a>
<a name="ln980"> </a>
<a name="ln981">		ConditionVariableEntry entry;</a>
<a name="ln982">		allocationEntry-&gt;condition.Add(&amp;entry);</a>
<a name="ln983"> </a>
<a name="ln984">		mutex_unlock(&amp;sLock);</a>
<a name="ln985">		entry.Wait();</a>
<a name="ln986">		mutex_lock(&amp;sLock);</a>
<a name="ln987"> </a>
<a name="ln988">		if (_GetChunks(metaChunkList, chunkSize, chunkCount, _metaChunk,</a>
<a name="ln989">				_chunk)) {</a>
<a name="ln990">			return B_OK;</a>
<a name="ln991">		}</a>
<a name="ln992">	}</a>
<a name="ln993"> </a>
<a name="ln994">	// prepare the allocation entry others can wait on</a>
<a name="ln995">	AllocationEntry*&amp; allocationEntry</a>
<a name="ln996">		= (flags &amp; CACHE_DONT_WAIT_FOR_MEMORY) != 0</a>
<a name="ln997">			? sAllocationEntryDontWait : sAllocationEntryCanWait;</a>
<a name="ln998"> </a>
<a name="ln999">	AllocationEntry myResizeEntry;</a>
<a name="ln1000">	allocationEntry = &amp;myResizeEntry;</a>
<a name="ln1001">	allocationEntry-&gt;condition.Init(metaChunkList, &quot;wait for slab area&quot;);</a>
<a name="ln1002">	allocationEntry-&gt;thread = find_thread(NULL);</a>
<a name="ln1003"> </a>
<a name="ln1004">	Area* area;</a>
<a name="ln1005">	status_t error = _AllocateArea(flags, area);</a>
<a name="ln1006"> </a>
<a name="ln1007">	allocationEntry-&gt;condition.NotifyAll();</a>
<a name="ln1008">	allocationEntry = NULL;</a>
<a name="ln1009"> </a>
<a name="ln1010">	if (error != B_OK)</a>
<a name="ln1011">		return error;</a>
<a name="ln1012"> </a>
<a name="ln1013">	// Try again to get a meta chunk. Something might have been freed in the</a>
<a name="ln1014">	// meantime. We can free the area in this case.</a>
<a name="ln1015">	if (_GetChunks(metaChunkList, chunkSize, chunkCount, _metaChunk, _chunk)) {</a>
<a name="ln1016">		_FreeArea(area, true, flags);</a>
<a name="ln1017">		return B_OK;</a>
<a name="ln1018">	}</a>
<a name="ln1019"> </a>
<a name="ln1020">	_AddArea(area);</a>
<a name="ln1021">	_GetChunks(metaChunkList, chunkSize, chunkCount, _metaChunk, _chunk);</a>
<a name="ln1022">	return B_OK;</a>
<a name="ln1023">}</a>
<a name="ln1024"> </a>
<a name="ln1025"> </a>
<a name="ln1026">/*static*/ bool</a>
<a name="ln1027">MemoryManager::_GetChunks(MetaChunkList* metaChunkList, size_t chunkSize,</a>
<a name="ln1028">	uint32 chunkCount, MetaChunk*&amp; _metaChunk, Chunk*&amp; _chunk)</a>
<a name="ln1029">{</a>
<a name="ln1030">	// the common and less complicated special case</a>
<a name="ln1031">	if (chunkCount == 1)</a>
<a name="ln1032">		return _GetChunk(metaChunkList, chunkSize, _metaChunk, _chunk);</a>
<a name="ln1033"> </a>
<a name="ln1034">	ASSERT(metaChunkList != NULL);</a>
<a name="ln1035"> </a>
<a name="ln1036">	// Iterate through the partial meta chunk list and try to find a free</a>
<a name="ln1037">	// range that is large enough.</a>
<a name="ln1038">	MetaChunk* metaChunk = NULL;</a>
<a name="ln1039">	for (MetaChunkList::Iterator it = metaChunkList-&gt;GetIterator();</a>
<a name="ln1040">			(metaChunk = it.Next()) != NULL;) {</a>
<a name="ln1041">		if (metaChunk-&gt;firstFreeChunk + chunkCount - 1</a>
<a name="ln1042">				&lt;= metaChunk-&gt;lastFreeChunk) {</a>
<a name="ln1043">			break;</a>
<a name="ln1044">		}</a>
<a name="ln1045">	}</a>
<a name="ln1046"> </a>
<a name="ln1047">	if (metaChunk == NULL) {</a>
<a name="ln1048">		// try to get a free meta chunk</a>
<a name="ln1049">		if ((SLAB_CHUNK_SIZE_LARGE - SLAB_AREA_STRUCT_OFFSET - kAreaAdminSize)</a>
<a name="ln1050">				/ chunkSize &gt;= chunkCount) {</a>
<a name="ln1051">			metaChunk = sFreeShortMetaChunks.RemoveHead();</a>
<a name="ln1052">		}</a>
<a name="ln1053">		if (metaChunk == NULL)</a>
<a name="ln1054">			metaChunk = sFreeCompleteMetaChunks.RemoveHead();</a>
<a name="ln1055"> </a>
<a name="ln1056">		if (metaChunk == NULL)</a>
<a name="ln1057">			return false;</a>
<a name="ln1058"> </a>
<a name="ln1059">		metaChunkList-&gt;Add(metaChunk);</a>
<a name="ln1060">		metaChunk-&gt;GetArea()-&gt;usedMetaChunkCount++;</a>
<a name="ln1061">		_PrepareMetaChunk(metaChunk, chunkSize);</a>
<a name="ln1062"> </a>
<a name="ln1063">		T(AllocateMetaChunk(metaChunk));</a>
<a name="ln1064">	}</a>
<a name="ln1065"> </a>
<a name="ln1066">	// pull the chunks out of the free list</a>
<a name="ln1067">	Chunk* firstChunk = metaChunk-&gt;chunks + metaChunk-&gt;firstFreeChunk;</a>
<a name="ln1068">	Chunk* lastChunk = firstChunk + (chunkCount - 1);</a>
<a name="ln1069">	Chunk** chunkPointer = &amp;metaChunk-&gt;freeChunks;</a>
<a name="ln1070">	uint32 remainingChunks = chunkCount;</a>
<a name="ln1071">	while (remainingChunks &gt; 0) {</a>
<a name="ln1072">		ASSERT_PRINT(chunkPointer, &quot;remaining: %&quot; B_PRIu32 &quot;/%&quot; B_PRIu32</a>
<a name="ln1073">			&quot;, area: %p, meta chunk: %&quot; B_PRIdSSIZE &quot;\n&quot;, remainingChunks,</a>
<a name="ln1074">			chunkCount, metaChunk-&gt;GetArea(),</a>
<a name="ln1075">			metaChunk - metaChunk-&gt;GetArea()-&gt;metaChunks);</a>
<a name="ln1076">		Chunk* chunk = *chunkPointer;</a>
<a name="ln1077">		if (chunk &gt;= firstChunk &amp;&amp; chunk &lt;= lastChunk) {</a>
<a name="ln1078">			*chunkPointer = chunk-&gt;next;</a>
<a name="ln1079">			chunk-&gt;reference = 1;</a>
<a name="ln1080">			remainingChunks--;</a>
<a name="ln1081">		} else</a>
<a name="ln1082">			chunkPointer = &amp;chunk-&gt;next;</a>
<a name="ln1083">	}</a>
<a name="ln1084"> </a>
<a name="ln1085">	// allocate the chunks</a>
<a name="ln1086">	metaChunk-&gt;usedChunkCount += chunkCount;</a>
<a name="ln1087">	if (metaChunk-&gt;usedChunkCount == metaChunk-&gt;chunkCount) {</a>
<a name="ln1088">		// meta chunk is full now -- remove it from its list</a>
<a name="ln1089">		if (metaChunkList != NULL)</a>
<a name="ln1090">			metaChunkList-&gt;Remove(metaChunk);</a>
<a name="ln1091">	}</a>
<a name="ln1092"> </a>
<a name="ln1093">	// update the free range</a>
<a name="ln1094">	metaChunk-&gt;firstFreeChunk += chunkCount;</a>
<a name="ln1095"> </a>
<a name="ln1096">	PARANOID_CHECKS_ONLY(_CheckMetaChunk(metaChunk));</a>
<a name="ln1097"> </a>
<a name="ln1098">	_chunk = firstChunk;</a>
<a name="ln1099">	_metaChunk = metaChunk;</a>
<a name="ln1100"> </a>
<a name="ln1101">	T(AllocateChunks(chunkSize, chunkCount, metaChunk, firstChunk));</a>
<a name="ln1102"> </a>
<a name="ln1103">	return true;</a>
<a name="ln1104">}</a>
<a name="ln1105"> </a>
<a name="ln1106"> </a>
<a name="ln1107">/*static*/ bool</a>
<a name="ln1108">MemoryManager::_GetChunk(MetaChunkList* metaChunkList, size_t chunkSize,</a>
<a name="ln1109">	MetaChunk*&amp; _metaChunk, Chunk*&amp; _chunk)</a>
<a name="ln1110">{</a>
<a name="ln1111">	MetaChunk* metaChunk = metaChunkList != NULL</a>
<a name="ln1112">		? metaChunkList-&gt;Head() : NULL;</a>
<a name="ln1113">	if (metaChunk == NULL) {</a>
<a name="ln1114">		// no partial meta chunk -- maybe there's a free one</a>
<a name="ln1115">		if (chunkSize == SLAB_CHUNK_SIZE_LARGE) {</a>
<a name="ln1116">			metaChunk = sFreeCompleteMetaChunks.RemoveHead();</a>
<a name="ln1117">		} else {</a>
<a name="ln1118">			metaChunk = sFreeShortMetaChunks.RemoveHead();</a>
<a name="ln1119">			if (metaChunk == NULL)</a>
<a name="ln1120">				metaChunk = sFreeCompleteMetaChunks.RemoveHead();</a>
<a name="ln1121">			if (metaChunk != NULL)</a>
<a name="ln1122">				metaChunkList-&gt;Add(metaChunk);</a>
<a name="ln1123">		}</a>
<a name="ln1124"> </a>
<a name="ln1125">		if (metaChunk == NULL)</a>
<a name="ln1126">			return false;</a>
<a name="ln1127"> </a>
<a name="ln1128">		metaChunk-&gt;GetArea()-&gt;usedMetaChunkCount++;</a>
<a name="ln1129">		_PrepareMetaChunk(metaChunk, chunkSize);</a>
<a name="ln1130"> </a>
<a name="ln1131">		T(AllocateMetaChunk(metaChunk));</a>
<a name="ln1132">	}</a>
<a name="ln1133"> </a>
<a name="ln1134">	// allocate the chunk</a>
<a name="ln1135">	if (++metaChunk-&gt;usedChunkCount == metaChunk-&gt;chunkCount) {</a>
<a name="ln1136">		// meta chunk is full now -- remove it from its list</a>
<a name="ln1137">		if (metaChunkList != NULL)</a>
<a name="ln1138">			metaChunkList-&gt;Remove(metaChunk);</a>
<a name="ln1139">	}</a>
<a name="ln1140"> </a>
<a name="ln1141">	_chunk = _pop(metaChunk-&gt;freeChunks);</a>
<a name="ln1142">	_metaChunk = metaChunk;</a>
<a name="ln1143"> </a>
<a name="ln1144">	_chunk-&gt;reference = 1;</a>
<a name="ln1145"> </a>
<a name="ln1146">	// update the free range</a>
<a name="ln1147">	uint32 chunkIndex = _chunk - metaChunk-&gt;chunks;</a>
<a name="ln1148">	if (chunkIndex &gt;= metaChunk-&gt;firstFreeChunk</a>
<a name="ln1149">			&amp;&amp; chunkIndex &lt;= metaChunk-&gt;lastFreeChunk) {</a>
<a name="ln1150">		if (chunkIndex - metaChunk-&gt;firstFreeChunk</a>
<a name="ln1151">				&lt;= metaChunk-&gt;lastFreeChunk - chunkIndex) {</a>
<a name="ln1152">			metaChunk-&gt;firstFreeChunk = chunkIndex + 1;</a>
<a name="ln1153">		} else</a>
<a name="ln1154">			metaChunk-&gt;lastFreeChunk = chunkIndex - 1;</a>
<a name="ln1155">	}</a>
<a name="ln1156"> </a>
<a name="ln1157">	PARANOID_CHECKS_ONLY(_CheckMetaChunk(metaChunk));</a>
<a name="ln1158"> </a>
<a name="ln1159">	T(AllocateChunk(chunkSize, metaChunk, _chunk));</a>
<a name="ln1160"> </a>
<a name="ln1161">	return true;</a>
<a name="ln1162">}</a>
<a name="ln1163"> </a>
<a name="ln1164"> </a>
<a name="ln1165">/*static*/ void</a>
<a name="ln1166">MemoryManager::_FreeChunk(Area* area, MetaChunk* metaChunk, Chunk* chunk,</a>
<a name="ln1167">	addr_t chunkAddress, bool alreadyUnmapped, uint32 flags)</a>
<a name="ln1168">{</a>
<a name="ln1169">	// unmap the chunk</a>
<a name="ln1170">	if (!alreadyUnmapped) {</a>
<a name="ln1171">		mutex_unlock(&amp;sLock);</a>
<a name="ln1172">		_UnmapChunk(area-&gt;vmArea, chunkAddress, metaChunk-&gt;chunkSize, flags);</a>
<a name="ln1173">		mutex_lock(&amp;sLock);</a>
<a name="ln1174">	}</a>
<a name="ln1175"> </a>
<a name="ln1176">	T(FreeChunk(metaChunk, chunk));</a>
<a name="ln1177"> </a>
<a name="ln1178">	_push(metaChunk-&gt;freeChunks, chunk);</a>
<a name="ln1179"> </a>
<a name="ln1180">	uint32 chunkIndex = chunk - metaChunk-&gt;chunks;</a>
<a name="ln1181"> </a>
<a name="ln1182">	// free the meta chunk, if it is unused now</a>
<a name="ln1183">	PARANOID_CHECKS_ONLY(bool areaDeleted = false;)</a>
<a name="ln1184">	ASSERT(metaChunk-&gt;usedChunkCount &gt; 0);</a>
<a name="ln1185">	if (--metaChunk-&gt;usedChunkCount == 0) {</a>
<a name="ln1186">		T(FreeMetaChunk(metaChunk));</a>
<a name="ln1187"> </a>
<a name="ln1188">		// remove from partial meta chunk list</a>
<a name="ln1189">		if (metaChunk-&gt;chunkSize == SLAB_CHUNK_SIZE_SMALL)</a>
<a name="ln1190">			sPartialMetaChunksSmall.Remove(metaChunk);</a>
<a name="ln1191">		else if (metaChunk-&gt;chunkSize == SLAB_CHUNK_SIZE_MEDIUM)</a>
<a name="ln1192">			sPartialMetaChunksMedium.Remove(metaChunk);</a>
<a name="ln1193"> </a>
<a name="ln1194">		// mark empty</a>
<a name="ln1195">		metaChunk-&gt;chunkSize = 0;</a>
<a name="ln1196"> </a>
<a name="ln1197">		// add to free list</a>
<a name="ln1198">		if (metaChunk == area-&gt;metaChunks)</a>
<a name="ln1199">			sFreeShortMetaChunks.Add(metaChunk, false);</a>
<a name="ln1200">		else</a>
<a name="ln1201">			sFreeCompleteMetaChunks.Add(metaChunk, false);</a>
<a name="ln1202"> </a>
<a name="ln1203">		// free the area, if it is unused now</a>
<a name="ln1204">		ASSERT(area-&gt;usedMetaChunkCount &gt; 0);</a>
<a name="ln1205">		if (--area-&gt;usedMetaChunkCount == 0) {</a>
<a name="ln1206">			_FreeArea(area, false, flags);</a>
<a name="ln1207">			PARANOID_CHECKS_ONLY(areaDeleted = true;)</a>
<a name="ln1208">		}</a>
<a name="ln1209">	} else if (metaChunk-&gt;usedChunkCount == metaChunk-&gt;chunkCount - 1) {</a>
<a name="ln1210">		// the meta chunk was full before -- add it back to its partial chunk</a>
<a name="ln1211">		// list</a>
<a name="ln1212">		if (metaChunk-&gt;chunkSize == SLAB_CHUNK_SIZE_SMALL)</a>
<a name="ln1213">			sPartialMetaChunksSmall.Add(metaChunk, false);</a>
<a name="ln1214">		else if (metaChunk-&gt;chunkSize == SLAB_CHUNK_SIZE_MEDIUM)</a>
<a name="ln1215">			sPartialMetaChunksMedium.Add(metaChunk, false);</a>
<a name="ln1216"> </a>
<a name="ln1217">		metaChunk-&gt;firstFreeChunk = chunkIndex;</a>
<a name="ln1218">		metaChunk-&gt;lastFreeChunk = chunkIndex;</a>
<a name="ln1219">	} else {</a>
<a name="ln1220">		// extend the free range, if the chunk adjoins</a>
<a name="ln1221">		if (chunkIndex + 1 == metaChunk-&gt;firstFreeChunk) {</a>
<a name="ln1222">			uint32 firstFree = chunkIndex;</a>
<a name="ln1223">			for (; firstFree &gt; 0; firstFree--) {</a>
<a name="ln1224">				Chunk* previousChunk = &amp;metaChunk-&gt;chunks[firstFree - 1];</a>
<a name="ln1225">				if (!_IsChunkFree(metaChunk, previousChunk))</a>
<a name="ln1226">					break;</a>
<a name="ln1227">			}</a>
<a name="ln1228">			metaChunk-&gt;firstFreeChunk = firstFree;</a>
<a name="ln1229">		} else if (chunkIndex == (uint32)metaChunk-&gt;lastFreeChunk + 1) {</a>
<a name="ln1230">			uint32 lastFree = chunkIndex;</a>
<a name="ln1231">			for (; lastFree + 1 &lt; metaChunk-&gt;chunkCount; lastFree++) {</a>
<a name="ln1232">				Chunk* nextChunk = &amp;metaChunk-&gt;chunks[lastFree + 1];</a>
<a name="ln1233">				if (!_IsChunkFree(metaChunk, nextChunk))</a>
<a name="ln1234">					break;</a>
<a name="ln1235">			}</a>
<a name="ln1236">			metaChunk-&gt;lastFreeChunk = lastFree;</a>
<a name="ln1237">		}</a>
<a name="ln1238">	}</a>
<a name="ln1239"> </a>
<a name="ln1240">	PARANOID_CHECKS_ONLY(</a>
<a name="ln1241">		if (!areaDeleted)</a>
<a name="ln1242">			_CheckMetaChunk(metaChunk);</a>
<a name="ln1243">	)</a>
<a name="ln1244">}</a>
<a name="ln1245"> </a>
<a name="ln1246"> </a>
<a name="ln1247">/*static*/ void</a>
<a name="ln1248">MemoryManager::_PrepareMetaChunk(MetaChunk* metaChunk, size_t chunkSize)</a>
<a name="ln1249">{</a>
<a name="ln1250">	Area* area = metaChunk-&gt;GetArea();</a>
<a name="ln1251"> </a>
<a name="ln1252">	if (metaChunk == area-&gt;metaChunks) {</a>
<a name="ln1253">		// the first chunk is shorter</a>
<a name="ln1254">		size_t unusableSize = ROUNDUP(SLAB_AREA_STRUCT_OFFSET + kAreaAdminSize,</a>
<a name="ln1255">			chunkSize);</a>
<a name="ln1256">		metaChunk-&gt;chunkBase = area-&gt;BaseAddress() + unusableSize;</a>
<a name="ln1257">		metaChunk-&gt;totalSize = SLAB_CHUNK_SIZE_LARGE - unusableSize;</a>
<a name="ln1258">	}</a>
<a name="ln1259"> </a>
<a name="ln1260">	metaChunk-&gt;chunkSize = chunkSize;</a>
<a name="ln1261">	metaChunk-&gt;chunkCount = metaChunk-&gt;totalSize / chunkSize;</a>
<a name="ln1262">	metaChunk-&gt;usedChunkCount = 0;</a>
<a name="ln1263"> </a>
<a name="ln1264">	metaChunk-&gt;freeChunks = NULL;</a>
<a name="ln1265">	for (int32 i = metaChunk-&gt;chunkCount - 1; i &gt;= 0; i--)</a>
<a name="ln1266">		_push(metaChunk-&gt;freeChunks, metaChunk-&gt;chunks + i);</a>
<a name="ln1267"> </a>
<a name="ln1268">	metaChunk-&gt;firstFreeChunk = 0;</a>
<a name="ln1269">	metaChunk-&gt;lastFreeChunk = metaChunk-&gt;chunkCount - 1;</a>
<a name="ln1270"> </a>
<a name="ln1271">	PARANOID_CHECKS_ONLY(_CheckMetaChunk(metaChunk));</a>
<a name="ln1272">}</a>
<a name="ln1273"> </a>
<a name="ln1274"> </a>
<a name="ln1275">/*static*/ void</a>
<a name="ln1276">MemoryManager::_AddArea(Area* area)</a>
<a name="ln1277">{</a>
<a name="ln1278">	T(AddArea(area));</a>
<a name="ln1279"> </a>
<a name="ln1280">	// add the area to the hash table</a>
<a name="ln1281">	WriteLocker writeLocker(sAreaTableLock);</a>
<a name="ln1282">	sAreaTable.InsertUnchecked(area);</a>
<a name="ln1283">	writeLocker.Unlock();</a>
<a name="ln1284"> </a>
<a name="ln1285">	// add the area's meta chunks to the free lists</a>
<a name="ln1286">	sFreeShortMetaChunks.Add(&amp;area-&gt;metaChunks[0]);</a>
<a name="ln1287">	for (int32 i = 1; i &lt; SLAB_META_CHUNKS_PER_AREA; i++)</a>
<a name="ln1288">		sFreeCompleteMetaChunks.Add(&amp;area-&gt;metaChunks[i]);</a>
<a name="ln1289">}</a>
<a name="ln1290"> </a>
<a name="ln1291"> </a>
<a name="ln1292">/*static*/ status_t</a>
<a name="ln1293">MemoryManager::_AllocateArea(uint32 flags, Area*&amp; _area)</a>
<a name="ln1294">{</a>
<a name="ln1295">	TRACE(&quot;MemoryManager::_AllocateArea(%#&quot; B_PRIx32 &quot;)\n&quot;, flags);</a>
<a name="ln1296"> </a>
<a name="ln1297">	ASSERT((flags &amp; CACHE_DONT_LOCK_KERNEL_SPACE) == 0);</a>
<a name="ln1298"> </a>
<a name="ln1299">	mutex_unlock(&amp;sLock);</a>
<a name="ln1300"> </a>
<a name="ln1301">	size_t pagesNeededToMap = 0;</a>
<a name="ln1302">	void* areaBase;</a>
<a name="ln1303">	Area* area;</a>
<a name="ln1304">	VMArea* vmArea = NULL;</a>
<a name="ln1305"> </a>
<a name="ln1306">	if (sKernelArgs == NULL) {</a>
<a name="ln1307">		// create an area</a>
<a name="ln1308">		uint32 areaCreationFlags = (flags &amp; CACHE_PRIORITY_VIP) != 0</a>
<a name="ln1309">			? CREATE_AREA_PRIORITY_VIP : 0;</a>
<a name="ln1310">		area_id areaID = vm_create_null_area(B_SYSTEM_TEAM, kSlabAreaName,</a>
<a name="ln1311">			&amp;areaBase, B_ANY_KERNEL_BLOCK_ADDRESS, SLAB_AREA_SIZE,</a>
<a name="ln1312">			areaCreationFlags);</a>
<a name="ln1313">		if (areaID &lt; 0) {</a>
<a name="ln1314">			mutex_lock(&amp;sLock);</a>
<a name="ln1315">			return areaID;</a>
<a name="ln1316">		}</a>
<a name="ln1317"> </a>
<a name="ln1318">		area = _AreaForAddress((addr_t)areaBase);</a>
<a name="ln1319"> </a>
<a name="ln1320">		// map the memory for the administrative structure</a>
<a name="ln1321">		VMAddressSpace* addressSpace = VMAddressSpace::Kernel();</a>
<a name="ln1322">		VMTranslationMap* translationMap = addressSpace-&gt;TranslationMap();</a>
<a name="ln1323"> </a>
<a name="ln1324">		pagesNeededToMap = translationMap-&gt;MaxPagesNeededToMap(</a>
<a name="ln1325">			(addr_t)area, (addr_t)areaBase + SLAB_AREA_SIZE - 1);</a>
<a name="ln1326"> </a>
<a name="ln1327">		vmArea = VMAreaHash::Lookup(areaID);</a>
<a name="ln1328">		status_t error = _MapChunk(vmArea, (addr_t)area, kAreaAdminSize,</a>
<a name="ln1329">			pagesNeededToMap, flags);</a>
<a name="ln1330">		if (error != B_OK) {</a>
<a name="ln1331">			delete_area(areaID);</a>
<a name="ln1332">			mutex_lock(&amp;sLock);</a>
<a name="ln1333">			return error;</a>
<a name="ln1334">		}</a>
<a name="ln1335"> </a>
<a name="ln1336">		dprintf(&quot;slab memory manager: created area %p (%&quot; B_PRId32 &quot;)\n&quot;, area,</a>
<a name="ln1337">			areaID);</a>
<a name="ln1338">	} else {</a>
<a name="ln1339">		// no areas yet -- allocate raw memory</a>
<a name="ln1340">		areaBase = (void*)vm_allocate_early(sKernelArgs, SLAB_AREA_SIZE,</a>
<a name="ln1341">			SLAB_AREA_SIZE, B_KERNEL_READ_AREA | B_KERNEL_WRITE_AREA,</a>
<a name="ln1342">			SLAB_AREA_SIZE);</a>
<a name="ln1343">		if (areaBase == NULL) {</a>
<a name="ln1344">			mutex_lock(&amp;sLock);</a>
<a name="ln1345">			return B_NO_MEMORY;</a>
<a name="ln1346">		}</a>
<a name="ln1347">		area = _AreaForAddress((addr_t)areaBase);</a>
<a name="ln1348"> </a>
<a name="ln1349">		TRACE(&quot;MemoryManager::_AllocateArea(): allocated early area %p\n&quot;,</a>
<a name="ln1350">			area);</a>
<a name="ln1351">	}</a>
<a name="ln1352"> </a>
<a name="ln1353">	// init the area structure</a>
<a name="ln1354">	area-&gt;vmArea = vmArea;</a>
<a name="ln1355">	area-&gt;reserved_memory_for_mapping = pagesNeededToMap * B_PAGE_SIZE;</a>
<a name="ln1356">	area-&gt;usedMetaChunkCount = 0;</a>
<a name="ln1357">	area-&gt;fullyMapped = vmArea == NULL;</a>
<a name="ln1358"> </a>
<a name="ln1359">	// init the meta chunks</a>
<a name="ln1360">	for (int32 i = 0; i &lt; SLAB_META_CHUNKS_PER_AREA; i++) {</a>
<a name="ln1361">		MetaChunk* metaChunk = area-&gt;metaChunks + i;</a>
<a name="ln1362">		metaChunk-&gt;chunkSize = 0;</a>
<a name="ln1363">		metaChunk-&gt;chunkBase = (addr_t)areaBase + i * SLAB_CHUNK_SIZE_LARGE;</a>
<a name="ln1364">		metaChunk-&gt;totalSize = SLAB_CHUNK_SIZE_LARGE;</a>
<a name="ln1365">			// Note: chunkBase and totalSize aren't correct for the first</a>
<a name="ln1366">			// meta chunk. They will be set in _PrepareMetaChunk().</a>
<a name="ln1367">		metaChunk-&gt;chunkCount = 0;</a>
<a name="ln1368">		metaChunk-&gt;usedChunkCount = 0;</a>
<a name="ln1369">		metaChunk-&gt;freeChunks = NULL;</a>
<a name="ln1370">	}</a>
<a name="ln1371"> </a>
<a name="ln1372">	mutex_lock(&amp;sLock);</a>
<a name="ln1373">	_area = area;</a>
<a name="ln1374"> </a>
<a name="ln1375">	T(AllocateArea(area, flags));</a>
<a name="ln1376"> </a>
<a name="ln1377">	return B_OK;</a>
<a name="ln1378">}</a>
<a name="ln1379"> </a>
<a name="ln1380"> </a>
<a name="ln1381">/*static*/ void</a>
<a name="ln1382">MemoryManager::_FreeArea(Area* area, bool areaRemoved, uint32 flags)</a>
<a name="ln1383">{</a>
<a name="ln1384">	TRACE(&quot;MemoryManager::_FreeArea(%p, %#&quot; B_PRIx32 &quot;)\n&quot;, area, flags);</a>
<a name="ln1385"> </a>
<a name="ln1386">	T(FreeArea(area, areaRemoved, flags));</a>
<a name="ln1387"> </a>
<a name="ln1388">	ASSERT(area-&gt;usedMetaChunkCount == 0);</a>
<a name="ln1389"> </a>
<a name="ln1390">	if (!areaRemoved) {</a>
<a name="ln1391">		// remove the area's meta chunks from the free lists</a>
<a name="ln1392">		ASSERT(area-&gt;metaChunks[0].usedChunkCount == 0);</a>
<a name="ln1393">		sFreeShortMetaChunks.Remove(&amp;area-&gt;metaChunks[0]);</a>
<a name="ln1394"> </a>
<a name="ln1395">		for (int32 i = 1; i &lt; SLAB_META_CHUNKS_PER_AREA; i++) {</a>
<a name="ln1396">			ASSERT(area-&gt;metaChunks[i].usedChunkCount == 0);</a>
<a name="ln1397">			sFreeCompleteMetaChunks.Remove(&amp;area-&gt;metaChunks[i]);</a>
<a name="ln1398">		}</a>
<a name="ln1399"> </a>
<a name="ln1400">		// remove the area from the hash table</a>
<a name="ln1401">		WriteLocker writeLocker(sAreaTableLock);</a>
<a name="ln1402">		sAreaTable.RemoveUnchecked(area);</a>
<a name="ln1403">		writeLocker.Unlock();</a>
<a name="ln1404">	}</a>
<a name="ln1405"> </a>
<a name="ln1406">	// We want to keep one or two free areas as a reserve.</a>
<a name="ln1407">	if (sFreeAreaCount &lt;= 1) {</a>
<a name="ln1408">		_PushFreeArea(area);</a>
<a name="ln1409">		return;</a>
<a name="ln1410">	}</a>
<a name="ln1411"> </a>
<a name="ln1412">	if (area-&gt;vmArea == NULL || (flags &amp; CACHE_DONT_LOCK_KERNEL_SPACE) != 0) {</a>
<a name="ln1413">		// This is either early in the boot process or we aren't allowed to</a>
<a name="ln1414">		// delete the area now.</a>
<a name="ln1415">		_PushFreeArea(area);</a>
<a name="ln1416">		_RequestMaintenance();</a>
<a name="ln1417">		return;</a>
<a name="ln1418">	}</a>
<a name="ln1419"> </a>
<a name="ln1420">	mutex_unlock(&amp;sLock);</a>
<a name="ln1421"> </a>
<a name="ln1422">	dprintf(&quot;slab memory manager: deleting area %p (%&quot; B_PRId32 &quot;)\n&quot;, area,</a>
<a name="ln1423">		area-&gt;vmArea-&gt;id);</a>
<a name="ln1424"> </a>
<a name="ln1425">	size_t memoryToUnreserve = area-&gt;reserved_memory_for_mapping;</a>
<a name="ln1426">	delete_area(area-&gt;vmArea-&gt;id);</a>
<a name="ln1427">	vm_unreserve_memory(memoryToUnreserve);</a>
<a name="ln1428"> </a>
<a name="ln1429">	mutex_lock(&amp;sLock);</a>
<a name="ln1430">}</a>
<a name="ln1431"> </a>
<a name="ln1432"> </a>
<a name="ln1433">/*static*/ status_t</a>
<a name="ln1434">MemoryManager::_MapChunk(VMArea* vmArea, addr_t address, size_t size,</a>
<a name="ln1435">	size_t reserveAdditionalMemory, uint32 flags)</a>
<a name="ln1436">{</a>
<a name="ln1437">	TRACE(&quot;MemoryManager::_MapChunk(%p, %#&quot; B_PRIxADDR &quot;, %#&quot; B_PRIxSIZE</a>
<a name="ln1438">		&quot;)\n&quot;, vmArea, address, size);</a>
<a name="ln1439"> </a>
<a name="ln1440">	T(Map(address, size, flags));</a>
<a name="ln1441"> </a>
<a name="ln1442">	if (vmArea == NULL) {</a>
<a name="ln1443">		// everything is mapped anyway</a>
<a name="ln1444">		return B_OK;</a>
<a name="ln1445">	}</a>
<a name="ln1446"> </a>
<a name="ln1447">	VMAddressSpace* addressSpace = VMAddressSpace::Kernel();</a>
<a name="ln1448">	VMTranslationMap* translationMap = addressSpace-&gt;TranslationMap();</a>
<a name="ln1449"> </a>
<a name="ln1450">	// reserve memory for the chunk</a>
<a name="ln1451">	int priority = (flags &amp; CACHE_PRIORITY_VIP) != 0</a>
<a name="ln1452">		? VM_PRIORITY_VIP : VM_PRIORITY_SYSTEM;</a>
<a name="ln1453">	size_t reservedMemory = size + reserveAdditionalMemory;</a>
<a name="ln1454">	status_t error = vm_try_reserve_memory(size, priority,</a>
<a name="ln1455">		(flags &amp; CACHE_DONT_WAIT_FOR_MEMORY) != 0 ? 0 : 1000000);</a>
<a name="ln1456">	if (error != B_OK)</a>
<a name="ln1457">		return error;</a>
<a name="ln1458"> </a>
<a name="ln1459">	// reserve the pages we need now</a>
<a name="ln1460">	size_t reservedPages = size / B_PAGE_SIZE</a>
<a name="ln1461">		+ translationMap-&gt;MaxPagesNeededToMap(address, address + size - 1);</a>
<a name="ln1462">	vm_page_reservation reservation;</a>
<a name="ln1463">	if ((flags &amp; CACHE_DONT_WAIT_FOR_MEMORY) != 0) {</a>
<a name="ln1464">		if (!vm_page_try_reserve_pages(&amp;reservation, reservedPages, priority)) {</a>
<a name="ln1465">			vm_unreserve_memory(reservedMemory);</a>
<a name="ln1466">			return B_WOULD_BLOCK;</a>
<a name="ln1467">		}</a>
<a name="ln1468">	} else</a>
<a name="ln1469">		vm_page_reserve_pages(&amp;reservation, reservedPages, priority);</a>
<a name="ln1470"> </a>
<a name="ln1471">	VMCache* cache = vm_area_get_locked_cache(vmArea);</a>
<a name="ln1472"> </a>
<a name="ln1473">	// map the pages</a>
<a name="ln1474">	translationMap-&gt;Lock();</a>
<a name="ln1475"> </a>
<a name="ln1476">	addr_t areaOffset = address - vmArea-&gt;Base();</a>
<a name="ln1477">	addr_t endAreaOffset = areaOffset + size;</a>
<a name="ln1478">	for (size_t offset = areaOffset; offset &lt; endAreaOffset;</a>
<a name="ln1479">			offset += B_PAGE_SIZE) {</a>
<a name="ln1480">		vm_page* page = vm_page_allocate_page(&amp;reservation, PAGE_STATE_WIRED);</a>
<a name="ln1481">		cache-&gt;InsertPage(page, offset);</a>
<a name="ln1482"> </a>
<a name="ln1483">		page-&gt;IncrementWiredCount();</a>
<a name="ln1484">		atomic_add(&amp;gMappedPagesCount, 1);</a>
<a name="ln1485">		DEBUG_PAGE_ACCESS_END(page);</a>
<a name="ln1486"> </a>
<a name="ln1487">		translationMap-&gt;Map(vmArea-&gt;Base() + offset,</a>
<a name="ln1488">			page-&gt;physical_page_number * B_PAGE_SIZE,</a>
<a name="ln1489">			B_KERNEL_READ_AREA | B_KERNEL_WRITE_AREA,</a>
<a name="ln1490">			vmArea-&gt;MemoryType(), &amp;reservation);</a>
<a name="ln1491">	}</a>
<a name="ln1492"> </a>
<a name="ln1493">	translationMap-&gt;Unlock();</a>
<a name="ln1494"> </a>
<a name="ln1495">	cache-&gt;ReleaseRefAndUnlock();</a>
<a name="ln1496"> </a>
<a name="ln1497">	vm_page_unreserve_pages(&amp;reservation);</a>
<a name="ln1498"> </a>
<a name="ln1499">	return B_OK;</a>
<a name="ln1500">}</a>
<a name="ln1501"> </a>
<a name="ln1502"> </a>
<a name="ln1503">/*static*/ status_t</a>
<a name="ln1504">MemoryManager::_UnmapChunk(VMArea* vmArea, addr_t address, size_t size,</a>
<a name="ln1505">	uint32 flags)</a>
<a name="ln1506">{</a>
<a name="ln1507">	T(Unmap(address, size, flags));</a>
<a name="ln1508"> </a>
<a name="ln1509">	if (vmArea == NULL)</a>
<a name="ln1510">		return B_ERROR;</a>
<a name="ln1511"> </a>
<a name="ln1512">	TRACE(&quot;MemoryManager::_UnmapChunk(%p, %#&quot; B_PRIxADDR &quot;, %#&quot; B_PRIxSIZE</a>
<a name="ln1513">		&quot;)\n&quot;, vmArea, address, size);</a>
<a name="ln1514"> </a>
<a name="ln1515">	VMAddressSpace* addressSpace = VMAddressSpace::Kernel();</a>
<a name="ln1516">	VMTranslationMap* translationMap = addressSpace-&gt;TranslationMap();</a>
<a name="ln1517">	VMCache* cache = vm_area_get_locked_cache(vmArea);</a>
<a name="ln1518"> </a>
<a name="ln1519">	// unmap the pages</a>
<a name="ln1520">	translationMap-&gt;Lock();</a>
<a name="ln1521">	translationMap-&gt;Unmap(address, address + size - 1);</a>
<a name="ln1522">	atomic_add(&amp;gMappedPagesCount, -(size / B_PAGE_SIZE));</a>
<a name="ln1523">	translationMap-&gt;Unlock();</a>
<a name="ln1524"> </a>
<a name="ln1525">	// free the pages</a>
<a name="ln1526">	addr_t areaPageOffset = (address - vmArea-&gt;Base()) / B_PAGE_SIZE;</a>
<a name="ln1527">	addr_t areaPageEndOffset = areaPageOffset + size / B_PAGE_SIZE;</a>
<a name="ln1528">	VMCachePagesTree::Iterator it = cache-&gt;pages.GetIterator(</a>
<a name="ln1529">		areaPageOffset, true, true);</a>
<a name="ln1530">	while (vm_page* page = it.Next()) {</a>
<a name="ln1531">		if (page-&gt;cache_offset &gt;= areaPageEndOffset)</a>
<a name="ln1532">			break;</a>
<a name="ln1533"> </a>
<a name="ln1534">		DEBUG_PAGE_ACCESS_START(page);</a>
<a name="ln1535"> </a>
<a name="ln1536">		page-&gt;DecrementWiredCount();</a>
<a name="ln1537"> </a>
<a name="ln1538">		cache-&gt;RemovePage(page);</a>
<a name="ln1539">			// the iterator is remove-safe</a>
<a name="ln1540">		vm_page_free(cache, page);</a>
<a name="ln1541">	}</a>
<a name="ln1542"> </a>
<a name="ln1543">	cache-&gt;ReleaseRefAndUnlock();</a>
<a name="ln1544"> </a>
<a name="ln1545">	vm_unreserve_memory(size);</a>
<a name="ln1546"> </a>
<a name="ln1547">	return B_OK;</a>
<a name="ln1548">}</a>
<a name="ln1549"> </a>
<a name="ln1550"> </a>
<a name="ln1551">/*static*/ void</a>
<a name="ln1552">MemoryManager::_UnmapFreeChunksEarly(Area* area)</a>
<a name="ln1553">{</a>
<a name="ln1554">	if (!area-&gt;fullyMapped)</a>
<a name="ln1555">		return;</a>
<a name="ln1556"> </a>
<a name="ln1557">	TRACE(&quot;MemoryManager::_UnmapFreeChunksEarly(%p)\n&quot;, area);</a>
<a name="ln1558"> </a>
<a name="ln1559">	// unmap the space before the Area structure</a>
<a name="ln1560">	#if SLAB_AREA_STRUCT_OFFSET &gt; 0</a>
<a name="ln1561">		_UnmapChunk(area-&gt;vmArea, area-&gt;BaseAddress(), SLAB_AREA_STRUCT_OFFSET,</a>
<a name="ln1562">			0);</a>
<a name="ln1563">	#endif</a>
<a name="ln1564"> </a>
<a name="ln1565">	for (int32 i = 0; i &lt; SLAB_META_CHUNKS_PER_AREA; i++) {</a>
<a name="ln1566">		MetaChunk* metaChunk = area-&gt;metaChunks + i;</a>
<a name="ln1567">		if (metaChunk-&gt;chunkSize == 0) {</a>
<a name="ln1568">			// meta chunk is free -- unmap it completely</a>
<a name="ln1569">			if (i == 0) {</a>
<a name="ln1570">				_UnmapChunk(area-&gt;vmArea, (addr_t)area + kAreaAdminSize,</a>
<a name="ln1571">					SLAB_CHUNK_SIZE_LARGE - kAreaAdminSize, 0);</a>
<a name="ln1572">			} else {</a>
<a name="ln1573">				_UnmapChunk(area-&gt;vmArea,</a>
<a name="ln1574">					area-&gt;BaseAddress() + i * SLAB_CHUNK_SIZE_LARGE,</a>
<a name="ln1575">					SLAB_CHUNK_SIZE_LARGE, 0);</a>
<a name="ln1576">			}</a>
<a name="ln1577">		} else {</a>
<a name="ln1578">			// unmap free chunks</a>
<a name="ln1579">			for (Chunk* chunk = metaChunk-&gt;freeChunks; chunk != NULL;</a>
<a name="ln1580">					chunk = chunk-&gt;next) {</a>
<a name="ln1581">				_UnmapChunk(area-&gt;vmArea, _ChunkAddress(metaChunk, chunk),</a>
<a name="ln1582">					metaChunk-&gt;chunkSize, 0);</a>
<a name="ln1583">			}</a>
<a name="ln1584"> </a>
<a name="ln1585">			// The first meta chunk might have space before its first chunk.</a>
<a name="ln1586">			if (i == 0) {</a>
<a name="ln1587">				addr_t unusedStart = (addr_t)area + kAreaAdminSize;</a>
<a name="ln1588">				if (unusedStart &lt; metaChunk-&gt;chunkBase) {</a>
<a name="ln1589">					_UnmapChunk(area-&gt;vmArea, unusedStart,</a>
<a name="ln1590">						metaChunk-&gt;chunkBase - unusedStart, 0);</a>
<a name="ln1591">				}</a>
<a name="ln1592">			}</a>
<a name="ln1593">		}</a>
<a name="ln1594">	}</a>
<a name="ln1595"> </a>
<a name="ln1596">	area-&gt;fullyMapped = false;</a>
<a name="ln1597">}</a>
<a name="ln1598"> </a>
<a name="ln1599"> </a>
<a name="ln1600">/*static*/ void</a>
<a name="ln1601">MemoryManager::_ConvertEarlyArea(Area* area)</a>
<a name="ln1602">{</a>
<a name="ln1603">	void* address = (void*)area-&gt;BaseAddress();</a>
<a name="ln1604">	area_id areaID = create_area(kSlabAreaName, &amp;address, B_EXACT_ADDRESS,</a>
<a name="ln1605">		SLAB_AREA_SIZE, B_ALREADY_WIRED,</a>
<a name="ln1606">		B_KERNEL_READ_AREA | B_KERNEL_WRITE_AREA);</a>
<a name="ln1607">	if (areaID &lt; 0)</a>
<a name="ln1608">		panic(&quot;out of memory&quot;);</a>
<a name="ln1609"> </a>
<a name="ln1610">	area-&gt;vmArea = VMAreaHash::Lookup(areaID);</a>
<a name="ln1611">}</a>
<a name="ln1612"> </a>
<a name="ln1613"> </a>
<a name="ln1614">/*static*/ void</a>
<a name="ln1615">MemoryManager::_RequestMaintenance()</a>
<a name="ln1616">{</a>
<a name="ln1617">	if ((sFreeAreaCount &gt; 0 &amp;&amp; sFreeAreaCount &lt;= 2) || sMaintenanceNeeded)</a>
<a name="ln1618">		return;</a>
<a name="ln1619"> </a>
<a name="ln1620">	sMaintenanceNeeded = true;</a>
<a name="ln1621">	request_memory_manager_maintenance();</a>
<a name="ln1622">}</a>
<a name="ln1623"> </a>
<a name="ln1624"> </a>
<a name="ln1625">/*static*/ bool</a>
<a name="ln1626">MemoryManager::_IsChunkInFreeList(const MetaChunk* metaChunk,</a>
<a name="ln1627">	const Chunk* chunk)</a>
<a name="ln1628">{</a>
<a name="ln1629">	Chunk* freeChunk = metaChunk-&gt;freeChunks;</a>
<a name="ln1630">	while (freeChunk != NULL) {</a>
<a name="ln1631">		if (freeChunk == chunk)</a>
<a name="ln1632">			return true;</a>
<a name="ln1633">		freeChunk = freeChunk-&gt;next;</a>
<a name="ln1634">	}</a>
<a name="ln1635"> </a>
<a name="ln1636">	return false;</a>
<a name="ln1637">}</a>
<a name="ln1638"> </a>
<a name="ln1639"> </a>
<a name="ln1640">#if DEBUG_SLAB_MEMORY_MANAGER_PARANOID_CHECKS</a>
<a name="ln1641"> </a>
<a name="ln1642">/*static*/ void</a>
<a name="ln1643">MemoryManager::_CheckMetaChunk(MetaChunk* metaChunk)</a>
<a name="ln1644">{</a>
<a name="ln1645">	Area* area = metaChunk-&gt;GetArea();</a>
<a name="ln1646">	int32 metaChunkIndex = metaChunk - area-&gt;metaChunks;</a>
<a name="ln1647">	if (metaChunkIndex &lt; 0 || metaChunkIndex &gt;= SLAB_META_CHUNKS_PER_AREA) {</a>
<a name="ln1648">		panic(&quot;invalid meta chunk %p!&quot;, metaChunk);</a>
<a name="ln1649">		return;</a>
<a name="ln1650">	}</a>
<a name="ln1651"> </a>
<a name="ln1652">	switch (metaChunk-&gt;chunkSize) {</a>
<a name="ln1653">		case 0:</a>
<a name="ln1654">			// unused</a>
<a name="ln1655">			return;</a>
<a name="ln1656">		case SLAB_CHUNK_SIZE_SMALL:</a>
<a name="ln1657">		case SLAB_CHUNK_SIZE_MEDIUM:</a>
<a name="ln1658">		case SLAB_CHUNK_SIZE_LARGE:</a>
<a name="ln1659">			break;</a>
<a name="ln1660">		default:</a>
<a name="ln1661">			panic(&quot;meta chunk %p has invalid chunk size: %&quot; B_PRIuSIZE,</a>
<a name="ln1662">				metaChunk, metaChunk-&gt;chunkSize);</a>
<a name="ln1663">			return;</a>
<a name="ln1664">	}</a>
<a name="ln1665"> </a>
<a name="ln1666">	if (metaChunk-&gt;totalSize &gt; SLAB_CHUNK_SIZE_LARGE) {</a>
<a name="ln1667">		panic(&quot;meta chunk %p has invalid total size: %&quot; B_PRIuSIZE,</a>
<a name="ln1668">			metaChunk, metaChunk-&gt;totalSize);</a>
<a name="ln1669">		return;</a>
<a name="ln1670">	}</a>
<a name="ln1671"> </a>
<a name="ln1672">	addr_t expectedBase = area-&gt;BaseAddress()</a>
<a name="ln1673">		+ metaChunkIndex * SLAB_CHUNK_SIZE_LARGE;</a>
<a name="ln1674">	if (metaChunk-&gt;chunkBase &lt; expectedBase</a>
<a name="ln1675">		|| metaChunk-&gt;chunkBase - expectedBase + metaChunk-&gt;totalSize</a>
<a name="ln1676">			&gt; SLAB_CHUNK_SIZE_LARGE) {</a>
<a name="ln1677">		panic(&quot;meta chunk %p has invalid base address: %&quot; B_PRIxADDR, metaChunk,</a>
<a name="ln1678">			metaChunk-&gt;chunkBase);</a>
<a name="ln1679">		return;</a>
<a name="ln1680">	}</a>
<a name="ln1681"> </a>
<a name="ln1682">	if (metaChunk-&gt;chunkCount != metaChunk-&gt;totalSize / metaChunk-&gt;chunkSize) {</a>
<a name="ln1683">		panic(&quot;meta chunk %p has invalid chunk count: %u&quot;, metaChunk,</a>
<a name="ln1684">			metaChunk-&gt;chunkCount);</a>
<a name="ln1685">		return;</a>
<a name="ln1686">	}</a>
<a name="ln1687"> </a>
<a name="ln1688">	if (metaChunk-&gt;usedChunkCount &gt; metaChunk-&gt;chunkCount) {</a>
<a name="ln1689">		panic(&quot;meta chunk %p has invalid unused chunk count: %u&quot;, metaChunk,</a>
<a name="ln1690">			metaChunk-&gt;usedChunkCount);</a>
<a name="ln1691">		return;</a>
<a name="ln1692">	}</a>
<a name="ln1693"> </a>
<a name="ln1694">	if (metaChunk-&gt;firstFreeChunk &gt; metaChunk-&gt;chunkCount) {</a>
<a name="ln1695">		panic(&quot;meta chunk %p has invalid first free chunk: %u&quot;, metaChunk,</a>
<a name="ln1696">			metaChunk-&gt;firstFreeChunk);</a>
<a name="ln1697">		return;</a>
<a name="ln1698">	}</a>
<a name="ln1699"> </a>
<a name="ln1700">	if (metaChunk-&gt;lastFreeChunk &gt;= metaChunk-&gt;chunkCount) {</a>
<a name="ln1701">		panic(&quot;meta chunk %p has invalid last free chunk: %u&quot;, metaChunk,</a>
<a name="ln1702">			metaChunk-&gt;lastFreeChunk);</a>
<a name="ln1703">		return;</a>
<a name="ln1704">	}</a>
<a name="ln1705"> </a>
<a name="ln1706">	// check free list for structural sanity</a>
<a name="ln1707">	uint32 freeChunks = 0;</a>
<a name="ln1708">	for (Chunk* chunk = metaChunk-&gt;freeChunks; chunk != NULL;</a>
<a name="ln1709">			chunk = chunk-&gt;next) {</a>
<a name="ln1710">		if ((addr_t)chunk % sizeof(Chunk) != 0 || chunk &lt; metaChunk-&gt;chunks</a>
<a name="ln1711">			|| chunk &gt;= metaChunk-&gt;chunks + metaChunk-&gt;chunkCount) {</a>
<a name="ln1712">			panic(&quot;meta chunk %p has invalid element in free list, chunk: %p&quot;,</a>
<a name="ln1713">				metaChunk, chunk);</a>
<a name="ln1714">			return;</a>
<a name="ln1715">		}</a>
<a name="ln1716"> </a>
<a name="ln1717">		if (++freeChunks &gt; metaChunk-&gt;chunkCount) {</a>
<a name="ln1718">			panic(&quot;meta chunk %p has cyclic free list&quot;, metaChunk);</a>
<a name="ln1719">			return;</a>
<a name="ln1720">		}</a>
<a name="ln1721">	}</a>
<a name="ln1722"> </a>
<a name="ln1723">	if (freeChunks + metaChunk-&gt;usedChunkCount &gt; metaChunk-&gt;chunkCount) {</a>
<a name="ln1724">		panic(&quot;meta chunk %p has mismatching free/used chunk counts: total: &quot;</a>
<a name="ln1725">			&quot;%u, used: %u, free: %&quot; B_PRIu32, metaChunk, metaChunk-&gt;chunkCount,</a>
<a name="ln1726">			metaChunk-&gt;usedChunkCount, freeChunks);</a>
<a name="ln1727">		return;</a>
<a name="ln1728">	}</a>
<a name="ln1729"> </a>
<a name="ln1730">	// count used chunks by looking at their reference/next field</a>
<a name="ln1731">	uint32 usedChunks = 0;</a>
<a name="ln1732">	for (uint32 i = 0; i &lt; metaChunk-&gt;chunkCount; i++) {</a>
<a name="ln1733">		if (!_IsChunkFree(metaChunk, metaChunk-&gt;chunks + i))</a>
<a name="ln1734">			usedChunks++;</a>
<a name="ln1735">	}</a>
<a name="ln1736"> </a>
<a name="ln1737">	if (usedChunks != metaChunk-&gt;usedChunkCount) {</a>
<a name="ln1738">		panic(&quot;meta chunk %p has used chunks that appear free: total: &quot;</a>
<a name="ln1739">			&quot;%u, used: %u, appearing used: %&quot; B_PRIu32, metaChunk,</a>
<a name="ln1740">			metaChunk-&gt;chunkCount, metaChunk-&gt;usedChunkCount, usedChunks);</a>
<a name="ln1741">		return;</a>
<a name="ln1742">	}</a>
<a name="ln1743"> </a>
<a name="ln1744">	// check free range</a>
<a name="ln1745">	for (uint32 i = metaChunk-&gt;firstFreeChunk; i &lt; metaChunk-&gt;lastFreeChunk;</a>
<a name="ln1746">			i++) {</a>
<a name="ln1747">		if (!_IsChunkFree(metaChunk, metaChunk-&gt;chunks + i)) {</a>
<a name="ln1748">			panic(&quot;meta chunk %p has used chunk in free range, chunk: %p (%&quot;</a>
<a name="ln1749">				B_PRIu32 &quot;, free range: %u - %u)&quot;, metaChunk,</a>
<a name="ln1750">				metaChunk-&gt;chunks + i, i, metaChunk-&gt;firstFreeChunk,</a>
<a name="ln1751">				metaChunk-&gt;lastFreeChunk);</a>
<a name="ln1752">			return;</a>
<a name="ln1753">		}</a>
<a name="ln1754">	}</a>
<a name="ln1755">}</a>
<a name="ln1756"> </a>
<a name="ln1757">#endif	// DEBUG_SLAB_MEMORY_MANAGER_PARANOID_CHECKS</a>
<a name="ln1758"> </a>
<a name="ln1759"> </a>
<a name="ln1760">/*static*/ int</a>
<a name="ln1761">MemoryManager::_DumpRawAllocations(int argc, char** argv)</a>
<a name="ln1762">{</a>
<a name="ln1763">	kprintf(&quot;%-*s    meta chunk  chunk  %-*s    size (KB)\n&quot;,</a>
<a name="ln1764">		B_PRINTF_POINTER_WIDTH, &quot;area&quot;, B_PRINTF_POINTER_WIDTH, &quot;base&quot;);</a>
<a name="ln1765"> </a>
<a name="ln1766">	size_t totalSize = 0;</a>
<a name="ln1767"> </a>
<a name="ln1768">	for (AreaTable::Iterator it = sAreaTable.GetIterator();</a>
<a name="ln1769">			Area* area = it.Next();) {</a>
<a name="ln1770">		for (int32 i = 0; i &lt; SLAB_META_CHUNKS_PER_AREA; i++) {</a>
<a name="ln1771">			MetaChunk* metaChunk = area-&gt;metaChunks + i;</a>
<a name="ln1772">			if (metaChunk-&gt;chunkSize == 0)</a>
<a name="ln1773">				continue;</a>
<a name="ln1774">			for (uint32 k = 0; k &lt; metaChunk-&gt;chunkCount; k++) {</a>
<a name="ln1775">				Chunk* chunk = metaChunk-&gt;chunks + k;</a>
<a name="ln1776"> </a>
<a name="ln1777">				// skip free chunks</a>
<a name="ln1778">				if (_IsChunkFree(metaChunk, chunk))</a>
<a name="ln1779">					continue;</a>
<a name="ln1780"> </a>
<a name="ln1781">				addr_t reference = chunk-&gt;reference;</a>
<a name="ln1782">				if ((reference &amp; 1) == 0 || reference == 1)</a>
<a name="ln1783">					continue;</a>
<a name="ln1784"> </a>
<a name="ln1785">				addr_t chunkAddress = _ChunkAddress(metaChunk, chunk);</a>
<a name="ln1786">				size_t size = reference - chunkAddress + 1;</a>
<a name="ln1787">				totalSize += size;</a>
<a name="ln1788"> </a>
<a name="ln1789">				kprintf(&quot;%p  %10&quot; B_PRId32 &quot;  %5&quot; B_PRIu32 &quot;  %p  %9&quot;</a>
<a name="ln1790">					B_PRIuSIZE &quot;\n&quot;, area, i, k, (void*)chunkAddress,</a>
<a name="ln1791">					size / 1024);</a>
<a name="ln1792">			}</a>
<a name="ln1793">		}</a>
<a name="ln1794">	}</a>
<a name="ln1795"> </a>
<a name="ln1796">	kprintf(&quot;total:%*s%9&quot; B_PRIuSIZE &quot;\n&quot;, (2 * B_PRINTF_POINTER_WIDTH) + 21,</a>
<a name="ln1797">		&quot;&quot;, totalSize / 1024);</a>
<a name="ln1798"> </a>
<a name="ln1799">	return 0;</a>
<a name="ln1800">}</a>
<a name="ln1801"> </a>
<a name="ln1802"> </a>
<a name="ln1803">/*static*/ void</a>
<a name="ln1804">MemoryManager::_PrintMetaChunkTableHeader(bool printChunks)</a>
<a name="ln1805">{</a>
<a name="ln1806">	if (printChunks)</a>
<a name="ln1807">		kprintf(&quot;chunk        base       cache  object size  cache name\n&quot;);</a>
<a name="ln1808">	else</a>
<a name="ln1809">		kprintf(&quot;chunk        base\n&quot;);</a>
<a name="ln1810">}</a>
<a name="ln1811"> </a>
<a name="ln1812">/*static*/ void</a>
<a name="ln1813">MemoryManager::_DumpMetaChunk(MetaChunk* metaChunk, bool printChunks,</a>
<a name="ln1814">	bool printHeader)</a>
<a name="ln1815">{</a>
<a name="ln1816">	if (printHeader)</a>
<a name="ln1817">		_PrintMetaChunkTableHeader(printChunks);</a>
<a name="ln1818"> </a>
<a name="ln1819">	const char* type = &quot;empty&quot;;</a>
<a name="ln1820">	if (metaChunk-&gt;chunkSize != 0) {</a>
<a name="ln1821">		switch (metaChunk-&gt;chunkSize) {</a>
<a name="ln1822">			case SLAB_CHUNK_SIZE_SMALL:</a>
<a name="ln1823">				type = &quot;small&quot;;</a>
<a name="ln1824">				break;</a>
<a name="ln1825">			case SLAB_CHUNK_SIZE_MEDIUM:</a>
<a name="ln1826">				type = &quot;medium&quot;;</a>
<a name="ln1827">				break;</a>
<a name="ln1828">			case SLAB_CHUNK_SIZE_LARGE:</a>
<a name="ln1829">				type = &quot;large&quot;;</a>
<a name="ln1830">				break;</a>
<a name="ln1831">		}</a>
<a name="ln1832">	}</a>
<a name="ln1833"> </a>
<a name="ln1834">	int metaChunkIndex = metaChunk - metaChunk-&gt;GetArea()-&gt;metaChunks;</a>
<a name="ln1835">	kprintf(&quot;%5d  %p  --- %6s meta chunk&quot;, metaChunkIndex,</a>
<a name="ln1836">		(void*)metaChunk-&gt;chunkBase, type);</a>
<a name="ln1837">	if (metaChunk-&gt;chunkSize != 0) {</a>
<a name="ln1838">		kprintf(&quot;: %4u/%4u used, %-4u-%4u free ------------\n&quot;,</a>
<a name="ln1839">			metaChunk-&gt;usedChunkCount, metaChunk-&gt;chunkCount,</a>
<a name="ln1840">			metaChunk-&gt;firstFreeChunk, metaChunk-&gt;lastFreeChunk);</a>
<a name="ln1841">	} else</a>
<a name="ln1842">		kprintf(&quot; --------------------------------------------\n&quot;);</a>
<a name="ln1843"> </a>
<a name="ln1844">	if (metaChunk-&gt;chunkSize == 0 || !printChunks)</a>
<a name="ln1845">		return;</a>
<a name="ln1846"> </a>
<a name="ln1847">	for (uint32 i = 0; i &lt; metaChunk-&gt;chunkCount; i++) {</a>
<a name="ln1848">		Chunk* chunk = metaChunk-&gt;chunks + i;</a>
<a name="ln1849"> </a>
<a name="ln1850">		// skip free chunks</a>
<a name="ln1851">		if (_IsChunkFree(metaChunk, chunk)) {</a>
<a name="ln1852">			if (!_IsChunkInFreeList(metaChunk, chunk)) {</a>
<a name="ln1853">				kprintf(&quot;%5&quot; B_PRIu32 &quot;  %p  appears free, but isn't in free &quot;</a>
<a name="ln1854">					&quot;list!\n&quot;, i, (void*)_ChunkAddress(metaChunk, chunk));</a>
<a name="ln1855">			}</a>
<a name="ln1856"> </a>
<a name="ln1857">			continue;</a>
<a name="ln1858">		}</a>
<a name="ln1859"> </a>
<a name="ln1860">		addr_t reference = chunk-&gt;reference;</a>
<a name="ln1861">		if ((reference &amp; 1) == 0) {</a>
<a name="ln1862">			ObjectCache* cache = (ObjectCache*)reference;</a>
<a name="ln1863">			kprintf(&quot;%5&quot; B_PRIu32 &quot;  %p  %p  %11&quot; B_PRIuSIZE &quot;  %s\n&quot;, i,</a>
<a name="ln1864">				(void*)_ChunkAddress(metaChunk, chunk), cache,</a>
<a name="ln1865">				cache != NULL ? cache-&gt;object_size : 0,</a>
<a name="ln1866">				cache != NULL ? cache-&gt;name : &quot;&quot;);</a>
<a name="ln1867">		} else if (reference != 1) {</a>
<a name="ln1868">			kprintf(&quot;%5&quot; B_PRIu32 &quot;  %p  raw allocation up to %p\n&quot;, i,</a>
<a name="ln1869">				(void*)_ChunkAddress(metaChunk, chunk), (void*)reference);</a>
<a name="ln1870">		}</a>
<a name="ln1871">	}</a>
<a name="ln1872">}</a>
<a name="ln1873"> </a>
<a name="ln1874"> </a>
<a name="ln1875">/*static*/ int</a>
<a name="ln1876">MemoryManager::_DumpMetaChunk(int argc, char** argv)</a>
<a name="ln1877">{</a>
<a name="ln1878">	if (argc != 2) {</a>
<a name="ln1879">		print_debugger_command_usage(argv[0]);</a>
<a name="ln1880">		return 0;</a>
<a name="ln1881">	}</a>
<a name="ln1882"> </a>
<a name="ln1883">	uint64 address;</a>
<a name="ln1884">	if (!evaluate_debug_expression(argv[1], &amp;address, false))</a>
<a name="ln1885">		return 0;</a>
<a name="ln1886"> </a>
<a name="ln1887">	Area* area = _AreaForAddress(address);</a>
<a name="ln1888"> </a>
<a name="ln1889">	MetaChunk* metaChunk;</a>
<a name="ln1890">	if ((addr_t)address &gt;= (addr_t)area-&gt;metaChunks</a>
<a name="ln1891">		&amp;&amp; (addr_t)address</a>
<a name="ln1892">			&lt; (addr_t)(area-&gt;metaChunks + SLAB_META_CHUNKS_PER_AREA)) {</a>
<a name="ln1893">		metaChunk = (MetaChunk*)(addr_t)address;</a>
<a name="ln1894">	} else {</a>
<a name="ln1895">		metaChunk = area-&gt;metaChunks</a>
<a name="ln1896">			+ (address % SLAB_AREA_SIZE) / SLAB_CHUNK_SIZE_LARGE;</a>
<a name="ln1897">	}</a>
<a name="ln1898"> </a>
<a name="ln1899">	_DumpMetaChunk(metaChunk, true, true);</a>
<a name="ln1900"> </a>
<a name="ln1901">	return 0;</a>
<a name="ln1902">}</a>
<a name="ln1903"> </a>
<a name="ln1904"> </a>
<a name="ln1905">/*static*/ void</a>
<a name="ln1906">MemoryManager::_DumpMetaChunks(const char* name, MetaChunkList&amp; metaChunkList,</a>
<a name="ln1907">	bool printChunks)</a>
<a name="ln1908">{</a>
<a name="ln1909">	kprintf(&quot;%s:\n&quot;, name);</a>
<a name="ln1910"> </a>
<a name="ln1911">	for (MetaChunkList::Iterator it = metaChunkList.GetIterator();</a>
<a name="ln1912">			MetaChunk* metaChunk = it.Next();) {</a>
<a name="ln1913">		_DumpMetaChunk(metaChunk, printChunks, false);</a>
<a name="ln1914">	}</a>
<a name="ln1915">}</a>
<a name="ln1916"> </a>
<a name="ln1917"> </a>
<a name="ln1918">/*static*/ int</a>
<a name="ln1919">MemoryManager::_DumpMetaChunks(int argc, char** argv)</a>
<a name="ln1920">{</a>
<a name="ln1921">	bool printChunks = argc &gt; 1 &amp;&amp; strcmp(argv[1], &quot;-c&quot;) == 0;</a>
<a name="ln1922"> </a>
<a name="ln1923">	_PrintMetaChunkTableHeader(printChunks);</a>
<a name="ln1924">	_DumpMetaChunks(&quot;free complete&quot;, sFreeCompleteMetaChunks, printChunks);</a>
<a name="ln1925">	_DumpMetaChunks(&quot;free short&quot;, sFreeShortMetaChunks, printChunks);</a>
<a name="ln1926">	_DumpMetaChunks(&quot;partial small&quot;, sPartialMetaChunksSmall, printChunks);</a>
<a name="ln1927">	_DumpMetaChunks(&quot;partial medium&quot;, sPartialMetaChunksMedium, printChunks);</a>
<a name="ln1928"> </a>
<a name="ln1929">	return 0;</a>
<a name="ln1930">}</a>
<a name="ln1931"> </a>
<a name="ln1932"> </a>
<a name="ln1933">/*static*/ int</a>
<a name="ln1934">MemoryManager::_DumpArea(int argc, char** argv)</a>
<a name="ln1935">{</a>
<a name="ln1936">	bool printChunks = false;</a>
<a name="ln1937"> </a>
<a name="ln1938">	int argi = 1;</a>
<a name="ln1939">	while (argi &lt; argc) {</a>
<a name="ln1940">		if (argv[argi][0] != '-')</a>
<a name="ln1941">			break;</a>
<a name="ln1942">		const char* arg = argv[argi++];</a>
<a name="ln1943">		if (strcmp(arg, &quot;-c&quot;) == 0) {</a>
<a name="ln1944">			printChunks = true;</a>
<a name="ln1945">		} else {</a>
<a name="ln1946">			print_debugger_command_usage(argv[0]);</a>
<a name="ln1947">			return 0;</a>
<a name="ln1948">		}</a>
<a name="ln1949">	}</a>
<a name="ln1950"> </a>
<a name="ln1951">	if (argi + 1 != argc) {</a>
<a name="ln1952">		print_debugger_command_usage(argv[0]);</a>
<a name="ln1953">		return 0;</a>
<a name="ln1954">	}</a>
<a name="ln1955"> </a>
<a name="ln1956">	uint64 address;</a>
<a name="ln1957">	if (!evaluate_debug_expression(argv[argi], &amp;address, false))</a>
<a name="ln1958">		return 0;</a>
<a name="ln1959"> </a>
<a name="ln1960">	Area* area = _AreaForAddress((addr_t)address);</a>
<a name="ln1961"> </a>
<a name="ln1962">	for (uint32 k = 0; k &lt; SLAB_META_CHUNKS_PER_AREA; k++) {</a>
<a name="ln1963">		MetaChunk* metaChunk = area-&gt;metaChunks + k;</a>
<a name="ln1964">		_DumpMetaChunk(metaChunk, printChunks, k == 0);</a>
<a name="ln1965">	}</a>
<a name="ln1966"> </a>
<a name="ln1967">	return 0;</a>
<a name="ln1968">}</a>
<a name="ln1969"> </a>
<a name="ln1970"> </a>
<a name="ln1971">/*static*/ int</a>
<a name="ln1972">MemoryManager::_DumpAreas(int argc, char** argv)</a>
<a name="ln1973">{</a>
<a name="ln1974">	kprintf(&quot;  %*s    %*s   meta      small   medium  large\n&quot;,</a>
<a name="ln1975">		B_PRINTF_POINTER_WIDTH, &quot;base&quot;, B_PRINTF_POINTER_WIDTH, &quot;area&quot;);</a>
<a name="ln1976"> </a>
<a name="ln1977">	size_t totalTotalSmall = 0;</a>
<a name="ln1978">	size_t totalUsedSmall = 0;</a>
<a name="ln1979">	size_t totalTotalMedium = 0;</a>
<a name="ln1980">	size_t totalUsedMedium = 0;</a>
<a name="ln1981">	size_t totalUsedLarge = 0;</a>
<a name="ln1982">	uint32 areaCount = 0;</a>
<a name="ln1983"> </a>
<a name="ln1984">	for (AreaTable::Iterator it = sAreaTable.GetIterator();</a>
<a name="ln1985">			Area* area = it.Next();) {</a>
<a name="ln1986">		areaCount++;</a>
<a name="ln1987"> </a>
<a name="ln1988">		// sum up the free/used counts for the chunk sizes</a>
<a name="ln1989">		int totalSmall = 0;</a>
<a name="ln1990">		int usedSmall = 0;</a>
<a name="ln1991">		int totalMedium = 0;</a>
<a name="ln1992">		int usedMedium = 0;</a>
<a name="ln1993">		int usedLarge = 0;</a>
<a name="ln1994"> </a>
<a name="ln1995">		for (int32 i = 0; i &lt; SLAB_META_CHUNKS_PER_AREA; i++) {</a>
<a name="ln1996">			MetaChunk* metaChunk = area-&gt;metaChunks + i;</a>
<a name="ln1997">			if (metaChunk-&gt;chunkSize == 0)</a>
<a name="ln1998">				continue;</a>
<a name="ln1999"> </a>
<a name="ln2000">			switch (metaChunk-&gt;chunkSize) {</a>
<a name="ln2001">				case SLAB_CHUNK_SIZE_SMALL:</a>
<a name="ln2002">					totalSmall += metaChunk-&gt;chunkCount;</a>
<a name="ln2003">					usedSmall += metaChunk-&gt;usedChunkCount;</a>
<a name="ln2004">					break;</a>
<a name="ln2005">				case SLAB_CHUNK_SIZE_MEDIUM:</a>
<a name="ln2006">					totalMedium += metaChunk-&gt;chunkCount;</a>
<a name="ln2007">					usedMedium += metaChunk-&gt;usedChunkCount;</a>
<a name="ln2008">					break;</a>
<a name="ln2009">				case SLAB_CHUNK_SIZE_LARGE:</a>
<a name="ln2010">					usedLarge += metaChunk-&gt;usedChunkCount;</a>
<a name="ln2011">					break;</a>
<a name="ln2012">			}</a>
<a name="ln2013">		}</a>
<a name="ln2014"> </a>
<a name="ln2015">		kprintf(&quot;%p  %p  %2u/%2u  %4d/%4d  %3d/%3d  %5d\n&quot;,</a>
<a name="ln2016">			area, area-&gt;vmArea, area-&gt;usedMetaChunkCount,</a>
<a name="ln2017">			SLAB_META_CHUNKS_PER_AREA, usedSmall, totalSmall, usedMedium,</a>
<a name="ln2018">			totalMedium, usedLarge);</a>
<a name="ln2019"> </a>
<a name="ln2020">		totalTotalSmall += totalSmall;</a>
<a name="ln2021">		totalUsedSmall += usedSmall;</a>
<a name="ln2022">		totalTotalMedium += totalMedium;</a>
<a name="ln2023">		totalUsedMedium += usedMedium;</a>
<a name="ln2024">		totalUsedLarge += usedLarge;</a>
<a name="ln2025">	}</a>
<a name="ln2026"> </a>
<a name="ln2027">	kprintf(&quot;%d free area%s:\n&quot;, sFreeAreaCount,</a>
<a name="ln2028">		sFreeAreaCount == 1 ? &quot;&quot; : &quot;s&quot;);</a>
<a name="ln2029">	for (Area* area = sFreeAreas; area != NULL; area = area-&gt;next) {</a>
<a name="ln2030">		areaCount++;</a>
<a name="ln2031">		kprintf(&quot;%p  %p\n&quot;, area, area-&gt;vmArea);</a>
<a name="ln2032">	}</a>
<a name="ln2033"> </a>
<a name="ln2034">	kprintf(&quot;total usage:\n&quot;);</a>
<a name="ln2035">	kprintf(&quot;  small:    %&quot; B_PRIuSIZE &quot;/%&quot; B_PRIuSIZE &quot;\n&quot;, totalUsedSmall,</a>
<a name="ln2036">		totalTotalSmall);</a>
<a name="ln2037">	kprintf(&quot;  medium:   %&quot; B_PRIuSIZE &quot;/%&quot; B_PRIuSIZE &quot;\n&quot;, totalUsedMedium,</a>
<a name="ln2038">		totalTotalMedium);</a>
<a name="ln2039">	kprintf(&quot;  large:    %&quot; B_PRIuSIZE &quot;\n&quot;, totalUsedLarge);</a>
<a name="ln2040">	kprintf(&quot;  memory:   %&quot; B_PRIuSIZE &quot;/%&quot; B_PRIu32 &quot; KB\n&quot;,</a>
<a name="ln2041">		(totalUsedSmall * SLAB_CHUNK_SIZE_SMALL</a>
<a name="ln2042">			+ totalUsedMedium * SLAB_CHUNK_SIZE_MEDIUM</a>
<a name="ln2043">			+ totalUsedLarge * SLAB_CHUNK_SIZE_LARGE) / 1024,</a>
<a name="ln2044">		areaCount * SLAB_AREA_SIZE / 1024);</a>
<a name="ln2045">	kprintf(&quot;  overhead: %&quot; B_PRIuSIZE &quot; KB\n&quot;,</a>
<a name="ln2046">		areaCount * kAreaAdminSize / 1024);</a>
<a name="ln2047"> </a>
<a name="ln2048">	return 0;</a>
<a name="ln2049">}</a>
<a name="ln2050"> </a>
<a name="ln2051"> </a>
<a name="ln2052">#if SLAB_MEMORY_MANAGER_ALLOCATION_TRACKING</a>
<a name="ln2053"> </a>
<a name="ln2054">void</a>
<a name="ln2055">MemoryManager::_AddTrackingInfo(void* allocation, size_t size,</a>
<a name="ln2056">	AbstractTraceEntryWithStackTrace* traceEntry)</a>
<a name="ln2057">{</a>
<a name="ln2058">	_TrackingInfoFor(allocation, size)-&gt;Init(traceEntry);</a>
<a name="ln2059">}</a>
<a name="ln2060"> </a>
<a name="ln2061">#endif // SLAB_MEMORY_MANAGER_ALLOCATION_TRACKING</a>
<a name="ln2062"> </a>
<a name="ln2063"> </a>
<a name="ln2064">RANGE_MARKER_FUNCTION_END(SlabMemoryManager)</a>

</code></pre>
<div class="balloon" rel="1122"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v595/" target="_blank">V595</a> The 'metaChunkList' pointer was utilized before it was verified against nullptr. Check lines: 1122, 1137.</p></div>
<div class="balloon" rel="1059"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v595/" target="_blank">V595</a> The 'metaChunkList' pointer was utilized before it was verified against nullptr. Check lines: 1059, 1089.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
