
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <title>AVCodecDecoder.cpp</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">/*</a>
<a name="ln2"> * Copyright (C) 2001 Carlos Hasan</a>
<a name="ln3"> * Copyright (C) 2001 François Revol</a>
<a name="ln4"> * Copyright (C) 2001 Axel Dörfler</a>
<a name="ln5"> * Copyright (C) 2004 Marcus Overhagen</a>
<a name="ln6"> * Copyright (C) 2009 Stephan Amßus &lt;superstippi@gmx.de&gt;</a>
<a name="ln7"> * Copyright (C) 2014 Colin Günther &lt;coling@gmx.de&gt;</a>
<a name="ln8"> * Copyright (C) 2015 Adrien Destugues &lt;pulkomandy@pulkomandy.tk&gt;</a>
<a name="ln9"> *</a>
<a name="ln10"> * All rights reserved. Distributed under the terms of the MIT License.</a>
<a name="ln11"> */</a>
<a name="ln12"> </a>
<a name="ln13">//! libavcodec based decoder for Haiku</a>
<a name="ln14"> </a>
<a name="ln15"> </a>
<a name="ln16">#include &quot;AVCodecDecoder.h&quot;</a>
<a name="ln17"> </a>
<a name="ln18">#include &lt;new&gt;</a>
<a name="ln19"> </a>
<a name="ln20">#include &lt;assert.h&gt;</a>
<a name="ln21">#include &lt;string.h&gt;</a>
<a name="ln22"> </a>
<a name="ln23">#include &lt;Bitmap.h&gt;</a>
<a name="ln24">#include &lt;Debug.h&gt;</a>
<a name="ln25">#include &lt;String.h&gt;</a>
<a name="ln26"> </a>
<a name="ln27">#include &quot;Utilities.h&quot;</a>
<a name="ln28"> </a>
<a name="ln29"> </a>
<a name="ln30">#undef TRACE</a>
<a name="ln31">//#define TRACE_AV_CODEC</a>
<a name="ln32">#ifdef TRACE_AV_CODEC</a>
<a name="ln33">#	define TRACE(x...)	printf(x)</a>
<a name="ln34">#	define TRACE_AUDIO(x...)	printf(x)</a>
<a name="ln35">#	define TRACE_VIDEO(x...)	printf(x)</a>
<a name="ln36">#else</a>
<a name="ln37">#	define TRACE(x...)</a>
<a name="ln38">#	define TRACE_AUDIO(x...)</a>
<a name="ln39">#	define TRACE_VIDEO(x...)</a>
<a name="ln40">#endif</a>
<a name="ln41"> </a>
<a name="ln42">//#define LOG_STREAM_TO_FILE</a>
<a name="ln43">#ifdef LOG_STREAM_TO_FILE</a>
<a name="ln44">#	include &lt;File.h&gt;</a>
<a name="ln45">	static BFile sAudioStreamLogFile(</a>
<a name="ln46">		&quot;/boot/home/Desktop/AVCodecDebugAudioStream.raw&quot;,</a>
<a name="ln47">		B_CREATE_FILE | B_ERASE_FILE | B_WRITE_ONLY);</a>
<a name="ln48">	static BFile sVideoStreamLogFile(</a>
<a name="ln49">		&quot;/boot/home/Desktop/AVCodecDebugVideoStream.raw&quot;,</a>
<a name="ln50">		B_CREATE_FILE | B_ERASE_FILE | B_WRITE_ONLY);</a>
<a name="ln51">	static int sDumpedPackets = 0;</a>
<a name="ln52">#endif</a>
<a name="ln53"> </a>
<a name="ln54">typedef AVCodecID CodecID;</a>
<a name="ln55"> </a>
<a name="ln56">struct wave_format_ex {</a>
<a name="ln57">	uint16 format_tag;</a>
<a name="ln58">	uint16 channels;</a>
<a name="ln59">	uint32 frames_per_sec;</a>
<a name="ln60">	uint32 avg_bytes_per_sec;</a>
<a name="ln61">	uint16 block_align;</a>
<a name="ln62">	uint16 bits_per_sample;</a>
<a name="ln63">	uint16 extra_size;</a>
<a name="ln64">	// extra_data[extra_size]</a>
<a name="ln65">} _PACKED;</a>
<a name="ln66"> </a>
<a name="ln67">struct avformat_codec_context {</a>
<a name="ln68">	int sample_rate;</a>
<a name="ln69">	int channels;</a>
<a name="ln70">};</a>
<a name="ln71"> </a>
<a name="ln72"> </a>
<a name="ln73">// profiling related globals</a>
<a name="ln74">#define DO_PROFILING 0</a>
<a name="ln75">#if DO_PROFILING</a>
<a name="ln76">static bigtime_t decodingTime = 0;</a>
<a name="ln77">static bigtime_t conversionTime = 0;</a>
<a name="ln78">static long profileCounter = 0;</a>
<a name="ln79">#endif</a>
<a name="ln80"> </a>
<a name="ln81"> </a>
<a name="ln82">AVCodecDecoder::AVCodecDecoder()</a>
<a name="ln83">	:</a>
<a name="ln84">	fHeader(),</a>
<a name="ln85">	fInputFormat(),</a>
<a name="ln86">	fFrame(0),</a>
<a name="ln87">	fIsAudio(false),</a>
<a name="ln88">	fCodec(NULL),</a>
<a name="ln89">	fCodecContext(avcodec_alloc_context3(NULL)),</a>
<a name="ln90">	fResampleContext(NULL),</a>
<a name="ln91">	fDecodedData(NULL),</a>
<a name="ln92">	fDecodedDataSizeInBytes(0),</a>
<a name="ln93">	fPostProcessedDecodedPicture(av_frame_alloc()),</a>
<a name="ln94">	fRawDecodedPicture(av_frame_alloc()),</a>
<a name="ln95">	fRawDecodedAudio(av_frame_alloc()),</a>
<a name="ln96"> </a>
<a name="ln97">	fCodecInitDone(false),</a>
<a name="ln98"> </a>
<a name="ln99">#if USE_SWS_FOR_COLOR_SPACE_CONVERSION</a>
<a name="ln100">	fSwsContext(NULL),</a>
<a name="ln101">#else</a>
<a name="ln102">	fFormatConversionFunc(NULL),</a>
<a name="ln103">#endif</a>
<a name="ln104"> </a>
<a name="ln105">	fExtraData(NULL),</a>
<a name="ln106">	fExtraDataSize(0),</a>
<a name="ln107">	fBlockAlign(0),</a>
<a name="ln108"> </a>
<a name="ln109">	fOutputColorSpace(B_NO_COLOR_SPACE),</a>
<a name="ln110">	fOutputFrameCount(0),</a>
<a name="ln111">	fOutputFrameRate(1.0),</a>
<a name="ln112">	fOutputFrameSize(0),</a>
<a name="ln113">	fInputFrameSize(0),</a>
<a name="ln114"> </a>
<a name="ln115">	fChunkBuffer(NULL),</a>
<a name="ln116">	fChunkBufferSize(0),</a>
<a name="ln117">	fAudioDecodeError(false),</a>
<a name="ln118"> </a>
<a name="ln119">	fDecodedDataBuffer(av_frame_alloc()),</a>
<a name="ln120">	fDecodedDataBufferOffset(0),</a>
<a name="ln121">	fDecodedDataBufferSize(0),</a>
<a name="ln122">	fBufferSinkContext(NULL),</a>
<a name="ln123">	fBufferSourceContext(NULL),</a>
<a name="ln124">	fFilterGraph(NULL),</a>
<a name="ln125">	fFilterFrame(NULL)</a>
<a name="ln126">{</a>
<a name="ln127">	TRACE(&quot;AVCodecDecoder::AVCodecDecoder()\n&quot;);</a>
<a name="ln128"> </a>
<a name="ln129">	system_info info;</a>
<a name="ln130">	get_system_info(&amp;info);</a>
<a name="ln131"> </a>
<a name="ln132">	fCodecContext-&gt;err_recognition = AV_EF_CAREFUL;</a>
<a name="ln133">	fCodecContext-&gt;error_concealment = 3;</a>
<a name="ln134">	fCodecContext-&gt;thread_count = info.cpu_count;</a>
<a name="ln135">}</a>
<a name="ln136"> </a>
<a name="ln137"> </a>
<a name="ln138">AVCodecDecoder::~AVCodecDecoder()</a>
<a name="ln139">{</a>
<a name="ln140">	TRACE(&quot;[%c] AVCodecDecoder::~AVCodecDecoder()\n&quot;, fIsAudio?('a'):('v'));</a>
<a name="ln141"> </a>
<a name="ln142">#if DO_PROFILING</a>
<a name="ln143">	if (profileCounter &gt; 0) {</a>
<a name="ln144">		printf(&quot;[%c] profile: d1 = %lld, d2 = %lld (%Ld)\n&quot;,</a>
<a name="ln145">			fIsAudio?('a'):('v'), decodingTime / profileCounter,</a>
<a name="ln146">			conversionTime / profileCounter, fFrame);</a>
<a name="ln147">	}</a>
<a name="ln148">#endif</a>
<a name="ln149"> </a>
<a name="ln150">	if (fCodecInitDone)</a>
<a name="ln151">		avcodec_close(fCodecContext);</a>
<a name="ln152"> </a>
<a name="ln153">	swr_free(&amp;fResampleContext);</a>
<a name="ln154">	free(fChunkBuffer);</a>
<a name="ln155">	free(fDecodedData);</a>
<a name="ln156"> </a>
<a name="ln157">	av_free(fPostProcessedDecodedPicture);</a>
<a name="ln158">	av_free(fRawDecodedPicture);</a>
<a name="ln159">	av_free(fRawDecodedAudio-&gt;opaque);</a>
<a name="ln160">	av_free(fRawDecodedAudio);</a>
<a name="ln161">	av_free(fCodecContext);</a>
<a name="ln162">	av_free(fDecodedDataBuffer);</a>
<a name="ln163"> </a>
<a name="ln164">	av_frame_free(&amp;fFilterFrame);</a>
<a name="ln165">	avfilter_graph_free(&amp;fFilterGraph);</a>
<a name="ln166"> </a>
<a name="ln167">#if USE_SWS_FOR_COLOR_SPACE_CONVERSION</a>
<a name="ln168">	if (fSwsContext != NULL)</a>
<a name="ln169">		sws_freeContext(fSwsContext);</a>
<a name="ln170">#endif</a>
<a name="ln171"> </a>
<a name="ln172">	delete[] fExtraData;</a>
<a name="ln173">}</a>
<a name="ln174"> </a>
<a name="ln175"> </a>
<a name="ln176">void</a>
<a name="ln177">AVCodecDecoder::GetCodecInfo(media_codec_info* mci)</a>
<a name="ln178">{</a>
<a name="ln179">	snprintf(mci-&gt;short_name, 32, &quot;%s&quot;, fCodec-&gt;name);</a>
<a name="ln180">	snprintf(mci-&gt;pretty_name, 96, &quot;%s&quot;, fCodec-&gt;long_name);</a>
<a name="ln181">	mci-&gt;id = 0;</a>
<a name="ln182">	mci-&gt;sub_id = fCodec-&gt;id;</a>
<a name="ln183">}</a>
<a name="ln184"> </a>
<a name="ln185"> </a>
<a name="ln186">status_t</a>
<a name="ln187">AVCodecDecoder::Setup(media_format* ioEncodedFormat, const void* infoBuffer,</a>
<a name="ln188">	size_t infoSize)</a>
<a name="ln189">{</a>
<a name="ln190">	if (ioEncodedFormat-&gt;type != B_MEDIA_ENCODED_AUDIO</a>
<a name="ln191">		&amp;&amp; ioEncodedFormat-&gt;type != B_MEDIA_ENCODED_VIDEO)</a>
<a name="ln192">		return B_ERROR;</a>
<a name="ln193"> </a>
<a name="ln194">	fIsAudio = (ioEncodedFormat-&gt;type == B_MEDIA_ENCODED_AUDIO);</a>
<a name="ln195">	TRACE(&quot;[%c] AVCodecDecoder::Setup()\n&quot;, fIsAudio?('a'):('v'));</a>
<a name="ln196"> </a>
<a name="ln197">#ifdef TRACE_AV_CODEC</a>
<a name="ln198">	char buffer[1024];</a>
<a name="ln199">	string_for_format(*ioEncodedFormat, buffer, sizeof(buffer));</a>
<a name="ln200">	TRACE(&quot;[%c]   input_format = %s\n&quot;, fIsAudio?('a'):('v'), buffer);</a>
<a name="ln201">	TRACE(&quot;[%c]   infoSize = %ld\n&quot;, fIsAudio?('a'):('v'), infoSize);</a>
<a name="ln202">	TRACE(&quot;[%c]   user_data_type = %08lx\n&quot;, fIsAudio?('a'):('v'),</a>
<a name="ln203">		ioEncodedFormat-&gt;user_data_type);</a>
<a name="ln204">	TRACE(&quot;[%c]   meta_data_size = %ld\n&quot;, fIsAudio?('a'):('v'),</a>
<a name="ln205">		ioEncodedFormat-&gt;MetaDataSize());</a>
<a name="ln206">#endif</a>
<a name="ln207"> </a>
<a name="ln208">	media_format_description description;</a>
<a name="ln209">	if (BMediaFormats().GetCodeFor(*ioEncodedFormat,</a>
<a name="ln210">			B_MISC_FORMAT_FAMILY, &amp;description) == B_OK) {</a>
<a name="ln211">		if (description.u.misc.file_format != 'ffmp')</a>
<a name="ln212">			return B_NOT_SUPPORTED;</a>
<a name="ln213">		fCodec = avcodec_find_decoder(static_cast&lt;CodecID&gt;(</a>
<a name="ln214">			description.u.misc.codec));</a>
<a name="ln215">		if (fCodec == NULL) {</a>
<a name="ln216">			TRACE(&quot;  unable to find the correct FFmpeg &quot;</a>
<a name="ln217">				&quot;decoder (id = %lu)\n&quot;, description.u.misc.codec);</a>
<a name="ln218">			return B_ERROR;</a>
<a name="ln219">		}</a>
<a name="ln220">		TRACE(&quot;  found decoder %s\n&quot;, fCodec-&gt;name);</a>
<a name="ln221"> </a>
<a name="ln222">		const void* extraData = infoBuffer;</a>
<a name="ln223">		fExtraDataSize = infoSize;</a>
<a name="ln224">		if (description.family == B_WAV_FORMAT_FAMILY</a>
<a name="ln225">				&amp;&amp; infoSize &gt;= sizeof(wave_format_ex)) {</a>
<a name="ln226">			TRACE(&quot;  trying to use wave_format_ex\n&quot;);</a>
<a name="ln227">			// Special case extra data in B_WAV_FORMAT_FAMILY</a>
<a name="ln228">			const wave_format_ex* waveFormatData</a>
<a name="ln229">				= (const wave_format_ex*)infoBuffer;</a>
<a name="ln230"> </a>
<a name="ln231">			size_t waveFormatSize = infoSize;</a>
<a name="ln232">			if (waveFormatData != NULL &amp;&amp; waveFormatSize &gt; 0) {</a>
<a name="ln233">				fBlockAlign = waveFormatData-&gt;block_align;</a>
<a name="ln234">				TRACE(&quot;  found block align: %d\n&quot;, fBlockAlign);</a>
<a name="ln235">				fExtraDataSize = waveFormatData-&gt;extra_size;</a>
<a name="ln236">				// skip the wave_format_ex from the extra data.</a>
<a name="ln237">				extraData = waveFormatData + 1;</a>
<a name="ln238">			}</a>
<a name="ln239">		} else {</a>
<a name="ln240">			if (fIsAudio) {</a>
<a name="ln241">				fBlockAlign</a>
<a name="ln242">					= ioEncodedFormat-&gt;u.encoded_audio.output.buffer_size;</a>
<a name="ln243">				TRACE(&quot;  using buffer_size as block align: %d\n&quot;,</a>
<a name="ln244">					fBlockAlign);</a>
<a name="ln245">			}</a>
<a name="ln246">		}</a>
<a name="ln247">		if (extraData != NULL &amp;&amp; fExtraDataSize &gt; 0) {</a>
<a name="ln248">			TRACE(&quot;AVCodecDecoder: extra data size %ld\n&quot;, infoSize);</a>
<a name="ln249">			delete[] fExtraData;</a>
<a name="ln250">			fExtraData = new(std::nothrow) char[fExtraDataSize];</a>
<a name="ln251">			if (fExtraData != NULL)</a>
<a name="ln252">				memcpy(fExtraData, infoBuffer, fExtraDataSize);</a>
<a name="ln253">			else</a>
<a name="ln254">				fExtraDataSize = 0;</a>
<a name="ln255">		}</a>
<a name="ln256"> </a>
<a name="ln257">		fInputFormat = *ioEncodedFormat;</a>
<a name="ln258">		return B_OK;</a>
<a name="ln259">	} else {</a>
<a name="ln260">		TRACE(&quot;AVCodecDecoder: BMediaFormats().GetCodeFor() failed.\n&quot;);</a>
<a name="ln261">	}</a>
<a name="ln262"> </a>
<a name="ln263">	printf(&quot;AVCodecDecoder::Setup failed!\n&quot;);</a>
<a name="ln264">	return B_ERROR;</a>
<a name="ln265">}</a>
<a name="ln266"> </a>
<a name="ln267"> </a>
<a name="ln268">status_t</a>
<a name="ln269">AVCodecDecoder::SeekedTo(int64 frame, bigtime_t time)</a>
<a name="ln270">{</a>
<a name="ln271">	status_t ret = B_OK;</a>
<a name="ln272">	// Reset the FFmpeg codec to flush buffers, so we keep the sync</a>
<a name="ln273">	if (fCodecInitDone) {</a>
<a name="ln274">		avcodec_flush_buffers(fCodecContext);</a>
<a name="ln275">		_ResetTempPacket();</a>
<a name="ln276">	}</a>
<a name="ln277"> </a>
<a name="ln278">	// Flush internal buffers as well.</a>
<a name="ln279">	free(fChunkBuffer);</a>
<a name="ln280">	fChunkBuffer = NULL;</a>
<a name="ln281">	fChunkBufferSize = 0;</a>
<a name="ln282">	fDecodedDataBufferOffset = 0;</a>
<a name="ln283">	fDecodedDataBufferSize = 0;</a>
<a name="ln284">	fDecodedDataSizeInBytes = 0;</a>
<a name="ln285"> </a>
<a name="ln286">	fFrame = frame;</a>
<a name="ln287"> </a>
<a name="ln288">	return ret;</a>
<a name="ln289">}</a>
<a name="ln290"> </a>
<a name="ln291"> </a>
<a name="ln292">status_t</a>
<a name="ln293">AVCodecDecoder::NegotiateOutputFormat(media_format* inOutFormat)</a>
<a name="ln294">{</a>
<a name="ln295">	TRACE(&quot;AVCodecDecoder::NegotiateOutputFormat() [%c] \n&quot;,</a>
<a name="ln296">		fIsAudio?('a'):('v'));</a>
<a name="ln297"> </a>
<a name="ln298">#ifdef TRACE_AV_CODEC</a>
<a name="ln299">	char buffer[1024];</a>
<a name="ln300">	string_for_format(*inOutFormat, buffer, sizeof(buffer));</a>
<a name="ln301">	TRACE(&quot;  [%c]  requested format = %s\n&quot;, fIsAudio?('a'):('v'), buffer);</a>
<a name="ln302">#endif</a>
<a name="ln303"> </a>
<a name="ln304">	if (fIsAudio)</a>
<a name="ln305">		return _NegotiateAudioOutputFormat(inOutFormat);</a>
<a name="ln306">	else</a>
<a name="ln307">		return _NegotiateVideoOutputFormat(inOutFormat);</a>
<a name="ln308">}</a>
<a name="ln309"> </a>
<a name="ln310"> </a>
<a name="ln311">status_t</a>
<a name="ln312">AVCodecDecoder::Decode(void* outBuffer, int64* outFrameCount,</a>
<a name="ln313">	media_header* mediaHeader, media_decode_info* info)</a>
<a name="ln314">{</a>
<a name="ln315">	if (!fCodecInitDone)</a>
<a name="ln316">		return B_NO_INIT;</a>
<a name="ln317"> </a>
<a name="ln318">	status_t ret;</a>
<a name="ln319">	if (fIsAudio)</a>
<a name="ln320">		ret = _DecodeAudio(outBuffer, outFrameCount, mediaHeader, info);</a>
<a name="ln321">	else</a>
<a name="ln322">		ret = _DecodeVideo(outBuffer, outFrameCount, mediaHeader, info);</a>
<a name="ln323"> </a>
<a name="ln324">	return ret;</a>
<a name="ln325">}</a>
<a name="ln326"> </a>
<a name="ln327"> </a>
<a name="ln328">// #pragma mark -</a>
<a name="ln329"> </a>
<a name="ln330"> </a>
<a name="ln331">void</a>
<a name="ln332">AVCodecDecoder::_ResetTempPacket()</a>
<a name="ln333">{</a>
<a name="ln334">	av_init_packet(&amp;fTempPacket);</a>
<a name="ln335">	fTempPacket.size = 0;</a>
<a name="ln336">	fTempPacket.data = NULL;</a>
<a name="ln337">}</a>
<a name="ln338"> </a>
<a name="ln339"> </a>
<a name="ln340">status_t</a>
<a name="ln341">AVCodecDecoder::_NegotiateAudioOutputFormat(media_format* inOutFormat)</a>
<a name="ln342">{</a>
<a name="ln343">	TRACE(&quot;AVCodecDecoder::_NegotiateAudioOutputFormat()\n&quot;);</a>
<a name="ln344"> </a>
<a name="ln345">	_ApplyEssentialAudioContainerPropertiesToContext();</a>
<a name="ln346">		// This makes audio formats play that encode the audio properties in</a>
<a name="ln347">		// the audio container (e.g. WMA) and not in the audio frames</a>
<a name="ln348">		// themself (e.g. MP3).</a>
<a name="ln349">		// Note: Doing this step unconditionally is OK, because the first call</a>
<a name="ln350">		// to _DecodeNextAudioFrameChunk() will update the essential audio</a>
<a name="ln351">		// format properties accordingly regardless of the settings here.</a>
<a name="ln352"> </a>
<a name="ln353">	// close any previous instance</a>
<a name="ln354">	if (fCodecInitDone) {</a>
<a name="ln355">		fCodecInitDone = false;</a>
<a name="ln356">		avcodec_close(fCodecContext);</a>
<a name="ln357">	}</a>
<a name="ln358"> </a>
<a name="ln359">	if (avcodec_open2(fCodecContext, fCodec, NULL) &gt;= 0)</a>
<a name="ln360">		fCodecInitDone = true;</a>
<a name="ln361">	else {</a>
<a name="ln362">		TRACE(&quot;avcodec_open() failed to init codec!\n&quot;);</a>
<a name="ln363">		return B_ERROR;</a>
<a name="ln364">	}</a>
<a name="ln365"> </a>
<a name="ln366">	free(fChunkBuffer);</a>
<a name="ln367">	fChunkBuffer = NULL;</a>
<a name="ln368">	fChunkBufferSize = 0;</a>
<a name="ln369">	fAudioDecodeError = false;</a>
<a name="ln370">	fDecodedDataBufferOffset = 0;</a>
<a name="ln371">	fDecodedDataBufferSize = 0;</a>
<a name="ln372"> </a>
<a name="ln373">	_ResetTempPacket();</a>
<a name="ln374"> </a>
<a name="ln375">	status_t statusOfDecodingFirstFrameChunk = _DecodeNextAudioFrameChunk();</a>
<a name="ln376">	if (statusOfDecodingFirstFrameChunk != B_OK) {</a>
<a name="ln377">		TRACE(&quot;[a] decoding first audio frame chunk failed\n&quot;);</a>
<a name="ln378">		return B_ERROR;</a>
<a name="ln379">	}</a>
<a name="ln380"> </a>
<a name="ln381">	media_multi_audio_format outputAudioFormat;</a>
<a name="ln382">	outputAudioFormat = media_raw_audio_format::wildcard;</a>
<a name="ln383">	outputAudioFormat.byte_order = B_MEDIA_HOST_ENDIAN;</a>
<a name="ln384">	outputAudioFormat.frame_rate = fCodecContext-&gt;sample_rate;</a>
<a name="ln385">	outputAudioFormat.channel_count = fCodecContext-&gt;channels;</a>
<a name="ln386">	ConvertAVSampleFormatToRawAudioFormat(fCodecContext-&gt;sample_fmt,</a>
<a name="ln387">		outputAudioFormat.format);</a>
<a name="ln388">	// Check that format is not still a wild card!</a>
<a name="ln389">	if (outputAudioFormat.format == 0) {</a>
<a name="ln390">		TRACE(&quot;  format still a wild-card, assuming B_AUDIO_SHORT.\n&quot;);</a>
<a name="ln391">		outputAudioFormat.format = media_raw_audio_format::B_AUDIO_SHORT;</a>
<a name="ln392">	}</a>
<a name="ln393">	outputAudioFormat.buffer_size = inOutFormat-&gt;u.raw_audio.buffer_size;</a>
<a name="ln394">	// Check that buffer_size has a sane value</a>
<a name="ln395">	size_t sampleSize = outputAudioFormat.format</a>
<a name="ln396">		&amp; media_raw_audio_format::B_AUDIO_SIZE_MASK;</a>
<a name="ln397">	if (outputAudioFormat.buffer_size == 0) {</a>
<a name="ln398">		outputAudioFormat.buffer_size = 512 * sampleSize</a>
<a name="ln399">			* outputAudioFormat.channel_count;</a>
<a name="ln400">	}</a>
<a name="ln401"> </a>
<a name="ln402">	inOutFormat-&gt;type = B_MEDIA_RAW_AUDIO;</a>
<a name="ln403">	inOutFormat-&gt;u.raw_audio = outputAudioFormat;</a>
<a name="ln404">	inOutFormat-&gt;require_flags = 0;</a>
<a name="ln405">	inOutFormat-&gt;deny_flags = B_MEDIA_MAUI_UNDEFINED_FLAGS;</a>
<a name="ln406"> </a>
<a name="ln407">	// Initialize variables needed to manage decoding as much audio frames as</a>
<a name="ln408">	// needed to fill the buffer_size.</a>
<a name="ln409">	fOutputFrameSize = sampleSize * outputAudioFormat.channel_count;</a>
<a name="ln410">	fOutputFrameCount = outputAudioFormat.buffer_size / fOutputFrameSize;</a>
<a name="ln411">	fOutputFrameRate = outputAudioFormat.frame_rate;</a>
<a name="ln412">	if (av_sample_fmt_is_planar(fCodecContext-&gt;sample_fmt))</a>
<a name="ln413">		fInputFrameSize = sampleSize;</a>
<a name="ln414">	else</a>
<a name="ln415">		fInputFrameSize = fOutputFrameSize;</a>
<a name="ln416"> </a>
<a name="ln417">	fRawDecodedAudio-&gt;opaque</a>
<a name="ln418">		= av_realloc(fRawDecodedAudio-&gt;opaque, sizeof(avformat_codec_context));</a>
<a name="ln419">	if (fRawDecodedAudio-&gt;opaque == NULL)</a>
<a name="ln420">		return B_NO_MEMORY;</a>
<a name="ln421"> </a>
<a name="ln422">	if (av_sample_fmt_is_planar(fCodecContext-&gt;sample_fmt)) {</a>
<a name="ln423">		fResampleContext = swr_alloc_set_opts(NULL,</a>
<a name="ln424">			fCodecContext-&gt;channel_layout,</a>
<a name="ln425">			fCodecContext-&gt;request_sample_fmt,</a>
<a name="ln426">			fCodecContext-&gt;sample_rate,</a>
<a name="ln427">			fCodecContext-&gt;channel_layout,</a>
<a name="ln428">			fCodecContext-&gt;sample_fmt,</a>
<a name="ln429">			fCodecContext-&gt;sample_rate,</a>
<a name="ln430">			0, NULL);</a>
<a name="ln431">		swr_init(fResampleContext);</a>
<a name="ln432">	}</a>
<a name="ln433"> </a>
<a name="ln434">	TRACE(&quot;  bit_rate = %d, sample_rate = %d, channels = %d, &quot;</a>
<a name="ln435">		&quot;output frame size: %d, count: %ld, rate: %.2f\n&quot;,</a>
<a name="ln436">		fCodecContext-&gt;bit_rate, fCodecContext-&gt;sample_rate, fCodecContext-&gt;channels,</a>
<a name="ln437">		fOutputFrameSize, fOutputFrameCount, fOutputFrameRate);</a>
<a name="ln438"> </a>
<a name="ln439">	return B_OK;</a>
<a name="ln440">}</a>
<a name="ln441"> </a>
<a name="ln442"> </a>
<a name="ln443">status_t</a>
<a name="ln444">AVCodecDecoder::_NegotiateVideoOutputFormat(media_format* inOutFormat)</a>
<a name="ln445">{</a>
<a name="ln446">	TRACE(&quot;AVCodecDecoder::_NegotiateVideoOutputFormat()\n&quot;);</a>
<a name="ln447"> </a>
<a name="ln448">	TRACE(&quot;  requested video format 0x%x\n&quot;,</a>
<a name="ln449">		inOutFormat-&gt;u.raw_video.display.format);</a>
<a name="ln450"> </a>
<a name="ln451">	_ApplyEssentialVideoContainerPropertiesToContext();</a>
<a name="ln452">		// This makes video formats play that encode the video properties in</a>
<a name="ln453">		// the video container (e.g. WMV) and not in the video frames</a>
<a name="ln454">		// themself (e.g. MPEG2).</a>
<a name="ln455">		// Note: Doing this step unconditionally is OK, because the first call</a>
<a name="ln456">		// to _DecodeNextVideoFrame() will update the essential video format</a>
<a name="ln457">		// properties accordingly regardless of the settings here.</a>
<a name="ln458"> </a>
<a name="ln459">	bool codecCanHandleIncompleteFrames</a>
<a name="ln460">		= (fCodec-&gt;capabilities &amp; AV_CODEC_CAP_TRUNCATED) != 0;</a>
<a name="ln461">	if (codecCanHandleIncompleteFrames) {</a>
<a name="ln462">		// Expect and handle video frames to be splitted across consecutive</a>
<a name="ln463">		// data chunks.</a>
<a name="ln464">		fCodecContext-&gt;flags |= AV_CODEC_FLAG_TRUNCATED;</a>
<a name="ln465">	}</a>
<a name="ln466"> </a>
<a name="ln467">	// close any previous instance</a>
<a name="ln468">	if (fCodecInitDone) {</a>
<a name="ln469">		fCodecInitDone = false;</a>
<a name="ln470">		avcodec_close(fCodecContext);</a>
<a name="ln471">	}</a>
<a name="ln472"> </a>
<a name="ln473">	if (avcodec_open2(fCodecContext, fCodec, NULL) &gt;= 0)</a>
<a name="ln474">		fCodecInitDone = true;</a>
<a name="ln475">	else {</a>
<a name="ln476">		TRACE(&quot;avcodec_open() failed to init codec!\n&quot;);</a>
<a name="ln477">		return B_ERROR;</a>
<a name="ln478">	}</a>
<a name="ln479"> </a>
<a name="ln480">#if USE_SWS_FOR_COLOR_SPACE_CONVERSION</a>
<a name="ln481">	fOutputColorSpace = B_RGB32;</a>
<a name="ln482">#else</a>
<a name="ln483">	// Make MediaPlayer happy (if not in rgb32 screen depth and no overlay,</a>
<a name="ln484">	// it will only ask for YCbCr, which DrawBitmap doesn't handle, so the</a>
<a name="ln485">	// default colordepth is RGB32).</a>
<a name="ln486">	if (inOutFormat-&gt;u.raw_video.display.format == B_YCbCr422)</a>
<a name="ln487">		fOutputColorSpace = B_YCbCr422;</a>
<a name="ln488">	else</a>
<a name="ln489">		fOutputColorSpace = B_RGB32;</a>
<a name="ln490">#endif</a>
<a name="ln491"> </a>
<a name="ln492">#if USE_SWS_FOR_COLOR_SPACE_CONVERSION</a>
<a name="ln493">	if (fSwsContext != NULL)</a>
<a name="ln494">		sws_freeContext(fSwsContext);</a>
<a name="ln495">	fSwsContext = NULL;</a>
<a name="ln496">#else</a>
<a name="ln497">	fFormatConversionFunc = 0;</a>
<a name="ln498">#endif</a>
<a name="ln499"> </a>
<a name="ln500">	free(fChunkBuffer);</a>
<a name="ln501">	fChunkBuffer = NULL;</a>
<a name="ln502">	fChunkBufferSize = 0;</a>
<a name="ln503"> </a>
<a name="ln504">	_ResetTempPacket();</a>
<a name="ln505"> </a>
<a name="ln506">	status_t statusOfDecodingFirstFrame = _DecodeNextVideoFrame();</a>
<a name="ln507">	if (statusOfDecodingFirstFrame != B_OK) {</a>
<a name="ln508">		TRACE(&quot;[v] decoding first video frame failed\n&quot;);</a>
<a name="ln509">		return B_ERROR;</a>
<a name="ln510">	}</a>
<a name="ln511"> </a>
<a name="ln512">	// Note: fSwsContext / fFormatConversionFunc should have been initialized</a>
<a name="ln513">	// by first call to _DecodeNextVideoFrame() above.</a>
<a name="ln514">#if USE_SWS_FOR_COLOR_SPACE_CONVERSION</a>
<a name="ln515">	if (fSwsContext == NULL) {</a>
<a name="ln516">		TRACE(&quot;No SWS Scale context or decoder has not set the pixel format &quot;</a>
<a name="ln517">			&quot;yet!\n&quot;);</a>
<a name="ln518">	}</a>
<a name="ln519">#else</a>
<a name="ln520">	if (fFormatConversionFunc == NULL) {</a>
<a name="ln521">		TRACE(&quot;no pixel format conversion function found or decoder has &quot;</a>
<a name="ln522">			&quot;not set the pixel format yet!\n&quot;);</a>
<a name="ln523">	}</a>
<a name="ln524">#endif</a>
<a name="ln525"> </a>
<a name="ln526">	inOutFormat-&gt;type = B_MEDIA_RAW_VIDEO;</a>
<a name="ln527">	inOutFormat-&gt;require_flags = 0;</a>
<a name="ln528">	inOutFormat-&gt;deny_flags = B_MEDIA_MAUI_UNDEFINED_FLAGS;</a>
<a name="ln529">	inOutFormat-&gt;u.raw_video = fInputFormat.u.encoded_video.output;</a>
<a name="ln530">	inOutFormat-&gt;u.raw_video.interlace = 1;</a>
<a name="ln531">		// Progressive (non-interlaced) video frames are delivered</a>
<a name="ln532">	inOutFormat-&gt;u.raw_video.first_active</a>
<a name="ln533">		= fHeader.u.raw_video.first_active_line;</a>
<a name="ln534">	inOutFormat-&gt;u.raw_video.last_active = fHeader.u.raw_video.line_count;</a>
<a name="ln535">	inOutFormat-&gt;u.raw_video.pixel_width_aspect</a>
<a name="ln536">		= fHeader.u.raw_video.pixel_width_aspect;</a>
<a name="ln537">	inOutFormat-&gt;u.raw_video.pixel_height_aspect</a>
<a name="ln538">		= fHeader.u.raw_video.pixel_height_aspect;</a>
<a name="ln539">#if 0</a>
<a name="ln540">	// This was added by Colin Günther in order to handle streams with a</a>
<a name="ln541">	// variable frame rate. fOutputFrameRate is computed from the stream</a>
<a name="ln542">	// time_base, but it actually assumes a timebase equal to the FPS. As far</a>
<a name="ln543">	// as I can see, a stream with a variable frame rate would have a higher</a>
<a name="ln544">	// resolution time_base and increment the pts (presentation time) of each</a>
<a name="ln545">	// frame by a value bigger than one.</a>
<a name="ln546">	//</a>
<a name="ln547">	// Fixed rate stream:</a>
<a name="ln548">	// time_base = 1/50s, frame PTS = 1, 2, 3... (for 50Hz)</a>
<a name="ln549">	//</a>
<a name="ln550">	// Variable rate stream:</a>
<a name="ln551">	// time_base = 1/300s, frame PTS = 6, 12, 18, ... (for 50Hz)</a>
<a name="ln552">	// time_base = 1/300s, frame PTS = 5, 10, 15, ... (for 60Hz)</a>
<a name="ln553">	//</a>
<a name="ln554">	// The fOutputFrameRate currently does not take this into account and</a>
<a name="ln555">	// ignores the PTS. This results in playing the above sample at 300Hz</a>
<a name="ln556">	// instead of 50 or 60.</a>
<a name="ln557">	//</a>
<a name="ln558">	// However, comparing the PTS for two consecutive implies we have already</a>
<a name="ln559">	// decoded 2 frames, which may not be the case when this method is first</a>
<a name="ln560">	// called.</a>
<a name="ln561">	inOutFormat-&gt;u.raw_video.field_rate = fOutputFrameRate;</a>
<a name="ln562">		// Was calculated by first call to _DecodeNextVideoFrame()</a>
<a name="ln563">#endif</a>
<a name="ln564">	inOutFormat-&gt;u.raw_video.display.format = fOutputColorSpace;</a>
<a name="ln565">	inOutFormat-&gt;u.raw_video.display.line_width</a>
<a name="ln566">		= fHeader.u.raw_video.display_line_width;</a>
<a name="ln567">	inOutFormat-&gt;u.raw_video.display.line_count</a>
<a name="ln568">		= fHeader.u.raw_video.display_line_count;</a>
<a name="ln569">	inOutFormat-&gt;u.raw_video.display.bytes_per_row</a>
<a name="ln570">		= fHeader.u.raw_video.bytes_per_row;</a>
<a name="ln571"> </a>
<a name="ln572">#ifdef TRACE_AV_CODEC</a>
<a name="ln573">	char buffer[1024];</a>
<a name="ln574">	string_for_format(*inOutFormat, buffer, sizeof(buffer));</a>
<a name="ln575">	TRACE(&quot;[v]  outFormat = %s\n&quot;, buffer);</a>
<a name="ln576">	TRACE(&quot;  returned  video format 0x%x\n&quot;,</a>
<a name="ln577">		inOutFormat-&gt;u.raw_video.display.format);</a>
<a name="ln578">#endif</a>
<a name="ln579"> </a>
<a name="ln580">	return B_OK;</a>
<a name="ln581">}</a>
<a name="ln582"> </a>
<a name="ln583"> </a>
<a name="ln584">/*! \brief Fills the outBuffer with one or more already decoded audio frames.</a>
<a name="ln585"> </a>
<a name="ln586">	Besides the main duty described above, this method also fills out the other</a>
<a name="ln587">	output parameters as documented below.</a>
<a name="ln588"> </a>
<a name="ln589">	\param outBuffer Pointer to the output buffer to copy the decoded audio</a>
<a name="ln590">		frames to.</a>
<a name="ln591">	\param outFrameCount Pointer to the output variable to assign the number of</a>
<a name="ln592">		copied audio frames (usually several audio frames at once).</a>
<a name="ln593">	\param mediaHeader Pointer to the output media header that contains the</a>
<a name="ln594">		properties of the decoded audio frame being the first in the outBuffer.</a>
<a name="ln595">	\param info Specifies additional decoding parameters. (Note: unused).</a>
<a name="ln596"> </a>
<a name="ln597">	\returns B_OK Decoding audio frames succeeded.</a>
<a name="ln598">	\returns B_LAST_BUFFER_ERROR There are no more audio frames available.</a>
<a name="ln599">	\returns Other error codes</a>
<a name="ln600">*/</a>
<a name="ln601">status_t</a>
<a name="ln602">AVCodecDecoder::_DecodeAudio(void* outBuffer, int64* outFrameCount,</a>
<a name="ln603">	media_header* mediaHeader, media_decode_info* info)</a>
<a name="ln604">{</a>
<a name="ln605">	TRACE_AUDIO(&quot;AVCodecDecoder::_DecodeAudio(audio start_time %.6fs)\n&quot;,</a>
<a name="ln606">		mediaHeader-&gt;start_time / 1000000.0);</a>
<a name="ln607"> </a>
<a name="ln608">	status_t audioDecodingStatus</a>
<a name="ln609">		= fDecodedDataSizeInBytes &gt; 0 ? B_OK : _DecodeNextAudioFrame();</a>
<a name="ln610"> </a>
<a name="ln611">	if (audioDecodingStatus != B_OK)</a>
<a name="ln612">		return audioDecodingStatus;</a>
<a name="ln613"> </a>
<a name="ln614">	*outFrameCount = fDecodedDataSizeInBytes / fOutputFrameSize;</a>
<a name="ln615">	*mediaHeader = fHeader;</a>
<a name="ln616">	memcpy(outBuffer, fDecodedData, fDecodedDataSizeInBytes);</a>
<a name="ln617"> </a>
<a name="ln618">	fDecodedDataSizeInBytes = 0;</a>
<a name="ln619"> </a>
<a name="ln620">	return B_OK;</a>
<a name="ln621">}</a>
<a name="ln622"> </a>
<a name="ln623"> </a>
<a name="ln624">/*! \brief Fills the outBuffer with an already decoded video frame.</a>
<a name="ln625"> </a>
<a name="ln626">	Besides the main duty described above, this method also fills out the other</a>
<a name="ln627">	output parameters as documented below.</a>
<a name="ln628"> </a>
<a name="ln629">	\param outBuffer Pointer to the output buffer to copy the decoded video</a>
<a name="ln630">		frame to.</a>
<a name="ln631">	\param outFrameCount Pointer to the output variable to assign the number of</a>
<a name="ln632">		copied video frames (usually one video frame).</a>
<a name="ln633">	\param mediaHeader Pointer to the output media header that contains the</a>
<a name="ln634">		decoded video frame properties.</a>
<a name="ln635">	\param info Specifies additional decoding parameters. (Note: unused).</a>
<a name="ln636"> </a>
<a name="ln637">	\returns B_OK Decoding a video frame succeeded.</a>
<a name="ln638">	\returns B_LAST_BUFFER_ERROR There are no more video frames available.</a>
<a name="ln639">	\returns Other error codes</a>
<a name="ln640">*/</a>
<a name="ln641">status_t</a>
<a name="ln642">AVCodecDecoder::_DecodeVideo(void* outBuffer, int64* outFrameCount,</a>
<a name="ln643">	media_header* mediaHeader, media_decode_info* info)</a>
<a name="ln644">{</a>
<a name="ln645">	status_t videoDecodingStatus</a>
<a name="ln646">		= fDecodedDataSizeInBytes &gt; 0 ? B_OK : _DecodeNextVideoFrame();</a>
<a name="ln647"> </a>
<a name="ln648">	if (videoDecodingStatus != B_OK)</a>
<a name="ln649">		return videoDecodingStatus;</a>
<a name="ln650"> </a>
<a name="ln651">	*outFrameCount = 1;</a>
<a name="ln652">	*mediaHeader = fHeader;</a>
<a name="ln653">	memcpy(outBuffer, fDecodedData, mediaHeader-&gt;size_used);</a>
<a name="ln654"> </a>
<a name="ln655">	fDecodedDataSizeInBytes = 0;</a>
<a name="ln656"> </a>
<a name="ln657">	return B_OK;</a>
<a name="ln658">}</a>
<a name="ln659"> </a>
<a name="ln660"> </a>
<a name="ln661">/*!	\brief Decodes next audio frame.</a>
<a name="ln662"> </a>
<a name="ln663">	We decode at least one audio frame into fDecodedData. To achieve this goal,</a>
<a name="ln664">    we might need to request several chunks of encoded data resulting in a</a>
<a name="ln665">    variable execution time of this function.</a>
<a name="ln666"> </a>
<a name="ln667">    The length of the decoded audio frame(s) is stored in</a>
<a name="ln668">    fDecodedDataSizeInBytes. If this variable is greater than zero you can</a>
<a name="ln669">    assert that all audio frames in fDecodedData are valid.</a>
<a name="ln670"> </a>
<a name="ln671">	It is assumed that the number of expected audio frames is stored in</a>
<a name="ln672">	fOutputFrameCount. So _DecodeNextAudioFrame() must be called only after</a>
<a name="ln673">	fOutputFrameCount has been set.</a>
<a name="ln674"> </a>
<a name="ln675">	Note: fOutputFrameCount contains the maximum number of frames a caller</a>
<a name="ln676">	of BMediaDecoder::Decode() expects to receive. There is a direct</a>
<a name="ln677">	relationship between fOutputFrameCount and the buffer size a caller of</a>
<a name="ln678">	BMediaDecoder::Decode() will provide so we make sure to respect this limit</a>
<a name="ln679">	for fDecodedDataSizeInBytes.</a>
<a name="ln680"> </a>
<a name="ln681">	On return with status code B_OK the following conditions hold true:</a>
<a name="ln682">		1. fDecodedData contains as much audio frames as the caller of</a>
<a name="ln683">		   BMediaDecoder::Decode() expects.</a>
<a name="ln684">		2. fDecodedData contains lesser audio frames as the caller of</a>
<a name="ln685">		   BMediaDecoder::Decode() expects only when one of the following</a>
<a name="ln686">		   conditions hold true:</a>
<a name="ln687">		       i  No more audio frames left. Consecutive calls to</a>
<a name="ln688">		          _DecodeNextAudioFrame() will then result in the return of</a>
<a name="ln689">		          status code B_LAST_BUFFER_ERROR.</a>
<a name="ln690">		       ii TODO: A change in the size of the audio frames.</a>
<a name="ln691">		3. fHeader is populated with the audio frame properties of the first</a>
<a name="ln692">		   audio frame in fDecodedData. Especially the start_time field of</a>
<a name="ln693">		   fHeader relates to that first audio frame. Start times of</a>
<a name="ln694">		   consecutive audio frames in fDecodedData have to be calculated</a>
<a name="ln695">		   manually (using the frame rate and the frame duration) if the</a>
<a name="ln696">		   caller needs them.</a>
<a name="ln697"> </a>
<a name="ln698">	TODO: Handle change of channel_count. Such a change results in a change of</a>
<a name="ln699">	the audio frame size and thus has different buffer requirements.</a>
<a name="ln700">	The most sane approach for implementing this is to return the audio frames</a>
<a name="ln701">	that were still decoded with the previous channel_count and inform the</a>
<a name="ln702">	client of BMediaDecoder::Decode() about the change so that it can adapt to</a>
<a name="ln703">	it. Furthermore we need to adapt our fDecodedData to the new buffer size</a>
<a name="ln704">	requirements accordingly.</a>
<a name="ln705"> </a>
<a name="ln706">	\returns B_OK when we successfully decoded enough audio frames</a>
<a name="ln707">	\returns B_LAST_BUFFER_ERROR when there are no more audio frames available.</a>
<a name="ln708">	\returns Other Errors</a>
<a name="ln709">*/</a>
<a name="ln710">status_t</a>
<a name="ln711">AVCodecDecoder::_DecodeNextAudioFrame()</a>
<a name="ln712">{</a>
<a name="ln713">	assert(fTempPacket.size &gt;= 0);</a>
<a name="ln714">	assert(fDecodedDataSizeInBytes == 0);</a>
<a name="ln715">		// _DecodeNextAudioFrame needs to be called on empty fDecodedData only!</a>
<a name="ln716">		// If this assert holds wrong we have a bug somewhere.</a>
<a name="ln717"> </a>
<a name="ln718">	status_t resetStatus = _ResetRawDecodedAudio();</a>
<a name="ln719">	if (resetStatus != B_OK)</a>
<a name="ln720">		return resetStatus;</a>
<a name="ln721"> </a>
<a name="ln722">	while (fRawDecodedAudio-&gt;nb_samples &lt; fOutputFrameCount) {</a>
<a name="ln723">		_CheckAndFixConditionsThatHintAtBrokenAudioCodeBelow();</a>
<a name="ln724"> </a>
<a name="ln725">		bool decodedDataBufferHasData = fDecodedDataBufferSize &gt; 0;</a>
<a name="ln726">		if (decodedDataBufferHasData) {</a>
<a name="ln727">			_MoveAudioFramesToRawDecodedAudioAndUpdateStartTimes();</a>
<a name="ln728">			continue;</a>
<a name="ln729">		}</a>
<a name="ln730"> </a>
<a name="ln731">		status_t decodeAudioChunkStatus = _DecodeNextAudioFrameChunk();</a>
<a name="ln732">		if (decodeAudioChunkStatus != B_OK)</a>
<a name="ln733">			return decodeAudioChunkStatus;</a>
<a name="ln734">	}</a>
<a name="ln735"> </a>
<a name="ln736">	fFrame += fRawDecodedAudio-&gt;nb_samples;</a>
<a name="ln737">	fDecodedDataSizeInBytes = fRawDecodedAudio-&gt;linesize[0];</a>
<a name="ln738"> </a>
<a name="ln739">	_UpdateMediaHeaderForAudioFrame();</a>
<a name="ln740"> </a>
<a name="ln741">#ifdef DEBUG</a>
<a name="ln742">	dump_ffframe_audio(fRawDecodedAudio, &quot;ffaudi&quot;);</a>
<a name="ln743">#endif</a>
<a name="ln744"> </a>
<a name="ln745">	TRACE_AUDIO(&quot;  frame count: %ld current: %lld\n&quot;,</a>
<a name="ln746">		fRawDecodedAudio-&gt;nb_samples, fFrame);</a>
<a name="ln747"> </a>
<a name="ln748">	return B_OK;</a>
<a name="ln749">}</a>
<a name="ln750"> </a>
<a name="ln751"> </a>
<a name="ln752">/*!	\brief Applies all essential audio input properties to fCodecContext that were</a>
<a name="ln753">		passed to AVCodecDecoder when Setup() was called.</a>
<a name="ln754"> </a>
<a name="ln755">	Note: This function must be called before the AVCodec is opened via</a>
<a name="ln756">	avcodec_open2(). Otherwise the behaviour of FFMPEG's audio decoding</a>
<a name="ln757">	function avcodec_decode_audio4() is undefined.</a>
<a name="ln758"> </a>
<a name="ln759">	Essential properties applied from fInputFormat.u.encoded_audio:</a>
<a name="ln760">		- bit_rate copied to fCodecContext-&gt;bit_rate</a>
<a name="ln761">		- frame_size copied to fCodecContext-&gt;frame_size</a>
<a name="ln762">		- output.format converted to fCodecContext-&gt;sample_fmt</a>
<a name="ln763">		- output.frame_rate copied to fCodecContext-&gt;sample_rate</a>
<a name="ln764">		- output.channel_count copied to fCodecContext-&gt;channels</a>
<a name="ln765"> </a>
<a name="ln766">	Other essential properties being applied:</a>
<a name="ln767">		- fBlockAlign to fCodecContext-&gt;block_align</a>
<a name="ln768">		- fExtraData to fCodecContext-&gt;extradata</a>
<a name="ln769">		- fExtraDataSize to fCodecContext-&gt;extradata_size</a>
<a name="ln770"> </a>
<a name="ln771">	TODO: Either the following documentation section should be removed or this</a>
<a name="ln772">	TODO when it is clear whether fInputFormat.MetaData() and</a>
<a name="ln773">	fInputFormat.MetaDataSize() have to be applied to fCodecContext. See the related</a>
<a name="ln774">	TODO in the method implementation.</a>
<a name="ln775">	Only applied when fInputFormat.MetaDataSize() is greater than zero:</a>
<a name="ln776">		- fInputFormat.MetaData() to fCodecContext-&gt;extradata</a>
<a name="ln777">		- fInputFormat.MetaDataSize() to fCodecContext-&gt;extradata_size</a>
<a name="ln778">*/</a>
<a name="ln779">void</a>
<a name="ln780">AVCodecDecoder::_ApplyEssentialAudioContainerPropertiesToContext()</a>
<a name="ln781">{</a>
<a name="ln782">	media_encoded_audio_format containerProperties</a>
<a name="ln783">		= fInputFormat.u.encoded_audio;</a>
<a name="ln784"> </a>
<a name="ln785">	fCodecContext-&gt;bit_rate</a>
<a name="ln786">		= static_cast&lt;int&gt;(containerProperties.bit_rate);</a>
<a name="ln787">	fCodecContext-&gt;frame_size</a>
<a name="ln788">		= static_cast&lt;int&gt;(containerProperties.frame_size);</a>
<a name="ln789">	ConvertRawAudioFormatToAVSampleFormat(</a>
<a name="ln790">		containerProperties.output.format, fCodecContext-&gt;sample_fmt);</a>
<a name="ln791">	ConvertRawAudioFormatToAVSampleFormat(</a>
<a name="ln792">		containerProperties.output.format, fCodecContext-&gt;request_sample_fmt);</a>
<a name="ln793">	fCodecContext-&gt;sample_rate</a>
<a name="ln794">		= static_cast&lt;int&gt;(containerProperties.output.frame_rate);</a>
<a name="ln795">	fCodecContext-&gt;channels</a>
<a name="ln796">		= static_cast&lt;int&gt;(containerProperties.output.channel_count);</a>
<a name="ln797">	// Check that channel count is not still a wild card!</a>
<a name="ln798">	if (fCodecContext-&gt;channels == 0) {</a>
<a name="ln799">		TRACE(&quot;  channel_count still a wild-card, assuming stereo.\n&quot;);</a>
<a name="ln800">		fCodecContext-&gt;channels = 2;</a>
<a name="ln801">	}</a>
<a name="ln802"> </a>
<a name="ln803">	fCodecContext-&gt;block_align = fBlockAlign;</a>
<a name="ln804">	fCodecContext-&gt;extradata = reinterpret_cast&lt;uint8_t*&gt;(fExtraData);</a>
<a name="ln805">	fCodecContext-&gt;extradata_size = fExtraDataSize;</a>
<a name="ln806"> </a>
<a name="ln807">	// TODO: This probably needs to go away, there is some misconception</a>
<a name="ln808">	// about extra data / info buffer and meta data. See</a>
<a name="ln809">	// Reader::GetStreamInfo(). The AVFormatReader puts extradata and</a>
<a name="ln810">	// extradata_size into media_format::MetaData(), but used to ignore</a>
<a name="ln811">	// the infoBuffer passed to GetStreamInfo(). I think this may be why</a>
<a name="ln812">	// the code below was added.</a>
<a name="ln813">	if (fInputFormat.MetaDataSize() &gt; 0) {</a>
<a name="ln814">		fCodecContext-&gt;extradata = static_cast&lt;uint8_t*&gt;(</a>
<a name="ln815">			const_cast&lt;void*&gt;(fInputFormat.MetaData()));</a>
<a name="ln816">		fCodecContext-&gt;extradata_size = fInputFormat.MetaDataSize();</a>
<a name="ln817">	}</a>
<a name="ln818"> </a>
<a name="ln819">	TRACE(&quot;  bit_rate %d, sample_rate %d, channels %d, block_align %d, &quot;</a>
<a name="ln820">		&quot;extradata_size %d\n&quot;,</a>
<a name="ln821">		fCodecContext-&gt;bit_rate,</a>
<a name="ln822">		fCodecContext-&gt;sample_rate,</a>
<a name="ln823">		fCodecContext-&gt;channels,</a>
<a name="ln824">		fCodecContext-&gt;block_align,</a>
<a name="ln825">		fCodecContext-&gt;extradata_size);</a>
<a name="ln826">}</a>
<a name="ln827"> </a>
<a name="ln828"> </a>
<a name="ln829">/*!	\brief Resets important fields in fRawDecodedVideo to their default values.</a>
<a name="ln830"> </a>
<a name="ln831">	Note: Also initializes fDecodedData if not done already.</a>
<a name="ln832"> </a>
<a name="ln833">	\returns B_OK Resetting successfully completed.</a>
<a name="ln834">	\returns B_NO_MEMORY No memory left for correct operation.</a>
<a name="ln835">*/</a>
<a name="ln836">status_t</a>
<a name="ln837">AVCodecDecoder::_ResetRawDecodedAudio()</a>
<a name="ln838">{</a>
<a name="ln839">	if (fDecodedData == NULL) {</a>
<a name="ln840">		size_t maximumSizeOfDecodedData = fOutputFrameCount * fOutputFrameSize;</a>
<a name="ln841">		fDecodedData</a>
<a name="ln842">			= static_cast&lt;uint8_t*&gt;(malloc(maximumSizeOfDecodedData));</a>
<a name="ln843">	}</a>
<a name="ln844">	if (fDecodedData == NULL)</a>
<a name="ln845">		return B_NO_MEMORY;</a>
<a name="ln846"> </a>
<a name="ln847">	fRawDecodedAudio-&gt;data[0] = fDecodedData;</a>
<a name="ln848">	fRawDecodedAudio-&gt;linesize[0] = 0;</a>
<a name="ln849">	fRawDecodedAudio-&gt;format = AV_SAMPLE_FMT_NONE;</a>
<a name="ln850">	fRawDecodedAudio-&gt;pkt_dts = AV_NOPTS_VALUE;</a>
<a name="ln851">	fRawDecodedAudio-&gt;nb_samples = 0;</a>
<a name="ln852">	memset(fRawDecodedAudio-&gt;opaque, 0, sizeof(avformat_codec_context));</a>
<a name="ln853"> </a>
<a name="ln854">	return B_OK;</a>
<a name="ln855">}</a>
<a name="ln856"> </a>
<a name="ln857"> </a>
<a name="ln858">/*!	\brief Checks fDecodedDataBufferSize and fTempPacket for invalid values,</a>
<a name="ln859">		reports them and assigns valid values.</a>
<a name="ln860"> </a>
<a name="ln861">	Note: This method is intended to be called before any code is executed that</a>
<a name="ln862">	deals with moving, loading or decoding any audio frames.</a>
<a name="ln863">*/</a>
<a name="ln864">void</a>
<a name="ln865">AVCodecDecoder::_CheckAndFixConditionsThatHintAtBrokenAudioCodeBelow()</a>
<a name="ln866">{</a>
<a name="ln867">	if (fDecodedDataBufferSize &lt; 0) {</a>
<a name="ln868">		fprintf(stderr, &quot;Decoding read past the end of the decoded data &quot;</a>
<a name="ln869">			&quot;buffer! %&quot; B_PRId32 &quot;\n&quot;, fDecodedDataBufferSize);</a>
<a name="ln870">		fDecodedDataBufferSize = 0;</a>
<a name="ln871">	}</a>
<a name="ln872">	if (fTempPacket.size &lt; 0) {</a>
<a name="ln873">		fprintf(stderr, &quot;Decoding read past the end of the temp packet! %d\n&quot;,</a>
<a name="ln874">			fTempPacket.size);</a>
<a name="ln875">		fTempPacket.size = 0;</a>
<a name="ln876">	}</a>
<a name="ln877">}</a>
<a name="ln878"> </a>
<a name="ln879"> </a>
<a name="ln880">/*!	\brief Moves audio frames from fDecodedDataBuffer to fRawDecodedAudio (and</a>
<a name="ln881">		thus to fDecodedData) and updates the start times of fRawDecodedAudio,</a>
<a name="ln882">		fDecodedDataBuffer and fTempPacket accordingly.</a>
<a name="ln883"> </a>
<a name="ln884">	When moving audio frames to fRawDecodedAudio this method also makes sure</a>
<a name="ln885">	that the following important fields of fRawDecodedAudio are populated and</a>
<a name="ln886">	updated with correct values:</a>
<a name="ln887">		- fRawDecodedAudio-&gt;data[0]: Points to first free byte of fDecodedData</a>
<a name="ln888">		- fRawDecodedAudio-&gt;linesize[0]: Total size of frames in fDecodedData</a>
<a name="ln889">		- fRawDecodedAudio-&gt;format: Format of first audio frame</a>
<a name="ln890">		- fRawDecodedAudio-&gt;pkt_dts: Start time of first audio frame</a>
<a name="ln891">		- fRawDecodedAudio-&gt;nb_samples: Number of audio frames</a>
<a name="ln892">		- fRawDecodedAudio-&gt;opaque: Contains the following fields for the first</a>
<a name="ln893">		  audio frame:</a>
<a name="ln894">		      - channels: Channel count of first audio frame</a>
<a name="ln895">		      - sample_rate: Frame rate of first audio frame</a>
<a name="ln896"> </a>
<a name="ln897">	This function assumes to be called only when the following assumptions</a>
<a name="ln898">	hold true:</a>
<a name="ln899">		1. There are decoded audio frames available in fDecodedDataBuffer</a>
<a name="ln900">		   meaning that fDecodedDataBufferSize is greater than zero.</a>
<a name="ln901">		2. There is space left in fRawDecodedAudio to move some audio frames</a>
<a name="ln902">		   in. This means that fRawDecodedAudio has lesser audio frames than</a>
<a name="ln903">		   the maximum allowed (specified by fOutputFrameCount).</a>
<a name="ln904">		3. The audio frame rate is known so that we can calculate the time</a>
<a name="ln905">		   range (covered by the moved audio frames) to update the start times</a>
<a name="ln906">		   accordingly.</a>
<a name="ln907">		4. The field fRawDecodedAudio-&gt;opaque points to a memory block</a>
<a name="ln908">		   representing a structure of type avformat_codec_context.</a>
<a name="ln909"> </a>
<a name="ln910">	After this function returns the caller can safely make the following</a>
<a name="ln911">	assumptions:</a>
<a name="ln912">		1. The number of decoded audio frames in fDecodedDataBuffer is</a>
<a name="ln913">		   decreased though it may still be greater then zero.</a>
<a name="ln914">		2. The number of frames in fRawDecodedAudio has increased and all</a>
<a name="ln915">		   important fields are updated (see listing above).</a>
<a name="ln916">		3. Start times of fDecodedDataBuffer and fTempPacket were increased</a>
<a name="ln917">		   with the time range covered by the moved audio frames.</a>
<a name="ln918"> </a>
<a name="ln919">	Note: This function raises an exception (by calling the debugger), when</a>
<a name="ln920">	fDecodedDataBufferSize is not a multiple of fOutputFrameSize.</a>
<a name="ln921">*/</a>
<a name="ln922">void</a>
<a name="ln923">AVCodecDecoder::_MoveAudioFramesToRawDecodedAudioAndUpdateStartTimes()</a>
<a name="ln924">{</a>
<a name="ln925">	assert(fDecodedDataBufferSize &gt; 0);</a>
<a name="ln926">	assert(fRawDecodedAudio-&gt;nb_samples &lt; fOutputFrameCount);</a>
<a name="ln927">	assert(fOutputFrameRate &gt; 0);</a>
<a name="ln928"> </a>
<a name="ln929">	int32 outFrames = fOutputFrameCount - fRawDecodedAudio-&gt;nb_samples;</a>
<a name="ln930">	int32 inFrames = fDecodedDataBufferSize;</a>
<a name="ln931"> </a>
<a name="ln932">	int32 frames = min_c(outFrames, inFrames);</a>
<a name="ln933">	if (frames == 0)</a>
<a name="ln934">		debugger(&quot;fDecodedDataBufferSize not multiple of frame size!&quot;);</a>
<a name="ln935"> </a>
<a name="ln936">	// Some decoders do not support format conversion on themselves, or use</a>
<a name="ln937">	// &quot;planar&quot; audio (each channel separated instead of interleaved samples).</a>
<a name="ln938">	// In that case, we use swresample to convert the data</a>
<a name="ln939">	if (av_sample_fmt_is_planar(fCodecContext-&gt;sample_fmt)) {</a>
<a name="ln940">#if 0</a>
<a name="ln941">		const uint8_t* ptr[8];</a>
<a name="ln942">		for (int i = 0; i &lt; 8; i++) {</a>
<a name="ln943">			if (fDecodedDataBuffer-&gt;data[i] == NULL)</a>
<a name="ln944">				ptr[i] = NULL;</a>
<a name="ln945">			else</a>
<a name="ln946">				ptr[i] = fDecodedDataBuffer-&gt;data[i] + fDecodedDataBufferOffset;</a>
<a name="ln947">		}</a>
<a name="ln948"> </a>
<a name="ln949">		// When there are more input frames than space in the output buffer,</a>
<a name="ln950">		// we could feed everything to swr and it would buffer the extra data.</a>
<a name="ln951">		// However, there is no easy way to flush that data without feeding more</a>
<a name="ln952">		// input, and it makes our timestamp computations fail.</a>
<a name="ln953">		// So, we feed only as much frames as we can get out, and handle the</a>
<a name="ln954">		// buffering ourselves.</a>
<a name="ln955">		// TODO Ideally, we should try to size our output buffer so that it can</a>
<a name="ln956">		// always hold all the output (swr provides helper functions for this)</a>
<a name="ln957">		inFrames = frames;</a>
<a name="ln958">		frames = swr_convert(fResampleContext, fRawDecodedAudio-&gt;data,</a>
<a name="ln959">			outFrames, ptr, inFrames);</a>
<a name="ln960"> </a>
<a name="ln961">		if (frames &lt; 0)</a>
<a name="ln962">			debugger(&quot;resampling failed&quot;);</a>
<a name="ln963">#else</a>
<a name="ln964">		// interleave planar audio with same format</a>
<a name="ln965">		uintptr_t out = (uintptr_t)fRawDecodedAudio-&gt;data[0];</a>
<a name="ln966">		int32 offset = fDecodedDataBufferOffset;</a>
<a name="ln967">		for (int i = 0; i &lt; frames; i++) {</a>
<a name="ln968">			for (int j = 0; j &lt; fCodecContext-&gt;channels; j++) {</a>
<a name="ln969">				memcpy((void*)out, fDecodedDataBuffer-&gt;data[j]</a>
<a name="ln970">					+ offset, fInputFrameSize);</a>
<a name="ln971">				out += fInputFrameSize;</a>
<a name="ln972">			}</a>
<a name="ln973">			offset += fInputFrameSize;</a>
<a name="ln974">		}</a>
<a name="ln975">		outFrames = frames;</a>
<a name="ln976">		inFrames = frames;</a>
<a name="ln977">#endif</a>
<a name="ln978">	} else {</a>
<a name="ln979">		memcpy(fRawDecodedAudio-&gt;data[0], fDecodedDataBuffer-&gt;data[0]</a>
<a name="ln980">				+ fDecodedDataBufferOffset, frames * fOutputFrameSize);</a>
<a name="ln981">		outFrames = frames;</a>
<a name="ln982">		inFrames = frames;</a>
<a name="ln983">	}</a>
<a name="ln984"> </a>
<a name="ln985">	size_t remainingSize = inFrames * fInputFrameSize;</a>
<a name="ln986">	size_t decodedSize = outFrames * fOutputFrameSize;</a>
<a name="ln987">	fDecodedDataBufferSize -= inFrames;</a>
<a name="ln988"> </a>
<a name="ln989">	bool firstAudioFramesCopiedToRawDecodedAudio</a>
<a name="ln990">		= fRawDecodedAudio-&gt;data[0] != fDecodedData;</a>
<a name="ln991">	if (!firstAudioFramesCopiedToRawDecodedAudio) {</a>
<a name="ln992">		fRawDecodedAudio-&gt;format = fDecodedDataBuffer-&gt;format;</a>
<a name="ln993">		fRawDecodedAudio-&gt;pkt_dts = fDecodedDataBuffer-&gt;pkt_dts;</a>
<a name="ln994"> </a>
<a name="ln995">		avformat_codec_context* codecContext</a>
<a name="ln996">			= static_cast&lt;avformat_codec_context*&gt;(fRawDecodedAudio-&gt;opaque);</a>
<a name="ln997">		codecContext-&gt;channels = fCodecContext-&gt;channels;</a>
<a name="ln998">		codecContext-&gt;sample_rate = fCodecContext-&gt;sample_rate;</a>
<a name="ln999">	}</a>
<a name="ln1000"> </a>
<a name="ln1001">	fRawDecodedAudio-&gt;data[0] += decodedSize;</a>
<a name="ln1002">	fRawDecodedAudio-&gt;linesize[0] += decodedSize;</a>
<a name="ln1003">	fRawDecodedAudio-&gt;nb_samples += outFrames;</a>
<a name="ln1004"> </a>
<a name="ln1005">	fDecodedDataBufferOffset += remainingSize;</a>
<a name="ln1006"> </a>
<a name="ln1007">	// Update start times accordingly</a>
<a name="ln1008">	bigtime_t framesTimeInterval = static_cast&lt;bigtime_t&gt;(</a>
<a name="ln1009">		(1000000LL * frames) / fOutputFrameRate);</a>
<a name="ln1010">	fDecodedDataBuffer-&gt;pkt_dts += framesTimeInterval;</a>
<a name="ln1011">	// Start time of buffer is updated in case that it contains</a>
<a name="ln1012">	// more audio frames to move.</a>
<a name="ln1013">	fTempPacket.dts += framesTimeInterval;</a>
<a name="ln1014">	// Start time of fTempPacket is updated in case the fTempPacket</a>
<a name="ln1015">	// contains more audio frames to decode.</a>
<a name="ln1016">}</a>
<a name="ln1017"> </a>
<a name="ln1018"> </a>
<a name="ln1019">/*!	\brief Decodes next chunk of audio frames.</a>
<a name="ln1020"> </a>
<a name="ln1021">	This method handles all the details of loading the input buffer</a>
<a name="ln1022">	(fChunkBuffer) at the right time and of calling FFMPEG often engouh until</a>
<a name="ln1023">	some audio frames have been decoded.</a>
<a name="ln1024"> </a>
<a name="ln1025">	FFMPEG decides how much audio frames belong to a chunk. Because of that</a>
<a name="ln1026">	it is very likely that _DecodeNextAudioFrameChunk has to be called several</a>
<a name="ln1027">	times to decode enough audio frames to please the caller of</a>
<a name="ln1028">	BMediaDecoder::Decode().</a>
<a name="ln1029"> </a>
<a name="ln1030">	This function assumes to be called only when the following assumptions</a>
<a name="ln1031">	hold true:</a>
<a name="ln1032">		1. fDecodedDataBufferSize equals zero.</a>
<a name="ln1033"> </a>
<a name="ln1034">	After this function returns successfully the caller can safely make the</a>
<a name="ln1035">	following assumptions:</a>
<a name="ln1036">		1. fDecodedDataBufferSize is greater than zero.</a>
<a name="ln1037">		2. fDecodedDataBufferOffset is set to zero.</a>
<a name="ln1038">		3. fDecodedDataBuffer contains audio frames.</a>
<a name="ln1039"> </a>
<a name="ln1040"> </a>
<a name="ln1041">	\returns B_OK on successfully decoding one audio frame chunk.</a>
<a name="ln1042">	\returns B_LAST_BUFFER_ERROR No more audio frame chunks available. From</a>
<a name="ln1043">		this point on further calls will return this same error.</a>
<a name="ln1044">	\returns B_ERROR Decoding failed</a>
<a name="ln1045">*/</a>
<a name="ln1046">status_t</a>
<a name="ln1047">AVCodecDecoder::_DecodeNextAudioFrameChunk()</a>
<a name="ln1048">{</a>
<a name="ln1049">	assert(fDecodedDataBufferSize == 0);</a>
<a name="ln1050"> </a>
<a name="ln1051">	while (fDecodedDataBufferSize == 0) {</a>
<a name="ln1052">		status_t loadingChunkStatus</a>
<a name="ln1053">			= _LoadNextChunkIfNeededAndAssignStartTime();</a>
<a name="ln1054">		if (loadingChunkStatus != B_OK)</a>
<a name="ln1055">			return loadingChunkStatus;</a>
<a name="ln1056"> </a>
<a name="ln1057">		status_t decodingStatus</a>
<a name="ln1058">			= _DecodeSomeAudioFramesIntoEmptyDecodedDataBuffer();</a>
<a name="ln1059">		if (decodingStatus != B_OK) {</a>
<a name="ln1060">			// Assume the audio decoded until now is broken so replace it with</a>
<a name="ln1061">			// some silence.</a>
<a name="ln1062">			memset(fDecodedData, 0, fRawDecodedAudio-&gt;linesize[0]);</a>
<a name="ln1063"> </a>
<a name="ln1064">			if (!fAudioDecodeError) {</a>
<a name="ln1065">				// Report failure if not done already</a>
<a name="ln1066">				int32 chunkBufferOffset = fTempPacket.data - fChunkBuffer;</a>
<a name="ln1067">				printf(&quot;########### audio decode error, &quot;</a>
<a name="ln1068">					&quot;fTempPacket.size %d, fChunkBuffer data offset %&quot; B_PRId32</a>
<a name="ln1069">					&quot;\n&quot;, fTempPacket.size, chunkBufferOffset);</a>
<a name="ln1070">				fAudioDecodeError = true;</a>
<a name="ln1071">			}</a>
<a name="ln1072"> </a>
<a name="ln1073">			// Assume that next audio chunk can be decoded so keep decoding.</a>
<a name="ln1074">			continue;</a>
<a name="ln1075">		}</a>
<a name="ln1076"> </a>
<a name="ln1077">		fAudioDecodeError = false;</a>
<a name="ln1078">	}</a>
<a name="ln1079"> </a>
<a name="ln1080">	return B_OK;</a>
<a name="ln1081">}</a>
<a name="ln1082"> </a>
<a name="ln1083"> </a>
<a name="ln1084">/*!	\brief Tries to decode at least one audio frame and store it in the</a>
<a name="ln1085">		fDecodedDataBuffer.</a>
<a name="ln1086"> </a>
<a name="ln1087">	This function assumes to be called only when the following assumptions</a>
<a name="ln1088">	hold true:</a>
<a name="ln1089">		1. fDecodedDataBufferSize equals zero.</a>
<a name="ln1090">		2. fTempPacket.size is greater than zero.</a>
<a name="ln1091"> </a>
<a name="ln1092">	After this function returns successfully the caller can safely make the</a>
<a name="ln1093">	following assumptions:</a>
<a name="ln1094">		1. fDecodedDataBufferSize is greater than zero in the common case.</a>
<a name="ln1095">		   Also see &quot;Note&quot; below.</a>
<a name="ln1096">		2. fTempPacket was updated to exclude the data chunk that was consumed</a>
<a name="ln1097">		   by avcodec_decode_audio4().</a>
<a name="ln1098">		3. fDecodedDataBufferOffset is set to zero.</a>
<a name="ln1099"> </a>
<a name="ln1100">	When this function failed to decode at least one audio frame due to a</a>
<a name="ln1101">	decoding error the caller can safely make the following assumptions:</a>
<a name="ln1102">		1. fDecodedDataBufferSize equals zero.</a>
<a name="ln1103">		2. fTempPacket.size equals zero.</a>
<a name="ln1104"> </a>
<a name="ln1105">	Note: It is possible that there wasn't any audio frame decoded into</a>
<a name="ln1106">	fDecodedDataBuffer after calling this function. This is normal and can</a>
<a name="ln1107">	happen when there was either a decoding error or there is some decoding</a>
<a name="ln1108">	delay in FFMPEGs audio decoder. Another call to this method is totally</a>
<a name="ln1109">	safe and is even expected as long as the calling assumptions hold true.</a>
<a name="ln1110"> </a>
<a name="ln1111">	\returns B_OK Decoding successful. fDecodedDataBuffer contains decoded</a>
<a name="ln1112">		audio frames only when fDecodedDataBufferSize is greater than zero.</a>
<a name="ln1113">		fDecodedDataBuffer is empty, when avcodec_decode_audio4() didn't return</a>
<a name="ln1114">		audio frames due to delayed decoding or incomplete audio frames.</a>
<a name="ln1115">	\returns B_ERROR Decoding failed thus fDecodedDataBuffer contains no audio</a>
<a name="ln1116">		frames.</a>
<a name="ln1117">*/</a>
<a name="ln1118">status_t</a>
<a name="ln1119">AVCodecDecoder::_DecodeSomeAudioFramesIntoEmptyDecodedDataBuffer()</a>
<a name="ln1120">{</a>
<a name="ln1121">	assert(fDecodedDataBufferSize == 0);</a>
<a name="ln1122"> </a>
<a name="ln1123">	memset(fDecodedDataBuffer, 0, sizeof(AVFrame));</a>
<a name="ln1124">    av_frame_unref(fDecodedDataBuffer);</a>
<a name="ln1125">	fDecodedDataBufferOffset = 0;</a>
<a name="ln1126">	int gotAudioFrame = 0;</a>
<a name="ln1127"> </a>
<a name="ln1128">	int encodedDataSizeInBytes = avcodec_decode_audio4(fCodecContext,</a>
<a name="ln1129">		fDecodedDataBuffer, &amp;gotAudioFrame, &amp;fTempPacket);</a>
<a name="ln1130">	if (encodedDataSizeInBytes &lt;= 0) {</a>
<a name="ln1131">		// Error or failure to produce decompressed output.</a>
<a name="ln1132">		// Skip the temp packet data entirely.</a>
<a name="ln1133">		fTempPacket.size = 0;</a>
<a name="ln1134">		return B_ERROR;</a>
<a name="ln1135">	}</a>
<a name="ln1136"> </a>
<a name="ln1137">	fTempPacket.data += encodedDataSizeInBytes;</a>
<a name="ln1138">	fTempPacket.size -= encodedDataSizeInBytes;</a>
<a name="ln1139"> </a>
<a name="ln1140">	bool gotNoAudioFrame = gotAudioFrame == 0;</a>
<a name="ln1141">	if (gotNoAudioFrame)</a>
<a name="ln1142">		return B_OK;</a>
<a name="ln1143"> </a>
<a name="ln1144">	fDecodedDataBufferSize = fDecodedDataBuffer-&gt;nb_samples;</a>
<a name="ln1145">	if (fDecodedDataBufferSize &lt; 0)</a>
<a name="ln1146">		fDecodedDataBufferSize = 0;</a>
<a name="ln1147"> </a>
<a name="ln1148">	return B_OK;</a>
<a name="ln1149">}</a>
<a name="ln1150"> </a>
<a name="ln1151"> </a>
<a name="ln1152">/*! \brief Updates relevant fields of the class member fHeader with the</a>
<a name="ln1153">		properties of the most recently decoded audio frame.</a>
<a name="ln1154"> </a>
<a name="ln1155">	The following fields of fHeader are updated:</a>
<a name="ln1156">		- fHeader.type</a>
<a name="ln1157">		- fHeader.file_pos</a>
<a name="ln1158">		- fHeader.orig_size</a>
<a name="ln1159">		- fHeader.start_time</a>
<a name="ln1160">		- fHeader.size_used</a>
<a name="ln1161">		- fHeader.u.raw_audio.frame_rate</a>
<a name="ln1162">		- fHeader.u.raw_audio.channel_count</a>
<a name="ln1163"> </a>
<a name="ln1164">	It is assumed that this function is called only	when the following asserts</a>
<a name="ln1165">	hold true:</a>
<a name="ln1166">		1. We actually got a new audio frame decoded by the audio decoder.</a>
<a name="ln1167">		2. fHeader wasn't updated for the new audio frame yet. You MUST call</a>
<a name="ln1168">		   this method only once per decoded audio frame.</a>
<a name="ln1169">		3. fRawDecodedAudio's fields relate to the first audio frame contained</a>
<a name="ln1170">		   in fDecodedData. Especially the following fields are of importance:</a>
<a name="ln1171">		       - fRawDecodedAudio-&gt;pkt_dts: Start time of first audio frame</a>
<a name="ln1172">		       - fRawDecodedAudio-&gt;opaque: Contains the following fields for</a>
<a name="ln1173">		         the first audio frame:</a>
<a name="ln1174">			         - channels: Channel count of first audio frame</a>
<a name="ln1175">			         - sample_rate: Frame rate of first audio frame</a>
<a name="ln1176">*/</a>
<a name="ln1177">void</a>
<a name="ln1178">AVCodecDecoder::_UpdateMediaHeaderForAudioFrame()</a>
<a name="ln1179">{</a>
<a name="ln1180">	fHeader.type = B_MEDIA_RAW_AUDIO;</a>
<a name="ln1181">	fHeader.file_pos = 0;</a>
<a name="ln1182">	fHeader.orig_size = 0;</a>
<a name="ln1183">	fHeader.start_time = fRawDecodedAudio-&gt;pkt_dts;</a>
<a name="ln1184">	fHeader.size_used = fRawDecodedAudio-&gt;linesize[0];</a>
<a name="ln1185"> </a>
<a name="ln1186">	avformat_codec_context* codecContext</a>
<a name="ln1187">		= static_cast&lt;avformat_codec_context*&gt;(fRawDecodedAudio-&gt;opaque);</a>
<a name="ln1188">	fHeader.u.raw_audio.channel_count = codecContext-&gt;channels;</a>
<a name="ln1189">	fHeader.u.raw_audio.frame_rate = codecContext-&gt;sample_rate;</a>
<a name="ln1190">}</a>
<a name="ln1191"> </a>
<a name="ln1192"> </a>
<a name="ln1193">/*! \brief Decodes next video frame.</a>
<a name="ln1194"> </a>
<a name="ln1195">    We decode exactly one video frame into fDecodedData. To achieve this goal,</a>
<a name="ln1196">    we might need to request several chunks of encoded data resulting in a</a>
<a name="ln1197">    variable execution time of this function.</a>
<a name="ln1198"> </a>
<a name="ln1199">    The length of the decoded video frame is stored in</a>
<a name="ln1200">    fDecodedDataSizeInBytes. If this variable is greater than zero, you can</a>
<a name="ln1201">    assert that there is a valid video frame available in fDecodedData.</a>
<a name="ln1202"> </a>
<a name="ln1203">    The decoded video frame in fDecodedData has color space conversion and</a>
<a name="ln1204">    deinterlacing already applied.</a>
<a name="ln1205"> </a>
<a name="ln1206">    To every decoded video frame there is a media_header populated in</a>
<a name="ln1207">    fHeader, containing the corresponding video frame properties.</a>
<a name="ln1208"> </a>
<a name="ln1209">	Normally every decoded video frame has a start_time field populated in the</a>
<a name="ln1210">	associated fHeader, that determines the presentation time of the frame.</a>
<a name="ln1211">	This relationship will only hold true, when each data chunk that is</a>
<a name="ln1212">	provided via GetNextChunk() contains data for exactly one encoded video</a>
<a name="ln1213">	frame (one complete frame) - not more and not less.</a>
<a name="ln1214"> </a>
<a name="ln1215">	We can decode data chunks that contain partial video frame data, too. In</a>
<a name="ln1216">	that case, you cannot trust the value of the start_time field in fHeader.</a>
<a name="ln1217">	We simply have no logic in place to establish a meaningful relationship</a>
<a name="ln1218">	between an incomplete frame and the start time it should be presented.</a>
<a name="ln1219">	Though this	might change in the future.</a>
<a name="ln1220"> </a>
<a name="ln1221">	We can decode data chunks that contain more than one video frame, too. In</a>
<a name="ln1222">	that case, you cannot trust the value of the start_time field in fHeader.</a>
<a name="ln1223">	We simply have no logic in place to track the start_time across multiple</a>
<a name="ln1224">	video frames. So a meaningful relationship between the 2nd, 3rd, ... frame</a>
<a name="ln1225">	and the start time it should be presented isn't established at the moment.</a>
<a name="ln1226">	Though this	might change in the future.</a>
<a name="ln1227"> </a>
<a name="ln1228">	More over the fOutputFrameRate variable is updated for every decoded video</a>
<a name="ln1229">	frame.</a>
<a name="ln1230"> </a>
<a name="ln1231">	On first call the member variables fSwsContext / fFormatConversionFunc	are</a>
<a name="ln1232">	initialized.</a>
<a name="ln1233"> </a>
<a name="ln1234">	\returns B_OK when we successfully decoded one video frame</a>
<a name="ln1235">	\returns B_LAST_BUFFER_ERROR when there are no more video frames available.</a>
<a name="ln1236">	\returns B_NO_MEMORY when we have no memory left for correct operation.</a>
<a name="ln1237">	\returns Other Errors</a>
<a name="ln1238">*/</a>
<a name="ln1239">status_t</a>
<a name="ln1240">AVCodecDecoder::_DecodeNextVideoFrame()</a>
<a name="ln1241">{</a>
<a name="ln1242">	int error;</a>
<a name="ln1243">	int send_error;</a>
<a name="ln1244"> </a>
<a name="ln1245">#if DO_PROFILING</a>
<a name="ln1246">	bigtime_t startTime = system_time();</a>
<a name="ln1247">#endif</a>
<a name="ln1248"> </a>
<a name="ln1249">	error = avcodec_receive_frame(fCodecContext, fRawDecodedPicture);</a>
<a name="ln1250"> </a>
<a name="ln1251">	if (error == AVERROR(EAGAIN)) {</a>
<a name="ln1252">		do {</a>
<a name="ln1253">			status_t loadingChunkStatus</a>
<a name="ln1254">				= _LoadNextChunkIfNeededAndAssignStartTime();</a>
<a name="ln1255">			if (loadingChunkStatus == B_LAST_BUFFER_ERROR)</a>
<a name="ln1256">				return _FlushOneVideoFrameFromDecoderBuffer();</a>
<a name="ln1257">			if (loadingChunkStatus != B_OK) {</a>
<a name="ln1258">				TRACE(&quot;[v] AVCodecDecoder::_DecodeNextVideoFrame(): error from &quot;</a>
<a name="ln1259">					&quot;GetNextChunk(): %s\n&quot;, strerror(loadingChunkStatus));</a>
<a name="ln1260">				return loadingChunkStatus;</a>
<a name="ln1261">			}</a>
<a name="ln1262"> </a>
<a name="ln1263">			char timestamp[AV_TS_MAX_STRING_SIZE];</a>
<a name="ln1264">			av_ts_make_time_string(timestamp,</a>
<a name="ln1265">				fTempPacket.dts, &amp;fCodecContext-&gt;time_base);</a>
<a name="ln1266">			TRACE(&quot;[v] Feed %d more bytes (dts %s)\n&quot;, fTempPacket.size,</a>
<a name="ln1267">				timestamp);</a>
<a name="ln1268"> </a>
<a name="ln1269">			send_error = avcodec_send_packet(fCodecContext, &amp;fTempPacket);</a>
<a name="ln1270">			if (send_error &lt; 0 &amp;&amp; send_error != AVERROR(EAGAIN)) {</a>
<a name="ln1271">				TRACE(&quot;[v] AVCodecDecoder: ignoring error in decoding frame &quot;</a>
<a name="ln1272">				&quot;%lld: %d\n&quot;, fFrame, error);</a>
<a name="ln1273">			}</a>
<a name="ln1274"> </a>
<a name="ln1275">			// Packet is consumed, clear it</a>
<a name="ln1276">			fTempPacket.data = NULL;</a>
<a name="ln1277">			fTempPacket.size = 0;</a>
<a name="ln1278"> </a>
<a name="ln1279">			error = avcodec_receive_frame(fCodecContext, fRawDecodedPicture);</a>
<a name="ln1280">			if (error != 0 &amp;&amp; error != AVERROR(EAGAIN)) {</a>
<a name="ln1281">				TRACE(&quot;[v] frame %lld - decoding error, error code: %d, &quot;</a>
<a name="ln1282">					&quot;chunk size: %ld\n&quot;, fFrame, error, fChunkBufferSize);</a>
<a name="ln1283">			}</a>
<a name="ln1284"> </a>
<a name="ln1285">		} while (error != 0);</a>
<a name="ln1286">	}</a>
<a name="ln1287"> </a>
<a name="ln1288">#if DO_PROFILING</a>
<a name="ln1289">	bigtime_t formatConversionStart = system_time();</a>
<a name="ln1290">#endif</a>
<a name="ln1291"> </a>
<a name="ln1292">	status_t handleStatus = _HandleNewVideoFrameAndUpdateSystemState();</a>
<a name="ln1293">	if (handleStatus != B_OK)</a>
<a name="ln1294">		return handleStatus;</a>
<a name="ln1295"> </a>
<a name="ln1296">#if DO_PROFILING</a>
<a name="ln1297">	bigtime_t doneTime = system_time();</a>
<a name="ln1298">	decodingTime += formatConversionStart - startTime;</a>
<a name="ln1299">	conversionTime += doneTime - formatConversionStart;</a>
<a name="ln1300">	profileCounter++;</a>
<a name="ln1301">	if (!(fFrame % 5)) {</a>
<a name="ln1302">		printf(&quot;[v] profile: d1 = %lld, d2 = %lld (%lld) required %Ld\n&quot;,</a>
<a name="ln1303">			decodingTime / profileCounter, conversionTime / profileCounter,</a>
<a name="ln1304">			fFrame, bigtime_t(1000000LL / fOutputFrameRate));</a>
<a name="ln1305">		decodingTime = 0;</a>
<a name="ln1306">		conversionTime = 0;</a>
<a name="ln1307">		profileCounter = 0;</a>
<a name="ln1308">	}</a>
<a name="ln1309">#endif</a>
<a name="ln1310">	return error;</a>
<a name="ln1311">}</a>
<a name="ln1312"> </a>
<a name="ln1313"> </a>
<a name="ln1314">/*!	\brief Applies all essential video input properties to fCodecContext that were</a>
<a name="ln1315">		passed to AVCodecDecoder when Setup() was called.</a>
<a name="ln1316"> </a>
<a name="ln1317">	Note: This function must be called before the AVCodec is opened via</a>
<a name="ln1318">	avcodec_open2(). Otherwise the behaviour of FFMPEG's video decoding</a>
<a name="ln1319">	function avcodec_decode_video2() is undefined.</a>
<a name="ln1320"> </a>
<a name="ln1321">	Essential properties applied from fInputFormat.u.encoded_video.output:</a>
<a name="ln1322">		- display.line_width copied to fCodecContext-&gt;width</a>
<a name="ln1323">		- display.line_count copied to fCodecContext-&gt;height</a>
<a name="ln1324">		- pixel_width_aspect and pixel_height_aspect converted to</a>
<a name="ln1325">		  fCodecContext-&gt;sample_aspect_ratio</a>
<a name="ln1326">		- field_rate converted to fCodecContext-&gt;time_base and</a>
<a name="ln1327">		  fCodecContext-&gt;ticks_per_frame</a>
<a name="ln1328"> </a>
<a name="ln1329">	Other essential properties being applied:</a>
<a name="ln1330">		- fExtraData to fCodecContext-&gt;extradata</a>
<a name="ln1331">		- fExtraDataSize to fCodecContext-&gt;extradata_size</a>
<a name="ln1332">*/</a>
<a name="ln1333">void</a>
<a name="ln1334">AVCodecDecoder::_ApplyEssentialVideoContainerPropertiesToContext()</a>
<a name="ln1335">{</a>
<a name="ln1336">	media_raw_video_format containerProperties</a>
<a name="ln1337">		= fInputFormat.u.encoded_video.output;</a>
<a name="ln1338"> </a>
<a name="ln1339">	fCodecContext-&gt;width = containerProperties.display.line_width;</a>
<a name="ln1340">	fCodecContext-&gt;height = containerProperties.display.line_count;</a>
<a name="ln1341"> </a>
<a name="ln1342">	if (containerProperties.pixel_width_aspect &gt; 0</a>
<a name="ln1343">		&amp;&amp; containerProperties.pixel_height_aspect &gt; 0) {</a>
<a name="ln1344">		ConvertVideoAspectWidthAndHeightToAVCodecContext(</a>
<a name="ln1345">			containerProperties.pixel_width_aspect,</a>
<a name="ln1346">			containerProperties.pixel_height_aspect, *fCodecContext);</a>
<a name="ln1347">	}</a>
<a name="ln1348"> </a>
<a name="ln1349">	if (containerProperties.field_rate &gt; 0.0) {</a>
<a name="ln1350">		ConvertVideoFrameRateToAVCodecContext(containerProperties.field_rate,</a>
<a name="ln1351">			*fCodecContext);</a>
<a name="ln1352">	}</a>
<a name="ln1353"> </a>
<a name="ln1354">	fCodecContext-&gt;extradata = reinterpret_cast&lt;uint8_t*&gt;(fExtraData);</a>
<a name="ln1355">	fCodecContext-&gt;extradata_size = fExtraDataSize;</a>
<a name="ln1356">}</a>
<a name="ln1357"> </a>
<a name="ln1358"> </a>
<a name="ln1359">/*! \brief Loads the next  chunk into fChunkBuffer and assigns it (including</a>
<a name="ln1360">		the start time) to fTempPacket but only if fTempPacket is empty.</a>
<a name="ln1361"> </a>
<a name="ln1362">	\returns B_OK</a>
<a name="ln1363">		1. meaning: Next chunk is loaded.</a>
<a name="ln1364">		2. meaning: No need to load and assign anything. Proceed as usual.</a>
<a name="ln1365">	\returns B_LAST_BUFFER_ERROR No more chunks available. fChunkBuffer	and</a>
<a name="ln1366">		fTempPacket are left untouched.</a>
<a name="ln1367">	\returns Other errors Caller should bail out because fChunkBuffer and</a>
<a name="ln1368">		fTempPacket are in unknown states. Normal operation cannot be</a>
<a name="ln1369">		guaranteed.</a>
<a name="ln1370">*/</a>
<a name="ln1371">status_t</a>
<a name="ln1372">AVCodecDecoder::_LoadNextChunkIfNeededAndAssignStartTime()</a>
<a name="ln1373">{</a>
<a name="ln1374">	if (fTempPacket.size &gt; 0)</a>
<a name="ln1375">		return B_OK;</a>
<a name="ln1376"> </a>
<a name="ln1377">	const void* chunkBuffer = NULL;</a>
<a name="ln1378">	size_t chunkBufferSize = 0;</a>
<a name="ln1379">		// In the case that GetNextChunk() returns an error fChunkBufferSize</a>
<a name="ln1380">		// should be left untouched.</a>
<a name="ln1381">	media_header chunkMediaHeader;</a>
<a name="ln1382"> </a>
<a name="ln1383">	status_t getNextChunkStatus = GetNextChunk(&amp;chunkBuffer, &amp;chunkBufferSize,</a>
<a name="ln1384">		&amp;chunkMediaHeader);</a>
<a name="ln1385">	if (getNextChunkStatus != B_OK)</a>
<a name="ln1386">		return getNextChunkStatus;</a>
<a name="ln1387"> </a>
<a name="ln1388">	status_t chunkBufferPaddingStatus</a>
<a name="ln1389">		= _CopyChunkToChunkBufferAndAddPadding(chunkBuffer, chunkBufferSize);</a>
<a name="ln1390">	if (chunkBufferPaddingStatus != B_OK)</a>
<a name="ln1391">		return chunkBufferPaddingStatus;</a>
<a name="ln1392"> </a>
<a name="ln1393">	fTempPacket.data = fChunkBuffer;</a>
<a name="ln1394">	fTempPacket.size = fChunkBufferSize;</a>
<a name="ln1395">	fTempPacket.dts = chunkMediaHeader.start_time;</a>
<a name="ln1396">		// Let FFMPEG handle the correct relationship between start_time and</a>
<a name="ln1397">		// decoded a/v frame. By doing so we are simply copying the way how it</a>
<a name="ln1398">		// is implemented in ffplay.c for video frames (for audio frames it</a>
<a name="ln1399">		// works, too, but isn't used by ffplay.c).</a>
<a name="ln1400">		// \see http://git.videolan.org/?p=ffmpeg.git;a=blob;f=ffplay.c;h=09623db374e5289ed20b7cc28c262c4375a8b2e4;hb=9153b33a742c4e2a85ff6230aea0e75f5a8b26c2#l1502</a>
<a name="ln1401">		//</a>
<a name="ln1402">		// FIXME: Research how to establish a meaningful relationship between</a>
<a name="ln1403">		// start_time and decoded a/v frame when the received chunk buffer</a>
<a name="ln1404">		// contains partial a/v frames. Maybe some data formats do contain time</a>
<a name="ln1405">		// stamps (ake pts / dts fields) that can be evaluated by FFMPEG. But</a>
<a name="ln1406">		// as long as I don't have such video data to test it, it makes no</a>
<a name="ln1407">		// sense trying to implement it.</a>
<a name="ln1408">		//</a>
<a name="ln1409">		// FIXME: Implement tracking start_time of video frames originating in</a>
<a name="ln1410">		// data chunks that encode more than one video frame at a time. In that</a>
<a name="ln1411">		// case on would increment the start_time for each consecutive frame of</a>
<a name="ln1412">		// such a data chunk (like it is done for audio frame decoding). But as</a>
<a name="ln1413">		// long as I don't have such video data to test it, it makes no sense</a>
<a name="ln1414">		// to implement it.</a>
<a name="ln1415"> </a>
<a name="ln1416">#ifdef LOG_STREAM_TO_FILE</a>
<a name="ln1417">	BFile* logFile = fIsAudio ? &amp;sAudioStreamLogFile : &amp;sVideoStreamLogFile;</a>
<a name="ln1418">	if (sDumpedPackets &lt; 100) {</a>
<a name="ln1419">		logFile-&gt;Write(chunkBuffer, fChunkBufferSize);</a>
<a name="ln1420">		printf(&quot;wrote %ld bytes\n&quot;, fChunkBufferSize);</a>
<a name="ln1421">		sDumpedPackets++;</a>
<a name="ln1422">	} else if (sDumpedPackets == 100)</a>
<a name="ln1423">		logFile-&gt;Unset();</a>
<a name="ln1424">#endif</a>
<a name="ln1425"> </a>
<a name="ln1426">	return B_OK;</a>
<a name="ln1427">}</a>
<a name="ln1428"> </a>
<a name="ln1429"> </a>
<a name="ln1430">/*! \brief Copies a chunk into fChunkBuffer and adds a &quot;safety net&quot; of</a>
<a name="ln1431">		additional memory as required by FFMPEG for input buffers to video</a>
<a name="ln1432">		decoders.</a>
<a name="ln1433"> </a>
<a name="ln1434">	This is needed so that some decoders can read safely a predefined number of</a>
<a name="ln1435">	bytes at a time for performance optimization purposes.</a>
<a name="ln1436"> </a>
<a name="ln1437">	The additional memory has a size of AV_INPUT_BUFFER_PADDING_SIZE as defined</a>
<a name="ln1438">	in avcodec.h.</a>
<a name="ln1439"> </a>
<a name="ln1440">	Ownership of fChunkBuffer memory is with the class so it needs to be freed</a>
<a name="ln1441">	at the right times (on destruction, on seeking).</a>
<a name="ln1442"> </a>
<a name="ln1443">	Also update fChunkBufferSize to reflect the size of the contained data</a>
<a name="ln1444">	(leaving out the padding).</a>
<a name="ln1445"> </a>
<a name="ln1446">	\param chunk The chunk to copy.</a>
<a name="ln1447">	\param chunkSize Size of the chunk in bytes</a>
<a name="ln1448"> </a>
<a name="ln1449">	\returns B_OK Padding was successful. You are responsible for releasing the</a>
<a name="ln1450">		allocated memory. fChunkBufferSize is set to chunkSize.</a>
<a name="ln1451">	\returns B_NO_MEMORY Padding failed.</a>
<a name="ln1452">		fChunkBuffer is set to NULL making it safe to call free() on it.</a>
<a name="ln1453">		fChunkBufferSize is set to 0 to reflect the size of fChunkBuffer.</a>
<a name="ln1454">*/</a>
<a name="ln1455">status_t</a>
<a name="ln1456">AVCodecDecoder::_CopyChunkToChunkBufferAndAddPadding(const void* chunk,</a>
<a name="ln1457">	size_t chunkSize)</a>
<a name="ln1458">{</a>
<a name="ln1459">	uint8_t* tmpBuffer = static_cast&lt;uint8_t*&gt;(realloc(fChunkBuffer,</a>
<a name="ln1460">		chunkSize + AV_INPUT_BUFFER_PADDING_SIZE));</a>
<a name="ln1461">	if (tmpBuffer == NULL) {</a>
<a name="ln1462">		free(fChunkBuffer);</a>
<a name="ln1463">		fChunkBuffer = NULL;</a>
<a name="ln1464">		fChunkBufferSize = 0;</a>
<a name="ln1465">		return B_NO_MEMORY;</a>
<a name="ln1466">	} else {</a>
<a name="ln1467">		fChunkBuffer = tmpBuffer;</a>
<a name="ln1468">	}</a>
<a name="ln1469"> </a>
<a name="ln1470">	memcpy(fChunkBuffer, chunk, chunkSize);</a>
<a name="ln1471">	memset(fChunkBuffer + chunkSize, 0, AV_INPUT_BUFFER_PADDING_SIZE);</a>
<a name="ln1472">		// Establish safety net, by zero'ing the padding area.</a>
<a name="ln1473"> </a>
<a name="ln1474">	fChunkBufferSize = chunkSize;</a>
<a name="ln1475"> </a>
<a name="ln1476">	return B_OK;</a>
<a name="ln1477">}</a>
<a name="ln1478"> </a>
<a name="ln1479"> </a>
<a name="ln1480">/*! \brief Executes all steps needed for a freshly decoded video frame.</a>
<a name="ln1481"> </a>
<a name="ln1482">	\see _UpdateMediaHeaderForVideoFrame() and</a>
<a name="ln1483">	\see _DeinterlaceAndColorConvertVideoFrame() for when you are allowed to</a>
<a name="ln1484">	call this method.</a>
<a name="ln1485"> </a>
<a name="ln1486">	\returns B_OK when video frame was handled successfully</a>
<a name="ln1487">	\returnb B_NO_MEMORY when no memory is left for correct operation.</a>
<a name="ln1488">*/</a>
<a name="ln1489">status_t</a>
<a name="ln1490">AVCodecDecoder::_HandleNewVideoFrameAndUpdateSystemState()</a>
<a name="ln1491">{</a>
<a name="ln1492">	_UpdateMediaHeaderForVideoFrame();</a>
<a name="ln1493">	status_t postProcessStatus = _DeinterlaceAndColorConvertVideoFrame();</a>
<a name="ln1494">	if (postProcessStatus != B_OK)</a>
<a name="ln1495">		return postProcessStatus;</a>
<a name="ln1496"> </a>
<a name="ln1497">	ConvertAVCodecContextToVideoFrameRate(*fCodecContext, fOutputFrameRate);</a>
<a name="ln1498"> </a>
<a name="ln1499">#ifdef DEBUG</a>
<a name="ln1500">	dump_ffframe_video(fRawDecodedPicture, &quot;ffpict&quot;);</a>
<a name="ln1501">#endif</a>
<a name="ln1502"> </a>
<a name="ln1503">	fFrame++;</a>
<a name="ln1504"> </a>
<a name="ln1505">	return B_OK;</a>
<a name="ln1506">}</a>
<a name="ln1507"> </a>
<a name="ln1508"> </a>
<a name="ln1509">/*! \brief Flushes one video frame - if any - still buffered by the decoder.</a>
<a name="ln1510"> </a>
<a name="ln1511">	Some FFMPEG decoder are buffering video frames. To retrieve those buffered</a>
<a name="ln1512">	frames the decoder needs to be told so.</a>
<a name="ln1513"> </a>
<a name="ln1514">	The intended use of this method is to call it, once there are no more data</a>
<a name="ln1515">	chunks for decoding left. Reframed in other words: Once GetNextChunk()</a>
<a name="ln1516">	returns with status B_LAST_BUFFER_ERROR it is time to start flushing.</a>
<a name="ln1517"> </a>
<a name="ln1518">	\returns B_OK Retrieved one video frame, handled it accordingly and updated</a>
<a name="ln1519">		the system state accordingly.</a>
<a name="ln1520">		There maybe more video frames left. So it is valid for the client of</a>
<a name="ln1521">		AVCodecDecoder to call it one more time.</a>
<a name="ln1522"> </a>
<a name="ln1523">	\returns B_LAST_BUFFER_ERROR No video frame left.</a>
<a name="ln1524">		The client of the AVCodecDecoder should stop calling it now.</a>
<a name="ln1525"> </a>
<a name="ln1526">	\returns B_NO_MEMORY No memory left for correct operation.</a>
<a name="ln1527">*/</a>
<a name="ln1528">status_t</a>
<a name="ln1529">AVCodecDecoder::_FlushOneVideoFrameFromDecoderBuffer()</a>
<a name="ln1530">{</a>
<a name="ln1531">	// Tell the decoder there is nothing to send anymore</a>
<a name="ln1532">	avcodec_send_packet(fCodecContext, NULL);</a>
<a name="ln1533"> </a>
<a name="ln1534">	// Get any remaining frame</a>
<a name="ln1535">	int error = avcodec_receive_frame(fCodecContext, fRawDecodedPicture);</a>
<a name="ln1536"> </a>
<a name="ln1537">	if (error != 0 &amp;&amp; error != AVERROR(EAGAIN)) {</a>
<a name="ln1538">		// video buffer is flushed successfully</a>
<a name="ln1539">		// (or there is an error, not much we can do about it)</a>
<a name="ln1540">		return B_LAST_BUFFER_ERROR;</a>
<a name="ln1541">	}</a>
<a name="ln1542"> </a>
<a name="ln1543">	return _HandleNewVideoFrameAndUpdateSystemState();</a>
<a name="ln1544">}</a>
<a name="ln1545"> </a>
<a name="ln1546"> </a>
<a name="ln1547">/*! \brief Updates relevant fields of the class member fHeader with the</a>
<a name="ln1548">		properties of the most recently decoded video frame.</a>
<a name="ln1549"> </a>
<a name="ln1550">	It is assumed that this function is called only	when the following asserts</a>
<a name="ln1551">	hold true:</a>
<a name="ln1552">		1. We actually got a new picture decoded by the video decoder.</a>
<a name="ln1553">		2. fHeader wasn't updated for the new picture yet. You MUST call this</a>
<a name="ln1554">		   method only once per decoded video frame.</a>
<a name="ln1555">		3. This function MUST be called after</a>
<a name="ln1556">		   _DeinterlaceAndColorConvertVideoFrame() as it relys on an updated</a>
<a name="ln1557">		    fDecodedDataSizeInBytes.</a>
<a name="ln1558">		4. There will be at maximumn only one decoded video frame in our cache</a>
<a name="ln1559">		   at any single point in time. Otherwise you couldn't tell to which</a>
<a name="ln1560">		   cached decoded video frame the properties in fHeader relate to.</a>
<a name="ln1561">		5. AVCodecContext is still valid for this video frame (This is the case</a>
<a name="ln1562">		   when this function is called after avcodec_decode_video2() and</a>
<a name="ln1563">		   before the next call to avcodec_decode_video2().</a>
<a name="ln1564">*/</a>
<a name="ln1565">void</a>
<a name="ln1566">AVCodecDecoder::_UpdateMediaHeaderForVideoFrame()</a>
<a name="ln1567">{</a>
<a name="ln1568">	fHeader.type = B_MEDIA_RAW_VIDEO;</a>
<a name="ln1569">	fHeader.file_pos = 0;</a>
<a name="ln1570">	fHeader.orig_size = 0;</a>
<a name="ln1571">	fHeader.start_time = fRawDecodedPicture-&gt;pkt_dts;</a>
<a name="ln1572">		// The pkt_dts is already in microseconds, even if ffmpeg docs says</a>
<a name="ln1573">		// 'in codec time_base units'</a>
<a name="ln1574">	fHeader.size_used = av_image_get_buffer_size(</a>
<a name="ln1575">		colorspace_to_pixfmt(fOutputColorSpace), fRawDecodedPicture-&gt;width,</a>
<a name="ln1576">		fRawDecodedPicture-&gt;height, 1);</a>
<a name="ln1577">	fHeader.u.raw_video.display_line_width = fRawDecodedPicture-&gt;width;</a>
<a name="ln1578">	fHeader.u.raw_video.display_line_count = fRawDecodedPicture-&gt;height;</a>
<a name="ln1579">	fHeader.u.raw_video.bytes_per_row</a>
<a name="ln1580">		= CalculateBytesPerRowWithColorSpaceAndVideoWidth(fOutputColorSpace,</a>
<a name="ln1581">			fRawDecodedPicture-&gt;width);</a>
<a name="ln1582">	fHeader.u.raw_video.field_gamma = 1.0;</a>
<a name="ln1583">	fHeader.u.raw_video.field_sequence = fFrame;</a>
<a name="ln1584">	fHeader.u.raw_video.field_number = 0;</a>
<a name="ln1585">	fHeader.u.raw_video.pulldown_number = 0;</a>
<a name="ln1586">	fHeader.u.raw_video.first_active_line = 1;</a>
<a name="ln1587">	fHeader.u.raw_video.line_count = fRawDecodedPicture-&gt;height;</a>
<a name="ln1588"> </a>
<a name="ln1589">	ConvertAVCodecContextToVideoAspectWidthAndHeight(*fCodecContext,</a>
<a name="ln1590">		fHeader.u.raw_video.pixel_width_aspect,</a>
<a name="ln1591">		fHeader.u.raw_video.pixel_height_aspect);</a>
<a name="ln1592"> </a>
<a name="ln1593">	char timestamp[AV_TS_MAX_STRING_SIZE];</a>
<a name="ln1594">	av_ts_make_time_string(timestamp,</a>
<a name="ln1595">		fRawDecodedPicture-&gt;best_effort_timestamp, &amp;fCodecContext-&gt;time_base);</a>
<a name="ln1596"> </a>
<a name="ln1597">	TRACE(&quot;[v] start_time=%s field_sequence=%lu\n&quot;,</a>
<a name="ln1598">		timestamp, fHeader.u.raw_video.field_sequence);</a>
<a name="ln1599">}</a>
<a name="ln1600"> </a>
<a name="ln1601"> </a>
<a name="ln1602">/*! \brief This function applies deinterlacing (only if needed) and color</a>
<a name="ln1603">	conversion to the video frame in fRawDecodedPicture.</a>
<a name="ln1604"> </a>
<a name="ln1605">	It is assumed that fRawDecodedPicture wasn't deinterlaced and color</a>
<a name="ln1606">	converted yet (otherwise this function behaves in unknown manners).</a>
<a name="ln1607"> </a>
<a name="ln1608">	This function MUST be called after _UpdateMediaHeaderForVideoFrame() as it</a>
<a name="ln1609">	relys on the fHeader.size_used and fHeader.u.raw_video.bytes_per_row fields</a>
<a name="ln1610">	for correct operation</a>
<a name="ln1611"> </a>
<a name="ln1612">	You should only call this function when you	got a new picture decoded by</a>
<a name="ln1613">	the video decoder.</a>
<a name="ln1614"> </a>
<a name="ln1615">	When this function finishes the postprocessed video frame will be available</a>
<a name="ln1616">	in fPostProcessedDecodedPicture and fDecodedData (fDecodedDataSizeInBytes</a>
<a name="ln1617">	will be set accordingly).</a>
<a name="ln1618"> </a>
<a name="ln1619">	\returns B_OK video frame successfully deinterlaced and color converted.</a>
<a name="ln1620">	\returns B_NO_MEMORY Not enough memory available for correct operation.</a>
<a name="ln1621">*/</a>
<a name="ln1622">status_t</a>
<a name="ln1623">AVCodecDecoder::_DeinterlaceAndColorConvertVideoFrame()</a>
<a name="ln1624">{</a>
<a name="ln1625">	int displayWidth = fRawDecodedPicture-&gt;width;</a>
<a name="ln1626">	int displayHeight = fRawDecodedPicture-&gt;height;</a>
<a name="ln1627">	AVFrame deinterlacedPicture;</a>
<a name="ln1628">	bool useDeinterlacedPicture = false;</a>
<a name="ln1629"> </a>
<a name="ln1630">	if (fRawDecodedPicture-&gt;interlaced_frame) {</a>
<a name="ln1631">		AVFrame rawPicture;</a>
<a name="ln1632">		rawPicture.data[0] = fRawDecodedPicture-&gt;data[0];</a>
<a name="ln1633">		rawPicture.data[1] = fRawDecodedPicture-&gt;data[1];</a>
<a name="ln1634">		rawPicture.data[2] = fRawDecodedPicture-&gt;data[2];</a>
<a name="ln1635">		rawPicture.data[3] = fRawDecodedPicture-&gt;data[3];</a>
<a name="ln1636">		rawPicture.linesize[0] = fRawDecodedPicture-&gt;linesize[0];</a>
<a name="ln1637">		rawPicture.linesize[1] = fRawDecodedPicture-&gt;linesize[1];</a>
<a name="ln1638">		rawPicture.linesize[2] = fRawDecodedPicture-&gt;linesize[2];</a>
<a name="ln1639">		rawPicture.linesize[3] = fRawDecodedPicture-&gt;linesize[3];</a>
<a name="ln1640"> </a>
<a name="ln1641">		if (av_image_alloc(deinterlacedPicture.data,</a>
<a name="ln1642">				deinterlacedPicture.linesize, displayWidth, displayHeight,</a>
<a name="ln1643">				fCodecContext-&gt;pix_fmt, 1) &lt; 0)</a>
<a name="ln1644">			return B_NO_MEMORY;</a>
<a name="ln1645"> </a>
<a name="ln1646">		// deinterlace implemented using avfilter</a>
<a name="ln1647">		_ProcessFilterGraph(&amp;deinterlacedPicture, &amp;rawPicture,</a>
<a name="ln1648">			fCodecContext-&gt;pix_fmt, displayWidth, displayHeight);</a>
<a name="ln1649">		useDeinterlacedPicture = true;</a>
<a name="ln1650">	}</a>
<a name="ln1651"> </a>
<a name="ln1652">	// Some decoders do not set pix_fmt until they have decoded 1 frame</a>
<a name="ln1653">#if USE_SWS_FOR_COLOR_SPACE_CONVERSION</a>
<a name="ln1654">	if (fSwsContext == NULL) {</a>
<a name="ln1655">		fSwsContext = sws_getContext(displayWidth, displayHeight,</a>
<a name="ln1656">			fCodecContext-&gt;pix_fmt, displayWidth, displayHeight,</a>
<a name="ln1657">			colorspace_to_pixfmt(fOutputColorSpace),</a>
<a name="ln1658">			SWS_FAST_BILINEAR, NULL, NULL, NULL);</a>
<a name="ln1659">	}</a>
<a name="ln1660">#else</a>
<a name="ln1661">	if (fFormatConversionFunc == NULL) {</a>
<a name="ln1662">		fFormatConversionFunc = resolve_colorspace(fOutputColorSpace,</a>
<a name="ln1663">			fCodecContext-&gt;pix_fmt, displayWidth, displayHeight);</a>
<a name="ln1664">	}</a>
<a name="ln1665">#endif</a>
<a name="ln1666"> </a>
<a name="ln1667">	fDecodedDataSizeInBytes = fHeader.size_used;</a>
<a name="ln1668"> </a>
<a name="ln1669">	if (fDecodedData == NULL) {</a>
<a name="ln1670">		const size_t kOptimalAlignmentForColorConversion = 32;</a>
<a name="ln1671">		posix_memalign(reinterpret_cast&lt;void**&gt;(&amp;fDecodedData),</a>
<a name="ln1672">			kOptimalAlignmentForColorConversion, fDecodedDataSizeInBytes);</a>
<a name="ln1673">	}</a>
<a name="ln1674">	if (fDecodedData == NULL)</a>
<a name="ln1675">		return B_NO_MEMORY;</a>
<a name="ln1676"> </a>
<a name="ln1677">	fPostProcessedDecodedPicture-&gt;data[0] = fDecodedData;</a>
<a name="ln1678">	fPostProcessedDecodedPicture-&gt;linesize[0]</a>
<a name="ln1679">		= fHeader.u.raw_video.bytes_per_row;</a>
<a name="ln1680"> </a>
<a name="ln1681">#if USE_SWS_FOR_COLOR_SPACE_CONVERSION</a>
<a name="ln1682">	if (fSwsContext != NULL) {</a>
<a name="ln1683">#else</a>
<a name="ln1684">	if (fFormatConversionFunc != NULL) {</a>
<a name="ln1685">#endif</a>
<a name="ln1686">		if (useDeinterlacedPicture) {</a>
<a name="ln1687">			AVFrame deinterlacedFrame;</a>
<a name="ln1688">			deinterlacedFrame.data[0] = deinterlacedPicture.data[0];</a>
<a name="ln1689">			deinterlacedFrame.data[1] = deinterlacedPicture.data[1];</a>
<a name="ln1690">			deinterlacedFrame.data[2] = deinterlacedPicture.data[2];</a>
<a name="ln1691">			deinterlacedFrame.data[3] = deinterlacedPicture.data[3];</a>
<a name="ln1692">			deinterlacedFrame.linesize[0]</a>
<a name="ln1693">				= deinterlacedPicture.linesize[0];</a>
<a name="ln1694">			deinterlacedFrame.linesize[1]</a>
<a name="ln1695">				= deinterlacedPicture.linesize[1];</a>
<a name="ln1696">			deinterlacedFrame.linesize[2]</a>
<a name="ln1697">				= deinterlacedPicture.linesize[2];</a>
<a name="ln1698">			deinterlacedFrame.linesize[3]</a>
<a name="ln1699">				= deinterlacedPicture.linesize[3];</a>
<a name="ln1700"> </a>
<a name="ln1701">#if USE_SWS_FOR_COLOR_SPACE_CONVERSION</a>
<a name="ln1702">			sws_scale(fSwsContext, deinterlacedFrame.data,</a>
<a name="ln1703">				deinterlacedFrame.linesize, 0, displayHeight,</a>
<a name="ln1704">				fPostProcessedDecodedPicture-&gt;data,</a>
<a name="ln1705">				fPostProcessedDecodedPicture-&gt;linesize);</a>
<a name="ln1706">#else</a>
<a name="ln1707">			(*fFormatConversionFunc)(&amp;deinterlacedFrame,</a>
<a name="ln1708">				fPostProcessedDecodedPicture, displayWidth, displayHeight);</a>
<a name="ln1709">#endif</a>
<a name="ln1710">		} else {</a>
<a name="ln1711">#if USE_SWS_FOR_COLOR_SPACE_CONVERSION</a>
<a name="ln1712">			sws_scale(fSwsContext, fRawDecodedPicture-&gt;data,</a>
<a name="ln1713">				fRawDecodedPicture-&gt;linesize, 0, displayHeight,</a>
<a name="ln1714">				fPostProcessedDecodedPicture-&gt;data,</a>
<a name="ln1715">				fPostProcessedDecodedPicture-&gt;linesize);</a>
<a name="ln1716">#else</a>
<a name="ln1717">			(*fFormatConversionFunc)(fRawDecodedPicture,</a>
<a name="ln1718">				fPostProcessedDecodedPicture, displayWidth, displayHeight);</a>
<a name="ln1719">#endif</a>
<a name="ln1720">		}</a>
<a name="ln1721">	}</a>
<a name="ln1722"> </a>
<a name="ln1723">	if (fRawDecodedPicture-&gt;interlaced_frame)</a>
<a name="ln1724">		av_freep(&amp;deinterlacedPicture.data[0]);</a>
<a name="ln1725"> </a>
<a name="ln1726">	return B_OK;</a>
<a name="ln1727">}</a>
<a name="ln1728"> </a>
<a name="ln1729"> </a>
<a name="ln1730">/*! \brief Init the deinterlace filter graph.</a>
<a name="ln1731"> </a>
<a name="ln1732">	\returns B_OK the filter graph could be built.</a>
<a name="ln1733">	\returns B_BAD_VALUE something was wrong with building the graph.</a>
<a name="ln1734">*/</a>
<a name="ln1735">status_t</a>
<a name="ln1736">AVCodecDecoder::_InitFilterGraph(enum AVPixelFormat pixfmt, int32 width,</a>
<a name="ln1737">	int32 height)</a>
<a name="ln1738">{</a>
<a name="ln1739">	if (fFilterGraph != NULL) {</a>
<a name="ln1740">		av_frame_free(&amp;fFilterFrame);</a>
<a name="ln1741">		avfilter_graph_free(&amp;fFilterGraph);</a>
<a name="ln1742">	}</a>
<a name="ln1743"> </a>
<a name="ln1744">	fFilterGraph = avfilter_graph_alloc();</a>
<a name="ln1745"> </a>
<a name="ln1746">	BString arguments;</a>
<a name="ln1747">	arguments.SetToFormat(&quot;buffer=video_size=%&quot; B_PRId32 &quot;x%&quot; B_PRId32</a>
<a name="ln1748">		&quot;:pix_fmt=%d:time_base=1/1:pixel_aspect=0/1[in];[in]yadif[out];&quot;</a>
<a name="ln1749">		&quot;[out]buffersink&quot;, width, height,</a>
<a name="ln1750">		pixfmt);</a>
<a name="ln1751">	AVFilterInOut* inputs = NULL;</a>
<a name="ln1752">	AVFilterInOut* outputs = NULL;</a>
<a name="ln1753">	TRACE(&quot;[v] _InitFilterGraph(): %s\n&quot;, arguments.String());</a>
<a name="ln1754">	int ret = avfilter_graph_parse2(fFilterGraph, arguments.String(), &amp;inputs,</a>
<a name="ln1755">		&amp;outputs);</a>
<a name="ln1756">	if (ret &lt; 0) {</a>
<a name="ln1757">		fprintf(stderr, &quot;avfilter_graph_parse2() failed\n&quot;);</a>
<a name="ln1758">		return B_BAD_VALUE;</a>
<a name="ln1759">	}</a>
<a name="ln1760"> </a>
<a name="ln1761">	ret = avfilter_graph_config(fFilterGraph, NULL);</a>
<a name="ln1762">	if (ret &lt; 0) {</a>
<a name="ln1763">		fprintf(stderr, &quot;avfilter_graph_config() failed\n&quot;);</a>
<a name="ln1764">		return B_BAD_VALUE;</a>
<a name="ln1765">	}</a>
<a name="ln1766"> </a>
<a name="ln1767">	fBufferSourceContext = avfilter_graph_get_filter(fFilterGraph,</a>
<a name="ln1768">		&quot;Parsed_buffer_0&quot;);</a>
<a name="ln1769">	fBufferSinkContext = avfilter_graph_get_filter(fFilterGraph,</a>
<a name="ln1770">		&quot;Parsed_buffersink_2&quot;);</a>
<a name="ln1771">	if (fBufferSourceContext == NULL || fBufferSinkContext == NULL) {</a>
<a name="ln1772">		fprintf(stderr, &quot;avfilter_graph_get_filter() failed\n&quot;);</a>
<a name="ln1773">		return B_BAD_VALUE;</a>
<a name="ln1774">	}</a>
<a name="ln1775">	fFilterFrame = av_frame_alloc();</a>
<a name="ln1776">	fLastWidth = width;</a>
<a name="ln1777">	fLastHeight = height;</a>
<a name="ln1778">	fLastPixfmt = pixfmt;</a>
<a name="ln1779"> </a>
<a name="ln1780">	return B_OK;</a>
<a name="ln1781">}</a>
<a name="ln1782"> </a>
<a name="ln1783"> </a>
<a name="ln1784">/*! \brief Process an AVPicture with the deinterlace filter graph.</a>
<a name="ln1785"> </a>
<a name="ln1786">    We decode exactly one video frame into dst.</a>
<a name="ln1787">	Equivalent function for avpicture_deinterlace() from version 2.x.</a>
<a name="ln1788"> </a>
<a name="ln1789">	\returns B_OK video frame successfully deinterlaced.</a>
<a name="ln1790">	\returns B_BAD_DATA No frame could be output.</a>
<a name="ln1791">	\returns B_NO_MEMORY Not enough memory available for correct operation.</a>
<a name="ln1792">*/</a>
<a name="ln1793">status_t</a>
<a name="ln1794">AVCodecDecoder::_ProcessFilterGraph(AVFrame *dst, const AVFrame *src,</a>
<a name="ln1795">	enum AVPixelFormat pixfmt, int32 width, int32 height)</a>
<a name="ln1796">{</a>
<a name="ln1797">	if (fFilterGraph == NULL || width != fLastWidth</a>
<a name="ln1798">		|| height != fLastHeight || pixfmt != fLastPixfmt) {</a>
<a name="ln1799"> </a>
<a name="ln1800">		status_t err = _InitFilterGraph(pixfmt, width, height);</a>
<a name="ln1801">		if (err != B_OK)</a>
<a name="ln1802">			return err;</a>
<a name="ln1803">	}</a>
<a name="ln1804"> </a>
<a name="ln1805">	memcpy(fFilterFrame-&gt;data, src-&gt;data, sizeof(src-&gt;data));</a>
<a name="ln1806">	memcpy(fFilterFrame-&gt;linesize, src-&gt;linesize, sizeof(src-&gt;linesize));</a>
<a name="ln1807">	fFilterFrame-&gt;width = width;</a>
<a name="ln1808">	fFilterFrame-&gt;height = height;</a>
<a name="ln1809">	fFilterFrame-&gt;format = pixfmt;</a>
<a name="ln1810"> </a>
<a name="ln1811">	int ret = av_buffersrc_add_frame(fBufferSourceContext, fFilterFrame);</a>
<a name="ln1812">	if (ret &lt; 0)</a>
<a name="ln1813">		return B_NO_MEMORY;</a>
<a name="ln1814"> </a>
<a name="ln1815">	ret = av_buffersink_get_frame(fBufferSinkContext, fFilterFrame);</a>
<a name="ln1816">	if (ret &lt; 0)</a>
<a name="ln1817">		return B_BAD_DATA;</a>
<a name="ln1818"> </a>
<a name="ln1819">	av_image_copy(dst-&gt;data, dst-&gt;linesize, (const uint8**)fFilterFrame-&gt;data,</a>
<a name="ln1820">		fFilterFrame-&gt;linesize, pixfmt, width, height);</a>
<a name="ln1821">	av_frame_unref(fFilterFrame);</a>
<a name="ln1822">	return B_OK;</a>
<a name="ln1823">}</a>

</code></pre>
<div class="balloon" rel="82"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v730/" target="_blank">V730</a> Not all members of a class are initialized inside the constructor. Consider inspecting: fFormatConversionFunc, fTempPacket, fLastWidth, fLastHeight, fLastPixfmt.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
