
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <title>arch_cpu.cpp</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">/*</a>
<a name="ln2"> * Copyright 2018, Jérôme Duval, jerome.duval@gmail.com.</a>
<a name="ln3"> * Copyright 2002-2010, Axel Dörfler, axeld@pinc-software.de.</a>
<a name="ln4"> * Copyright 2013, Paweł Dziepak, pdziepak@quarnos.org.</a>
<a name="ln5"> * Copyright 2012, Alex Smith, alex@alex-smith.me.uk.</a>
<a name="ln6"> * Distributed under the terms of the MIT License.</a>
<a name="ln7"> *</a>
<a name="ln8"> * Copyright 2001-2002, Travis Geiselbrecht. All rights reserved.</a>
<a name="ln9"> * Distributed under the terms of the NewOS License.</a>
<a name="ln10"> */</a>
<a name="ln11"> </a>
<a name="ln12"> </a>
<a name="ln13">#include &lt;cpu.h&gt;</a>
<a name="ln14"> </a>
<a name="ln15">#include &lt;string.h&gt;</a>
<a name="ln16">#include &lt;stdlib.h&gt;</a>
<a name="ln17">#include &lt;stdio.h&gt;</a>
<a name="ln18"> </a>
<a name="ln19">#include &lt;algorithm&gt;</a>
<a name="ln20"> </a>
<a name="ln21">#include &lt;ACPI.h&gt;</a>
<a name="ln22"> </a>
<a name="ln23">#include &lt;boot_device.h&gt;</a>
<a name="ln24">#include &lt;commpage.h&gt;</a>
<a name="ln25">#include &lt;debug.h&gt;</a>
<a name="ln26">#include &lt;elf.h&gt;</a>
<a name="ln27">#include &lt;safemode.h&gt;</a>
<a name="ln28">#include &lt;smp.h&gt;</a>
<a name="ln29">#include &lt;util/BitUtils.h&gt;</a>
<a name="ln30">#include &lt;vm/vm.h&gt;</a>
<a name="ln31">#include &lt;vm/vm_types.h&gt;</a>
<a name="ln32">#include &lt;vm/VMAddressSpace.h&gt;</a>
<a name="ln33"> </a>
<a name="ln34">#include &lt;arch_system_info.h&gt;</a>
<a name="ln35">#include &lt;arch/x86/apic.h&gt;</a>
<a name="ln36">#include &lt;boot/kernel_args.h&gt;</a>
<a name="ln37"> </a>
<a name="ln38">#include &quot;paging/X86PagingStructures.h&quot;</a>
<a name="ln39">#include &quot;paging/X86VMTranslationMap.h&quot;</a>
<a name="ln40"> </a>
<a name="ln41"> </a>
<a name="ln42">#define DUMP_FEATURE_STRING 1</a>
<a name="ln43">#define DUMP_CPU_TOPOLOGY	1</a>
<a name="ln44"> </a>
<a name="ln45"> </a>
<a name="ln46">/* cpu vendor info */</a>
<a name="ln47">struct cpu_vendor_info {</a>
<a name="ln48">	const char *vendor;</a>
<a name="ln49">	const char *ident_string[2];</a>
<a name="ln50">};</a>
<a name="ln51"> </a>
<a name="ln52">static const struct cpu_vendor_info vendor_info[VENDOR_NUM] = {</a>
<a name="ln53">	{ &quot;Intel&quot;, { &quot;GenuineIntel&quot; } },</a>
<a name="ln54">	{ &quot;AMD&quot;, { &quot;AuthenticAMD&quot; } },</a>
<a name="ln55">	{ &quot;Cyrix&quot;, { &quot;CyrixInstead&quot; } },</a>
<a name="ln56">	{ &quot;UMC&quot;, { &quot;UMC UMC UMC&quot; } },</a>
<a name="ln57">	{ &quot;NexGen&quot;, { &quot;NexGenDriven&quot; } },</a>
<a name="ln58">	{ &quot;Centaur&quot;, { &quot;CentaurHauls&quot; } },</a>
<a name="ln59">	{ &quot;Rise&quot;, { &quot;RiseRiseRise&quot; } },</a>
<a name="ln60">	{ &quot;Transmeta&quot;, { &quot;GenuineTMx86&quot;, &quot;TransmetaCPU&quot; } },</a>
<a name="ln61">	{ &quot;NSC&quot;, { &quot;Geode by NSC&quot; } },</a>
<a name="ln62">};</a>
<a name="ln63"> </a>
<a name="ln64">#define K8_SMIONCMPHALT			(1ULL &lt;&lt; 27)</a>
<a name="ln65">#define K8_C1EONCMPHALT			(1ULL &lt;&lt; 28)</a>
<a name="ln66"> </a>
<a name="ln67">#define K8_CMPHALT				(K8_SMIONCMPHALT | K8_C1EONCMPHALT)</a>
<a name="ln68"> </a>
<a name="ln69">struct set_mtrr_parameter {</a>
<a name="ln70">	int32	index;</a>
<a name="ln71">	uint64	base;</a>
<a name="ln72">	uint64	length;</a>
<a name="ln73">	uint8	type;</a>
<a name="ln74">};</a>
<a name="ln75"> </a>
<a name="ln76">struct set_mtrrs_parameter {</a>
<a name="ln77">	const x86_mtrr_info*	infos;</a>
<a name="ln78">	uint32					count;</a>
<a name="ln79">	uint8					defaultType;</a>
<a name="ln80">};</a>
<a name="ln81"> </a>
<a name="ln82"> </a>
<a name="ln83">#ifdef __x86_64__</a>
<a name="ln84">extern addr_t _stac;</a>
<a name="ln85">extern addr_t _clac;</a>
<a name="ln86">#endif</a>
<a name="ln87"> </a>
<a name="ln88">extern &quot;C&quot; void x86_reboot(void);</a>
<a name="ln89">	// from arch.S</a>
<a name="ln90"> </a>
<a name="ln91">void (*gCpuIdleFunc)(void);</a>
<a name="ln92">#ifndef __x86_64__</a>
<a name="ln93">void (*gX86SwapFPUFunc)(void* oldState, const void* newState) = x86_noop_swap;</a>
<a name="ln94">bool gHasSSE = false;</a>
<a name="ln95">#endif</a>
<a name="ln96"> </a>
<a name="ln97">static uint32 sCpuRendezvous;</a>
<a name="ln98">static uint32 sCpuRendezvous2;</a>
<a name="ln99">static uint32 sCpuRendezvous3;</a>
<a name="ln100">static vint32 sTSCSyncRendezvous;</a>
<a name="ln101"> </a>
<a name="ln102">/* Some specials for the double fault handler */</a>
<a name="ln103">static uint8* sDoubleFaultStacks;</a>
<a name="ln104">static const size_t kDoubleFaultStackSize = 4096;	// size per CPU</a>
<a name="ln105"> </a>
<a name="ln106">static x86_cpu_module_info* sCpuModule;</a>
<a name="ln107"> </a>
<a name="ln108"> </a>
<a name="ln109">/* CPU topology information */</a>
<a name="ln110">static uint32 (*sGetCPUTopologyID)(int currentCPU);</a>
<a name="ln111">static uint32 sHierarchyMask[CPU_TOPOLOGY_LEVELS];</a>
<a name="ln112">static uint32 sHierarchyShift[CPU_TOPOLOGY_LEVELS];</a>
<a name="ln113"> </a>
<a name="ln114">/* Cache topology information */</a>
<a name="ln115">static uint32 sCacheSharingMask[CPU_MAX_CACHE_LEVEL];</a>
<a name="ln116"> </a>
<a name="ln117"> </a>
<a name="ln118">static status_t</a>
<a name="ln119">acpi_shutdown(bool rebootSystem)</a>
<a name="ln120">{</a>
<a name="ln121">	if (debug_debugger_running() || !are_interrupts_enabled())</a>
<a name="ln122">		return B_ERROR;</a>
<a name="ln123"> </a>
<a name="ln124">	acpi_module_info* acpi;</a>
<a name="ln125">	if (get_module(B_ACPI_MODULE_NAME, (module_info**)&amp;acpi) != B_OK)</a>
<a name="ln126">		return B_NOT_SUPPORTED;</a>
<a name="ln127"> </a>
<a name="ln128">	status_t status;</a>
<a name="ln129">	if (rebootSystem) {</a>
<a name="ln130">		status = acpi-&gt;reboot();</a>
<a name="ln131">	} else {</a>
<a name="ln132">		status = acpi-&gt;prepare_sleep_state(ACPI_POWER_STATE_OFF, NULL, 0);</a>
<a name="ln133">		if (status == B_OK) {</a>
<a name="ln134">			//cpu_status state = disable_interrupts();</a>
<a name="ln135">			status = acpi-&gt;enter_sleep_state(ACPI_POWER_STATE_OFF);</a>
<a name="ln136">			//restore_interrupts(state);</a>
<a name="ln137">		}</a>
<a name="ln138">	}</a>
<a name="ln139"> </a>
<a name="ln140">	put_module(B_ACPI_MODULE_NAME);</a>
<a name="ln141">	return status;</a>
<a name="ln142">}</a>
<a name="ln143"> </a>
<a name="ln144"> </a>
<a name="ln145">/*!	Disable CPU caches, and invalidate them. */</a>
<a name="ln146">static void</a>
<a name="ln147">disable_caches()</a>
<a name="ln148">{</a>
<a name="ln149">	x86_write_cr0((x86_read_cr0() | CR0_CACHE_DISABLE)</a>
<a name="ln150">		&amp; ~CR0_NOT_WRITE_THROUGH);</a>
<a name="ln151">	wbinvd();</a>
<a name="ln152">	arch_cpu_global_TLB_invalidate();</a>
<a name="ln153">}</a>
<a name="ln154"> </a>
<a name="ln155"> </a>
<a name="ln156">/*!	Invalidate CPU caches, and enable them. */</a>
<a name="ln157">static void</a>
<a name="ln158">enable_caches()</a>
<a name="ln159">{</a>
<a name="ln160">	wbinvd();</a>
<a name="ln161">	arch_cpu_global_TLB_invalidate();</a>
<a name="ln162">	x86_write_cr0(x86_read_cr0()</a>
<a name="ln163">		&amp; ~(CR0_CACHE_DISABLE | CR0_NOT_WRITE_THROUGH));</a>
<a name="ln164">}</a>
<a name="ln165"> </a>
<a name="ln166"> </a>
<a name="ln167">static void</a>
<a name="ln168">set_mtrr(void* _parameter, int cpu)</a>
<a name="ln169">{</a>
<a name="ln170">	struct set_mtrr_parameter* parameter</a>
<a name="ln171">		= (struct set_mtrr_parameter*)_parameter;</a>
<a name="ln172"> </a>
<a name="ln173">	// wait until all CPUs have arrived here</a>
<a name="ln174">	smp_cpu_rendezvous(&amp;sCpuRendezvous);</a>
<a name="ln175"> </a>
<a name="ln176">	// One CPU has to reset sCpuRendezvous3 -- it is needed to prevent the CPU</a>
<a name="ln177">	// that initiated the call_all_cpus() from doing that again and clearing</a>
<a name="ln178">	// sCpuRendezvous2 before the last CPU has actually left the loop in</a>
<a name="ln179">	// smp_cpu_rendezvous();</a>
<a name="ln180">	if (cpu == 0)</a>
<a name="ln181">		atomic_set((int32*)&amp;sCpuRendezvous3, 0);</a>
<a name="ln182"> </a>
<a name="ln183">	disable_caches();</a>
<a name="ln184"> </a>
<a name="ln185">	sCpuModule-&gt;set_mtrr(parameter-&gt;index, parameter-&gt;base, parameter-&gt;length,</a>
<a name="ln186">		parameter-&gt;type);</a>
<a name="ln187"> </a>
<a name="ln188">	enable_caches();</a>
<a name="ln189"> </a>
<a name="ln190">	// wait until all CPUs have arrived here</a>
<a name="ln191">	smp_cpu_rendezvous(&amp;sCpuRendezvous2);</a>
<a name="ln192">	smp_cpu_rendezvous(&amp;sCpuRendezvous3);</a>
<a name="ln193">}</a>
<a name="ln194"> </a>
<a name="ln195"> </a>
<a name="ln196">static void</a>
<a name="ln197">set_mtrrs(void* _parameter, int cpu)</a>
<a name="ln198">{</a>
<a name="ln199">	set_mtrrs_parameter* parameter = (set_mtrrs_parameter*)_parameter;</a>
<a name="ln200"> </a>
<a name="ln201">	// wait until all CPUs have arrived here</a>
<a name="ln202">	smp_cpu_rendezvous(&amp;sCpuRendezvous);</a>
<a name="ln203"> </a>
<a name="ln204">	// One CPU has to reset sCpuRendezvous3 -- it is needed to prevent the CPU</a>
<a name="ln205">	// that initiated the call_all_cpus() from doing that again and clearing</a>
<a name="ln206">	// sCpuRendezvous2 before the last CPU has actually left the loop in</a>
<a name="ln207">	// smp_cpu_rendezvous();</a>
<a name="ln208">	if (cpu == 0)</a>
<a name="ln209">		atomic_set((int32*)&amp;sCpuRendezvous3, 0);</a>
<a name="ln210"> </a>
<a name="ln211">	disable_caches();</a>
<a name="ln212"> </a>
<a name="ln213">	sCpuModule-&gt;set_mtrrs(parameter-&gt;defaultType, parameter-&gt;infos,</a>
<a name="ln214">		parameter-&gt;count);</a>
<a name="ln215"> </a>
<a name="ln216">	enable_caches();</a>
<a name="ln217"> </a>
<a name="ln218">	// wait until all CPUs have arrived here</a>
<a name="ln219">	smp_cpu_rendezvous(&amp;sCpuRendezvous2);</a>
<a name="ln220">	smp_cpu_rendezvous(&amp;sCpuRendezvous3);</a>
<a name="ln221">}</a>
<a name="ln222"> </a>
<a name="ln223"> </a>
<a name="ln224">static void</a>
<a name="ln225">init_mtrrs(void* _unused, int cpu)</a>
<a name="ln226">{</a>
<a name="ln227">	// wait until all CPUs have arrived here</a>
<a name="ln228">	smp_cpu_rendezvous(&amp;sCpuRendezvous);</a>
<a name="ln229"> </a>
<a name="ln230">	// One CPU has to reset sCpuRendezvous3 -- it is needed to prevent the CPU</a>
<a name="ln231">	// that initiated the call_all_cpus() from doing that again and clearing</a>
<a name="ln232">	// sCpuRendezvous2 before the last CPU has actually left the loop in</a>
<a name="ln233">	// smp_cpu_rendezvous();</a>
<a name="ln234">	if (cpu == 0)</a>
<a name="ln235">		atomic_set((int32*)&amp;sCpuRendezvous3, 0);</a>
<a name="ln236"> </a>
<a name="ln237">	disable_caches();</a>
<a name="ln238"> </a>
<a name="ln239">	sCpuModule-&gt;init_mtrrs();</a>
<a name="ln240"> </a>
<a name="ln241">	enable_caches();</a>
<a name="ln242"> </a>
<a name="ln243">	// wait until all CPUs have arrived here</a>
<a name="ln244">	smp_cpu_rendezvous(&amp;sCpuRendezvous2);</a>
<a name="ln245">	smp_cpu_rendezvous(&amp;sCpuRendezvous3);</a>
<a name="ln246">}</a>
<a name="ln247"> </a>
<a name="ln248"> </a>
<a name="ln249">uint32</a>
<a name="ln250">x86_count_mtrrs(void)</a>
<a name="ln251">{</a>
<a name="ln252">	if (sCpuModule == NULL)</a>
<a name="ln253">		return 0;</a>
<a name="ln254"> </a>
<a name="ln255">	return sCpuModule-&gt;count_mtrrs();</a>
<a name="ln256">}</a>
<a name="ln257"> </a>
<a name="ln258"> </a>
<a name="ln259">void</a>
<a name="ln260">x86_set_mtrr(uint32 index, uint64 base, uint64 length, uint8 type)</a>
<a name="ln261">{</a>
<a name="ln262">	struct set_mtrr_parameter parameter;</a>
<a name="ln263">	parameter.index = index;</a>
<a name="ln264">	parameter.base = base;</a>
<a name="ln265">	parameter.length = length;</a>
<a name="ln266">	parameter.type = type;</a>
<a name="ln267"> </a>
<a name="ln268">	sCpuRendezvous = sCpuRendezvous2 = 0;</a>
<a name="ln269">	call_all_cpus(&amp;set_mtrr, &amp;parameter);</a>
<a name="ln270">}</a>
<a name="ln271"> </a>
<a name="ln272"> </a>
<a name="ln273">status_t</a>
<a name="ln274">x86_get_mtrr(uint32 index, uint64* _base, uint64* _length, uint8* _type)</a>
<a name="ln275">{</a>
<a name="ln276">	// the MTRRs are identical on all CPUs, so it doesn't matter</a>
<a name="ln277">	// on which CPU this runs</a>
<a name="ln278">	return sCpuModule-&gt;get_mtrr(index, _base, _length, _type);</a>
<a name="ln279">}</a>
<a name="ln280"> </a>
<a name="ln281"> </a>
<a name="ln282">void</a>
<a name="ln283">x86_set_mtrrs(uint8 defaultType, const x86_mtrr_info* infos, uint32 count)</a>
<a name="ln284">{</a>
<a name="ln285">	if (sCpuModule == NULL)</a>
<a name="ln286">		return;</a>
<a name="ln287"> </a>
<a name="ln288">	struct set_mtrrs_parameter parameter;</a>
<a name="ln289">	parameter.defaultType = defaultType;</a>
<a name="ln290">	parameter.infos = infos;</a>
<a name="ln291">	parameter.count = count;</a>
<a name="ln292"> </a>
<a name="ln293">	sCpuRendezvous = sCpuRendezvous2 = 0;</a>
<a name="ln294">	call_all_cpus(&amp;set_mtrrs, &amp;parameter);</a>
<a name="ln295">}</a>
<a name="ln296"> </a>
<a name="ln297"> </a>
<a name="ln298">void</a>
<a name="ln299">x86_init_fpu(void)</a>
<a name="ln300">{</a>
<a name="ln301">	// All x86_64 CPUs support SSE, don't need to bother checking for it.</a>
<a name="ln302">#ifndef __x86_64__</a>
<a name="ln303">	if (!x86_check_feature(IA32_FEATURE_FPU, FEATURE_COMMON)) {</a>
<a name="ln304">		// No FPU... time to install one in your 386?</a>
<a name="ln305">		dprintf(&quot;%s: Warning: CPU has no reported FPU.\n&quot;, __func__);</a>
<a name="ln306">		gX86SwapFPUFunc = x86_noop_swap;</a>
<a name="ln307">		return;</a>
<a name="ln308">	}</a>
<a name="ln309"> </a>
<a name="ln310">	if (!x86_check_feature(IA32_FEATURE_SSE, FEATURE_COMMON)</a>
<a name="ln311">		|| !x86_check_feature(IA32_FEATURE_FXSR, FEATURE_COMMON)) {</a>
<a name="ln312">		dprintf(&quot;%s: CPU has no SSE... just enabling FPU.\n&quot;, __func__);</a>
<a name="ln313">		// we don't have proper SSE support, just enable FPU</a>
<a name="ln314">		x86_write_cr0(x86_read_cr0() &amp; ~(CR0_FPU_EMULATION | CR0_MONITOR_FPU));</a>
<a name="ln315">		gX86SwapFPUFunc = x86_fnsave_swap;</a>
<a name="ln316">		return;</a>
<a name="ln317">	}</a>
<a name="ln318">#endif</a>
<a name="ln319"> </a>
<a name="ln320">	dprintf(&quot;%s: CPU has SSE... enabling FXSR and XMM.\n&quot;, __func__);</a>
<a name="ln321">#ifndef __x86_64__</a>
<a name="ln322">	// enable OS support for SSE</a>
<a name="ln323">	x86_write_cr4(x86_read_cr4() | CR4_OS_FXSR | CR4_OS_XMM_EXCEPTION);</a>
<a name="ln324">	x86_write_cr0(x86_read_cr0() &amp; ~(CR0_FPU_EMULATION | CR0_MONITOR_FPU));</a>
<a name="ln325"> </a>
<a name="ln326">	gX86SwapFPUFunc = x86_fxsave_swap;</a>
<a name="ln327">	gHasSSE = true;</a>
<a name="ln328">#endif</a>
<a name="ln329">}</a>
<a name="ln330"> </a>
<a name="ln331"> </a>
<a name="ln332">#if DUMP_FEATURE_STRING</a>
<a name="ln333">static void</a>
<a name="ln334">dump_feature_string(int currentCPU, cpu_ent* cpu)</a>
<a name="ln335">{</a>
<a name="ln336">	char features[512];</a>
<a name="ln337">	features[0] = 0;</a>
<a name="ln338"> </a>
<a name="ln339">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_FPU)</a>
<a name="ln340">		strlcat(features, &quot;fpu &quot;, sizeof(features));</a>
<a name="ln341">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_VME)</a>
<a name="ln342">		strlcat(features, &quot;vme &quot;, sizeof(features));</a>
<a name="ln343">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_DE)</a>
<a name="ln344">		strlcat(features, &quot;de &quot;, sizeof(features));</a>
<a name="ln345">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_PSE)</a>
<a name="ln346">		strlcat(features, &quot;pse &quot;, sizeof(features));</a>
<a name="ln347">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_TSC)</a>
<a name="ln348">		strlcat(features, &quot;tsc &quot;, sizeof(features));</a>
<a name="ln349">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_MSR)</a>
<a name="ln350">		strlcat(features, &quot;msr &quot;, sizeof(features));</a>
<a name="ln351">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_PAE)</a>
<a name="ln352">		strlcat(features, &quot;pae &quot;, sizeof(features));</a>
<a name="ln353">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_MCE)</a>
<a name="ln354">		strlcat(features, &quot;mce &quot;, sizeof(features));</a>
<a name="ln355">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_CX8)</a>
<a name="ln356">		strlcat(features, &quot;cx8 &quot;, sizeof(features));</a>
<a name="ln357">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_APIC)</a>
<a name="ln358">		strlcat(features, &quot;apic &quot;, sizeof(features));</a>
<a name="ln359">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_SEP)</a>
<a name="ln360">		strlcat(features, &quot;sep &quot;, sizeof(features));</a>
<a name="ln361">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_MTRR)</a>
<a name="ln362">		strlcat(features, &quot;mtrr &quot;, sizeof(features));</a>
<a name="ln363">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_PGE)</a>
<a name="ln364">		strlcat(features, &quot;pge &quot;, sizeof(features));</a>
<a name="ln365">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_MCA)</a>
<a name="ln366">		strlcat(features, &quot;mca &quot;, sizeof(features));</a>
<a name="ln367">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_CMOV)</a>
<a name="ln368">		strlcat(features, &quot;cmov &quot;, sizeof(features));</a>
<a name="ln369">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_PAT)</a>
<a name="ln370">		strlcat(features, &quot;pat &quot;, sizeof(features));</a>
<a name="ln371">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_PSE36)</a>
<a name="ln372">		strlcat(features, &quot;pse36 &quot;, sizeof(features));</a>
<a name="ln373">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_PSN)</a>
<a name="ln374">		strlcat(features, &quot;psn &quot;, sizeof(features));</a>
<a name="ln375">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_CLFSH)</a>
<a name="ln376">		strlcat(features, &quot;clfsh &quot;, sizeof(features));</a>
<a name="ln377">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_DS)</a>
<a name="ln378">		strlcat(features, &quot;ds &quot;, sizeof(features));</a>
<a name="ln379">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_ACPI)</a>
<a name="ln380">		strlcat(features, &quot;acpi &quot;, sizeof(features));</a>
<a name="ln381">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_MMX)</a>
<a name="ln382">		strlcat(features, &quot;mmx &quot;, sizeof(features));</a>
<a name="ln383">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_FXSR)</a>
<a name="ln384">		strlcat(features, &quot;fxsr &quot;, sizeof(features));</a>
<a name="ln385">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_SSE)</a>
<a name="ln386">		strlcat(features, &quot;sse &quot;, sizeof(features));</a>
<a name="ln387">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_SSE2)</a>
<a name="ln388">		strlcat(features, &quot;sse2 &quot;, sizeof(features));</a>
<a name="ln389">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_SS)</a>
<a name="ln390">		strlcat(features, &quot;ss &quot;, sizeof(features));</a>
<a name="ln391">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_HTT)</a>
<a name="ln392">		strlcat(features, &quot;htt &quot;, sizeof(features));</a>
<a name="ln393">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_TM)</a>
<a name="ln394">		strlcat(features, &quot;tm &quot;, sizeof(features));</a>
<a name="ln395">	if (cpu-&gt;arch.feature[FEATURE_COMMON] &amp; IA32_FEATURE_PBE)</a>
<a name="ln396">		strlcat(features, &quot;pbe &quot;, sizeof(features));</a>
<a name="ln397">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_SSE3)</a>
<a name="ln398">		strlcat(features, &quot;sse3 &quot;, sizeof(features));</a>
<a name="ln399">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_PCLMULQDQ)</a>
<a name="ln400">		strlcat(features, &quot;pclmulqdq &quot;, sizeof(features));</a>
<a name="ln401">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_DTES64)</a>
<a name="ln402">		strlcat(features, &quot;dtes64 &quot;, sizeof(features));</a>
<a name="ln403">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_MONITOR)</a>
<a name="ln404">		strlcat(features, &quot;monitor &quot;, sizeof(features));</a>
<a name="ln405">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_DSCPL)</a>
<a name="ln406">		strlcat(features, &quot;dscpl &quot;, sizeof(features));</a>
<a name="ln407">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_VMX)</a>
<a name="ln408">		strlcat(features, &quot;vmx &quot;, sizeof(features));</a>
<a name="ln409">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_SMX)</a>
<a name="ln410">		strlcat(features, &quot;smx &quot;, sizeof(features));</a>
<a name="ln411">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_EST)</a>
<a name="ln412">		strlcat(features, &quot;est &quot;, sizeof(features));</a>
<a name="ln413">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_TM2)</a>
<a name="ln414">		strlcat(features, &quot;tm2 &quot;, sizeof(features));</a>
<a name="ln415">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_SSSE3)</a>
<a name="ln416">		strlcat(features, &quot;ssse3 &quot;, sizeof(features));</a>
<a name="ln417">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_CNXTID)</a>
<a name="ln418">		strlcat(features, &quot;cnxtid &quot;, sizeof(features));</a>
<a name="ln419">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_FMA)</a>
<a name="ln420">		strlcat(features, &quot;fma &quot;, sizeof(features));</a>
<a name="ln421">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_CX16)</a>
<a name="ln422">		strlcat(features, &quot;cx16 &quot;, sizeof(features));</a>
<a name="ln423">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_XTPR)</a>
<a name="ln424">		strlcat(features, &quot;xtpr &quot;, sizeof(features));</a>
<a name="ln425">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_PDCM)</a>
<a name="ln426">		strlcat(features, &quot;pdcm &quot;, sizeof(features));</a>
<a name="ln427">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_PCID)</a>
<a name="ln428">		strlcat(features, &quot;pcid &quot;, sizeof(features));</a>
<a name="ln429">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_DCA)</a>
<a name="ln430">		strlcat(features, &quot;dca &quot;, sizeof(features));</a>
<a name="ln431">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_SSE4_1)</a>
<a name="ln432">		strlcat(features, &quot;sse4_1 &quot;, sizeof(features));</a>
<a name="ln433">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_SSE4_2)</a>
<a name="ln434">		strlcat(features, &quot;sse4_2 &quot;, sizeof(features));</a>
<a name="ln435">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_X2APIC)</a>
<a name="ln436">		strlcat(features, &quot;x2apic &quot;, sizeof(features));</a>
<a name="ln437">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_MOVBE)</a>
<a name="ln438">		strlcat(features, &quot;movbe &quot;, sizeof(features));</a>
<a name="ln439">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_POPCNT)</a>
<a name="ln440">		strlcat(features, &quot;popcnt &quot;, sizeof(features));</a>
<a name="ln441">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_TSCDEADLINE)</a>
<a name="ln442">		strlcat(features, &quot;tscdeadline &quot;, sizeof(features));</a>
<a name="ln443">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_AES)</a>
<a name="ln444">		strlcat(features, &quot;aes &quot;, sizeof(features));</a>
<a name="ln445">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_XSAVE)</a>
<a name="ln446">		strlcat(features, &quot;xsave &quot;, sizeof(features));</a>
<a name="ln447">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_OSXSAVE)</a>
<a name="ln448">		strlcat(features, &quot;osxsave &quot;, sizeof(features));</a>
<a name="ln449">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_AVX)</a>
<a name="ln450">		strlcat(features, &quot;avx &quot;, sizeof(features));</a>
<a name="ln451">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_F16C)</a>
<a name="ln452">		strlcat(features, &quot;f16c &quot;, sizeof(features));</a>
<a name="ln453">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_RDRND)</a>
<a name="ln454">		strlcat(features, &quot;rdrnd &quot;, sizeof(features));</a>
<a name="ln455">	if (cpu-&gt;arch.feature[FEATURE_EXT] &amp; IA32_FEATURE_EXT_HYPERVISOR)</a>
<a name="ln456">		strlcat(features, &quot;hypervisor &quot;, sizeof(features));</a>
<a name="ln457">	if (cpu-&gt;arch.feature[FEATURE_EXT_AMD] &amp; IA32_FEATURE_AMD_EXT_SYSCALL)</a>
<a name="ln458">		strlcat(features, &quot;syscall &quot;, sizeof(features));</a>
<a name="ln459">	if (cpu-&gt;arch.feature[FEATURE_EXT_AMD] &amp; IA32_FEATURE_AMD_EXT_NX)</a>
<a name="ln460">		strlcat(features, &quot;nx &quot;, sizeof(features));</a>
<a name="ln461">	if (cpu-&gt;arch.feature[FEATURE_EXT_AMD] &amp; IA32_FEATURE_AMD_EXT_MMXEXT)</a>
<a name="ln462">		strlcat(features, &quot;mmxext &quot;, sizeof(features));</a>
<a name="ln463">	if (cpu-&gt;arch.feature[FEATURE_EXT_AMD] &amp; IA32_FEATURE_AMD_EXT_FFXSR)</a>
<a name="ln464">		strlcat(features, &quot;ffxsr &quot;, sizeof(features));</a>
<a name="ln465">	if (cpu-&gt;arch.feature[FEATURE_EXT_AMD] &amp; IA32_FEATURE_AMD_EXT_LONG)</a>
<a name="ln466">		strlcat(features, &quot;long &quot;, sizeof(features));</a>
<a name="ln467">	if (cpu-&gt;arch.feature[FEATURE_EXT_AMD] &amp; IA32_FEATURE_AMD_EXT_3DNOWEXT)</a>
<a name="ln468">		strlcat(features, &quot;3dnowext &quot;, sizeof(features));</a>
<a name="ln469">	if (cpu-&gt;arch.feature[FEATURE_EXT_AMD] &amp; IA32_FEATURE_AMD_EXT_3DNOW)</a>
<a name="ln470">		strlcat(features, &quot;3dnow &quot;, sizeof(features));</a>
<a name="ln471">	if (cpu-&gt;arch.feature[FEATURE_6_EAX] &amp; IA32_FEATURE_DTS)</a>
<a name="ln472">		strlcat(features, &quot;dts &quot;, sizeof(features));</a>
<a name="ln473">	if (cpu-&gt;arch.feature[FEATURE_6_EAX] &amp; IA32_FEATURE_ITB)</a>
<a name="ln474">		strlcat(features, &quot;itb &quot;, sizeof(features));</a>
<a name="ln475">	if (cpu-&gt;arch.feature[FEATURE_6_EAX] &amp; IA32_FEATURE_ARAT)</a>
<a name="ln476">		strlcat(features, &quot;arat &quot;, sizeof(features));</a>
<a name="ln477">	if (cpu-&gt;arch.feature[FEATURE_6_EAX] &amp; IA32_FEATURE_PLN)</a>
<a name="ln478">		strlcat(features, &quot;pln &quot;, sizeof(features));</a>
<a name="ln479">	if (cpu-&gt;arch.feature[FEATURE_6_EAX] &amp; IA32_FEATURE_ECMD)</a>
<a name="ln480">		strlcat(features, &quot;ecmd &quot;, sizeof(features));</a>
<a name="ln481">	if (cpu-&gt;arch.feature[FEATURE_6_EAX] &amp; IA32_FEATURE_PTM)</a>
<a name="ln482">		strlcat(features, &quot;ptm &quot;, sizeof(features));</a>
<a name="ln483">	if (cpu-&gt;arch.feature[FEATURE_6_ECX] &amp; IA32_FEATURE_APERFMPERF)</a>
<a name="ln484">		strlcat(features, &quot;aperfmperf &quot;, sizeof(features));</a>
<a name="ln485">	if (cpu-&gt;arch.feature[FEATURE_6_ECX] &amp; IA32_FEATURE_EPB)</a>
<a name="ln486">		strlcat(features, &quot;epb &quot;, sizeof(features));</a>
<a name="ln487">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_TSC_ADJUST)</a>
<a name="ln488">		strlcat(features, &quot;tsc_adjust &quot;, sizeof(features));</a>
<a name="ln489">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_SGX)</a>
<a name="ln490">		strlcat(features, &quot;sgx &quot;, sizeof(features));</a>
<a name="ln491">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_BMI1)</a>
<a name="ln492">		strlcat(features, &quot;bmi1 &quot;, sizeof(features));</a>
<a name="ln493">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_HLE)</a>
<a name="ln494">		strlcat(features, &quot;hle &quot;, sizeof(features));</a>
<a name="ln495">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_AVX2)</a>
<a name="ln496">		strlcat(features, &quot;avx2 &quot;, sizeof(features));</a>
<a name="ln497">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_SMEP)</a>
<a name="ln498">		strlcat(features, &quot;smep &quot;, sizeof(features));</a>
<a name="ln499">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_BMI2)</a>
<a name="ln500">		strlcat(features, &quot;bmi2 &quot;, sizeof(features));</a>
<a name="ln501">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_ERMS)</a>
<a name="ln502">		strlcat(features, &quot;erms &quot;, sizeof(features));</a>
<a name="ln503">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_INVPCID)</a>
<a name="ln504">		strlcat(features, &quot;invpcid &quot;, sizeof(features));</a>
<a name="ln505">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_RTM)</a>
<a name="ln506">		strlcat(features, &quot;rtm &quot;, sizeof(features));</a>
<a name="ln507">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_CQM)</a>
<a name="ln508">		strlcat(features, &quot;cqm &quot;, sizeof(features));</a>
<a name="ln509">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_MPX)</a>
<a name="ln510">		strlcat(features, &quot;mpx &quot;, sizeof(features));</a>
<a name="ln511">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_RDT_A)</a>
<a name="ln512">		strlcat(features, &quot;rdt_a &quot;, sizeof(features));</a>
<a name="ln513">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_AVX512F)</a>
<a name="ln514">		strlcat(features, &quot;avx512f &quot;, sizeof(features));</a>
<a name="ln515">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_AVX512DQ)</a>
<a name="ln516">		strlcat(features, &quot;avx512dq &quot;, sizeof(features));</a>
<a name="ln517">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_RDSEED)</a>
<a name="ln518">		strlcat(features, &quot;rdseed &quot;, sizeof(features));</a>
<a name="ln519">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_ADX)</a>
<a name="ln520">		strlcat(features, &quot;adx &quot;, sizeof(features));</a>
<a name="ln521">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_SMAP)</a>
<a name="ln522">		strlcat(features, &quot;smap &quot;, sizeof(features));</a>
<a name="ln523">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_AVX512IFMA)</a>
<a name="ln524">		strlcat(features, &quot;avx512ifma &quot;, sizeof(features));</a>
<a name="ln525">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_PCOMMIT)</a>
<a name="ln526">		strlcat(features, &quot;pcommit &quot;, sizeof(features));</a>
<a name="ln527">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_CLFLUSHOPT)</a>
<a name="ln528">		strlcat(features, &quot;cflushopt &quot;, sizeof(features));</a>
<a name="ln529">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_CLWB)</a>
<a name="ln530">		strlcat(features, &quot;clwb &quot;, sizeof(features));</a>
<a name="ln531">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_INTEL_PT)</a>
<a name="ln532">		strlcat(features, &quot;intel_pt &quot;, sizeof(features));</a>
<a name="ln533">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_AVX512PF)</a>
<a name="ln534">		strlcat(features, &quot;avx512pf &quot;, sizeof(features));</a>
<a name="ln535">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_AVX512ER)</a>
<a name="ln536">		strlcat(features, &quot;avx512er &quot;, sizeof(features));</a>
<a name="ln537">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_AVX512CD)</a>
<a name="ln538">		strlcat(features, &quot;avx512cd &quot;, sizeof(features));</a>
<a name="ln539">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_SHA_NI)</a>
<a name="ln540">		strlcat(features, &quot;sha_ni &quot;, sizeof(features));</a>
<a name="ln541">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_AVX512BW)</a>
<a name="ln542">		strlcat(features, &quot;avx512bw &quot;, sizeof(features));</a>
<a name="ln543">	if (cpu-&gt;arch.feature[FEATURE_7_EBX] &amp; IA32_FEATURE_AVX512VI)</a>
<a name="ln544">		strlcat(features, &quot;avx512vi &quot;, sizeof(features));</a>
<a name="ln545">	if (cpu-&gt;arch.feature[FEATURE_7_EDX] &amp; IA32_FEATURE_IBRS)</a>
<a name="ln546">		strlcat(features, &quot;ibrs &quot;, sizeof(features));</a>
<a name="ln547">	if (cpu-&gt;arch.feature[FEATURE_7_EDX] &amp; IA32_FEATURE_STIBP)</a>
<a name="ln548">		strlcat(features, &quot;stibp &quot;, sizeof(features));</a>
<a name="ln549">	if (cpu-&gt;arch.feature[FEATURE_7_EDX] &amp; IA32_FEATURE_L1D_FLUSH)</a>
<a name="ln550">		strlcat(features, &quot;l1d_flush &quot;, sizeof(features));</a>
<a name="ln551">	if (cpu-&gt;arch.feature[FEATURE_7_EDX] &amp; IA32_FEATURE_ARCH_CAPABILITIES)</a>
<a name="ln552">		strlcat(features, &quot;msr_arch &quot;, sizeof(features));</a>
<a name="ln553">	if (cpu-&gt;arch.feature[FEATURE_7_EDX] &amp; IA32_FEATURE_SSBD)</a>
<a name="ln554">		strlcat(features, &quot;ssbd &quot;, sizeof(features));</a>
<a name="ln555">	if (cpu-&gt;arch.feature[FEATURE_EXT_8_EBX] &amp; IA32_FEATURE_AMD_EXT_IBPB)</a>
<a name="ln556">		strlcat(features, &quot;ibpb &quot;, sizeof(features));</a>
<a name="ln557">	dprintf(&quot;CPU %d: features: %s\n&quot;, currentCPU, features);</a>
<a name="ln558">}</a>
<a name="ln559">#endif	// DUMP_FEATURE_STRING</a>
<a name="ln560"> </a>
<a name="ln561"> </a>
<a name="ln562">static void</a>
<a name="ln563">compute_cpu_hierarchy_masks(int maxLogicalID, int maxCoreID)</a>
<a name="ln564">{</a>
<a name="ln565">	ASSERT(maxLogicalID &gt;= maxCoreID);</a>
<a name="ln566">	const int kMaxSMTID = maxLogicalID / maxCoreID;</a>
<a name="ln567"> </a>
<a name="ln568">	sHierarchyMask[CPU_TOPOLOGY_SMT] = kMaxSMTID - 1;</a>
<a name="ln569">	sHierarchyShift[CPU_TOPOLOGY_SMT] = 0;</a>
<a name="ln570"> </a>
<a name="ln571">	sHierarchyMask[CPU_TOPOLOGY_CORE] = (maxCoreID - 1) * kMaxSMTID;</a>
<a name="ln572">	sHierarchyShift[CPU_TOPOLOGY_CORE]</a>
<a name="ln573">		= count_set_bits(sHierarchyMask[CPU_TOPOLOGY_SMT]);</a>
<a name="ln574"> </a>
<a name="ln575">	const uint32 kSinglePackageMask = sHierarchyMask[CPU_TOPOLOGY_SMT]</a>
<a name="ln576">		| sHierarchyMask[CPU_TOPOLOGY_CORE];</a>
<a name="ln577">	sHierarchyMask[CPU_TOPOLOGY_PACKAGE] = ~kSinglePackageMask;</a>
<a name="ln578">	sHierarchyShift[CPU_TOPOLOGY_PACKAGE] = count_set_bits(kSinglePackageMask);</a>
<a name="ln579">}</a>
<a name="ln580"> </a>
<a name="ln581"> </a>
<a name="ln582">static uint32</a>
<a name="ln583">get_cpu_legacy_initial_apic_id(int /* currentCPU */)</a>
<a name="ln584">{</a>
<a name="ln585">	cpuid_info cpuid;</a>
<a name="ln586">	get_current_cpuid(&amp;cpuid, 1, 0);</a>
<a name="ln587">	return cpuid.regs.ebx &gt;&gt; 24;</a>
<a name="ln588">}</a>
<a name="ln589"> </a>
<a name="ln590"> </a>
<a name="ln591">static inline status_t</a>
<a name="ln592">detect_amd_cpu_topology(uint32 maxBasicLeaf, uint32 maxExtendedLeaf)</a>
<a name="ln593">{</a>
<a name="ln594">	sGetCPUTopologyID = get_cpu_legacy_initial_apic_id;</a>
<a name="ln595"> </a>
<a name="ln596">	cpuid_info cpuid;</a>
<a name="ln597">	get_current_cpuid(&amp;cpuid, 1, 0);</a>
<a name="ln598">	int maxLogicalID = next_power_of_2((cpuid.regs.ebx &gt;&gt; 16) &amp; 0xff);</a>
<a name="ln599"> </a>
<a name="ln600">	int maxCoreID = 1;</a>
<a name="ln601">	if (maxExtendedLeaf &gt;= 0x80000008) {</a>
<a name="ln602">		get_current_cpuid(&amp;cpuid, 0x80000008, 0);</a>
<a name="ln603">		maxCoreID = (cpuid.regs.ecx &gt;&gt; 12) &amp; 0xf;</a>
<a name="ln604">		if (maxCoreID != 0)</a>
<a name="ln605">			maxCoreID = 1 &lt;&lt; maxCoreID;</a>
<a name="ln606">		else</a>
<a name="ln607">			maxCoreID = next_power_of_2((cpuid.regs.edx &amp; 0xf) + 1);</a>
<a name="ln608">	}</a>
<a name="ln609"> </a>
<a name="ln610">	if (maxExtendedLeaf &gt;= 0x80000001) {</a>
<a name="ln611">		get_current_cpuid(&amp;cpuid, 0x80000001, 0);</a>
<a name="ln612">		if (x86_check_feature(IA32_FEATURE_AMD_EXT_CMPLEGACY,</a>
<a name="ln613">				FEATURE_EXT_AMD_ECX))</a>
<a name="ln614">			maxCoreID = maxLogicalID;</a>
<a name="ln615">	}</a>
<a name="ln616"> </a>
<a name="ln617">	compute_cpu_hierarchy_masks(maxLogicalID, maxCoreID);</a>
<a name="ln618"> </a>
<a name="ln619">	return B_OK;</a>
<a name="ln620">}</a>
<a name="ln621"> </a>
<a name="ln622"> </a>
<a name="ln623">static void</a>
<a name="ln624">detect_amd_cache_topology(uint32 maxExtendedLeaf)</a>
<a name="ln625">{</a>
<a name="ln626">	if (!x86_check_feature(IA32_FEATURE_AMD_EXT_TOPOLOGY, FEATURE_EXT_AMD_ECX))</a>
<a name="ln627">		return;</a>
<a name="ln628"> </a>
<a name="ln629">	if (maxExtendedLeaf &lt; 0x8000001d)</a>
<a name="ln630">		return;</a>
<a name="ln631"> </a>
<a name="ln632">	uint8 hierarchyLevels[CPU_MAX_CACHE_LEVEL];</a>
<a name="ln633">	int maxCacheLevel = 0;</a>
<a name="ln634"> </a>
<a name="ln635">	int currentLevel = 0;</a>
<a name="ln636">	int cacheType;</a>
<a name="ln637">	do {</a>
<a name="ln638">		cpuid_info cpuid;</a>
<a name="ln639">		get_current_cpuid(&amp;cpuid, 0x8000001d, currentLevel);</a>
<a name="ln640"> </a>
<a name="ln641">		cacheType = cpuid.regs.eax &amp; 0x1f;</a>
<a name="ln642">		if (cacheType == 0)</a>
<a name="ln643">			break;</a>
<a name="ln644"> </a>
<a name="ln645">		int cacheLevel = (cpuid.regs.eax &gt;&gt; 5) &amp; 0x7;</a>
<a name="ln646">		int coresCount = next_power_of_2(((cpuid.regs.eax &gt;&gt; 14) &amp; 0x3f) + 1);</a>
<a name="ln647">		hierarchyLevels[cacheLevel - 1]</a>
<a name="ln648">			= coresCount * (sHierarchyMask[CPU_TOPOLOGY_SMT] + 1);</a>
<a name="ln649">		maxCacheLevel = std::max(maxCacheLevel, cacheLevel);</a>
<a name="ln650"> </a>
<a name="ln651">		currentLevel++;</a>
<a name="ln652">	} while (true);</a>
<a name="ln653"> </a>
<a name="ln654">	for (int i = 0; i &lt; maxCacheLevel; i++)</a>
<a name="ln655">		sCacheSharingMask[i] = ~uint32(hierarchyLevels[i] - 1);</a>
<a name="ln656">	gCPUCacheLevelCount = maxCacheLevel;</a>
<a name="ln657">}</a>
<a name="ln658"> </a>
<a name="ln659"> </a>
<a name="ln660">static uint32</a>
<a name="ln661">get_intel_cpu_initial_x2apic_id(int /* currentCPU */)</a>
<a name="ln662">{</a>
<a name="ln663">	cpuid_info cpuid;</a>
<a name="ln664">	get_current_cpuid(&amp;cpuid, 11, 0);</a>
<a name="ln665">	return cpuid.regs.edx;</a>
<a name="ln666">}</a>
<a name="ln667"> </a>
<a name="ln668"> </a>
<a name="ln669">static inline status_t</a>
<a name="ln670">detect_intel_cpu_topology_x2apic(uint32 maxBasicLeaf)</a>
<a name="ln671">{</a>
<a name="ln672">	if (maxBasicLeaf &lt; 11)</a>
<a name="ln673">		return B_UNSUPPORTED;</a>
<a name="ln674"> </a>
<a name="ln675">	uint8 hierarchyLevels[CPU_TOPOLOGY_LEVELS] = { 0 };</a>
<a name="ln676"> </a>
<a name="ln677">	int currentLevel = 0;</a>
<a name="ln678">	int levelType;</a>
<a name="ln679">	unsigned int levelsSet = 0;</a>
<a name="ln680"> </a>
<a name="ln681">	do {</a>
<a name="ln682">		cpuid_info cpuid;</a>
<a name="ln683">		get_current_cpuid(&amp;cpuid, 11, currentLevel);</a>
<a name="ln684">		if (currentLevel == 0 &amp;&amp; cpuid.regs.ebx == 0)</a>
<a name="ln685">			return B_UNSUPPORTED;</a>
<a name="ln686"> </a>
<a name="ln687">		levelType = (cpuid.regs.ecx &gt;&gt; 8) &amp; 0xff;</a>
<a name="ln688">		int levelValue = cpuid.regs.eax &amp; 0x1f;</a>
<a name="ln689"> </a>
<a name="ln690">		switch (levelType) {</a>
<a name="ln691">			case 1:	// SMT</a>
<a name="ln692">				hierarchyLevels[CPU_TOPOLOGY_SMT] = levelValue;</a>
<a name="ln693">				levelsSet |= 1;</a>
<a name="ln694">				break;</a>
<a name="ln695">			case 2:	// core</a>
<a name="ln696">				hierarchyLevels[CPU_TOPOLOGY_CORE] = levelValue;</a>
<a name="ln697">				levelsSet |= 2;</a>
<a name="ln698">				break;</a>
<a name="ln699">		}</a>
<a name="ln700"> </a>
<a name="ln701">		currentLevel++;</a>
<a name="ln702">	} while (levelType != 0 &amp;&amp; levelsSet != 3);</a>
<a name="ln703"> </a>
<a name="ln704">	sGetCPUTopologyID = get_intel_cpu_initial_x2apic_id;</a>
<a name="ln705"> </a>
<a name="ln706">	for (int i = 1; i &lt; CPU_TOPOLOGY_LEVELS; i++) {</a>
<a name="ln707">		if ((levelsSet &amp; (1u &lt;&lt; i)) != 0)</a>
<a name="ln708">			continue;</a>
<a name="ln709">		hierarchyLevels[i] = hierarchyLevels[i - 1];</a>
<a name="ln710">	}</a>
<a name="ln711"> </a>
<a name="ln712">	for (int i = 0; i &lt; CPU_TOPOLOGY_LEVELS; i++) {</a>
<a name="ln713">		uint32 mask = ~uint32(0);</a>
<a name="ln714">		if (i &lt; CPU_TOPOLOGY_LEVELS - 1)</a>
<a name="ln715">			mask = (1u &lt;&lt; hierarchyLevels[i]) - 1;</a>
<a name="ln716">		if (i &gt; 0)</a>
<a name="ln717">			mask &amp;= ~sHierarchyMask[i - 1];</a>
<a name="ln718">		sHierarchyMask[i] = mask;</a>
<a name="ln719">		sHierarchyShift[i] = i &gt; 0 ? hierarchyLevels[i - 1] : 0;</a>
<a name="ln720">	}</a>
<a name="ln721"> </a>
<a name="ln722">	return B_OK;</a>
<a name="ln723">}</a>
<a name="ln724"> </a>
<a name="ln725"> </a>
<a name="ln726">static inline status_t</a>
<a name="ln727">detect_intel_cpu_topology_legacy(uint32 maxBasicLeaf)</a>
<a name="ln728">{</a>
<a name="ln729">	sGetCPUTopologyID = get_cpu_legacy_initial_apic_id;</a>
<a name="ln730"> </a>
<a name="ln731">	cpuid_info cpuid;</a>
<a name="ln732"> </a>
<a name="ln733">	get_current_cpuid(&amp;cpuid, 1, 0);</a>
<a name="ln734">	int maxLogicalID = next_power_of_2((cpuid.regs.ebx &gt;&gt; 16) &amp; 0xff);</a>
<a name="ln735"> </a>
<a name="ln736">	int maxCoreID = 1;</a>
<a name="ln737">	if (maxBasicLeaf &gt;= 4) {</a>
<a name="ln738">		get_current_cpuid(&amp;cpuid, 4, 0);</a>
<a name="ln739">		maxCoreID = next_power_of_2((cpuid.regs.eax &gt;&gt; 26) + 1);</a>
<a name="ln740">	}</a>
<a name="ln741"> </a>
<a name="ln742">	compute_cpu_hierarchy_masks(maxLogicalID, maxCoreID);</a>
<a name="ln743"> </a>
<a name="ln744">	return B_OK;</a>
<a name="ln745">}</a>
<a name="ln746"> </a>
<a name="ln747"> </a>
<a name="ln748">static void</a>
<a name="ln749">detect_intel_cache_topology(uint32 maxBasicLeaf)</a>
<a name="ln750">{</a>
<a name="ln751">	if (maxBasicLeaf &lt; 4)</a>
<a name="ln752">		return;</a>
<a name="ln753"> </a>
<a name="ln754">	uint8 hierarchyLevels[CPU_MAX_CACHE_LEVEL];</a>
<a name="ln755">	int maxCacheLevel = 0;</a>
<a name="ln756"> </a>
<a name="ln757">	int currentLevel = 0;</a>
<a name="ln758">	int cacheType;</a>
<a name="ln759">	do {</a>
<a name="ln760">		cpuid_info cpuid;</a>
<a name="ln761">		get_current_cpuid(&amp;cpuid, 4, currentLevel);</a>
<a name="ln762"> </a>
<a name="ln763">		cacheType = cpuid.regs.eax &amp; 0x1f;</a>
<a name="ln764">		if (cacheType == 0)</a>
<a name="ln765">			break;</a>
<a name="ln766"> </a>
<a name="ln767">		int cacheLevel = (cpuid.regs.eax &gt;&gt; 5) &amp; 0x7;</a>
<a name="ln768">		hierarchyLevels[cacheLevel - 1]</a>
<a name="ln769">			= next_power_of_2(((cpuid.regs.eax &gt;&gt; 14) &amp; 0x3f) + 1);</a>
<a name="ln770">		maxCacheLevel = std::max(maxCacheLevel, cacheLevel);</a>
<a name="ln771"> </a>
<a name="ln772">		currentLevel++;</a>
<a name="ln773">	} while (true);</a>
<a name="ln774"> </a>
<a name="ln775">	for (int i = 0; i &lt; maxCacheLevel; i++)</a>
<a name="ln776">		sCacheSharingMask[i] = ~uint32(hierarchyLevels[i] - 1);</a>
<a name="ln777"> </a>
<a name="ln778">	gCPUCacheLevelCount = maxCacheLevel;</a>
<a name="ln779">}</a>
<a name="ln780"> </a>
<a name="ln781"> </a>
<a name="ln782">static uint32</a>
<a name="ln783">get_simple_cpu_topology_id(int currentCPU)</a>
<a name="ln784">{</a>
<a name="ln785">	return currentCPU;</a>
<a name="ln786">}</a>
<a name="ln787"> </a>
<a name="ln788"> </a>
<a name="ln789">static inline int</a>
<a name="ln790">get_topology_level_id(uint32 id, cpu_topology_level level)</a>
<a name="ln791">{</a>
<a name="ln792">	ASSERT(level &lt; CPU_TOPOLOGY_LEVELS);</a>
<a name="ln793">	return (id &amp; sHierarchyMask[level]) &gt;&gt; sHierarchyShift[level];</a>
<a name="ln794">}</a>
<a name="ln795"> </a>
<a name="ln796"> </a>
<a name="ln797">static void</a>
<a name="ln798">detect_cpu_topology(int currentCPU, cpu_ent* cpu, uint32 maxBasicLeaf,</a>
<a name="ln799">	uint32 maxExtendedLeaf)</a>
<a name="ln800">{</a>
<a name="ln801">	if (currentCPU == 0) {</a>
<a name="ln802">		memset(sCacheSharingMask, 0xff, sizeof(sCacheSharingMask));</a>
<a name="ln803"> </a>
<a name="ln804">		status_t result = B_UNSUPPORTED;</a>
<a name="ln805">		if (x86_check_feature(IA32_FEATURE_HTT, FEATURE_COMMON)) {</a>
<a name="ln806">			if (cpu-&gt;arch.vendor == VENDOR_AMD) {</a>
<a name="ln807">				result = detect_amd_cpu_topology(maxBasicLeaf, maxExtendedLeaf);</a>
<a name="ln808"> </a>
<a name="ln809">				if (result == B_OK)</a>
<a name="ln810">					detect_amd_cache_topology(maxExtendedLeaf);</a>
<a name="ln811">			}</a>
<a name="ln812"> </a>
<a name="ln813">			if (cpu-&gt;arch.vendor == VENDOR_INTEL) {</a>
<a name="ln814">				result = detect_intel_cpu_topology_x2apic(maxBasicLeaf);</a>
<a name="ln815">				if (result != B_OK)</a>
<a name="ln816">					result = detect_intel_cpu_topology_legacy(maxBasicLeaf);</a>
<a name="ln817"> </a>
<a name="ln818">				if (result == B_OK)</a>
<a name="ln819">					detect_intel_cache_topology(maxBasicLeaf);</a>
<a name="ln820">			}</a>
<a name="ln821">		}</a>
<a name="ln822"> </a>
<a name="ln823">		if (result != B_OK) {</a>
<a name="ln824">			dprintf(&quot;No CPU topology information available.\n&quot;);</a>
<a name="ln825"> </a>
<a name="ln826">			sGetCPUTopologyID = get_simple_cpu_topology_id;</a>
<a name="ln827"> </a>
<a name="ln828">			sHierarchyMask[CPU_TOPOLOGY_PACKAGE] = ~uint32(0);</a>
<a name="ln829">		}</a>
<a name="ln830">	}</a>
<a name="ln831"> </a>
<a name="ln832">	ASSERT(sGetCPUTopologyID != NULL);</a>
<a name="ln833">	int topologyID = sGetCPUTopologyID(currentCPU);</a>
<a name="ln834">	cpu-&gt;topology_id[CPU_TOPOLOGY_SMT]</a>
<a name="ln835">		= get_topology_level_id(topologyID, CPU_TOPOLOGY_SMT);</a>
<a name="ln836">	cpu-&gt;topology_id[CPU_TOPOLOGY_CORE]</a>
<a name="ln837">		= get_topology_level_id(topologyID, CPU_TOPOLOGY_CORE);</a>
<a name="ln838">	cpu-&gt;topology_id[CPU_TOPOLOGY_PACKAGE]</a>
<a name="ln839">		= get_topology_level_id(topologyID, CPU_TOPOLOGY_PACKAGE);</a>
<a name="ln840"> </a>
<a name="ln841">	unsigned int i;</a>
<a name="ln842">	for (i = 0; i &lt; gCPUCacheLevelCount; i++)</a>
<a name="ln843">		cpu-&gt;cache_id[i] = topologyID &amp; sCacheSharingMask[i];</a>
<a name="ln844">	for (; i &lt; CPU_MAX_CACHE_LEVEL; i++)</a>
<a name="ln845">		cpu-&gt;cache_id[i] = -1;</a>
<a name="ln846"> </a>
<a name="ln847">#if DUMP_CPU_TOPOLOGY</a>
<a name="ln848">	dprintf(&quot;CPU %d: apic id %d, package %d, core %d, smt %d\n&quot;, currentCPU,</a>
<a name="ln849">		topologyID, cpu-&gt;topology_id[CPU_TOPOLOGY_PACKAGE],</a>
<a name="ln850">		cpu-&gt;topology_id[CPU_TOPOLOGY_CORE],</a>
<a name="ln851">		cpu-&gt;topology_id[CPU_TOPOLOGY_SMT]);</a>
<a name="ln852"> </a>
<a name="ln853">	if (gCPUCacheLevelCount &gt; 0) {</a>
<a name="ln854">		char cacheLevels[256];</a>
<a name="ln855">		unsigned int offset = 0;</a>
<a name="ln856">		for (i = 0; i &lt; gCPUCacheLevelCount; i++) {</a>
<a name="ln857">			offset += snprintf(cacheLevels + offset,</a>
<a name="ln858">					sizeof(cacheLevels) - offset,</a>
<a name="ln859">					&quot; L%d id %d%s&quot;, i + 1, cpu-&gt;cache_id[i],</a>
<a name="ln860">					i &lt; gCPUCacheLevelCount - 1 ? &quot;,&quot; : &quot;&quot;);</a>
<a name="ln861"> </a>
<a name="ln862">			if (offset &gt;= sizeof(cacheLevels))</a>
<a name="ln863">				break;</a>
<a name="ln864">		}</a>
<a name="ln865"> </a>
<a name="ln866">		dprintf(&quot;CPU %d: cache sharing:%s\n&quot;, currentCPU, cacheLevels);</a>
<a name="ln867">	}</a>
<a name="ln868">#endif</a>
<a name="ln869">}</a>
<a name="ln870"> </a>
<a name="ln871"> </a>
<a name="ln872">static void</a>
<a name="ln873">detect_cpu(int currentCPU)</a>
<a name="ln874">{</a>
<a name="ln875">	cpu_ent* cpu = get_cpu_struct();</a>
<a name="ln876">	char vendorString[17];</a>
<a name="ln877">	cpuid_info cpuid;</a>
<a name="ln878"> </a>
<a name="ln879">	// clear out the cpu info data</a>
<a name="ln880">	cpu-&gt;arch.vendor = VENDOR_UNKNOWN;</a>
<a name="ln881">	cpu-&gt;arch.vendor_name = &quot;UNKNOWN VENDOR&quot;;</a>
<a name="ln882">	cpu-&gt;arch.feature[FEATURE_COMMON] = 0;</a>
<a name="ln883">	cpu-&gt;arch.feature[FEATURE_EXT] = 0;</a>
<a name="ln884">	cpu-&gt;arch.feature[FEATURE_EXT_AMD] = 0;</a>
<a name="ln885">	cpu-&gt;arch.feature[FEATURE_7_EBX] = 0;</a>
<a name="ln886">	cpu-&gt;arch.feature[FEATURE_7_ECX] = 0;</a>
<a name="ln887">	cpu-&gt;arch.feature[FEATURE_7_EDX] = 0;</a>
<a name="ln888">	cpu-&gt;arch.model_name[0] = 0;</a>
<a name="ln889"> </a>
<a name="ln890">	// print some fun data</a>
<a name="ln891">	get_current_cpuid(&amp;cpuid, 0, 0);</a>
<a name="ln892">	uint32 maxBasicLeaf = cpuid.eax_0.max_eax;</a>
<a name="ln893"> </a>
<a name="ln894">	// build the vendor string</a>
<a name="ln895">	memset(vendorString, 0, sizeof(vendorString));</a>
<a name="ln896">	memcpy(vendorString, cpuid.eax_0.vendor_id, sizeof(cpuid.eax_0.vendor_id));</a>
<a name="ln897"> </a>
<a name="ln898">	// get the family, model, stepping</a>
<a name="ln899">	get_current_cpuid(&amp;cpuid, 1, 0);</a>
<a name="ln900">	cpu-&gt;arch.type = cpuid.eax_1.type;</a>
<a name="ln901">	cpu-&gt;arch.family = cpuid.eax_1.family;</a>
<a name="ln902">	cpu-&gt;arch.extended_family = cpuid.eax_1.extended_family;</a>
<a name="ln903">	cpu-&gt;arch.model = cpuid.eax_1.model;</a>
<a name="ln904">	cpu-&gt;arch.extended_model = cpuid.eax_1.extended_model;</a>
<a name="ln905">	cpu-&gt;arch.stepping = cpuid.eax_1.stepping;</a>
<a name="ln906">	dprintf(&quot;CPU %d: type %d family %d extended_family %d model %d &quot;</a>
<a name="ln907">		&quot;extended_model %d stepping %d, string '%s'\n&quot;,</a>
<a name="ln908">		currentCPU, cpu-&gt;arch.type, cpu-&gt;arch.family,</a>
<a name="ln909">		cpu-&gt;arch.extended_family, cpu-&gt;arch.model,</a>
<a name="ln910">		cpu-&gt;arch.extended_model, cpu-&gt;arch.stepping, vendorString);</a>
<a name="ln911"> </a>
<a name="ln912">	// figure out what vendor we have here</a>
<a name="ln913"> </a>
<a name="ln914">	for (int32 i = 0; i &lt; VENDOR_NUM; i++) {</a>
<a name="ln915">		if (vendor_info[i].ident_string[0]</a>
<a name="ln916">			&amp;&amp; !strcmp(vendorString, vendor_info[i].ident_string[0])) {</a>
<a name="ln917">			cpu-&gt;arch.vendor = (x86_vendors)i;</a>
<a name="ln918">			cpu-&gt;arch.vendor_name = vendor_info[i].vendor;</a>
<a name="ln919">			break;</a>
<a name="ln920">		}</a>
<a name="ln921">		if (vendor_info[i].ident_string[1]</a>
<a name="ln922">			&amp;&amp; !strcmp(vendorString, vendor_info[i].ident_string[1])) {</a>
<a name="ln923">			cpu-&gt;arch.vendor = (x86_vendors)i;</a>
<a name="ln924">			cpu-&gt;arch.vendor_name = vendor_info[i].vendor;</a>
<a name="ln925">			break;</a>
<a name="ln926">		}</a>
<a name="ln927">	}</a>
<a name="ln928"> </a>
<a name="ln929">	// see if we can get the model name</a>
<a name="ln930">	get_current_cpuid(&amp;cpuid, 0x80000000, 0);</a>
<a name="ln931">	uint32 maxExtendedLeaf = cpuid.eax_0.max_eax;</a>
<a name="ln932">	if (maxExtendedLeaf &gt;= 0x80000004) {</a>
<a name="ln933">		// build the model string (need to swap ecx/edx data before copying)</a>
<a name="ln934">		unsigned int temp;</a>
<a name="ln935">		memset(cpu-&gt;arch.model_name, 0, sizeof(cpu-&gt;arch.model_name));</a>
<a name="ln936"> </a>
<a name="ln937">		get_current_cpuid(&amp;cpuid, 0x80000002, 0);</a>
<a name="ln938">		temp = cpuid.regs.edx;</a>
<a name="ln939">		cpuid.regs.edx = cpuid.regs.ecx;</a>
<a name="ln940">		cpuid.regs.ecx = temp;</a>
<a name="ln941">		memcpy(cpu-&gt;arch.model_name, cpuid.as_chars, sizeof(cpuid.as_chars));</a>
<a name="ln942"> </a>
<a name="ln943">		get_current_cpuid(&amp;cpuid, 0x80000003, 0);</a>
<a name="ln944">		temp = cpuid.regs.edx;</a>
<a name="ln945">		cpuid.regs.edx = cpuid.regs.ecx;</a>
<a name="ln946">		cpuid.regs.ecx = temp;</a>
<a name="ln947">		memcpy(cpu-&gt;arch.model_name + 16, cpuid.as_chars,</a>
<a name="ln948">			sizeof(cpuid.as_chars));</a>
<a name="ln949"> </a>
<a name="ln950">		get_current_cpuid(&amp;cpuid, 0x80000004, 0);</a>
<a name="ln951">		temp = cpuid.regs.edx;</a>
<a name="ln952">		cpuid.regs.edx = cpuid.regs.ecx;</a>
<a name="ln953">		cpuid.regs.ecx = temp;</a>
<a name="ln954">		memcpy(cpu-&gt;arch.model_name + 32, cpuid.as_chars,</a>
<a name="ln955">			sizeof(cpuid.as_chars));</a>
<a name="ln956"> </a>
<a name="ln957">		// some cpus return a right-justified string</a>
<a name="ln958">		int32 i = 0;</a>
<a name="ln959">		while (cpu-&gt;arch.model_name[i] == ' ')</a>
<a name="ln960">			i++;</a>
<a name="ln961">		if (i &gt; 0) {</a>
<a name="ln962">			memmove(cpu-&gt;arch.model_name, &amp;cpu-&gt;arch.model_name[i],</a>
<a name="ln963">				strlen(&amp;cpu-&gt;arch.model_name[i]) + 1);</a>
<a name="ln964">		}</a>
<a name="ln965"> </a>
<a name="ln966">		dprintf(&quot;CPU %d: vendor '%s' model name '%s'\n&quot;,</a>
<a name="ln967">			currentCPU, cpu-&gt;arch.vendor_name, cpu-&gt;arch.model_name);</a>
<a name="ln968">	} else {</a>
<a name="ln969">		strlcpy(cpu-&gt;arch.model_name, &quot;unknown&quot;, sizeof(cpu-&gt;arch.model_name));</a>
<a name="ln970">	}</a>
<a name="ln971"> </a>
<a name="ln972">	// load feature bits</a>
<a name="ln973">	get_current_cpuid(&amp;cpuid, 1, 0);</a>
<a name="ln974">	cpu-&gt;arch.feature[FEATURE_COMMON] = cpuid.eax_1.features; // edx</a>
<a name="ln975">	cpu-&gt;arch.feature[FEATURE_EXT] = cpuid.eax_1.extended_features; // ecx</a>
<a name="ln976"> </a>
<a name="ln977">	if (maxExtendedLeaf &gt;= 0x80000001) {</a>
<a name="ln978">		get_current_cpuid(&amp;cpuid, 0x80000001, 0);</a>
<a name="ln979">		if (cpu-&gt;arch.vendor == VENDOR_AMD)</a>
<a name="ln980">			cpu-&gt;arch.feature[FEATURE_EXT_AMD_ECX] = cpuid.regs.ecx; // ecx</a>
<a name="ln981">		cpu-&gt;arch.feature[FEATURE_EXT_AMD] = cpuid.regs.edx; // edx</a>
<a name="ln982">		if (cpu-&gt;arch.vendor != VENDOR_AMD)</a>
<a name="ln983">			cpu-&gt;arch.feature[FEATURE_EXT_AMD] &amp;= IA32_FEATURES_INTEL_EXT;</a>
<a name="ln984">	}</a>
<a name="ln985"> </a>
<a name="ln986">	if (maxBasicLeaf &gt;= 5) {</a>
<a name="ln987">		get_current_cpuid(&amp;cpuid, 5, 0);</a>
<a name="ln988">		cpu-&gt;arch.feature[FEATURE_5_ECX] = cpuid.regs.ecx;</a>
<a name="ln989">	}</a>
<a name="ln990"> </a>
<a name="ln991">	if (maxBasicLeaf &gt;= 6) {</a>
<a name="ln992">		get_current_cpuid(&amp;cpuid, 6, 0);</a>
<a name="ln993">		cpu-&gt;arch.feature[FEATURE_6_EAX] = cpuid.regs.eax;</a>
<a name="ln994">		cpu-&gt;arch.feature[FEATURE_6_ECX] = cpuid.regs.ecx;</a>
<a name="ln995">	}</a>
<a name="ln996"> </a>
<a name="ln997">	if (maxBasicLeaf &gt;= 7) {</a>
<a name="ln998">		get_current_cpuid(&amp;cpuid, 7, 0);</a>
<a name="ln999">		cpu-&gt;arch.feature[FEATURE_7_EBX] = cpuid.regs.ebx;</a>
<a name="ln1000">		cpu-&gt;arch.feature[FEATURE_7_ECX] = cpuid.regs.ecx;</a>
<a name="ln1001">		cpu-&gt;arch.feature[FEATURE_7_EDX] = cpuid.regs.edx;</a>
<a name="ln1002">	}</a>
<a name="ln1003"> </a>
<a name="ln1004">	if (maxExtendedLeaf &gt;= 0x80000007) {</a>
<a name="ln1005">		get_current_cpuid(&amp;cpuid, 0x80000007, 0);</a>
<a name="ln1006">		cpu-&gt;arch.feature[FEATURE_EXT_7_EDX] = cpuid.regs.edx;</a>
<a name="ln1007">	}</a>
<a name="ln1008"> </a>
<a name="ln1009">	if (maxExtendedLeaf &gt;= 0x80000008) {</a>
<a name="ln1010">		get_current_cpuid(&amp;cpuid, 0x80000008, 0);</a>
<a name="ln1011">			cpu-&gt;arch.feature[FEATURE_EXT_8_EBX] = cpuid.regs.ebx;</a>
<a name="ln1012">	}</a>
<a name="ln1013"> </a>
<a name="ln1014">	detect_cpu_topology(currentCPU, cpu, maxBasicLeaf, maxExtendedLeaf);</a>
<a name="ln1015"> </a>
<a name="ln1016">#if DUMP_FEATURE_STRING</a>
<a name="ln1017">	dump_feature_string(currentCPU, cpu);</a>
<a name="ln1018">#endif</a>
<a name="ln1019">}</a>
<a name="ln1020"> </a>
<a name="ln1021"> </a>
<a name="ln1022">bool</a>
<a name="ln1023">x86_check_feature(uint32 feature, enum x86_feature_type type)</a>
<a name="ln1024">{</a>
<a name="ln1025">	cpu_ent* cpu = get_cpu_struct();</a>
<a name="ln1026"> </a>
<a name="ln1027">#if 0</a>
<a name="ln1028">	int i;</a>
<a name="ln1029">	dprintf(&quot;x86_check_feature: feature 0x%x, type %d\n&quot;, feature, type);</a>
<a name="ln1030">	for (i = 0; i &lt; FEATURE_NUM; i++) {</a>
<a name="ln1031">		dprintf(&quot;features %d: 0x%x\n&quot;, i, cpu-&gt;arch.feature[i]);</a>
<a name="ln1032">	}</a>
<a name="ln1033">#endif</a>
<a name="ln1034"> </a>
<a name="ln1035">	return (cpu-&gt;arch.feature[type] &amp; feature) != 0;</a>
<a name="ln1036">}</a>
<a name="ln1037"> </a>
<a name="ln1038"> </a>
<a name="ln1039">void*</a>
<a name="ln1040">x86_get_double_fault_stack(int32 cpu, size_t* _size)</a>
<a name="ln1041">{</a>
<a name="ln1042">	*_size = kDoubleFaultStackSize;</a>
<a name="ln1043">	return sDoubleFaultStacks + kDoubleFaultStackSize * cpu;</a>
<a name="ln1044">}</a>
<a name="ln1045"> </a>
<a name="ln1046"> </a>
<a name="ln1047">/*!	Returns the index of the current CPU. Can only be called from the double</a>
<a name="ln1048">	fault handler.</a>
<a name="ln1049">*/</a>
<a name="ln1050">int32</a>
<a name="ln1051">x86_double_fault_get_cpu(void)</a>
<a name="ln1052">{</a>
<a name="ln1053">	addr_t stack = x86_get_stack_frame();</a>
<a name="ln1054">	return (stack - (addr_t)sDoubleFaultStacks) / kDoubleFaultStackSize;</a>
<a name="ln1055">}</a>
<a name="ln1056"> </a>
<a name="ln1057"> </a>
<a name="ln1058">//	#pragma mark -</a>
<a name="ln1059"> </a>
<a name="ln1060"> </a>
<a name="ln1061">status_t</a>
<a name="ln1062">arch_cpu_preboot_init_percpu(kernel_args* args, int cpu)</a>
<a name="ln1063">{</a>
<a name="ln1064">	// On SMP system we want to synchronize the CPUs' TSCs, so system_time()</a>
<a name="ln1065">	// will return consistent values.</a>
<a name="ln1066">	if (smp_get_num_cpus() &gt; 1) {</a>
<a name="ln1067">		// let the first CPU prepare the rendezvous point</a>
<a name="ln1068">		if (cpu == 0)</a>
<a name="ln1069">			sTSCSyncRendezvous = smp_get_num_cpus() - 1;</a>
<a name="ln1070"> </a>
<a name="ln1071">		// One CPU after the other will drop out of this loop and be caught by</a>
<a name="ln1072">		// the loop below, until the last CPU (0) gets there. Save for +/- a few</a>
<a name="ln1073">		// cycles the CPUs should pass the second loop at the same time.</a>
<a name="ln1074">		while (sTSCSyncRendezvous != cpu) {</a>
<a name="ln1075">		}</a>
<a name="ln1076"> </a>
<a name="ln1077">		sTSCSyncRendezvous = cpu - 1;</a>
<a name="ln1078"> </a>
<a name="ln1079">		while (sTSCSyncRendezvous != -1) {</a>
<a name="ln1080">		}</a>
<a name="ln1081"> </a>
<a name="ln1082">		// reset TSC to 0</a>
<a name="ln1083">		x86_write_msr(IA32_MSR_TSC, 0);</a>
<a name="ln1084">	}</a>
<a name="ln1085"> </a>
<a name="ln1086">	x86_descriptors_preboot_init_percpu(args, cpu);</a>
<a name="ln1087"> </a>
<a name="ln1088">	return B_OK;</a>
<a name="ln1089">}</a>
<a name="ln1090"> </a>
<a name="ln1091"> </a>
<a name="ln1092">static void</a>
<a name="ln1093">halt_idle(void)</a>
<a name="ln1094">{</a>
<a name="ln1095">	asm(&quot;hlt&quot;);</a>
<a name="ln1096">}</a>
<a name="ln1097"> </a>
<a name="ln1098"> </a>
<a name="ln1099">static void</a>
<a name="ln1100">amdc1e_noarat_idle(void)</a>
<a name="ln1101">{</a>
<a name="ln1102">	uint64 msr = x86_read_msr(K8_MSR_IPM);</a>
<a name="ln1103">	if (msr &amp; K8_CMPHALT)</a>
<a name="ln1104">		x86_write_msr(K8_MSR_IPM, msr &amp; ~K8_CMPHALT);</a>
<a name="ln1105">	halt_idle();</a>
<a name="ln1106">}</a>
<a name="ln1107"> </a>
<a name="ln1108"> </a>
<a name="ln1109">static bool</a>
<a name="ln1110">detect_amdc1e_noarat()</a>
<a name="ln1111">{</a>
<a name="ln1112">	cpu_ent* cpu = get_cpu_struct();</a>
<a name="ln1113"> </a>
<a name="ln1114">	if (cpu-&gt;arch.vendor != VENDOR_AMD)</a>
<a name="ln1115">		return false;</a>
<a name="ln1116"> </a>
<a name="ln1117">	// Family 0x12 and higher processors support ARAT</a>
<a name="ln1118">	// Family lower than 0xf processors doesn't support C1E</a>
<a name="ln1119">	// Family 0xf with model &lt;= 0x40 procssors doesn't support C1E</a>
<a name="ln1120">	uint32 family = cpu-&gt;arch.family + cpu-&gt;arch.extended_family;</a>
<a name="ln1121">	uint32 model = (cpu-&gt;arch.extended_model &lt;&lt; 4) | cpu-&gt;arch.model;</a>
<a name="ln1122">	return (family &lt; 0x12 &amp;&amp; family &gt; 0xf) || (family == 0xf &amp;&amp; model &gt; 0x40);</a>
<a name="ln1123">}</a>
<a name="ln1124"> </a>
<a name="ln1125"> </a>
<a name="ln1126">status_t</a>
<a name="ln1127">arch_cpu_init_percpu(kernel_args* args, int cpu)</a>
<a name="ln1128">{</a>
<a name="ln1129">	detect_cpu(cpu);</a>
<a name="ln1130"> </a>
<a name="ln1131">	if (!gCpuIdleFunc) {</a>
<a name="ln1132">		if (detect_amdc1e_noarat())</a>
<a name="ln1133">			gCpuIdleFunc = amdc1e_noarat_idle;</a>
<a name="ln1134">		else</a>
<a name="ln1135">			gCpuIdleFunc = halt_idle;</a>
<a name="ln1136">	}</a>
<a name="ln1137"> </a>
<a name="ln1138">	return B_OK;</a>
<a name="ln1139">}</a>
<a name="ln1140"> </a>
<a name="ln1141"> </a>
<a name="ln1142">status_t</a>
<a name="ln1143">arch_cpu_init(kernel_args* args)</a>
<a name="ln1144">{</a>
<a name="ln1145">	// init the TSC -&gt; system_time() conversion factors</a>
<a name="ln1146"> </a>
<a name="ln1147">	uint32 conversionFactor = args-&gt;arch_args.system_time_cv_factor;</a>
<a name="ln1148">	uint64 conversionFactorNsecs = (uint64)conversionFactor * 1000;</a>
<a name="ln1149"> </a>
<a name="ln1150">#ifdef __x86_64__</a>
<a name="ln1151">	// The x86_64 system_time() implementation uses 64-bit multiplication and</a>
<a name="ln1152">	// therefore shifting is not necessary for low frequencies (it's also not</a>
<a name="ln1153">	// too likely that there'll be any x86_64 CPUs clocked under 1GHz).</a>
<a name="ln1154">	__x86_setup_system_time((uint64)conversionFactor &lt;&lt; 32,</a>
<a name="ln1155">		conversionFactorNsecs);</a>
<a name="ln1156">#else</a>
<a name="ln1157">	if (conversionFactorNsecs &gt;&gt; 32 != 0) {</a>
<a name="ln1158">		// the TSC frequency is &lt; 1 GHz, which forces us to shift the factor</a>
<a name="ln1159">		__x86_setup_system_time(conversionFactor, conversionFactorNsecs &gt;&gt; 16,</a>
<a name="ln1160">			true);</a>
<a name="ln1161">	} else {</a>
<a name="ln1162">		// the TSC frequency is &gt;= 1 GHz</a>
<a name="ln1163">		__x86_setup_system_time(conversionFactor, conversionFactorNsecs, false);</a>
<a name="ln1164">	}</a>
<a name="ln1165">#endif</a>
<a name="ln1166"> </a>
<a name="ln1167">	// Initialize descriptor tables.</a>
<a name="ln1168">	x86_descriptors_init(args);</a>
<a name="ln1169"> </a>
<a name="ln1170">	return B_OK;</a>
<a name="ln1171">}</a>
<a name="ln1172"> </a>
<a name="ln1173"> </a>
<a name="ln1174">#ifdef __x86_64__</a>
<a name="ln1175">static void</a>
<a name="ln1176">enable_smap(void* dummy, int cpu)</a>
<a name="ln1177">{</a>
<a name="ln1178">	x86_write_cr4(x86_read_cr4() | IA32_CR4_SMAP);</a>
<a name="ln1179">}</a>
<a name="ln1180"> </a>
<a name="ln1181"> </a>
<a name="ln1182">static void</a>
<a name="ln1183">enable_smep(void* dummy, int cpu)</a>
<a name="ln1184">{</a>
<a name="ln1185">	x86_write_cr4(x86_read_cr4() | IA32_CR4_SMEP);</a>
<a name="ln1186">}</a>
<a name="ln1187">#endif</a>
<a name="ln1188"> </a>
<a name="ln1189"> </a>
<a name="ln1190">status_t</a>
<a name="ln1191">arch_cpu_init_post_vm(kernel_args* args)</a>
<a name="ln1192">{</a>
<a name="ln1193">	uint32 i;</a>
<a name="ln1194"> </a>
<a name="ln1195">	// allocate an area for the double fault stacks</a>
<a name="ln1196">	virtual_address_restrictions virtualRestrictions = {};</a>
<a name="ln1197">	virtualRestrictions.address_specification = B_ANY_KERNEL_ADDRESS;</a>
<a name="ln1198">	physical_address_restrictions physicalRestrictions = {};</a>
<a name="ln1199">	create_area_etc(B_SYSTEM_TEAM, &quot;double fault stacks&quot;,</a>
<a name="ln1200">		kDoubleFaultStackSize * smp_get_num_cpus(), B_FULL_LOCK,</a>
<a name="ln1201">		B_KERNEL_READ_AREA | B_KERNEL_WRITE_AREA, CREATE_AREA_DONT_WAIT, 0,</a>
<a name="ln1202">		&amp;virtualRestrictions, &amp;physicalRestrictions,</a>
<a name="ln1203">		(void**)&amp;sDoubleFaultStacks);</a>
<a name="ln1204"> </a>
<a name="ln1205">	X86PagingStructures* kernelPagingStructures</a>
<a name="ln1206">		= static_cast&lt;X86VMTranslationMap*&gt;(</a>
<a name="ln1207">			VMAddressSpace::Kernel()-&gt;TranslationMap())-&gt;PagingStructures();</a>
<a name="ln1208"> </a>
<a name="ln1209">	// Set active translation map on each CPU.</a>
<a name="ln1210">	for (i = 0; i &lt; args-&gt;num_cpus; i++) {</a>
<a name="ln1211">		gCPU[i].arch.active_paging_structures = kernelPagingStructures;</a>
<a name="ln1212">		kernelPagingStructures-&gt;AddReference();</a>
<a name="ln1213">	}</a>
<a name="ln1214"> </a>
<a name="ln1215">	if (!apic_available())</a>
<a name="ln1216">		x86_init_fpu();</a>
<a name="ln1217">	// else fpu gets set up in smp code</a>
<a name="ln1218"> </a>
<a name="ln1219">#ifdef __x86_64__</a>
<a name="ln1220">	// if available enable SMEP (Supervisor Memory Execution Protection)</a>
<a name="ln1221">	if (x86_check_feature(IA32_FEATURE_SMEP, FEATURE_7_EBX)) {</a>
<a name="ln1222">		if (!get_safemode_boolean(B_SAFEMODE_DISABLE_SMEP_SMAP, false)) {</a>
<a name="ln1223">			dprintf(&quot;enable SMEP\n&quot;);</a>
<a name="ln1224">			call_all_cpus_sync(&amp;enable_smep, NULL);</a>
<a name="ln1225">		} else</a>
<a name="ln1226">			dprintf(&quot;SMEP disabled per safemode setting\n&quot;);</a>
<a name="ln1227">	}</a>
<a name="ln1228"> </a>
<a name="ln1229">	// if available enable SMAP (Supervisor Memory Access Protection)</a>
<a name="ln1230">	if (x86_check_feature(IA32_FEATURE_SMAP, FEATURE_7_EBX)) {</a>
<a name="ln1231">		if (!get_safemode_boolean(B_SAFEMODE_DISABLE_SMEP_SMAP, false)) {</a>
<a name="ln1232">			dprintf(&quot;enable SMAP\n&quot;);</a>
<a name="ln1233">			call_all_cpus_sync(&amp;enable_smap, NULL);</a>
<a name="ln1234"> </a>
<a name="ln1235">			arch_altcodepatch_replace(ALTCODEPATCH_TAG_STAC, &amp;_stac, 3);</a>
<a name="ln1236">			arch_altcodepatch_replace(ALTCODEPATCH_TAG_CLAC, &amp;_clac, 3);</a>
<a name="ln1237">		} else</a>
<a name="ln1238">			dprintf(&quot;SMAP disabled per safemode setting\n&quot;);</a>
<a name="ln1239">	}</a>
<a name="ln1240">#endif</a>
<a name="ln1241"> </a>
<a name="ln1242">	return B_OK;</a>
<a name="ln1243">}</a>
<a name="ln1244"> </a>
<a name="ln1245"> </a>
<a name="ln1246">status_t</a>
<a name="ln1247">arch_cpu_init_post_modules(kernel_args* args)</a>
<a name="ln1248">{</a>
<a name="ln1249">	// initialize CPU module</a>
<a name="ln1250"> </a>
<a name="ln1251">	void* cookie = open_module_list(&quot;cpu&quot;);</a>
<a name="ln1252"> </a>
<a name="ln1253">	while (true) {</a>
<a name="ln1254">		char name[B_FILE_NAME_LENGTH];</a>
<a name="ln1255">		size_t nameLength = sizeof(name);</a>
<a name="ln1256"> </a>
<a name="ln1257">		if (read_next_module_name(cookie, name, &amp;nameLength) != B_OK</a>
<a name="ln1258">			|| get_module(name, (module_info**)&amp;sCpuModule) == B_OK)</a>
<a name="ln1259">			break;</a>
<a name="ln1260">	}</a>
<a name="ln1261"> </a>
<a name="ln1262">	close_module_list(cookie);</a>
<a name="ln1263"> </a>
<a name="ln1264">	// initialize MTRRs if available</a>
<a name="ln1265">	if (x86_count_mtrrs() &gt; 0) {</a>
<a name="ln1266">		sCpuRendezvous = sCpuRendezvous2 = 0;</a>
<a name="ln1267">		call_all_cpus(&amp;init_mtrrs, NULL);</a>
<a name="ln1268">	}</a>
<a name="ln1269"> </a>
<a name="ln1270">	size_t threadExitLen = (addr_t)x86_end_userspace_thread_exit</a>
<a name="ln1271">		- (addr_t)x86_userspace_thread_exit;</a>
<a name="ln1272">	addr_t threadExitPosition = fill_commpage_entry(</a>
<a name="ln1273">		COMMPAGE_ENTRY_X86_THREAD_EXIT, (const void*)x86_userspace_thread_exit,</a>
<a name="ln1274">		threadExitLen);</a>
<a name="ln1275"> </a>
<a name="ln1276">	// add the functions to the commpage image</a>
<a name="ln1277">	image_id image = get_commpage_image();</a>
<a name="ln1278"> </a>
<a name="ln1279">	elf_add_memory_image_symbol(image, &quot;commpage_thread_exit&quot;,</a>
<a name="ln1280">		threadExitPosition, threadExitLen, B_SYMBOL_TYPE_TEXT);</a>
<a name="ln1281"> </a>
<a name="ln1282">	return B_OK;</a>
<a name="ln1283">}</a>
<a name="ln1284"> </a>
<a name="ln1285"> </a>
<a name="ln1286">void</a>
<a name="ln1287">arch_cpu_user_TLB_invalidate(void)</a>
<a name="ln1288">{</a>
<a name="ln1289">	x86_write_cr3(x86_read_cr3());</a>
<a name="ln1290">}</a>
<a name="ln1291"> </a>
<a name="ln1292"> </a>
<a name="ln1293">void</a>
<a name="ln1294">arch_cpu_global_TLB_invalidate(void)</a>
<a name="ln1295">{</a>
<a name="ln1296">	uint32 flags = x86_read_cr4();</a>
<a name="ln1297"> </a>
<a name="ln1298">	if (flags &amp; IA32_CR4_GLOBAL_PAGES) {</a>
<a name="ln1299">		// disable and reenable the global pages to flush all TLBs regardless</a>
<a name="ln1300">		// of the global page bit</a>
<a name="ln1301">		x86_write_cr4(flags &amp; ~IA32_CR4_GLOBAL_PAGES);</a>
<a name="ln1302">		x86_write_cr4(flags | IA32_CR4_GLOBAL_PAGES);</a>
<a name="ln1303">	} else {</a>
<a name="ln1304">		cpu_status state = disable_interrupts();</a>
<a name="ln1305">		arch_cpu_user_TLB_invalidate();</a>
<a name="ln1306">		restore_interrupts(state);</a>
<a name="ln1307">	}</a>
<a name="ln1308">}</a>
<a name="ln1309"> </a>
<a name="ln1310"> </a>
<a name="ln1311">void</a>
<a name="ln1312">arch_cpu_invalidate_TLB_range(addr_t start, addr_t end)</a>
<a name="ln1313">{</a>
<a name="ln1314">	int32 num_pages = end / B_PAGE_SIZE - start / B_PAGE_SIZE;</a>
<a name="ln1315">	while (num_pages-- &gt;= 0) {</a>
<a name="ln1316">		invalidate_TLB(start);</a>
<a name="ln1317">		start += B_PAGE_SIZE;</a>
<a name="ln1318">	}</a>
<a name="ln1319">}</a>
<a name="ln1320"> </a>
<a name="ln1321"> </a>
<a name="ln1322">void</a>
<a name="ln1323">arch_cpu_invalidate_TLB_list(addr_t pages[], int num_pages)</a>
<a name="ln1324">{</a>
<a name="ln1325">	int i;</a>
<a name="ln1326">	for (i = 0; i &lt; num_pages; i++) {</a>
<a name="ln1327">		invalidate_TLB(pages[i]);</a>
<a name="ln1328">	}</a>
<a name="ln1329">}</a>
<a name="ln1330"> </a>
<a name="ln1331"> </a>
<a name="ln1332">status_t</a>
<a name="ln1333">arch_cpu_shutdown(bool rebootSystem)</a>
<a name="ln1334">{</a>
<a name="ln1335">	if (acpi_shutdown(rebootSystem) == B_OK)</a>
<a name="ln1336">		return B_OK;</a>
<a name="ln1337"> </a>
<a name="ln1338">	if (!rebootSystem) {</a>
<a name="ln1339">#ifndef __x86_64__</a>
<a name="ln1340">		return apm_shutdown();</a>
<a name="ln1341">#else</a>
<a name="ln1342">		return B_NOT_SUPPORTED;</a>
<a name="ln1343">#endif</a>
<a name="ln1344">	}</a>
<a name="ln1345"> </a>
<a name="ln1346">	cpu_status state = disable_interrupts();</a>
<a name="ln1347"> </a>
<a name="ln1348">	// try to reset the system using the keyboard controller</a>
<a name="ln1349">	out8(0xfe, 0x64);</a>
<a name="ln1350"> </a>
<a name="ln1351">	// Give some time to the controller to do its job (0.5s)</a>
<a name="ln1352">	snooze(500000);</a>
<a name="ln1353"> </a>
<a name="ln1354">	// if that didn't help, try it this way</a>
<a name="ln1355">	x86_reboot();</a>
<a name="ln1356"> </a>
<a name="ln1357">	restore_interrupts(state);</a>
<a name="ln1358">	return B_ERROR;</a>
<a name="ln1359">}</a>
<a name="ln1360"> </a>
<a name="ln1361"> </a>
<a name="ln1362">void</a>
<a name="ln1363">arch_cpu_sync_icache(void* address, size_t length)</a>
<a name="ln1364">{</a>
<a name="ln1365">	// instruction cache is always consistent on x86</a>
<a name="ln1366">}</a>
<a name="ln1367"> </a>

</code></pre>
<div class="balloon" rel="818"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v547/" target="_blank">V547</a> Expression 'result == ((int) 0)' is always true.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
