
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
  <title>nvme_ctrlr.c</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">/*-</a>
<a name="ln2"> *   BSD LICENSE</a>
<a name="ln3"> *</a>
<a name="ln4"> *   Copyright (c) Intel Corporation. All rights reserved.</a>
<a name="ln5"> *   Copyright (c) 2017, Western Digital Corporation or its affiliates.</a>
<a name="ln6"> *</a>
<a name="ln7"> *   Redistribution and use in sourete and binary forms, with or without</a>
<a name="ln8"> *   modification, are permitted provided that the following conditions</a>
<a name="ln9"> *   are met:</a>
<a name="ln10"> *</a>
<a name="ln11"> *     * Redistributions of sourete code must retain the above copyright</a>
<a name="ln12"> *       notice, this list of conditions and the following disclaimer.</a>
<a name="ln13"> *     * Redistributions in binary form must reproduce the above copyright</a>
<a name="ln14"> *       notice, this list of conditions and the following disclaimer in</a>
<a name="ln15"> *       the documentation and/or other materials provided with the</a>
<a name="ln16"> *       distribution.</a>
<a name="ln17"> *     * Neither the name of Intel Corporation nor the names of its</a>
<a name="ln18"> *       contributors may be used to endorse or promote products derived</a>
<a name="ln19"> *       from this software without specific prior written permission.</a>
<a name="ln20"> *</a>
<a name="ln21"> *   THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS</a>
<a name="ln22"> *   &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT</a>
<a name="ln23"> *   LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR</a>
<a name="ln24"> *   A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT</a>
<a name="ln25"> *   OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,</a>
<a name="ln26"> *   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT</a>
<a name="ln27"> *   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,</a>
<a name="ln28"> *   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY</a>
<a name="ln29"> *   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT</a>
<a name="ln30"> *   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE</a>
<a name="ln31"> *   OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</a>
<a name="ln32"> */</a>
<a name="ln33"> </a>
<a name="ln34">#include &quot;nvme_internal.h&quot;</a>
<a name="ln35"> </a>
<a name="ln36">/*</a>
<a name="ln37"> * Host software shall wait a minimum of CAP.TO x 500 milleseconds for CSTS.RDY</a>
<a name="ln38"> * to be set to '1' after setting CC.EN to '1' from a previous value of '0'.</a>
<a name="ln39"> */</a>
<a name="ln40">static inline unsigned int</a>
<a name="ln41">nvme_ctrlr_get_ready_to_in_ms(struct nvme_ctrlr *ctrlr)</a>
<a name="ln42">{</a>
<a name="ln43">	union nvme_cap_register	cap;</a>
<a name="ln44"> </a>
<a name="ln45">/* The TO unit in ms */</a>
<a name="ln46">#define NVME_READY_TIMEOUT_UNIT 500</a>
<a name="ln47"> </a>
<a name="ln48">	cap.raw = nvme_reg_mmio_read_8(ctrlr, cap.raw);</a>
<a name="ln49"> </a>
<a name="ln50">	return (NVME_READY_TIMEOUT_UNIT * cap.bits.to);</a>
<a name="ln51">}</a>
<a name="ln52"> </a>
<a name="ln53">/*</a>
<a name="ln54"> * Create a queue pair.</a>
<a name="ln55"> */</a>
<a name="ln56">static int nvme_ctrlr_create_qpair(struct nvme_ctrlr *ctrlr,</a>
<a name="ln57">				   struct nvme_qpair *qpair)</a>
<a name="ln58">{</a>
<a name="ln59">	int ret;</a>
<a name="ln60"> </a>
<a name="ln61">	/* Create the completion queue */</a>
<a name="ln62">	ret = nvme_admin_create_ioq(ctrlr, qpair, NVME_IO_COMPLETION_QUEUE);</a>
<a name="ln63">	if (ret != 0) {</a>
<a name="ln64">		nvme_notice(&quot;Create completion queue %u failed\n&quot;,</a>
<a name="ln65">			    qpair-&gt;id);</a>
<a name="ln66">		return ret;</a>
<a name="ln67">	}</a>
<a name="ln68"> </a>
<a name="ln69">	/* Create the submission queue */</a>
<a name="ln70">	ret = nvme_admin_create_ioq(ctrlr, qpair, NVME_IO_SUBMISSION_QUEUE);</a>
<a name="ln71">	if (ret != 0) {</a>
<a name="ln72">		/* Attempt to delete the completion queue */</a>
<a name="ln73">		nvme_notice(&quot;Create submission queue %u failed\n&quot;,</a>
<a name="ln74">			    qpair-&gt;id);</a>
<a name="ln75">		nvme_admin_delete_ioq(ctrlr, qpair, NVME_IO_COMPLETION_QUEUE);</a>
<a name="ln76">		return ret;</a>
<a name="ln77">	}</a>
<a name="ln78"> </a>
<a name="ln79">	nvme_qpair_reset(qpair);</a>
<a name="ln80"> </a>
<a name="ln81">	return 0;</a>
<a name="ln82">}</a>
<a name="ln83"> </a>
<a name="ln84">/*</a>
<a name="ln85"> * Delete a queue pair.</a>
<a name="ln86"> */</a>
<a name="ln87">static int nvme_ctrlr_delete_qpair(struct nvme_ctrlr *ctrlr,</a>
<a name="ln88">				   struct nvme_qpair *qpair)</a>
<a name="ln89">{</a>
<a name="ln90">	int ret;</a>
<a name="ln91"> </a>
<a name="ln92">	/* Delete the submission queue */</a>
<a name="ln93">	ret = nvme_admin_delete_ioq(ctrlr, qpair, NVME_IO_SUBMISSION_QUEUE);</a>
<a name="ln94">	if (ret != 0) {</a>
<a name="ln95">		nvme_notice(&quot;Delete submission queue %u failed\n&quot;,</a>
<a name="ln96">			    qpair-&gt;id);</a>
<a name="ln97">		return ret;</a>
<a name="ln98">	}</a>
<a name="ln99"> </a>
<a name="ln100">	/* Delete the completion queue */</a>
<a name="ln101">	ret = nvme_admin_delete_ioq(ctrlr, qpair, NVME_IO_COMPLETION_QUEUE);</a>
<a name="ln102">	if (ret != 0) {</a>
<a name="ln103">		nvme_notice(&quot;Delete completion queue %u failed\n&quot;,</a>
<a name="ln104">			    qpair-&gt;id);</a>
<a name="ln105">		return ret;</a>
<a name="ln106">	}</a>
<a name="ln107"> </a>
<a name="ln108">	return 0;</a>
<a name="ln109">}</a>
<a name="ln110"> </a>
<a name="ln111">/*</a>
<a name="ln112"> * Intel log page.</a>
<a name="ln113"> */</a>
<a name="ln114">static void</a>
<a name="ln115">nvme_ctrlr_construct_intel_support_log_page_list(struct nvme_ctrlr *ctrlr,</a>
<a name="ln116">				struct nvme_intel_log_page_dir *log_page_dir)</a>
<a name="ln117">{</a>
<a name="ln118"> </a>
<a name="ln119">	if (ctrlr-&gt;cdata.vid != NVME_PCI_VID_INTEL ||</a>
<a name="ln120">	    log_page_dir == NULL)</a>
<a name="ln121">		return;</a>
<a name="ln122"> </a>
<a name="ln123">	ctrlr-&gt;log_page_supported[NVME_INTEL_LOG_PAGE_DIR] = true;</a>
<a name="ln124"> </a>
<a name="ln125">	if (log_page_dir-&gt;read_latency_log_len ||</a>
<a name="ln126">	    (ctrlr-&gt;quirks &amp; NVME_INTEL_QUIRK_READ_LATENCY))</a>
<a name="ln127">		ctrlr-&gt;log_page_supported[NVME_INTEL_LOG_READ_CMD_LATENCY] = true;</a>
<a name="ln128"> </a>
<a name="ln129">	if (log_page_dir-&gt;write_latency_log_len ||</a>
<a name="ln130">	    (ctrlr-&gt;quirks &amp; NVME_INTEL_QUIRK_WRITE_LATENCY))</a>
<a name="ln131">		ctrlr-&gt;log_page_supported[NVME_INTEL_LOG_WRITE_CMD_LATENCY] = true;</a>
<a name="ln132"> </a>
<a name="ln133">	if (log_page_dir-&gt;temperature_statistics_log_len)</a>
<a name="ln134">		ctrlr-&gt;log_page_supported[NVME_INTEL_LOG_TEMPERATURE] = true;</a>
<a name="ln135"> </a>
<a name="ln136">	if (log_page_dir-&gt;smart_log_len)</a>
<a name="ln137">		ctrlr-&gt;log_page_supported[NVME_INTEL_LOG_SMART] = true;</a>
<a name="ln138"> </a>
<a name="ln139">	if (log_page_dir-&gt;marketing_description_log_len)</a>
<a name="ln140">		ctrlr-&gt;log_page_supported[NVME_INTEL_MARKETING_DESCRIPTION] = true;</a>
<a name="ln141">}</a>
<a name="ln142"> </a>
<a name="ln143">/*</a>
<a name="ln144"> * Intel log page.</a>
<a name="ln145"> */</a>
<a name="ln146">static int nvme_ctrlr_set_intel_support_log_pages(struct nvme_ctrlr *ctrlr)</a>
<a name="ln147">{</a>
<a name="ln148">	struct nvme_intel_log_page_dir *log_page_dir;</a>
<a name="ln149">	int ret;</a>
<a name="ln150"> </a>
<a name="ln151">	log_page_dir = nvme_zmalloc(sizeof(struct nvme_intel_log_page_dir), 64);</a>
<a name="ln152">	if (!log_page_dir) {</a>
<a name="ln153">		nvme_err(&quot;Allocate log_page_directory failed\n&quot;);</a>
<a name="ln154">		return ENOMEM;</a>
<a name="ln155">	}</a>
<a name="ln156"> </a>
<a name="ln157">	ret = nvme_admin_get_log_page(ctrlr, NVME_INTEL_LOG_PAGE_DIR,</a>
<a name="ln158">				      NVME_GLOBAL_NS_TAG,</a>
<a name="ln159">				      log_page_dir,</a>
<a name="ln160">				      sizeof(struct nvme_intel_log_page_dir));</a>
<a name="ln161">	if (ret != 0)</a>
<a name="ln162">		nvme_notice(&quot;Get NVME_INTEL_LOG_PAGE_DIR log page failed\n&quot;);</a>
<a name="ln163">	else</a>
<a name="ln164">		nvme_ctrlr_construct_intel_support_log_page_list(ctrlr,</a>
<a name="ln165">								 log_page_dir);</a>
<a name="ln166"> </a>
<a name="ln167">	nvme_free(log_page_dir);</a>
<a name="ln168"> </a>
<a name="ln169">	return ret;</a>
<a name="ln170">}</a>
<a name="ln171"> </a>
<a name="ln172">/*</a>
<a name="ln173"> * Initialize log page support directory.</a>
<a name="ln174"> */</a>
<a name="ln175">static void nvme_ctrlr_set_supported_log_pages(struct nvme_ctrlr *ctrlr)</a>
<a name="ln176">{</a>
<a name="ln177"> </a>
<a name="ln178">	memset(ctrlr-&gt;log_page_supported, 0, sizeof(ctrlr-&gt;log_page_supported));</a>
<a name="ln179"> </a>
<a name="ln180">	/* Mandatory pages */</a>
<a name="ln181">	ctrlr-&gt;log_page_supported[NVME_LOG_ERROR] = true;</a>
<a name="ln182">	ctrlr-&gt;log_page_supported[NVME_LOG_HEALTH_INFORMATION] = true;</a>
<a name="ln183">	ctrlr-&gt;log_page_supported[NVME_LOG_FIRMWARE_SLOT] = true;</a>
<a name="ln184"> </a>
<a name="ln185">	if (ctrlr-&gt;cdata.lpa.celp)</a>
<a name="ln186">		ctrlr-&gt;log_page_supported[NVME_LOG_COMMAND_EFFECTS_LOG] = true;</a>
<a name="ln187"> </a>
<a name="ln188">	if (ctrlr-&gt;cdata.vid == NVME_PCI_VID_INTEL)</a>
<a name="ln189">		nvme_ctrlr_set_intel_support_log_pages(ctrlr);</a>
<a name="ln190">}</a>
<a name="ln191"> </a>
<a name="ln192">/*</a>
<a name="ln193"> * Set Intel device features.</a>
<a name="ln194"> */</a>
<a name="ln195">static void nvme_ctrlr_set_intel_supported_features(struct nvme_ctrlr *ctrlr)</a>
<a name="ln196">{</a>
<a name="ln197">	bool *supported_feature = ctrlr-&gt;feature_supported;</a>
<a name="ln198"> </a>
<a name="ln199">	supported_feature[NVME_INTEL_FEAT_MAX_LBA] = true;</a>
<a name="ln200">	supported_feature[NVME_INTEL_FEAT_MAX_LBA] = true;</a>
<a name="ln201">	supported_feature[NVME_INTEL_FEAT_NATIVE_MAX_LBA] = true;</a>
<a name="ln202">	supported_feature[NVME_INTEL_FEAT_POWER_GOVERNOR_SETTING] = true;</a>
<a name="ln203">	supported_feature[NVME_INTEL_FEAT_SMBUS_ADDRESS] = true;</a>
<a name="ln204">	supported_feature[NVME_INTEL_FEAT_LED_PATTERN] = true;</a>
<a name="ln205">	supported_feature[NVME_INTEL_FEAT_RESET_TIMED_WORKLOAD_COUNTERS] = true;</a>
<a name="ln206">	supported_feature[NVME_INTEL_FEAT_LATENCY_TRACKING] = true;</a>
<a name="ln207">}</a>
<a name="ln208"> </a>
<a name="ln209">/*</a>
<a name="ln210"> * Set device features.</a>
<a name="ln211"> */</a>
<a name="ln212">static void nvme_ctrlr_set_supported_features(struct nvme_ctrlr *ctrlr)</a>
<a name="ln213">{</a>
<a name="ln214">	bool *supported_feature = ctrlr-&gt;feature_supported;</a>
<a name="ln215"> </a>
<a name="ln216">	memset(ctrlr-&gt;feature_supported, 0, sizeof(ctrlr-&gt;feature_supported));</a>
<a name="ln217"> </a>
<a name="ln218">	/* Mandatory features */</a>
<a name="ln219">	supported_feature[NVME_FEAT_ARBITRATION] = true;</a>
<a name="ln220">	supported_feature[NVME_FEAT_POWER_MANAGEMENT] = true;</a>
<a name="ln221">	supported_feature[NVME_FEAT_TEMPERATURE_THRESHOLD] = true;</a>
<a name="ln222">	supported_feature[NVME_FEAT_ERROR_RECOVERY] = true;</a>
<a name="ln223">	supported_feature[NVME_FEAT_NUMBER_OF_QUEUES] = true;</a>
<a name="ln224">	supported_feature[NVME_FEAT_INTERRUPT_COALESCING] = true;</a>
<a name="ln225">	supported_feature[NVME_FEAT_INTERRUPT_VECTOR_CONFIGURATION] = true;</a>
<a name="ln226">	supported_feature[NVME_FEAT_WRITE_ATOMICITY] = true;</a>
<a name="ln227">	supported_feature[NVME_FEAT_ASYNC_EVENT_CONFIGURATION] = true;</a>
<a name="ln228"> </a>
<a name="ln229">	/* Optional features */</a>
<a name="ln230">	if (ctrlr-&gt;cdata.vwc.present)</a>
<a name="ln231">		supported_feature[NVME_FEAT_VOLATILE_WRITE_CACHE] = true;</a>
<a name="ln232">	if (ctrlr-&gt;cdata.apsta.supported)</a>
<a name="ln233">		supported_feature[NVME_FEAT_AUTONOMOUS_POWER_STATE_TRANSITION]</a>
<a name="ln234">			= true;</a>
<a name="ln235">	if (ctrlr-&gt;cdata.hmpre)</a>
<a name="ln236">		supported_feature[NVME_FEAT_HOST_MEM_BUFFER] = true;</a>
<a name="ln237">	if (ctrlr-&gt;cdata.vid == NVME_PCI_VID_INTEL)</a>
<a name="ln238">		nvme_ctrlr_set_intel_supported_features(ctrlr);</a>
<a name="ln239">}</a>
<a name="ln240"> </a>
<a name="ln241">/*</a>
<a name="ln242"> * Initialize I/O queue pairs.</a>
<a name="ln243"> */</a>
<a name="ln244">static int nvme_ctrlr_init_io_qpairs(struct nvme_ctrlr *ctrlr)</a>
<a name="ln245">{</a>
<a name="ln246">	struct nvme_qpair *qpair;</a>
<a name="ln247">	union nvme_cap_register	cap;</a>
<a name="ln248">	uint32_t i;</a>
<a name="ln249"> </a>
<a name="ln250">	if (ctrlr-&gt;ioq != NULL)</a>
<a name="ln251">		/*</a>
<a name="ln252">		 * io_qpairs were already constructed, so just return.</a>
<a name="ln253">		 * This typically happens when the controller is</a>
<a name="ln254">		 * initialized a second (or subsequent) time after a</a>
<a name="ln255">		 * controller reset.</a>
<a name="ln256">		 */</a>
<a name="ln257">		return 0;</a>
<a name="ln258"> </a>
<a name="ln259">	/*</a>
<a name="ln260">	 * NVMe spec sets a hard limit of 64K max entries, but</a>
<a name="ln261">	 * devices may specify a smaller limit, so we need to check</a>
<a name="ln262">	 * the MQES field in the capabilities register.</a>
<a name="ln263">	 */</a>
<a name="ln264">	cap.raw = nvme_reg_mmio_read_8(ctrlr, cap.raw);</a>
<a name="ln265">	ctrlr-&gt;io_qpairs_max_entries =</a>
<a name="ln266">		nvme_min(NVME_IO_ENTRIES, (unsigned int)cap.bits.mqes + 1);</a>
<a name="ln267"> </a>
<a name="ln268">	ctrlr-&gt;ioq = calloc(ctrlr-&gt;io_queues, sizeof(struct nvme_qpair));</a>
<a name="ln269">	if (!ctrlr-&gt;ioq)</a>
<a name="ln270">		return ENOMEM;</a>
<a name="ln271"> </a>
<a name="ln272">	/* Keep queue pair ID 0 for the admin queue */</a>
<a name="ln273">	for (i = 0; i &lt; ctrlr-&gt;io_queues; i++) {</a>
<a name="ln274">		qpair = &amp;ctrlr-&gt;ioq[i];</a>
<a name="ln275">		qpair-&gt;id = i + 1;</a>
<a name="ln276">		TAILQ_INSERT_TAIL(&amp;ctrlr-&gt;free_io_qpairs, qpair, tailq);</a>
<a name="ln277">	}</a>
<a name="ln278"> </a>
<a name="ln279">	return 0;</a>
<a name="ln280">}</a>
<a name="ln281"> </a>
<a name="ln282">/*</a>
<a name="ln283"> * Shutdown a controller.</a>
<a name="ln284"> */</a>
<a name="ln285">static void nvme_ctrlr_shutdown(struct nvme_ctrlr *ctrlr)</a>
<a name="ln286">{</a>
<a name="ln287">	union nvme_cc_register	cc;</a>
<a name="ln288">	union nvme_csts_register csts;</a>
<a name="ln289">	int ms_waited = 0;</a>
<a name="ln290"> </a>
<a name="ln291">	cc.raw = nvme_reg_mmio_read_4(ctrlr, cc.raw);</a>
<a name="ln292">	cc.bits.shn = NVME_SHN_NORMAL;</a>
<a name="ln293">	nvme_reg_mmio_write_4(ctrlr, cc.raw, cc.raw);</a>
<a name="ln294"> </a>
<a name="ln295">	csts.raw = nvme_reg_mmio_read_4(ctrlr, csts.raw);</a>
<a name="ln296">	/*</a>
<a name="ln297">	 * The NVMe spec does not define a timeout period for shutdown</a>
<a name="ln298">	 * notification, so we just pick 5 seconds as a reasonable amount</a>
<a name="ln299">	 * of time to wait before proceeding.</a>
<a name="ln300">	 */</a>
<a name="ln301">#define NVME_CTRLR_SHUTDOWN_TIMEOUT 5000</a>
<a name="ln302">	while (csts.bits.shst != NVME_SHST_COMPLETE) {</a>
<a name="ln303">		nvme_usleep(1000);</a>
<a name="ln304">		csts.raw = nvme_reg_mmio_read_4(ctrlr, csts.raw);</a>
<a name="ln305">		if (ms_waited++ &gt;= NVME_CTRLR_SHUTDOWN_TIMEOUT)</a>
<a name="ln306">			break;</a>
<a name="ln307">	}</a>
<a name="ln308"> </a>
<a name="ln309">	if (csts.bits.shst != NVME_SHST_COMPLETE)</a>
<a name="ln310">		nvme_err(&quot;Controller did not shutdown within %d seconds\n&quot;,</a>
<a name="ln311">			 NVME_CTRLR_SHUTDOWN_TIMEOUT / 1000);</a>
<a name="ln312">}</a>
<a name="ln313"> </a>
<a name="ln314">/*</a>
<a name="ln315"> * Enable a controller.</a>
<a name="ln316"> */</a>
<a name="ln317">static int nvme_ctrlr_enable(struct nvme_ctrlr *ctrlr)</a>
<a name="ln318">{</a>
<a name="ln319">	union nvme_cc_register	cc;</a>
<a name="ln320">	union nvme_aqa_register	aqa;</a>
<a name="ln321">	union nvme_cap_register	cap;</a>
<a name="ln322"> </a>
<a name="ln323">	cc.raw = nvme_reg_mmio_read_4(ctrlr, cc.raw);</a>
<a name="ln324"> </a>
<a name="ln325">	if (cc.bits.en != 0) {</a>
<a name="ln326">		nvme_err(&quot;COntroller enable called with CC.EN = 1\n&quot;);</a>
<a name="ln327">		return EINVAL;</a>
<a name="ln328">	}</a>
<a name="ln329"> </a>
<a name="ln330">	nvme_reg_mmio_write_8(ctrlr, asq, ctrlr-&gt;adminq.cmd_bus_addr);</a>
<a name="ln331">	nvme_reg_mmio_write_8(ctrlr, acq, ctrlr-&gt;adminq.cpl_bus_addr);</a>
<a name="ln332"> </a>
<a name="ln333">	aqa.raw = 0;</a>
<a name="ln334">	/* acqs and asqs are 0-based. */</a>
<a name="ln335">	aqa.bits.acqs = ctrlr-&gt;adminq.entries - 1;</a>
<a name="ln336">	aqa.bits.asqs = ctrlr-&gt;adminq.entries - 1;</a>
<a name="ln337">	nvme_reg_mmio_write_4(ctrlr, aqa.raw, aqa.raw);</a>
<a name="ln338"> </a>
<a name="ln339">	cc.bits.en = 1;</a>
<a name="ln340">	cc.bits.css = 0;</a>
<a name="ln341">	cc.bits.shn = 0;</a>
<a name="ln342">	cc.bits.iosqes = 6; /* SQ entry size == 64 == 2^6 */</a>
<a name="ln343">	cc.bits.iocqes = 4; /* CQ entry size == 16 == 2^4 */</a>
<a name="ln344"> </a>
<a name="ln345">	/* Page size is 2 ^ (12 + mps). */</a>
<a name="ln346">	cc.bits.mps = PAGE_SHIFT - 12;</a>
<a name="ln347"> </a>
<a name="ln348">	cap.raw = nvme_reg_mmio_read_8(ctrlr, cap.raw);</a>
<a name="ln349"> </a>
<a name="ln350">	switch (ctrlr-&gt;opts.arb_mechanism) {</a>
<a name="ln351">	case NVME_CC_AMS_RR:</a>
<a name="ln352">		break;</a>
<a name="ln353">	case NVME_CC_AMS_WRR:</a>
<a name="ln354">		if (NVME_CAP_AMS_WRR &amp; cap.bits.ams)</a>
<a name="ln355">			break;</a>
<a name="ln356">		return EINVAL;</a>
<a name="ln357">	case NVME_CC_AMS_VS:</a>
<a name="ln358">		if (NVME_CAP_AMS_VS &amp; cap.bits.ams)</a>
<a name="ln359">			break;</a>
<a name="ln360">		return EINVAL;</a>
<a name="ln361">	default:</a>
<a name="ln362">		return EINVAL;</a>
<a name="ln363">	}</a>
<a name="ln364"> </a>
<a name="ln365">	cc.bits.ams = ctrlr-&gt;opts.arb_mechanism;</a>
<a name="ln366"> </a>
<a name="ln367">	nvme_reg_mmio_write_4(ctrlr, cc.raw, cc.raw);</a>
<a name="ln368"> </a>
<a name="ln369">	return 0;</a>
<a name="ln370">}</a>
<a name="ln371"> </a>
<a name="ln372">/*</a>
<a name="ln373"> * Disable a controller.</a>
<a name="ln374"> */</a>
<a name="ln375">static inline void nvme_ctrlr_disable(struct nvme_ctrlr *ctrlr)</a>
<a name="ln376">{</a>
<a name="ln377">	union nvme_cc_register cc;</a>
<a name="ln378"> </a>
<a name="ln379">	cc.raw = nvme_reg_mmio_read_4(ctrlr, cc.raw);</a>
<a name="ln380">	cc.bits.en = 0;</a>
<a name="ln381"> </a>
<a name="ln382">	nvme_reg_mmio_write_4(ctrlr, cc.raw, cc.raw);</a>
<a name="ln383">}</a>
<a name="ln384"> </a>
<a name="ln385">/*</a>
<a name="ln386"> * Test if a controller is enabled.</a>
<a name="ln387"> */</a>
<a name="ln388">static inline int nvme_ctrlr_enabled(struct nvme_ctrlr *ctrlr)</a>
<a name="ln389">{</a>
<a name="ln390">	union nvme_cc_register cc;</a>
<a name="ln391"> </a>
<a name="ln392">	cc.raw = nvme_reg_mmio_read_4(ctrlr, cc.raw);</a>
<a name="ln393"> </a>
<a name="ln394">	return cc.bits.en;</a>
<a name="ln395">}</a>
<a name="ln396"> </a>
<a name="ln397">/*</a>
<a name="ln398"> * Test if a controller is ready.</a>
<a name="ln399"> */</a>
<a name="ln400">static inline int nvme_ctrlr_ready(struct nvme_ctrlr *ctrlr)</a>
<a name="ln401">{</a>
<a name="ln402">	union nvme_csts_register csts;</a>
<a name="ln403"> </a>
<a name="ln404">	csts.raw = nvme_reg_mmio_read_4(ctrlr, csts.raw);</a>
<a name="ln405"> </a>
<a name="ln406">	return csts.bits.rdy;</a>
<a name="ln407">}</a>
<a name="ln408"> </a>
<a name="ln409">/*</a>
<a name="ln410"> * Set a controller state.</a>
<a name="ln411"> */</a>
<a name="ln412">static void nvme_ctrlr_set_state(struct nvme_ctrlr *ctrlr,</a>
<a name="ln413">				 enum nvme_ctrlr_state state,</a>
<a name="ln414">				 uint64_t timeout_in_ms)</a>
<a name="ln415">{</a>
<a name="ln416">	ctrlr-&gt;state = state;</a>
<a name="ln417">	if (timeout_in_ms == NVME_TIMEOUT_INFINITE)</a>
<a name="ln418">		ctrlr-&gt;state_timeout_ms = NVME_TIMEOUT_INFINITE;</a>
<a name="ln419">	else</a>
<a name="ln420">		ctrlr-&gt;state_timeout_ms = nvme_time_msec() + timeout_in_ms;</a>
<a name="ln421">}</a>
<a name="ln422"> </a>
<a name="ln423">/*</a>
<a name="ln424"> * Get a controller data.</a>
<a name="ln425"> */</a>
<a name="ln426">static int nvme_ctrlr_identify(struct nvme_ctrlr *ctrlr)</a>
<a name="ln427">{</a>
<a name="ln428">	int ret;</a>
<a name="ln429"> </a>
<a name="ln430">	ret = nvme_admin_identify_ctrlr(ctrlr, &amp;ctrlr-&gt;cdata);</a>
<a name="ln431">	if (ret != 0) {</a>
<a name="ln432">		nvme_notice(&quot;Identify controller failed\n&quot;);</a>
<a name="ln433">		return ret;</a>
<a name="ln434">	}</a>
<a name="ln435"> </a>
<a name="ln436">	/*</a>
<a name="ln437">	 * Use MDTS to ensure our default max_xfer_size doesn't</a>
<a name="ln438">	 * exceed what the controller supports.</a>
<a name="ln439">	 */</a>
<a name="ln440">	if (ctrlr-&gt;cdata.mdts &gt; 0)</a>
<a name="ln441">		ctrlr-&gt;max_xfer_size = nvme_min(ctrlr-&gt;max_xfer_size,</a>
<a name="ln442">						ctrlr-&gt;min_page_size</a>
<a name="ln443">						* (1 &lt;&lt; (ctrlr-&gt;cdata.mdts)));</a>
<a name="ln444">	return 0;</a>
<a name="ln445">}</a>
<a name="ln446"> </a>
<a name="ln447">/*</a>
<a name="ln448"> * Set the number of I/O queue pairs.</a>
<a name="ln449"> */</a>
<a name="ln450">static int nvme_ctrlr_get_max_io_qpairs(struct nvme_ctrlr *ctrlr)</a>
<a name="ln451">{</a>
<a name="ln452">	unsigned int cdw0, cq_allocated, sq_allocated;</a>
<a name="ln453">	int ret;</a>
<a name="ln454"> </a>
<a name="ln455">	ret = nvme_admin_get_feature(ctrlr, NVME_FEAT_CURRENT,</a>
<a name="ln456">				     NVME_FEAT_NUMBER_OF_QUEUES,</a>
<a name="ln457">				     0, &amp;cdw0);</a>
<a name="ln458">	if (ret != 0) {</a>
<a name="ln459">		nvme_notice(&quot;Get feature NVME_FEAT_NUMBER_OF_QUEUES failed\n&quot;);</a>
<a name="ln460">		return ret;</a>
<a name="ln461">	}</a>
<a name="ln462"> </a>
<a name="ln463">	/*</a>
<a name="ln464">	 * Data in cdw0 is 0-based.</a>
<a name="ln465">	 * Lower 16-bits indicate number of submission queues allocated.</a>
<a name="ln466">	 * Upper 16-bits indicate number of completion queues allocated.</a>
<a name="ln467">	 */</a>
<a name="ln468">	sq_allocated = (cdw0 &amp; 0xFFFF) + 1;</a>
<a name="ln469">	cq_allocated = (cdw0 &gt;&gt; 16) + 1;</a>
<a name="ln470"> </a>
<a name="ln471">	ctrlr-&gt;max_io_queues = nvme_min(sq_allocated, cq_allocated);</a>
<a name="ln472"> </a>
<a name="ln473">	return 0;</a>
<a name="ln474">}</a>
<a name="ln475"> </a>
<a name="ln476">/*</a>
<a name="ln477"> * Set the number of I/O queue pairs.</a>
<a name="ln478"> */</a>
<a name="ln479">static int nvme_ctrlr_set_num_qpairs(struct nvme_ctrlr *ctrlr)</a>
<a name="ln480">{</a>
<a name="ln481">	unsigned int num_queues, cdw0;</a>
<a name="ln482">	unsigned int cq_allocated, sq_allocated;</a>
<a name="ln483">	int ret;</a>
<a name="ln484"> </a>
<a name="ln485">	ret = nvme_ctrlr_get_max_io_qpairs(ctrlr);</a>
<a name="ln486">	if (ret != 0) {</a>
<a name="ln487">		nvme_notice(&quot;Failed to get the maximum of I/O qpairs\n&quot;);</a>
<a name="ln488">		return ret;</a>
<a name="ln489">	}</a>
<a name="ln490"> </a>
<a name="ln491">	/*</a>
<a name="ln492">	 * Format number of I/O queue:</a>
<a name="ln493">	 * Remove 1 as it as be be 0-based,</a>
<a name="ln494">	 * bits 31:16 represent the number of completion queues,</a>
<a name="ln495">	 * bits 0:15 represent the number of submission queues</a>
<a name="ln496">	*/</a>
<a name="ln497">	num_queues = ((ctrlr-&gt;opts.io_queues - 1) &lt;&lt; 16) |</a>
<a name="ln498">		(ctrlr-&gt;opts.io_queues - 1);</a>
<a name="ln499"> </a>
<a name="ln500">	/*</a>
<a name="ln501">	 * Set the number of I/O queues.</a>
<a name="ln502">	 * Note: The value allocated may be smaller or larger than the number</a>
<a name="ln503">	 * of queues requested (see specifications).</a>
<a name="ln504">	 */</a>
<a name="ln505">	ret = nvme_admin_set_feature(ctrlr, false, NVME_FEAT_NUMBER_OF_QUEUES,</a>
<a name="ln506">				     num_queues, 0, &amp;cdw0);</a>
<a name="ln507">	if (ret != 0) {</a>
<a name="ln508">		nvme_notice(&quot;Set feature NVME_FEAT_NUMBER_OF_QUEUES failed\n&quot;);</a>
<a name="ln509">		return ret;</a>
<a name="ln510">	}</a>
<a name="ln511"> </a>
<a name="ln512">	/*</a>
<a name="ln513">	 * Data in cdw0 is 0-based.</a>
<a name="ln514">	 * Lower 16-bits indicate number of submission queues allocated.</a>
<a name="ln515">	 * Upper 16-bits indicate number of completion queues allocated.</a>
<a name="ln516">	 */</a>
<a name="ln517">	sq_allocated = (cdw0 &amp; 0xFFFF) + 1;</a>
<a name="ln518">	cq_allocated = (cdw0 &gt;&gt; 16) + 1;</a>
<a name="ln519">	ctrlr-&gt;io_queues = nvme_min(sq_allocated, cq_allocated);</a>
<a name="ln520"> </a>
<a name="ln521">	/*</a>
<a name="ln522">	 * Make sure the number of constructed qpair listed in free_io_qpairs</a>
<a name="ln523">	 * will not be more than the requested one.</a>
<a name="ln524">	 */</a>
<a name="ln525">	ctrlr-&gt;io_queues = nvme_min(ctrlr-&gt;io_queues, ctrlr-&gt;opts.io_queues);</a>
<a name="ln526"> </a>
<a name="ln527">	return 0;</a>
<a name="ln528">}</a>
<a name="ln529"> </a>
<a name="ln530">static void nvme_ctrlr_destruct_namespaces(struct nvme_ctrlr *ctrlr)</a>
<a name="ln531">{</a>
<a name="ln532"> </a>
<a name="ln533">	if (ctrlr-&gt;ns) {</a>
<a name="ln534">		free(ctrlr-&gt;ns);</a>
<a name="ln535">		ctrlr-&gt;ns = NULL;</a>
<a name="ln536">		ctrlr-&gt;nr_ns = 0;</a>
<a name="ln537">	}</a>
<a name="ln538"> </a>
<a name="ln539">	if (ctrlr-&gt;nsdata) {</a>
<a name="ln540">		nvme_free(ctrlr-&gt;nsdata);</a>
<a name="ln541">		ctrlr-&gt;nsdata = NULL;</a>
<a name="ln542">	}</a>
<a name="ln543">}</a>
<a name="ln544"> </a>
<a name="ln545">static int nvme_ctrlr_construct_namespaces(struct nvme_ctrlr *ctrlr)</a>
<a name="ln546">{</a>
<a name="ln547">	unsigned int i, nr_ns = ctrlr-&gt;cdata.nn;</a>
<a name="ln548">	struct nvme_ns *ns = NULL;</a>
<a name="ln549"> </a>
<a name="ln550">	/*</a>
<a name="ln551">	 * ctrlr-&gt;nr_ns may be 0 (startup) or a different number of</a>
<a name="ln552">	 * namespaces (reset), so check if we need to reallocate.</a>
<a name="ln553">	 */</a>
<a name="ln554">	if (nr_ns != ctrlr-&gt;nr_ns) {</a>
<a name="ln555"> </a>
<a name="ln556">		nvme_ctrlr_destruct_namespaces(ctrlr);</a>
<a name="ln557"> </a>
<a name="ln558">		ctrlr-&gt;ns = calloc(nr_ns, sizeof(struct nvme_ns));</a>
<a name="ln559">		if (!ctrlr-&gt;ns)</a>
<a name="ln560">			goto fail;</a>
<a name="ln561"> </a>
<a name="ln562">		nvme_debug(&quot;Allocate %u namespace data\n&quot;, nr_ns);</a>
<a name="ln563">		ctrlr-&gt;nsdata = nvme_calloc(nr_ns, sizeof(struct nvme_ns_data),</a>
<a name="ln564">					    PAGE_SIZE);</a>
<a name="ln565">		if (!ctrlr-&gt;nsdata)</a>
<a name="ln566">			goto fail;</a>
<a name="ln567"> </a>
<a name="ln568">		ctrlr-&gt;nr_ns = nr_ns;</a>
<a name="ln569"> </a>
<a name="ln570">	}</a>
<a name="ln571"> </a>
<a name="ln572">	for (i = 0; i &lt; nr_ns; i++) {</a>
<a name="ln573">		ns = &amp;ctrlr-&gt;ns[i];</a>
<a name="ln574">		if (nvme_ns_construct(ctrlr, ns, i + 1) != 0)</a>
<a name="ln575">			goto fail;</a>
<a name="ln576">	}</a>
<a name="ln577"> </a>
<a name="ln578">	return 0;</a>
<a name="ln579"> </a>
<a name="ln580">fail:</a>
<a name="ln581">	nvme_ctrlr_destruct_namespaces(ctrlr);</a>
<a name="ln582"> </a>
<a name="ln583">	return -1;</a>
<a name="ln584">}</a>
<a name="ln585"> </a>
<a name="ln586">/*</a>
<a name="ln587"> * Forward declaration.</a>
<a name="ln588"> */</a>
<a name="ln589">static int nvme_ctrlr_construct_and_submit_aer(struct nvme_ctrlr *ctrlr,</a>
<a name="ln590">				struct nvme_async_event_request *aer);</a>
<a name="ln591"> </a>
<a name="ln592">/*</a>
<a name="ln593"> * Async event completion callback.</a>
<a name="ln594"> */</a>
<a name="ln595">static void nvme_ctrlr_async_event_cb(void *arg, const struct nvme_cpl *cpl)</a>
<a name="ln596">{</a>
<a name="ln597">	struct nvme_async_event_request	*aer = arg;</a>
<a name="ln598">	struct nvme_ctrlr *ctrlr = aer-&gt;ctrlr;</a>
<a name="ln599"> </a>
<a name="ln600">	if (cpl-&gt;status.sc == NVME_SC_ABORTED_SQ_DELETION)</a>
<a name="ln601">		/*</a>
<a name="ln602">		 *  This is simulated when controller is being shut down, to</a>
<a name="ln603">		 *  effectively abort outstanding asynchronous event requests</a>
<a name="ln604">		 *  and make sure all memory is freed. Do not repost the</a>
<a name="ln605">		 *  request in this case.</a>
<a name="ln606">		 */</a>
<a name="ln607">		return;</a>
<a name="ln608"> </a>
<a name="ln609">	if (ctrlr-&gt;aer_cb_fn != NULL)</a>
<a name="ln610">		ctrlr-&gt;aer_cb_fn(ctrlr-&gt;aer_cb_arg, cpl);</a>
<a name="ln611"> </a>
<a name="ln612">	/*</a>
<a name="ln613">	 * Repost another asynchronous event request to replace</a>
<a name="ln614">	 * the one that just completed.</a>
<a name="ln615">	 */</a>
<a name="ln616">	if (nvme_ctrlr_construct_and_submit_aer(ctrlr, aer))</a>
<a name="ln617">		/*</a>
<a name="ln618">		 * We can't do anything to recover from a failure here,</a>
<a name="ln619">		 * so just print a warning message and leave the</a>
<a name="ln620">		 * AER unsubmitted.</a>
<a name="ln621">		 */</a>
<a name="ln622">		nvme_err(&quot;Initialize AER failed\n&quot;);</a>
<a name="ln623">}</a>
<a name="ln624"> </a>
<a name="ln625">/*</a>
<a name="ln626"> * Issue an async event request.</a>
<a name="ln627"> */</a>
<a name="ln628">static int nvme_ctrlr_construct_and_submit_aer(struct nvme_ctrlr *ctrlr,</a>
<a name="ln629">					       struct nvme_async_event_request *aer)</a>
<a name="ln630">{</a>
<a name="ln631">	struct nvme_request *req;</a>
<a name="ln632"> </a>
<a name="ln633">	req = nvme_request_allocate_null(&amp;ctrlr-&gt;adminq,</a>
<a name="ln634">					 nvme_ctrlr_async_event_cb, aer);</a>
<a name="ln635">	if (req == NULL)</a>
<a name="ln636">		return -1;</a>
<a name="ln637"> </a>
<a name="ln638">	aer-&gt;ctrlr = ctrlr;</a>
<a name="ln639">	aer-&gt;req = req;</a>
<a name="ln640">	req-&gt;cmd.opc = NVME_OPC_ASYNC_EVENT_REQUEST;</a>
<a name="ln641"> </a>
<a name="ln642">	return nvme_qpair_submit_request(&amp;ctrlr-&gt;adminq, req);</a>
<a name="ln643">}</a>
<a name="ln644"> </a>
<a name="ln645">/*</a>
<a name="ln646"> * Configure async event management.</a>
<a name="ln647"> */</a>
<a name="ln648">static int nvme_ctrlr_configure_aer(struct nvme_ctrlr *ctrlr)</a>
<a name="ln649">{</a>
<a name="ln650">	union nvme_critical_warning_state state;</a>
<a name="ln651">	struct nvme_async_event_request	*aer;</a>
<a name="ln652">	unsigned int i;</a>
<a name="ln653">	int ret;</a>
<a name="ln654"> </a>
<a name="ln655">	state.raw = 0xFF;</a>
<a name="ln656">	state.bits.reserved = 0;</a>
<a name="ln657"> </a>
<a name="ln658">	ret =  nvme_admin_set_feature(ctrlr, false,</a>
<a name="ln659">				      NVME_FEAT_ASYNC_EVENT_CONFIGURATION,</a>
<a name="ln660">				      state.raw, 0, NULL);</a>
<a name="ln661">	if (ret != 0) {</a>
<a name="ln662">		nvme_notice(&quot;Set feature ASYNC_EVENT_CONFIGURATION failed\n&quot;);</a>
<a name="ln663">		return ret;</a>
<a name="ln664">	}</a>
<a name="ln665"> </a>
<a name="ln666">	/* aerl is a zero-based value, so we need to add 1 here. */</a>
<a name="ln667">	ctrlr-&gt;num_aers = nvme_min(NVME_MAX_ASYNC_EVENTS,</a>
<a name="ln668">				   (ctrlr-&gt;cdata.aerl + 1));</a>
<a name="ln669"> </a>
<a name="ln670">	for (i = 0; i &lt; ctrlr-&gt;num_aers; i++) {</a>
<a name="ln671">		aer = &amp;ctrlr-&gt;aer[i];</a>
<a name="ln672">		if (nvme_ctrlr_construct_and_submit_aer(ctrlr, aer)) {</a>
<a name="ln673">			nvme_notice(&quot;Construct AER failed\n&quot;);</a>
<a name="ln674">			return -1;</a>
<a name="ln675">		}</a>
<a name="ln676">	}</a>
<a name="ln677"> </a>
<a name="ln678">	return 0;</a>
<a name="ln679">}</a>
<a name="ln680"> </a>
<a name="ln681">/*</a>
<a name="ln682"> * Start a controller.</a>
<a name="ln683"> */</a>
<a name="ln684">static int nvme_ctrlr_start(struct nvme_ctrlr *ctrlr)</a>
<a name="ln685">{</a>
<a name="ln686"> </a>
<a name="ln687">	nvme_qpair_reset(&amp;ctrlr-&gt;adminq);</a>
<a name="ln688">	nvme_qpair_enable(&amp;ctrlr-&gt;adminq);</a>
<a name="ln689"> </a>
<a name="ln690">	if (nvme_ctrlr_identify(ctrlr) != 0)</a>
<a name="ln691">		return -1;</a>
<a name="ln692"> </a>
<a name="ln693">	if (nvme_ctrlr_set_num_qpairs(ctrlr) != 0)</a>
<a name="ln694">		return -1;</a>
<a name="ln695"> </a>
<a name="ln696">	if (nvme_ctrlr_init_io_qpairs(ctrlr))</a>
<a name="ln697">		return -1;</a>
<a name="ln698"> </a>
<a name="ln699">	if (nvme_ctrlr_construct_namespaces(ctrlr) != 0)</a>
<a name="ln700">		return -1;</a>
<a name="ln701"> </a>
<a name="ln702">	if (nvme_ctrlr_configure_aer(ctrlr) != 0)</a>
<a name="ln703">		return -1;</a>
<a name="ln704"> </a>
<a name="ln705">	nvme_ctrlr_set_supported_log_pages(ctrlr);</a>
<a name="ln706">	nvme_ctrlr_set_supported_features(ctrlr);</a>
<a name="ln707"> </a>
<a name="ln708">	if (ctrlr-&gt;cdata.sgls.supported)</a>
<a name="ln709">		ctrlr-&gt;flags |= NVME_CTRLR_SGL_SUPPORTED;</a>
<a name="ln710"> </a>
<a name="ln711">	return 0;</a>
<a name="ln712">}</a>
<a name="ln713"> </a>
<a name="ln714">/*</a>
<a name="ln715"> * Memory map the controller side buffer.</a>
<a name="ln716"> */</a>
<a name="ln717">static void nvme_ctrlr_map_cmb(struct nvme_ctrlr *ctrlr)</a>
<a name="ln718">{</a>
<a name="ln719">	int ret;</a>
<a name="ln720">	void *addr;</a>
<a name="ln721">	uint32_t bir;</a>
<a name="ln722">	union nvme_cmbsz_register cmbsz;</a>
<a name="ln723">	union nvme_cmbloc_register cmbloc;</a>
<a name="ln724">	uint64_t size, unit_size, offset, bar_size, bar_phys_addr;</a>
<a name="ln725"> </a>
<a name="ln726">	cmbsz.raw = nvme_reg_mmio_read_4(ctrlr, cmbsz.raw);</a>
<a name="ln727">	cmbloc.raw = nvme_reg_mmio_read_4(ctrlr, cmbloc.raw);</a>
<a name="ln728">	if (!cmbsz.bits.sz)</a>
<a name="ln729">		goto out;</a>
<a name="ln730"> </a>
<a name="ln731">	/* Values 0 2 3 4 5 are valid for BAR */</a>
<a name="ln732">	bir = cmbloc.bits.bir;</a>
<a name="ln733">	if (bir &gt; 5 || bir == 1)</a>
<a name="ln734">		goto out;</a>
<a name="ln735"> </a>
<a name="ln736">	/* unit size for 4KB/64KB/1MB/16MB/256MB/4GB/64GB */</a>
<a name="ln737">	unit_size = (uint64_t)1 &lt;&lt; (12 + 4 * cmbsz.bits.szu);</a>
<a name="ln738"> </a>
<a name="ln739">	/* controller memory buffer size in Bytes */</a>
<a name="ln740">	size = unit_size * cmbsz.bits.sz;</a>
<a name="ln741"> </a>
<a name="ln742">	/* controller memory buffer offset from BAR in Bytes */</a>
<a name="ln743">	offset = unit_size * cmbloc.bits.ofst;</a>
<a name="ln744"> </a>
<a name="ln745">	nvme_pcicfg_get_bar_addr_len(ctrlr-&gt;pci_dev, bir, &amp;bar_phys_addr,</a>
<a name="ln746">				     &amp;bar_size);</a>
<a name="ln747"> </a>
<a name="ln748">	if (offset &gt; bar_size)</a>
<a name="ln749">		goto out;</a>
<a name="ln750"> </a>
<a name="ln751">	if (size &gt; bar_size - offset)</a>
<a name="ln752">		goto out;</a>
<a name="ln753"> </a>
<a name="ln754">	ret = nvme_pcicfg_map_bar_write_combine(ctrlr-&gt;pci_dev, bir, &amp;addr);</a>
<a name="ln755">	if ((ret != 0) || addr == NULL)</a>
<a name="ln756">		goto out;</a>
<a name="ln757"> </a>
<a name="ln758">	ctrlr-&gt;cmb_bar_virt_addr = addr;</a>
<a name="ln759">	ctrlr-&gt;cmb_bar_phys_addr = bar_phys_addr;</a>
<a name="ln760">	ctrlr-&gt;cmb_size = size;</a>
<a name="ln761">	ctrlr-&gt;cmb_current_offset = offset;</a>
<a name="ln762"> </a>
<a name="ln763">	if (!cmbsz.bits.sqs)</a>
<a name="ln764">		ctrlr-&gt;opts.use_cmb_sqs = false;</a>
<a name="ln765"> </a>
<a name="ln766">	return;</a>
<a name="ln767"> </a>
<a name="ln768">out:</a>
<a name="ln769">	ctrlr-&gt;cmb_bar_virt_addr = NULL;</a>
<a name="ln770">	ctrlr-&gt;opts.use_cmb_sqs = false;</a>
<a name="ln771"> </a>
<a name="ln772">	return;</a>
<a name="ln773">}</a>
<a name="ln774"> </a>
<a name="ln775">/*</a>
<a name="ln776"> * Unmap the controller side buffer.</a>
<a name="ln777"> */</a>
<a name="ln778">static int nvme_ctrlr_unmap_cmb(struct nvme_ctrlr *ctrlr)</a>
<a name="ln779">{</a>
<a name="ln780">	union nvme_cmbloc_register cmbloc;</a>
<a name="ln781">	void *addr = ctrlr-&gt;cmb_bar_virt_addr;</a>
<a name="ln782">	int ret = 0;</a>
<a name="ln783"> </a>
<a name="ln784">	if (addr) {</a>
<a name="ln785">		cmbloc.raw = nvme_reg_mmio_read_4(ctrlr, cmbloc.raw);</a>
<a name="ln786">		ret = nvme_pcicfg_unmap_bar(ctrlr-&gt;pci_dev, cmbloc.bits.bir,</a>
<a name="ln787">					    addr);</a>
<a name="ln788">	}</a>
<a name="ln789">	return ret;</a>
<a name="ln790">}</a>
<a name="ln791"> </a>
<a name="ln792">/*</a>
<a name="ln793"> * Map the controller PCI bars.</a>
<a name="ln794"> */</a>
<a name="ln795">static int nvme_ctrlr_map_bars(struct nvme_ctrlr *ctrlr)</a>
<a name="ln796">{</a>
<a name="ln797">	void *addr;</a>
<a name="ln798">	int ret;</a>
<a name="ln799"> </a>
<a name="ln800">	ret = nvme_pcicfg_map_bar(ctrlr-&gt;pci_dev, 0, 0, &amp;addr);</a>
<a name="ln801">	if (ret != 0 || addr == NULL) {</a>
<a name="ln802">		nvme_err(&quot;Map PCI device bar failed %d (%s)\n&quot;,</a>
<a name="ln803">			 ret, strerror(ret));</a>
<a name="ln804">		return ret;</a>
<a name="ln805">	}</a>
<a name="ln806"> </a>
<a name="ln807">	nvme_debug(&quot;Controller BAR mapped at %p\n&quot;, addr);</a>
<a name="ln808"> </a>
<a name="ln809">	ctrlr-&gt;regs = (volatile struct nvme_registers *)addr;</a>
<a name="ln810">	nvme_ctrlr_map_cmb(ctrlr);</a>
<a name="ln811"> </a>
<a name="ln812">	return 0;</a>
<a name="ln813">}</a>
<a name="ln814"> </a>
<a name="ln815">/*</a>
<a name="ln816"> * Unmap the controller PCI bars.</a>
<a name="ln817"> */</a>
<a name="ln818">static int nvme_ctrlr_unmap_bars(struct nvme_ctrlr *ctrlr)</a>
<a name="ln819">{</a>
<a name="ln820">	void *addr = (void *)ctrlr-&gt;regs;</a>
<a name="ln821">	int ret;</a>
<a name="ln822"> </a>
<a name="ln823">	ret = nvme_ctrlr_unmap_cmb(ctrlr);</a>
<a name="ln824">	if (ret != 0) {</a>
<a name="ln825">		nvme_err(&quot;Unmap controller side buffer failed %d\n&quot;, ret);</a>
<a name="ln826">		return ret;</a>
<a name="ln827">	}</a>
<a name="ln828"> </a>
<a name="ln829">	if (addr) {</a>
<a name="ln830">		ret = nvme_pcicfg_unmap_bar(ctrlr-&gt;pci_dev, 0, addr);</a>
<a name="ln831">		if (ret != 0) {</a>
<a name="ln832">			nvme_err(&quot;Unmap PCI device bar failed %d\n&quot;, ret);</a>
<a name="ln833">			return ret;</a>
<a name="ln834">		}</a>
<a name="ln835">	}</a>
<a name="ln836"> </a>
<a name="ln837">	return 0;</a>
<a name="ln838">}</a>
<a name="ln839"> </a>
<a name="ln840">/*</a>
<a name="ln841"> * Set a controller in the failed state.</a>
<a name="ln842"> */</a>
<a name="ln843">static void nvme_ctrlr_fail(struct nvme_ctrlr *ctrlr)</a>
<a name="ln844">{</a>
<a name="ln845">	unsigned int i;</a>
<a name="ln846"> </a>
<a name="ln847">	ctrlr-&gt;failed = true;</a>
<a name="ln848"> </a>
<a name="ln849">	nvme_qpair_fail(&amp;ctrlr-&gt;adminq);</a>
<a name="ln850">	if (ctrlr-&gt;ioq)</a>
<a name="ln851">		for (i = 0; i &lt; ctrlr-&gt;io_queues; i++)</a>
<a name="ln852">			nvme_qpair_fail(&amp;ctrlr-&gt;ioq[i]);</a>
<a name="ln853">}</a>
<a name="ln854"> </a>
<a name="ln855">/*</a>
<a name="ln856"> * This function will be called repeatedly during initialization</a>
<a name="ln857"> * until the controller is ready.</a>
<a name="ln858"> */</a>
<a name="ln859">static int nvme_ctrlr_init(struct nvme_ctrlr *ctrlr)</a>
<a name="ln860">{</a>
<a name="ln861">	unsigned int ready_timeout_in_ms = nvme_ctrlr_get_ready_to_in_ms(ctrlr);</a>
<a name="ln862">	int ret;</a>
<a name="ln863"> </a>
<a name="ln864">	/*</a>
<a name="ln865">	 * Check if the current initialization step is done or has timed out.</a>
<a name="ln866">	 */</a>
<a name="ln867">	switch (ctrlr-&gt;state) {</a>
<a name="ln868"> </a>
<a name="ln869">	case NVME_CTRLR_STATE_INIT:</a>
<a name="ln870"> </a>
<a name="ln871">		/* Begin the hardware initialization by making</a>
<a name="ln872">		 * sure the controller is disabled. */</a>
<a name="ln873">		if (nvme_ctrlr_enabled(ctrlr)) {</a>
<a name="ln874">			/*</a>
<a name="ln875">			 * Disable the controller to cause a reset.</a>
<a name="ln876">			 */</a>
<a name="ln877">			if (!nvme_ctrlr_ready(ctrlr)) {</a>
<a name="ln878">				/* Wait for the controller to be ready */</a>
<a name="ln879">				nvme_ctrlr_set_state(ctrlr,</a>
<a name="ln880">				      NVME_CTRLR_STATE_DISABLE_WAIT_FOR_READY_1,</a>
<a name="ln881">				      ready_timeout_in_ms);</a>
<a name="ln882">				return 0;</a>
<a name="ln883">			}</a>
<a name="ln884"> </a>
<a name="ln885">			/*</a>
<a name="ln886">			 * The controller is enabled and ready.</a>
<a name="ln887">			 * It can be immediatly disabled</a>
<a name="ln888">			 */</a>
<a name="ln889">			nvme_ctrlr_disable(ctrlr);</a>
<a name="ln890">			nvme_ctrlr_set_state(ctrlr,</a>
<a name="ln891">				      NVME_CTRLR_STATE_DISABLE_WAIT_FOR_READY_0,</a>
<a name="ln892">				      ready_timeout_in_ms);</a>
<a name="ln893"> </a>
<a name="ln894">			if (ctrlr-&gt;quirks &amp; NVME_QUIRK_DELAY_BEFORE_CHK_RDY)</a>
<a name="ln895">				nvme_msleep(2000);</a>
<a name="ln896"> </a>
<a name="ln897">			return 0;</a>
<a name="ln898">		}</a>
<a name="ln899"> </a>
<a name="ln900">		if (nvme_ctrlr_ready(ctrlr)) {</a>
<a name="ln901">			/*</a>
<a name="ln902">			 * Controller is in the process of shutting down.</a>
<a name="ln903">			 * We need to wait for CSTS.RDY to become 0.</a>
<a name="ln904">			 */</a>
<a name="ln905">			nvme_ctrlr_set_state(ctrlr,</a>
<a name="ln906">				      NVME_CTRLR_STATE_DISABLE_WAIT_FOR_READY_0,</a>
<a name="ln907">				      ready_timeout_in_ms);</a>
<a name="ln908">			return 0;</a>
<a name="ln909">		}</a>
<a name="ln910"> </a>
<a name="ln911">		/*</a>
<a name="ln912">		 * Controller is currently disabled.</a>
<a name="ln913">		 * We can jump straight to enabling it.</a>
<a name="ln914">		 */</a>
<a name="ln915">		ret = nvme_ctrlr_enable(ctrlr);</a>
<a name="ln916">		if (ret)</a>
<a name="ln917">			nvme_err(&quot;Enable controller failed\n&quot;);</a>
<a name="ln918">		else</a>
<a name="ln919">			nvme_ctrlr_set_state(ctrlr,</a>
<a name="ln920">				       NVME_CTRLR_STATE_ENABLE_WAIT_FOR_READY_1,</a>
<a name="ln921">				       ready_timeout_in_ms);</a>
<a name="ln922">		return ret;</a>
<a name="ln923"> </a>
<a name="ln924">	case NVME_CTRLR_STATE_DISABLE_WAIT_FOR_READY_1:</a>
<a name="ln925"> </a>
<a name="ln926">		if (nvme_ctrlr_ready(ctrlr)) {</a>
<a name="ln927">			/* CC.EN = 1 &amp;&amp; CSTS.RDY = 1,</a>
<a name="ln928">			 * so we can disable the controller now. */</a>
<a name="ln929">			nvme_ctrlr_disable(ctrlr);</a>
<a name="ln930">			nvme_ctrlr_set_state(ctrlr,</a>
<a name="ln931">				      NVME_CTRLR_STATE_DISABLE_WAIT_FOR_READY_0,</a>
<a name="ln932">				      ready_timeout_in_ms);</a>
<a name="ln933">			return 0;</a>
<a name="ln934">		}</a>
<a name="ln935"> </a>
<a name="ln936">		break;</a>
<a name="ln937"> </a>
<a name="ln938">	case NVME_CTRLR_STATE_DISABLE_WAIT_FOR_READY_0:</a>
<a name="ln939"> </a>
<a name="ln940">		if (!nvme_ctrlr_ready(ctrlr)) {</a>
<a name="ln941">			/* CC.EN = 0 &amp;&amp; CSTS.RDY = 0,</a>
<a name="ln942">			 * so we can enable the controller now. */</a>
<a name="ln943">			ret = nvme_ctrlr_enable(ctrlr);</a>
<a name="ln944">			if (ret)</a>
<a name="ln945">				nvme_err(&quot;Enable controller failed\n&quot;);</a>
<a name="ln946">			else</a>
<a name="ln947">				nvme_ctrlr_set_state(ctrlr,</a>
<a name="ln948">				       NVME_CTRLR_STATE_ENABLE_WAIT_FOR_READY_1,</a>
<a name="ln949">				       ready_timeout_in_ms);</a>
<a name="ln950">			return ret;</a>
<a name="ln951">		}</a>
<a name="ln952">		break;</a>
<a name="ln953"> </a>
<a name="ln954">	case NVME_CTRLR_STATE_ENABLE_WAIT_FOR_READY_1:</a>
<a name="ln955"> </a>
<a name="ln956">		if (nvme_ctrlr_ready(ctrlr)) {</a>
<a name="ln957">			if (ctrlr-&gt;quirks &amp; NVME_QUIRK_DELAY_AFTER_RDY)</a>
<a name="ln958">				nvme_msleep(2000);</a>
<a name="ln959"> </a>
<a name="ln960">			ret = nvme_ctrlr_start(ctrlr);</a>
<a name="ln961">			if (ret)</a>
<a name="ln962">				nvme_err(&quot;Start controller failed\n&quot;);</a>
<a name="ln963">			else</a>
<a name="ln964">				nvme_ctrlr_set_state(ctrlr,</a>
<a name="ln965">						     NVME_CTRLR_STATE_READY,</a>
<a name="ln966">						     NVME_TIMEOUT_INFINITE);</a>
<a name="ln967">			return ret;</a>
<a name="ln968">		}</a>
<a name="ln969">		break;</a>
<a name="ln970"> </a>
<a name="ln971">	default:</a>
<a name="ln972">		nvme_panic(&quot;Unhandled ctrlr state %d\n&quot;, ctrlr-&gt;state);</a>
<a name="ln973">		nvme_ctrlr_fail(ctrlr);</a>
<a name="ln974">		return -1;</a>
<a name="ln975">	}</a>
<a name="ln976"> </a>
<a name="ln977">	if ((ctrlr-&gt;state_timeout_ms != NVME_TIMEOUT_INFINITE) &amp;&amp;</a>
<a name="ln978">	    (nvme_time_msec() &gt; ctrlr-&gt;state_timeout_ms)) {</a>
<a name="ln979">		nvme_err(&quot;Initialization timed out in state %d\n&quot;,</a>
<a name="ln980">			 ctrlr-&gt;state);</a>
<a name="ln981">		nvme_ctrlr_fail(ctrlr);</a>
<a name="ln982">		return -1;</a>
<a name="ln983">	}</a>
<a name="ln984"> </a>
<a name="ln985">	return 0;</a>
<a name="ln986">}</a>
<a name="ln987"> </a>
<a name="ln988">/*</a>
<a name="ln989"> * Reset a controller.</a>
<a name="ln990"> */</a>
<a name="ln991">static int nvme_ctrlr_reset(struct nvme_ctrlr *ctrlr)</a>
<a name="ln992">{</a>
<a name="ln993">	struct nvme_qpair *qpair;</a>
<a name="ln994">	unsigned int i;</a>
<a name="ln995"> </a>
<a name="ln996">	if (ctrlr-&gt;resetting || ctrlr-&gt;failed)</a>
<a name="ln997">		/*</a>
<a name="ln998">		 * Controller is already resetting or has failed. Return</a>
<a name="ln999">		 * immediately since there is no need to kick off another</a>
<a name="ln1000">		 * reset in these cases.</a>
<a name="ln1001">		 */</a>
<a name="ln1002">		return 0;</a>
<a name="ln1003"> </a>
<a name="ln1004">	ctrlr-&gt;resetting = true;</a>
<a name="ln1005"> </a>
<a name="ln1006">	/* Disable all queues before disabling the controller hardware. */</a>
<a name="ln1007">	nvme_qpair_disable(&amp;ctrlr-&gt;adminq);</a>
<a name="ln1008">	for (i = 0; i &lt; ctrlr-&gt;io_queues; i++)</a>
<a name="ln1009">		nvme_qpair_disable(&amp;ctrlr-&gt;ioq[i]);</a>
<a name="ln1010"> </a>
<a name="ln1011">	/* Set the state back to INIT to cause a full hardware reset. */</a>
<a name="ln1012">	nvme_ctrlr_set_state(ctrlr, NVME_CTRLR_STATE_INIT,</a>
<a name="ln1013">			     NVME_TIMEOUT_INFINITE);</a>
<a name="ln1014"> </a>
<a name="ln1015">	while (ctrlr-&gt;state != NVME_CTRLR_STATE_READY) {</a>
<a name="ln1016">		if (nvme_ctrlr_init(ctrlr) != 0) {</a>
<a name="ln1017">			nvme_crit(&quot;Controller reset failed\n&quot;);</a>
<a name="ln1018">			nvme_ctrlr_fail(ctrlr);</a>
<a name="ln1019">			goto out;</a>
<a name="ln1020">		}</a>
<a name="ln1021">	}</a>
<a name="ln1022"> </a>
<a name="ln1023">	/* Reinitialize qpairs */</a>
<a name="ln1024">	TAILQ_FOREACH(qpair, &amp;ctrlr-&gt;active_io_qpairs, tailq) {</a>
<a name="ln1025">		if (nvme_ctrlr_create_qpair(ctrlr, qpair) != 0)</a>
<a name="ln1026">			nvme_ctrlr_fail(ctrlr);</a>
<a name="ln1027">	}</a>
<a name="ln1028"> </a>
<a name="ln1029">out:</a>
<a name="ln1030">	ctrlr-&gt;resetting = false;</a>
<a name="ln1031"> </a>
<a name="ln1032">	return ctrlr-&gt;failed ? -1 : 0;</a>
<a name="ln1033">}</a>
<a name="ln1034"> </a>
<a name="ln1035">/*</a>
<a name="ln1036"> * Set a controller options.</a>
<a name="ln1037"> */</a>
<a name="ln1038">static void nvme_ctrlr_set_opts(struct nvme_ctrlr *ctrlr,</a>
<a name="ln1039">				struct nvme_ctrlr_opts *opts)</a>
<a name="ln1040">{</a>
<a name="ln1041">	if (opts)</a>
<a name="ln1042">		memcpy(&amp;ctrlr-&gt;opts, opts, sizeof(struct nvme_ctrlr_opts));</a>
<a name="ln1043">	else</a>
<a name="ln1044">		memset(&amp;ctrlr-&gt;opts, 0, sizeof(struct nvme_ctrlr_opts));</a>
<a name="ln1045"> </a>
<a name="ln1046">	if (ctrlr-&gt;opts.io_queues == 0)</a>
<a name="ln1047">		ctrlr-&gt;opts.io_queues = DEFAULT_MAX_IO_QUEUES;</a>
<a name="ln1048"> </a>
<a name="ln1049">	if (ctrlr-&gt;opts.io_queues &gt; NVME_MAX_IO_QUEUES) {</a>
<a name="ln1050">		nvme_info(&quot;Limiting requested I/O queues %u to %d\n&quot;,</a>
<a name="ln1051">			  ctrlr-&gt;opts.io_queues, NVME_MAX_IO_QUEUES);</a>
<a name="ln1052">		ctrlr-&gt;opts.io_queues = NVME_MAX_IO_QUEUES;</a>
<a name="ln1053">	}</a>
<a name="ln1054">}</a>
<a name="ln1055"> </a>
<a name="ln1056">/*</a>
<a name="ln1057"> * Attach a PCI controller.</a>
<a name="ln1058"> */</a>
<a name="ln1059">struct nvme_ctrlr *</a>
<a name="ln1060">nvme_ctrlr_attach(struct pci_device *pci_dev,</a>
<a name="ln1061">		  struct nvme_ctrlr_opts *opts)</a>
<a name="ln1062">{</a>
<a name="ln1063">	struct nvme_ctrlr *ctrlr;</a>
<a name="ln1064">	union nvme_cap_register	cap;</a>
<a name="ln1065">	uint32_t cmd_reg;</a>
<a name="ln1066">	int ret;</a>
<a name="ln1067"> </a>
<a name="ln1068">	/* Get a new controller handle */</a>
<a name="ln1069">	ctrlr = malloc(sizeof(struct nvme_ctrlr));</a>
<a name="ln1070">	if (!ctrlr) {</a>
<a name="ln1071">		nvme_err(&quot;Allocate controller handle failed\n&quot;);</a>
<a name="ln1072">		return NULL;</a>
<a name="ln1073">	}</a>
<a name="ln1074"> </a>
<a name="ln1075">	nvme_debug(&quot;New controller handle %p\n&quot;, ctrlr);</a>
<a name="ln1076"> </a>
<a name="ln1077">	/* Initialize the handle */</a>
<a name="ln1078">	memset(ctrlr, 0, sizeof(struct nvme_ctrlr));</a>
<a name="ln1079">	ctrlr-&gt;pci_dev = pci_dev;</a>
<a name="ln1080">	ctrlr-&gt;resetting = false;</a>
<a name="ln1081">	ctrlr-&gt;failed = false;</a>
<a name="ln1082">	TAILQ_INIT(&amp;ctrlr-&gt;free_io_qpairs);</a>
<a name="ln1083">	TAILQ_INIT(&amp;ctrlr-&gt;active_io_qpairs);</a>
<a name="ln1084">	pthread_mutex_init(&amp;ctrlr-&gt;lock, NULL);</a>
<a name="ln1085">	ctrlr-&gt;quirks = nvme_ctrlr_get_quirks(pci_dev);</a>
<a name="ln1086"> </a>
<a name="ln1087">	nvme_ctrlr_set_state(ctrlr,</a>
<a name="ln1088">			     NVME_CTRLR_STATE_INIT,</a>
<a name="ln1089">			     NVME_TIMEOUT_INFINITE);</a>
<a name="ln1090"> </a>
<a name="ln1091">	ret = nvme_ctrlr_map_bars(ctrlr);</a>
<a name="ln1092">	if (ret != 0) {</a>
<a name="ln1093">		nvme_err(&quot;Map controller BAR failed\n&quot;);</a>
<a name="ln1094">		pthread_mutex_destroy(&amp;ctrlr-&gt;lock);</a>
<a name="ln1095">		free(ctrlr);</a>
<a name="ln1096">		return NULL;</a>
<a name="ln1097">	}</a>
<a name="ln1098"> </a>
<a name="ln1099">	/* Enable PCI busmaster and disable INTx */</a>
<a name="ln1100">	nvme_pcicfg_read32(pci_dev, &amp;cmd_reg, 4);</a>
<a name="ln1101">	cmd_reg |= 0x0404;</a>
<a name="ln1102">	nvme_pcicfg_write32(pci_dev, cmd_reg, 4);</a>
<a name="ln1103"> </a>
<a name="ln1104">	/*</a>
<a name="ln1105">	 * Doorbell stride is 2 ^ (dstrd + 2),</a>
<a name="ln1106">	 * but we want multiples of 4, so drop the + 2.</a>
<a name="ln1107">	 */</a>
<a name="ln1108">	cap.raw = nvme_reg_mmio_read_8(ctrlr, cap.raw);</a>
<a name="ln1109">	ctrlr-&gt;doorbell_stride_u32 = 1 &lt;&lt; cap.bits.dstrd;</a>
<a name="ln1110">	ctrlr-&gt;min_page_size = 1 &lt;&lt; (12 + cap.bits.mpsmin);</a>
<a name="ln1111"> </a>
<a name="ln1112">	/* Set default transfer size */</a>
<a name="ln1113">	ctrlr-&gt;max_xfer_size = NVME_MAX_XFER_SIZE;</a>
<a name="ln1114"> </a>
<a name="ln1115">	/* Create the admin queue pair */</a>
<a name="ln1116">	ret = nvme_qpair_construct(ctrlr, &amp;ctrlr-&gt;adminq, 0,</a>
<a name="ln1117">				   NVME_ADMIN_ENTRIES, NVME_ADMIN_TRACKERS);</a>
<a name="ln1118">	if (ret != 0) {</a>
<a name="ln1119">		nvme_err(&quot;Initialize admin queue pair failed\n&quot;);</a>
<a name="ln1120">		goto err;</a>
<a name="ln1121">	}</a>
<a name="ln1122"> </a>
<a name="ln1123">	/* Set options and then initialize */</a>
<a name="ln1124">	nvme_ctrlr_set_opts(ctrlr, opts);</a>
<a name="ln1125">	do {</a>
<a name="ln1126">		ret = nvme_ctrlr_init(ctrlr);</a>
<a name="ln1127">		if (ret)</a>
<a name="ln1128">			goto err;</a>
<a name="ln1129">	} while (ctrlr-&gt;state != NVME_CTRLR_STATE_READY);</a>
<a name="ln1130"> </a>
<a name="ln1131">	return ctrlr;</a>
<a name="ln1132"> </a>
<a name="ln1133">err:</a>
<a name="ln1134">	nvme_ctrlr_detach(ctrlr);</a>
<a name="ln1135"> </a>
<a name="ln1136">	return NULL;</a>
<a name="ln1137">}</a>
<a name="ln1138"> </a>
<a name="ln1139">/*</a>
<a name="ln1140"> * Detach a PCI controller.</a>
<a name="ln1141"> */</a>
<a name="ln1142">void nvme_ctrlr_detach(struct nvme_ctrlr *ctrlr)</a>
<a name="ln1143">{</a>
<a name="ln1144">	struct nvme_qpair *qpair;</a>
<a name="ln1145">	uint32_t i;</a>
<a name="ln1146"> </a>
<a name="ln1147">	while (!TAILQ_EMPTY(&amp;ctrlr-&gt;active_io_qpairs)) {</a>
<a name="ln1148">		qpair = TAILQ_FIRST(&amp;ctrlr-&gt;active_io_qpairs);</a>
<a name="ln1149">		nvme_ioqp_release(qpair);</a>
<a name="ln1150">	}</a>
<a name="ln1151"> </a>
<a name="ln1152">	nvme_ctrlr_shutdown(ctrlr);</a>
<a name="ln1153"> </a>
<a name="ln1154">	nvme_ctrlr_destruct_namespaces(ctrlr);</a>
<a name="ln1155">	if (ctrlr-&gt;ioq) {</a>
<a name="ln1156">		for (i = 0; i &lt; ctrlr-&gt;io_queues; i++)</a>
<a name="ln1157">			nvme_qpair_destroy(&amp;ctrlr-&gt;ioq[i]);</a>
<a name="ln1158">		free(ctrlr-&gt;ioq);</a>
<a name="ln1159">	}</a>
<a name="ln1160"> </a>
<a name="ln1161">	nvme_qpair_destroy(&amp;ctrlr-&gt;adminq);</a>
<a name="ln1162"> </a>
<a name="ln1163">	nvme_ctrlr_unmap_bars(ctrlr);</a>
<a name="ln1164"> </a>
<a name="ln1165">	pthread_mutex_destroy(&amp;ctrlr-&gt;lock);</a>
<a name="ln1166">	free(ctrlr);</a>
<a name="ln1167">}</a>
<a name="ln1168"> </a>
<a name="ln1169">/*</a>
<a name="ln1170"> * Get a controller feature.</a>
<a name="ln1171"> */</a>
<a name="ln1172">int nvme_ctrlr_get_feature(struct nvme_ctrlr *ctrlr,</a>
<a name="ln1173">			   enum nvme_feat_sel sel, enum nvme_feat feature,</a>
<a name="ln1174">			   uint32_t cdw11,</a>
<a name="ln1175">			   uint32_t *attributes)</a>
<a name="ln1176">{</a>
<a name="ln1177">	int ret;</a>
<a name="ln1178"> </a>
<a name="ln1179">	pthread_mutex_lock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1180"> </a>
<a name="ln1181">	ret = nvme_admin_get_feature(ctrlr, sel, feature, cdw11, attributes);</a>
<a name="ln1182">	if (ret != 0)</a>
<a name="ln1183">		nvme_notice(&quot;Get feature 0x%08x failed\n&quot;,</a>
<a name="ln1184">			    (unsigned int) feature);</a>
<a name="ln1185"> </a>
<a name="ln1186">	pthread_mutex_unlock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1187"> </a>
<a name="ln1188">	return ret;</a>
<a name="ln1189">}</a>
<a name="ln1190"> </a>
<a name="ln1191">/*</a>
<a name="ln1192"> * Set a controller feature.</a>
<a name="ln1193"> */</a>
<a name="ln1194">int nvme_ctrlr_set_feature(struct nvme_ctrlr *ctrlr,</a>
<a name="ln1195">			   bool save, enum nvme_feat feature,</a>
<a name="ln1196">			   uint32_t cdw11, uint32_t cdw12,</a>
<a name="ln1197">			   uint32_t *attributes)</a>
<a name="ln1198">{</a>
<a name="ln1199">	int ret;</a>
<a name="ln1200"> </a>
<a name="ln1201">	pthread_mutex_lock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1202"> </a>
<a name="ln1203">	ret = nvme_admin_set_feature(ctrlr, save, feature,</a>
<a name="ln1204">				     cdw11, cdw12, attributes);</a>
<a name="ln1205">	if (ret != 0)</a>
<a name="ln1206">		nvme_notice(&quot;Set feature 0x%08x failed\n&quot;,</a>
<a name="ln1207">			    (unsigned int) feature);</a>
<a name="ln1208"> </a>
<a name="ln1209">	pthread_mutex_unlock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1210"> </a>
<a name="ln1211">	return ret;</a>
<a name="ln1212">}</a>
<a name="ln1213"> </a>
<a name="ln1214">/*</a>
<a name="ln1215"> * Attach a namespace.</a>
<a name="ln1216"> */</a>
<a name="ln1217">int nvme_ctrlr_attach_ns(struct nvme_ctrlr *ctrlr, unsigned int nsid,</a>
<a name="ln1218">			 struct nvme_ctrlr_list *clist)</a>
<a name="ln1219">{</a>
<a name="ln1220">	int ret;</a>
<a name="ln1221"> </a>
<a name="ln1222">	pthread_mutex_lock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1223"> </a>
<a name="ln1224">	ret = nvme_admin_attach_ns(ctrlr, nsid, clist);</a>
<a name="ln1225">	if (ret) {</a>
<a name="ln1226">		nvme_notice(&quot;Attach namespace %u failed\n&quot;, nsid);</a>
<a name="ln1227">		goto out;</a>
<a name="ln1228">	}</a>
<a name="ln1229"> </a>
<a name="ln1230">	ret = nvme_ctrlr_reset(ctrlr);</a>
<a name="ln1231">	if (ret != 0)</a>
<a name="ln1232">		nvme_notice(&quot;Reset controller failed\n&quot;);</a>
<a name="ln1233"> </a>
<a name="ln1234">out:</a>
<a name="ln1235">	pthread_mutex_unlock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1236"> </a>
<a name="ln1237">	return ret;</a>
<a name="ln1238">}</a>
<a name="ln1239"> </a>
<a name="ln1240">/*</a>
<a name="ln1241"> * Detach a namespace.</a>
<a name="ln1242"> */</a>
<a name="ln1243">int nvme_ctrlr_detach_ns(struct nvme_ctrlr *ctrlr, unsigned int nsid,</a>
<a name="ln1244">			 struct nvme_ctrlr_list *clist)</a>
<a name="ln1245">{</a>
<a name="ln1246">	int ret;</a>
<a name="ln1247"> </a>
<a name="ln1248">	pthread_mutex_lock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1249"> </a>
<a name="ln1250">	ret = nvme_admin_detach_ns(ctrlr, nsid, clist);</a>
<a name="ln1251">	if (ret != 0) {</a>
<a name="ln1252">		nvme_notice(&quot;Detach namespace %u failed\n&quot;, nsid);</a>
<a name="ln1253">		goto out;</a>
<a name="ln1254">	}</a>
<a name="ln1255"> </a>
<a name="ln1256">	ret = nvme_ctrlr_reset(ctrlr);</a>
<a name="ln1257">	if (ret)</a>
<a name="ln1258">		nvme_notice(&quot;Reset controller failed\n&quot;);</a>
<a name="ln1259"> </a>
<a name="ln1260">out:</a>
<a name="ln1261">	pthread_mutex_unlock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1262"> </a>
<a name="ln1263">	return ret;</a>
<a name="ln1264">}</a>
<a name="ln1265"> </a>
<a name="ln1266">/*</a>
<a name="ln1267"> * Create a namespace.</a>
<a name="ln1268"> */</a>
<a name="ln1269">unsigned int nvme_ctrlr_create_ns(struct nvme_ctrlr *ctrlr,</a>
<a name="ln1270">				  struct nvme_ns_data *nsdata)</a>
<a name="ln1271">{</a>
<a name="ln1272">	unsigned int nsid;</a>
<a name="ln1273">	int ret;</a>
<a name="ln1274"> </a>
<a name="ln1275">	pthread_mutex_lock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1276"> </a>
<a name="ln1277">	ret = nvme_admin_create_ns(ctrlr, nsdata, &amp;nsid);</a>
<a name="ln1278">	if (ret != 0) {</a>
<a name="ln1279">		nvme_notice(&quot;Create namespace failed\n&quot;);</a>
<a name="ln1280">		nsid = 0;</a>
<a name="ln1281">	}</a>
<a name="ln1282"> </a>
<a name="ln1283">	pthread_mutex_unlock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1284"> </a>
<a name="ln1285">	return nsid;</a>
<a name="ln1286">}</a>
<a name="ln1287"> </a>
<a name="ln1288">/*</a>
<a name="ln1289"> * Delete a namespace.</a>
<a name="ln1290"> */</a>
<a name="ln1291">int nvme_ctrlr_delete_ns(struct nvme_ctrlr *ctrlr, unsigned int nsid)</a>
<a name="ln1292">{</a>
<a name="ln1293">	int ret;</a>
<a name="ln1294"> </a>
<a name="ln1295">	pthread_mutex_lock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1296"> </a>
<a name="ln1297">	ret = nvme_admin_delete_ns(ctrlr, nsid);</a>
<a name="ln1298">	if (ret != 0) {</a>
<a name="ln1299">		nvme_notice(&quot;Delete namespace %u failed\n&quot;, nsid);</a>
<a name="ln1300">		goto out;</a>
<a name="ln1301">	}</a>
<a name="ln1302"> </a>
<a name="ln1303">	ret = nvme_ctrlr_reset(ctrlr);</a>
<a name="ln1304">	if (ret)</a>
<a name="ln1305">		nvme_notice(&quot;Reset controller failed\n&quot;);</a>
<a name="ln1306"> </a>
<a name="ln1307">out:</a>
<a name="ln1308">	pthread_mutex_unlock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1309"> </a>
<a name="ln1310">	return ret;</a>
<a name="ln1311">}</a>
<a name="ln1312"> </a>
<a name="ln1313">/*</a>
<a name="ln1314"> * Format NVM media.</a>
<a name="ln1315"> */</a>
<a name="ln1316">int nvme_ctrlr_format_ns(struct nvme_ctrlr *ctrlr, unsigned int nsid,</a>
<a name="ln1317">			 struct nvme_format *format)</a>
<a name="ln1318">{</a>
<a name="ln1319">	int ret;</a>
<a name="ln1320"> </a>
<a name="ln1321">	pthread_mutex_lock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1322"> </a>
<a name="ln1323">	ret = nvme_admin_format_nvm(ctrlr, nsid, format);</a>
<a name="ln1324">	if (ret != 0) {</a>
<a name="ln1325">		if (nsid == NVME_GLOBAL_NS_TAG)</a>
<a name="ln1326">			nvme_notice(&quot;Format device failed\n&quot;);</a>
<a name="ln1327">		else</a>
<a name="ln1328">			nvme_notice(&quot;Format namespace %u failed\n&quot;, nsid);</a>
<a name="ln1329">		goto out;</a>
<a name="ln1330">	}</a>
<a name="ln1331"> </a>
<a name="ln1332">	ret = nvme_ctrlr_reset(ctrlr);</a>
<a name="ln1333">	if (ret)</a>
<a name="ln1334">		nvme_notice(&quot;Reset controller failed\n&quot;);</a>
<a name="ln1335"> </a>
<a name="ln1336">out:</a>
<a name="ln1337">	pthread_mutex_unlock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1338"> </a>
<a name="ln1339">	return ret;</a>
<a name="ln1340">}</a>
<a name="ln1341"> </a>
<a name="ln1342">/*</a>
<a name="ln1343"> * Update a device firmware.</a>
<a name="ln1344"> */</a>
<a name="ln1345">int nvme_ctrlr_update_firmware(struct nvme_ctrlr *ctrlr,</a>
<a name="ln1346">			       void *fw, size_t size, int slot)</a>
<a name="ln1347">{</a>
<a name="ln1348">	struct nvme_fw_commit fw_commit;</a>
<a name="ln1349">	unsigned int size_remaining = size, offset = 0, transfer;</a>
<a name="ln1350">	void *f = fw;</a>
<a name="ln1351">	int ret;</a>
<a name="ln1352"> </a>
<a name="ln1353">	if (size &amp; 0x3) {</a>
<a name="ln1354">		nvme_err(&quot;Invalid firmware size\n&quot;);</a>
<a name="ln1355">		return EINVAL;</a>
<a name="ln1356">	}</a>
<a name="ln1357"> </a>
<a name="ln1358">	pthread_mutex_lock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1359"> </a>
<a name="ln1360">	/* Download firmware */</a>
<a name="ln1361">	while (size_remaining &gt; 0) {</a>
<a name="ln1362"> </a>
<a name="ln1363">		transfer = nvme_min(size_remaining, ctrlr-&gt;min_page_size);</a>
<a name="ln1364"> </a>
<a name="ln1365">		ret = nvme_admin_fw_image_dl(ctrlr, f, transfer, offset);</a>
<a name="ln1366">		if (ret != 0) {</a>
<a name="ln1367">			nvme_err(&quot;Download FW (%u B at %u) failed\n&quot;,</a>
<a name="ln1368">				 transfer, offset);</a>
<a name="ln1369">			goto out;</a>
<a name="ln1370">		}</a>
<a name="ln1371"> </a>
<a name="ln1372">		f += transfer;</a>
<a name="ln1373">		offset += transfer;</a>
<a name="ln1374">		size_remaining -= transfer;</a>
<a name="ln1375"> </a>
<a name="ln1376">	}</a>
<a name="ln1377"> </a>
<a name="ln1378">	/* Commit firmware */</a>
<a name="ln1379">	memset(&amp;fw_commit, 0, sizeof(struct nvme_fw_commit));</a>
<a name="ln1380">	fw_commit.fs = slot;</a>
<a name="ln1381">	fw_commit.ca = NVME_FW_COMMIT_REPLACE_IMG;</a>
<a name="ln1382"> </a>
<a name="ln1383">	ret = nvme_admin_fw_commit(ctrlr, &amp;fw_commit);</a>
<a name="ln1384">	if (ret != 0) {</a>
<a name="ln1385">		nvme_err(&quot;Commit downloaded FW (%zu B) failed\n&quot;,</a>
<a name="ln1386">			 size);</a>
<a name="ln1387">		goto out;</a>
<a name="ln1388">	}</a>
<a name="ln1389"> </a>
<a name="ln1390">	ret = nvme_ctrlr_reset(ctrlr);</a>
<a name="ln1391">	if (ret)</a>
<a name="ln1392">		nvme_notice(&quot;Reset controller failed\n&quot;);</a>
<a name="ln1393"> </a>
<a name="ln1394">out:</a>
<a name="ln1395">	pthread_mutex_unlock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1396"> </a>
<a name="ln1397">	return ret;</a>
<a name="ln1398">}</a>
<a name="ln1399"> </a>
<a name="ln1400">/*</a>
<a name="ln1401"> * Get an unused I/O queue pair.</a>
<a name="ln1402"> */</a>
<a name="ln1403">struct nvme_qpair *nvme_ioqp_get(struct nvme_ctrlr *ctrlr,</a>
<a name="ln1404">				 enum nvme_qprio qprio, unsigned int qd)</a>
<a name="ln1405">{</a>
<a name="ln1406">	struct nvme_qpair *qpair = NULL;</a>
<a name="ln1407">	union nvme_cc_register cc;</a>
<a name="ln1408">	uint32_t trackers;</a>
<a name="ln1409">	int ret;</a>
<a name="ln1410"> </a>
<a name="ln1411">	cc.raw = nvme_reg_mmio_read_4(ctrlr, cc.raw);</a>
<a name="ln1412"> </a>
<a name="ln1413">	/* Only the low 2 bits (values 0, 1, 2, 3) of QPRIO are valid. */</a>
<a name="ln1414">	if ((qprio &amp; 3) != qprio)</a>
<a name="ln1415">		return NULL;</a>
<a name="ln1416"> </a>
<a name="ln1417">	/*</a>
<a name="ln1418">	 * Only value NVME_QPRIO_URGENT(0) is valid for the</a>
<a name="ln1419">	 * default round robin arbitration method.</a>
<a name="ln1420">	 */</a>
<a name="ln1421">	if ((cc.bits.ams == NVME_CC_AMS_RR) &amp;&amp; (qprio != NVME_QPRIO_URGENT)) {</a>
<a name="ln1422">		nvme_err(&quot;Invalid queue priority for default round &quot;</a>
<a name="ln1423">			 &quot;robin arbitration method\n&quot;);</a>
<a name="ln1424">		return NULL;</a>
<a name="ln1425">	}</a>
<a name="ln1426"> </a>
<a name="ln1427">	/* I/O qpairs number of entries belong to [2, io_qpairs_max_entries] */</a>
<a name="ln1428">	if (qd == 1) {</a>
<a name="ln1429">		nvme_err(&quot;Invalid queue depth\n&quot;);</a>
<a name="ln1430">		return NULL;</a>
<a name="ln1431">	}</a>
<a name="ln1432"> </a>
<a name="ln1433">	if (qd == 0 || qd &gt; ctrlr-&gt;io_qpairs_max_entries)</a>
<a name="ln1434">		qd = ctrlr-&gt;io_qpairs_max_entries;</a>
<a name="ln1435"> </a>
<a name="ln1436">	/*</a>
<a name="ln1437">	 * No need to have more trackers than entries in the submit queue.</a>
<a name="ln1438">	 * Note also that for a queue size of N, we can only have (N-1)</a>
<a name="ln1439">	 * commands outstanding, hence the &quot;-1&quot; here.</a>
<a name="ln1440">	 */</a>
<a name="ln1441">	trackers = nvme_min(NVME_IO_TRACKERS, (qd - 1));</a>
<a name="ln1442"> </a>
<a name="ln1443">	pthread_mutex_lock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1444"> </a>
<a name="ln1445">	/* Get the first available qpair structure */</a>
<a name="ln1446">	qpair = TAILQ_FIRST(&amp;ctrlr-&gt;free_io_qpairs);</a>
<a name="ln1447">	if (qpair == NULL) {</a>
<a name="ln1448">		/* No free queue IDs */</a>
<a name="ln1449">		nvme_err(&quot;No free I/O queue pairs\n&quot;);</a>
<a name="ln1450">		goto out;</a>
<a name="ln1451">	}</a>
<a name="ln1452"> </a>
<a name="ln1453">	/* Construct the qpair */</a>
<a name="ln1454">	ret = nvme_qpair_construct(ctrlr, qpair, qprio, qd, trackers);</a>
<a name="ln1455">	if (ret != 0) {</a>
<a name="ln1456">		nvme_qpair_destroy(qpair);</a>
<a name="ln1457">		qpair = NULL;</a>
<a name="ln1458">		goto out;</a>
<a name="ln1459">	}</a>
<a name="ln1460"> </a>
<a name="ln1461">	/*</a>
<a name="ln1462">	 * At this point, qpair contains a preallocated submission</a>
<a name="ln1463">	 * and completion queue and a unique queue ID, but it is not</a>
<a name="ln1464">	 * yet created on the controller.</a>
<a name="ln1465">	 * Fill out the submission queue priority and send out the</a>
<a name="ln1466">	 * Create I/O Queue commands.</a>
<a name="ln1467">	 */</a>
<a name="ln1468">	if (nvme_ctrlr_create_qpair(ctrlr, qpair) != 0) {</a>
<a name="ln1469">		nvme_err(&quot;Create queue pair on the controller failed\n&quot;);</a>
<a name="ln1470">		nvme_qpair_destroy(qpair);</a>
<a name="ln1471">		qpair = NULL;</a>
<a name="ln1472">		goto out;</a>
<a name="ln1473">	}</a>
<a name="ln1474"> </a>
<a name="ln1475">	TAILQ_REMOVE(&amp;ctrlr-&gt;free_io_qpairs, qpair, tailq);</a>
<a name="ln1476">	TAILQ_INSERT_TAIL(&amp;ctrlr-&gt;active_io_qpairs, qpair, tailq);</a>
<a name="ln1477"> </a>
<a name="ln1478">out:</a>
<a name="ln1479">	pthread_mutex_unlock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1480"> </a>
<a name="ln1481">	return qpair;</a>
<a name="ln1482">}</a>
<a name="ln1483"> </a>
<a name="ln1484">/*</a>
<a name="ln1485"> * Free an I/O queue pair.</a>
<a name="ln1486"> */</a>
<a name="ln1487">int nvme_ioqp_release(struct nvme_qpair *qpair)</a>
<a name="ln1488">{</a>
<a name="ln1489">	struct nvme_ctrlr *ctrlr;</a>
<a name="ln1490">	int ret;</a>
<a name="ln1491"> </a>
<a name="ln1492">	if (qpair == NULL)</a>
<a name="ln1493">		return 0;</a>
<a name="ln1494"> </a>
<a name="ln1495">	ctrlr = qpair-&gt;ctrlr;</a>
<a name="ln1496"> </a>
<a name="ln1497">	pthread_mutex_lock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1498"> </a>
<a name="ln1499">	/* Delete the I/O submission and completion queues */</a>
<a name="ln1500">	ret = nvme_ctrlr_delete_qpair(ctrlr, qpair);</a>
<a name="ln1501">	if (ret != 0) {</a>
<a name="ln1502">		nvme_notice(&quot;Delete queue pair %u failed\n&quot;, qpair-&gt;id);</a>
<a name="ln1503">	} else {</a>
<a name="ln1504">		TAILQ_REMOVE(&amp;ctrlr-&gt;active_io_qpairs, qpair, tailq);</a>
<a name="ln1505">		TAILQ_INSERT_HEAD(&amp;ctrlr-&gt;free_io_qpairs, qpair, tailq);</a>
<a name="ln1506">	}</a>
<a name="ln1507"> </a>
<a name="ln1508">	pthread_mutex_unlock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1509"> </a>
<a name="ln1510">	return ret;</a>
<a name="ln1511">}</a>
<a name="ln1512"> </a>
<a name="ln1513">/*</a>
<a name="ln1514"> * Submit an NVMe command using the specified I/O queue pair.</a>
<a name="ln1515"> */</a>
<a name="ln1516">int nvme_ioqp_submit_cmd(struct nvme_qpair *qpair,</a>
<a name="ln1517">			 struct nvme_cmd *cmd,</a>
<a name="ln1518">			 void *buf, size_t len,</a>
<a name="ln1519">			 nvme_cmd_cb cb_fn, void *cb_arg)</a>
<a name="ln1520">{</a>
<a name="ln1521">	struct nvme_ctrlr *ctrlr = qpair-&gt;ctrlr;</a>
<a name="ln1522">	struct nvme_request *req;</a>
<a name="ln1523">	int ret = ENOMEM;</a>
<a name="ln1524"> </a>
<a name="ln1525">	pthread_mutex_lock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1526"> </a>
<a name="ln1527">	req = nvme_request_allocate_contig(qpair, buf, len, cb_fn, cb_arg);</a>
<a name="ln1528">	if (req) {</a>
<a name="ln1529">		memcpy(&amp;req-&gt;cmd, cmd, sizeof(req-&gt;cmd));</a>
<a name="ln1530">		ret = nvme_qpair_submit_request(qpair, req);</a>
<a name="ln1531">	}</a>
<a name="ln1532"> </a>
<a name="ln1533">	pthread_mutex_unlock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1534"> </a>
<a name="ln1535">	return ret;</a>
<a name="ln1536">}</a>
<a name="ln1537"> </a>
<a name="ln1538">/*</a>
<a name="ln1539"> * Poll for completion of NVMe commands submitted to the</a>
<a name="ln1540"> * specified I/O queue pair.</a>
<a name="ln1541"> */</a>
<a name="ln1542">unsigned int nvme_ioqp_poll(struct nvme_qpair *qpair,</a>
<a name="ln1543">			    unsigned int max_completions)</a>
<a name="ln1544">{</a>
<a name="ln1545">	struct nvme_ctrlr *ctrlr = qpair-&gt;ctrlr;</a>
<a name="ln1546">	int ret;</a>
<a name="ln1547"> </a>
<a name="ln1548">	pthread_mutex_lock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1549">	ret = nvme_qpair_poll(qpair, max_completions);</a>
<a name="ln1550">	pthread_mutex_unlock(&amp;ctrlr-&gt;lock);</a>
<a name="ln1551"> </a>
<a name="ln1552">	return ret;</a>
<a name="ln1553">}</a>

</code></pre>
<div class="balloon" rel="200"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v519/" target="_blank">V519</a> The variable is assigned values twice successively. Perhaps this is a mistake. Check lines: 199, 200.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
