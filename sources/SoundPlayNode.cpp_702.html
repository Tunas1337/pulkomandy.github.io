
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <title>SoundPlayNode.cpp</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">/*</a>
<a name="ln2"> * Copyright 2002-2010, Haiku.</a>
<a name="ln3"> * Distributed under the terms of the MIT License.</a>
<a name="ln4"> *</a>
<a name="ln5"> * Authors:</a>
<a name="ln6"> *		Marcus Overhagen</a>
<a name="ln7"> *		Jérôme Duval</a>
<a name="ln8"> */</a>
<a name="ln9"> </a>
<a name="ln10"> </a>
<a name="ln11">/*!	This is the BBufferProducer used internally by BSoundPlayer.</a>
<a name="ln12">*/</a>
<a name="ln13"> </a>
<a name="ln14"> </a>
<a name="ln15">#include &quot;SoundPlayNode.h&quot;</a>
<a name="ln16"> </a>
<a name="ln17">#include &lt;string.h&gt;</a>
<a name="ln18">#include &lt;stdlib.h&gt;</a>
<a name="ln19">#include &lt;unistd.h&gt;</a>
<a name="ln20"> </a>
<a name="ln21">#include &lt;TimeSource.h&gt;</a>
<a name="ln22">#include &lt;MediaRoster.h&gt;</a>
<a name="ln23">#include &quot;MediaDebug.h&quot;</a>
<a name="ln24"> </a>
<a name="ln25"> </a>
<a name="ln26">#define SEND_NEW_BUFFER_EVENT (BTimedEventQueue::B_USER_EVENT + 1)</a>
<a name="ln27"> </a>
<a name="ln28"> </a>
<a name="ln29">namespace BPrivate {</a>
<a name="ln30"> </a>
<a name="ln31"> </a>
<a name="ln32">SoundPlayNode::SoundPlayNode(const char* name, BSoundPlayer* player)</a>
<a name="ln33">	:</a>
<a name="ln34">	BMediaNode(name),</a>
<a name="ln35">	BBufferProducer(B_MEDIA_RAW_AUDIO),</a>
<a name="ln36">	BMediaEventLooper(),</a>
<a name="ln37">	fPlayer(player),</a>
<a name="ln38">	fInitStatus(B_OK),</a>
<a name="ln39">	fOutputEnabled(true),</a>
<a name="ln40">	fBufferGroup(NULL),</a>
<a name="ln41">	fFramesSent(0),</a>
<a name="ln42">	fTooEarlyCount(0)</a>
<a name="ln43">{</a>
<a name="ln44">	CALLED();</a>
<a name="ln45">	fOutput.format.type = B_MEDIA_RAW_AUDIO;</a>
<a name="ln46">	fOutput.format.u.raw_audio = media_multi_audio_format::wildcard;</a>
<a name="ln47">}</a>
<a name="ln48"> </a>
<a name="ln49"> </a>
<a name="ln50">SoundPlayNode::~SoundPlayNode()</a>
<a name="ln51">{</a>
<a name="ln52">	CALLED();</a>
<a name="ln53">	Quit();</a>
<a name="ln54">}</a>
<a name="ln55"> </a>
<a name="ln56"> </a>
<a name="ln57">bool</a>
<a name="ln58">SoundPlayNode::IsPlaying()</a>
<a name="ln59">{</a>
<a name="ln60">	return RunState() == B_STARTED;</a>
<a name="ln61">}</a>
<a name="ln62"> </a>
<a name="ln63"> </a>
<a name="ln64">bigtime_t</a>
<a name="ln65">SoundPlayNode::CurrentTime()</a>
<a name="ln66">{</a>
<a name="ln67">	int frameRate = (int)fOutput.format.u.raw_audio.frame_rate;</a>
<a name="ln68">	return frameRate == 0 ? 0</a>
<a name="ln69">		: bigtime_t((1000000LL * fFramesSent) / frameRate);</a>
<a name="ln70">}</a>
<a name="ln71"> </a>
<a name="ln72"> </a>
<a name="ln73">media_multi_audio_format</a>
<a name="ln74">SoundPlayNode::Format() const</a>
<a name="ln75">{</a>
<a name="ln76">	return fOutput.format.u.raw_audio;</a>
<a name="ln77">}</a>
<a name="ln78"> </a>
<a name="ln79"> </a>
<a name="ln80">// #pragma mark - implementation of BMediaNode</a>
<a name="ln81"> </a>
<a name="ln82"> </a>
<a name="ln83">BMediaAddOn*</a>
<a name="ln84">SoundPlayNode::AddOn(int32* _internalID) const</a>
<a name="ln85">{</a>
<a name="ln86">	CALLED();</a>
<a name="ln87">	// This only gets called if we are in an add-on.</a>
<a name="ln88">	return NULL;</a>
<a name="ln89">}</a>
<a name="ln90"> </a>
<a name="ln91"> </a>
<a name="ln92">void</a>
<a name="ln93">SoundPlayNode::Preroll()</a>
<a name="ln94">{</a>
<a name="ln95">	CALLED();</a>
<a name="ln96">	// TODO: Performance opportunity</a>
<a name="ln97">	BMediaNode::Preroll();</a>
<a name="ln98">}</a>
<a name="ln99"> </a>
<a name="ln100"> </a>
<a name="ln101">status_t</a>
<a name="ln102">SoundPlayNode::HandleMessage(int32 message, const void* data, size_t size)</a>
<a name="ln103">{</a>
<a name="ln104">	CALLED();</a>
<a name="ln105">	return B_ERROR;</a>
<a name="ln106">}</a>
<a name="ln107"> </a>
<a name="ln108"> </a>
<a name="ln109">void</a>
<a name="ln110">SoundPlayNode::NodeRegistered()</a>
<a name="ln111">{</a>
<a name="ln112">	CALLED();</a>
<a name="ln113"> </a>
<a name="ln114">	if (fInitStatus != B_OK) {</a>
<a name="ln115">		ReportError(B_NODE_IN_DISTRESS);</a>
<a name="ln116">		return;</a>
<a name="ln117">	}</a>
<a name="ln118"> </a>
<a name="ln119">	SetPriority(B_URGENT_PRIORITY);</a>
<a name="ln120"> </a>
<a name="ln121">	fOutput.format.type = B_MEDIA_RAW_AUDIO;</a>
<a name="ln122">	fOutput.format.u.raw_audio = media_multi_audio_format::wildcard;</a>
<a name="ln123">	fOutput.destination = media_destination::null;</a>
<a name="ln124">	fOutput.source.port = ControlPort();</a>
<a name="ln125">	fOutput.source.id = 0;</a>
<a name="ln126">	fOutput.node = Node();</a>
<a name="ln127">	strcpy(fOutput.name, Name());</a>
<a name="ln128"> </a>
<a name="ln129">	Run();</a>
<a name="ln130">}</a>
<a name="ln131"> </a>
<a name="ln132"> </a>
<a name="ln133">status_t</a>
<a name="ln134">SoundPlayNode::RequestCompleted(const media_request_info&amp; info)</a>
<a name="ln135">{</a>
<a name="ln136">	CALLED();</a>
<a name="ln137">	return B_OK;</a>
<a name="ln138">}</a>
<a name="ln139"> </a>
<a name="ln140"> </a>
<a name="ln141">void</a>
<a name="ln142">SoundPlayNode::SetTimeSource(BTimeSource* timeSource)</a>
<a name="ln143">{</a>
<a name="ln144">	CALLED();</a>
<a name="ln145">	BMediaNode::SetTimeSource(timeSource);</a>
<a name="ln146">}</a>
<a name="ln147"> </a>
<a name="ln148"> </a>
<a name="ln149">void</a>
<a name="ln150">SoundPlayNode::SetRunMode(run_mode mode)</a>
<a name="ln151">{</a>
<a name="ln152">	TRACE(&quot;SoundPlayNode::SetRunMode mode:%i\n&quot;, mode);</a>
<a name="ln153">	BMediaNode::SetRunMode(mode);</a>
<a name="ln154">}</a>
<a name="ln155"> </a>
<a name="ln156"> </a>
<a name="ln157">// #pragma mark - implementation for BBufferProducer</a>
<a name="ln158"> </a>
<a name="ln159"> </a>
<a name="ln160">status_t</a>
<a name="ln161">SoundPlayNode::FormatSuggestionRequested(media_type type, int32 /*quality*/,</a>
<a name="ln162">	media_format* format)</a>
<a name="ln163">{</a>
<a name="ln164">	// FormatSuggestionRequested() is not necessarily part of the format</a>
<a name="ln165">	// negotiation process; it's simply an interrogation -- the caller wants</a>
<a name="ln166">	// to see what the node's preferred data format is, given a suggestion by</a>
<a name="ln167">	// the caller.</a>
<a name="ln168">	CALLED();</a>
<a name="ln169"> </a>
<a name="ln170">	// a wildcard type is okay; but we only support raw audio</a>
<a name="ln171">	if (type != B_MEDIA_RAW_AUDIO &amp;&amp; type != B_MEDIA_UNKNOWN_TYPE)</a>
<a name="ln172">		return B_MEDIA_BAD_FORMAT;</a>
<a name="ln173"> </a>
<a name="ln174">	// this is the format we'll be returning (our preferred format)</a>
<a name="ln175">	format-&gt;type = B_MEDIA_RAW_AUDIO;</a>
<a name="ln176">	format-&gt;u.raw_audio = media_multi_audio_format::wildcard;</a>
<a name="ln177"> </a>
<a name="ln178">	return B_OK;</a>
<a name="ln179">}</a>
<a name="ln180"> </a>
<a name="ln181"> </a>
<a name="ln182">status_t</a>
<a name="ln183">SoundPlayNode::FormatProposal(const media_source&amp; output, media_format* format)</a>
<a name="ln184">{</a>
<a name="ln185">	// FormatProposal() is the first stage in the BMediaRoster::Connect()</a>
<a name="ln186">	// process. We hand out a suggested format, with wildcards for any</a>
<a name="ln187">	// variations we support.</a>
<a name="ln188">	CALLED();</a>
<a name="ln189"> </a>
<a name="ln190">	// is this a proposal for our one output?</a>
<a name="ln191">	if (output != fOutput.source) {</a>
<a name="ln192">		TRACE(&quot;SoundPlayNode::FormatProposal returning B_MEDIA_BAD_SOURCE\n&quot;);</a>
<a name="ln193">		return B_MEDIA_BAD_SOURCE;</a>
<a name="ln194">	}</a>
<a name="ln195"> </a>
<a name="ln196">	// if wildcard, change it to raw audio</a>
<a name="ln197">	if (format-&gt;type == B_MEDIA_UNKNOWN_TYPE)</a>
<a name="ln198">		format-&gt;type = B_MEDIA_RAW_AUDIO;</a>
<a name="ln199"> </a>
<a name="ln200">	// if not raw audio, we can't support it</a>
<a name="ln201">	if (format-&gt;type != B_MEDIA_RAW_AUDIO) {</a>
<a name="ln202">		TRACE(&quot;SoundPlayNode::FormatProposal returning B_MEDIA_BAD_FORMAT\n&quot;);</a>
<a name="ln203">		return B_MEDIA_BAD_FORMAT;</a>
<a name="ln204">	}</a>
<a name="ln205"> </a>
<a name="ln206">#if DEBUG &gt;0</a>
<a name="ln207">	char buf[100];</a>
<a name="ln208">	string_for_format(*format, buf, sizeof(buf));</a>
<a name="ln209">	TRACE(&quot;SoundPlayNode::FormatProposal: format %s\n&quot;, buf);</a>
<a name="ln210">#endif</a>
<a name="ln211"> </a>
<a name="ln212">	return B_OK;</a>
<a name="ln213">}</a>
<a name="ln214"> </a>
<a name="ln215"> </a>
<a name="ln216">status_t</a>
<a name="ln217">SoundPlayNode::FormatChangeRequested(const media_source&amp; source,</a>
<a name="ln218">	const media_destination&amp; destination, media_format* _format,</a>
<a name="ln219">	int32* /* deprecated */)</a>
<a name="ln220">{</a>
<a name="ln221">	CALLED();</a>
<a name="ln222"> </a>
<a name="ln223">	// we don't support any other formats, so we just reject any format changes.</a>
<a name="ln224">	return B_ERROR;</a>
<a name="ln225">}</a>
<a name="ln226"> </a>
<a name="ln227"> </a>
<a name="ln228">status_t</a>
<a name="ln229">SoundPlayNode::GetNextOutput(int32* cookie, media_output* _output)</a>
<a name="ln230">{</a>
<a name="ln231">	CALLED();</a>
<a name="ln232"> </a>
<a name="ln233">	if (*cookie == 0) {</a>
<a name="ln234">		*_output = fOutput;</a>
<a name="ln235">		*cookie += 1;</a>
<a name="ln236">		return B_OK;</a>
<a name="ln237">	} else {</a>
<a name="ln238">		return B_BAD_INDEX;</a>
<a name="ln239">	}</a>
<a name="ln240">}</a>
<a name="ln241"> </a>
<a name="ln242"> </a>
<a name="ln243">status_t</a>
<a name="ln244">SoundPlayNode::DisposeOutputCookie(int32 cookie)</a>
<a name="ln245">{</a>
<a name="ln246">	CALLED();</a>
<a name="ln247">	// do nothing because we don't use the cookie for anything special</a>
<a name="ln248">	return B_OK;</a>
<a name="ln249">}</a>
<a name="ln250"> </a>
<a name="ln251"> </a>
<a name="ln252">status_t</a>
<a name="ln253">SoundPlayNode::SetBufferGroup(const media_source&amp; forSource,</a>
<a name="ln254">	BBufferGroup* newGroup)</a>
<a name="ln255">{</a>
<a name="ln256">	CALLED();</a>
<a name="ln257"> </a>
<a name="ln258">	// is this our output?</a>
<a name="ln259">	if (forSource != fOutput.source) {</a>
<a name="ln260">		TRACE(&quot;SoundPlayNode::SetBufferGroup returning B_MEDIA_BAD_SOURCE\n&quot;);</a>
<a name="ln261">		return B_MEDIA_BAD_SOURCE;</a>
<a name="ln262">	}</a>
<a name="ln263"> </a>
<a name="ln264">	// Are we being passed the buffer group we're already using?</a>
<a name="ln265">	if (newGroup == fBufferGroup)</a>
<a name="ln266">		return B_OK;</a>
<a name="ln267"> </a>
<a name="ln268">	// Ahh, someone wants us to use a different buffer group. At this point we</a>
<a name="ln269">	// delete the one we are using and use the specified one instead.</a>
<a name="ln270">	// If the specified group is NULL, we need to recreate one ourselves, and</a>
<a name="ln271">	// use *that*. Note that if we're caching a BBuffer that we requested</a>
<a name="ln272">	// earlier, we have to Recycle() that buffer *before* deleting the buffer</a>
<a name="ln273">	// group, otherwise we'll deadlock waiting for that buffer to be recycled!</a>
<a name="ln274">	delete fBufferGroup;</a>
<a name="ln275">		// waits for all buffers to recycle</a>
<a name="ln276"> </a>
<a name="ln277">	if (newGroup != NULL) {</a>
<a name="ln278">		// we were given a valid group; just use that one from now on</a>
<a name="ln279">		fBufferGroup = newGroup;</a>
<a name="ln280">		return B_OK;</a>
<a name="ln281">	}</a>
<a name="ln282"> </a>
<a name="ln283">	// we were passed a NULL group pointer; that means we construct</a>
<a name="ln284">	// our own buffer group to use from now on</a>
<a name="ln285">	return AllocateBuffers();</a>
<a name="ln286">}</a>
<a name="ln287"> </a>
<a name="ln288"> </a>
<a name="ln289">status_t</a>
<a name="ln290">SoundPlayNode::GetLatency(bigtime_t* _latency)</a>
<a name="ln291">{</a>
<a name="ln292">	CALLED();</a>
<a name="ln293"> </a>
<a name="ln294">	// report our *total* latency:  internal plus downstream plus scheduling</a>
<a name="ln295">	*_latency = EventLatency() + SchedulingLatency();</a>
<a name="ln296">	return B_OK;</a>
<a name="ln297">}</a>
<a name="ln298"> </a>
<a name="ln299"> </a>
<a name="ln300">status_t</a>
<a name="ln301">SoundPlayNode::PrepareToConnect(const media_source&amp; what,</a>
<a name="ln302">	const media_destination&amp; where, media_format* format,</a>
<a name="ln303">	media_source* _source, char* _name)</a>
<a name="ln304">{</a>
<a name="ln305">	// PrepareToConnect() is the second stage of format negotiations that</a>
<a name="ln306">	// happens inside BMediaRoster::Connect(). At this point, the consumer's</a>
<a name="ln307">	// AcceptFormat() method has been called, and that node has potentially</a>
<a name="ln308">	// changed the proposed format. It may also have left wildcards in the</a>
<a name="ln309">	// format. PrepareToConnect() *must* fully specialize the format before</a>
<a name="ln310">	// returning!</a>
<a name="ln311">	CALLED();</a>
<a name="ln312"> </a>
<a name="ln313">	// is this our output?</a>
<a name="ln314">	if (what != fOutput.source)	{</a>
<a name="ln315">		TRACE(&quot;SoundPlayNode::PrepareToConnect returning &quot;</a>
<a name="ln316">			&quot;B_MEDIA_BAD_SOURCE\n&quot;);</a>
<a name="ln317">		return B_MEDIA_BAD_SOURCE;</a>
<a name="ln318">	}</a>
<a name="ln319"> </a>
<a name="ln320">	// are we already connected?</a>
<a name="ln321">	if (fOutput.destination != media_destination::null)</a>
<a name="ln322">		return B_MEDIA_ALREADY_CONNECTED;</a>
<a name="ln323"> </a>
<a name="ln324">	// the format may not yet be fully specialized (the consumer might have</a>
<a name="ln325">	// passed back some wildcards). Finish specializing it now, and return an</a>
<a name="ln326">	// error if we don't support the requested format.</a>
<a name="ln327"> </a>
<a name="ln328">#if DEBUG &gt; 0</a>
<a name="ln329">	char buf[100];</a>
<a name="ln330">	string_for_format(*format, buf, sizeof(buf));</a>
<a name="ln331">	TRACE(&quot;SoundPlayNode::PrepareToConnect: input format %s\n&quot;, buf);</a>
<a name="ln332">#endif</a>
<a name="ln333"> </a>
<a name="ln334">	// if not raw audio, we can't support it</a>
<a name="ln335">	if (format-&gt;type != B_MEDIA_UNKNOWN_TYPE</a>
<a name="ln336">		&amp;&amp; format-&gt;type != B_MEDIA_RAW_AUDIO) {</a>
<a name="ln337">		TRACE(&quot;SoundPlayNode::PrepareToConnect: non raw format, returning &quot;</a>
<a name="ln338">			&quot;B_MEDIA_BAD_FORMAT\n&quot;);</a>
<a name="ln339">		return B_MEDIA_BAD_FORMAT;</a>
<a name="ln340">	}</a>
<a name="ln341"> </a>
<a name="ln342">	// the haiku mixer might have a hint</a>
<a name="ln343">	// for us, so check for it</a>
<a name="ln344">	#define FORMAT_USER_DATA_TYPE 		0x7294a8f3</a>
<a name="ln345">	#define FORMAT_USER_DATA_MAGIC_1	0xc84173bd</a>
<a name="ln346">	#define FORMAT_USER_DATA_MAGIC_2	0x4af62b7d</a>
<a name="ln347">	uint32 channel_count = 0;</a>
<a name="ln348">	float frame_rate = 0;</a>
<a name="ln349">	if (format-&gt;user_data_type == FORMAT_USER_DATA_TYPE</a>
<a name="ln350">		&amp;&amp; *(uint32 *)&amp;format-&gt;user_data[0] == FORMAT_USER_DATA_MAGIC_1</a>
<a name="ln351">		&amp;&amp; *(uint32 *)&amp;format-&gt;user_data[44] == FORMAT_USER_DATA_MAGIC_2) {</a>
<a name="ln352">		channel_count = *(uint32 *)&amp;format-&gt;user_data[4];</a>
<a name="ln353">		frame_rate = *(float *)&amp;format-&gt;user_data[20];</a>
<a name="ln354">		TRACE(&quot;SoundPlayNode::PrepareToConnect: found mixer info: &quot;</a>
<a name="ln355">			&quot;channel_count %&quot; B_PRId32 &quot; , frame_rate %.1f\n&quot;, channel_count, frame_rate);</a>
<a name="ln356">	}</a>
<a name="ln357"> </a>
<a name="ln358">	media_format default_format;</a>
<a name="ln359">	default_format.type = B_MEDIA_RAW_AUDIO;</a>
<a name="ln360">	default_format.u.raw_audio.frame_rate = frame_rate &gt; 0 ? frame_rate : 44100;</a>
<a name="ln361">	default_format.u.raw_audio.channel_count = channel_count &gt; 0</a>
<a name="ln362">		? channel_count : 2;</a>
<a name="ln363">	default_format.u.raw_audio.format = media_raw_audio_format::B_AUDIO_FLOAT;</a>
<a name="ln364">	default_format.u.raw_audio.byte_order = B_MEDIA_HOST_ENDIAN;</a>
<a name="ln365">	default_format.u.raw_audio.buffer_size = 0;</a>
<a name="ln366">	format-&gt;SpecializeTo(&amp;default_format);</a>
<a name="ln367"> </a>
<a name="ln368">	if (format-&gt;u.raw_audio.buffer_size == 0) {</a>
<a name="ln369">		format-&gt;u.raw_audio.buffer_size</a>
<a name="ln370">			= BMediaRoster::Roster()-&gt;AudioBufferSizeFor(</a>
<a name="ln371">				format-&gt;u.raw_audio.channel_count, format-&gt;u.raw_audio.format,</a>
<a name="ln372">				format-&gt;u.raw_audio.frame_rate);</a>
<a name="ln373">	}</a>
<a name="ln374"> </a>
<a name="ln375">#if DEBUG &gt; 0</a>
<a name="ln376">	string_for_format(*format, buf, sizeof(buf));</a>
<a name="ln377">	TRACE(&quot;SoundPlayNode::PrepareToConnect: output format %s\n&quot;, buf);</a>
<a name="ln378">#endif</a>
<a name="ln379"> </a>
<a name="ln380">	// Now reserve the connection, and return information about it</a>
<a name="ln381">	fOutput.destination = where;</a>
<a name="ln382">	fOutput.format = *format;</a>
<a name="ln383">	*_source = fOutput.source;</a>
<a name="ln384">	strcpy(_name, Name());</a>
<a name="ln385">	return B_OK;</a>
<a name="ln386">}</a>
<a name="ln387"> </a>
<a name="ln388"> </a>
<a name="ln389">void</a>
<a name="ln390">SoundPlayNode::Connect(status_t error, const media_source&amp; source,</a>
<a name="ln391">	const media_destination&amp; destination, const media_format&amp; format,</a>
<a name="ln392">	char* name)</a>
<a name="ln393">{</a>
<a name="ln394">	CALLED();</a>
<a name="ln395"> </a>
<a name="ln396">	// is this our output?</a>
<a name="ln397">	if (source != fOutput.source) {</a>
<a name="ln398">		TRACE(&quot;SoundPlayNode::Connect returning\n&quot;);</a>
<a name="ln399">		return;</a>
<a name="ln400">	}</a>
<a name="ln401"> </a>
<a name="ln402">	// If something earlier failed, Connect() might still be called, but with</a>
<a name="ln403">	// a non-zero error code.  When that happens we simply unreserve the</a>
<a name="ln404">	// connection and do nothing else.</a>
<a name="ln405">	if (error) {</a>
<a name="ln406">		fOutput.destination = media_destination::null;</a>
<a name="ln407">		fOutput.format.type = B_MEDIA_RAW_AUDIO;</a>
<a name="ln408">		fOutput.format.u.raw_audio = media_multi_audio_format::wildcard;</a>
<a name="ln409">		return;</a>
<a name="ln410">	}</a>
<a name="ln411"> </a>
<a name="ln412">	// Okay, the connection has been confirmed.  Record the destination and</a>
<a name="ln413">	// format that we agreed on, and report our connection name again.</a>
<a name="ln414">	fOutput.destination = destination;</a>
<a name="ln415">	fOutput.format = format;</a>
<a name="ln416">	strcpy(name, Name());</a>
<a name="ln417"> </a>
<a name="ln418">	// Now that we're connected, we can determine our downstream latency.</a>
<a name="ln419">	// Do so, then make sure we get our events early enough.</a>
<a name="ln420">	media_node_id id;</a>
<a name="ln421">	FindLatencyFor(fOutput.destination, &amp;fLatency, &amp;id);</a>
<a name="ln422">	TRACE(&quot;SoundPlayNode::Connect: downstream latency = %&quot; B_PRId64 &quot;\n&quot;,</a>
<a name="ln423">		fLatency);</a>
<a name="ln424"> </a>
<a name="ln425">	// reset our buffer duration, etc. to avoid later calculations</a>
<a name="ln426">	bigtime_t duration = ((fOutput.format.u.raw_audio.buffer_size * 1000000LL)</a>
<a name="ln427">		/ ((fOutput.format.u.raw_audio.format</a>
<a name="ln428">				&amp; media_raw_audio_format::B_AUDIO_SIZE_MASK)</a>
<a name="ln429">			* fOutput.format.u.raw_audio.channel_count))</a>
<a name="ln430">		/ (int32)fOutput.format.u.raw_audio.frame_rate;</a>
<a name="ln431">	SetBufferDuration(duration);</a>
<a name="ln432">	TRACE(&quot;SoundPlayNode::Connect: buffer duration is %&quot; B_PRId64 &quot;\n&quot;,</a>
<a name="ln433">		duration);</a>
<a name="ln434"> </a>
<a name="ln435">	fInternalLatency = (3 * BufferDuration()) / 4;</a>
<a name="ln436">	TRACE(&quot;SoundPlayNode::Connect: using %&quot; B_PRId64 &quot; as internal latency\n&quot;,</a>
<a name="ln437">		fInternalLatency);</a>
<a name="ln438">	SetEventLatency(fLatency + fInternalLatency);</a>
<a name="ln439"> </a>
<a name="ln440">	// Set up the buffer group for our connection, as long as nobody handed us</a>
<a name="ln441">	// a buffer group (via SetBufferGroup()) prior to this.</a>
<a name="ln442">	// That can happen, for example, if the consumer calls SetOutputBuffersFor()</a>
<a name="ln443">	// on us from within its Connected() method.</a>
<a name="ln444">	if (!fBufferGroup)</a>
<a name="ln445">		AllocateBuffers();</a>
<a name="ln446">}</a>
<a name="ln447"> </a>
<a name="ln448"> </a>
<a name="ln449">void</a>
<a name="ln450">SoundPlayNode::Disconnect(const media_source&amp; what,</a>
<a name="ln451">	const media_destination&amp; where)</a>
<a name="ln452">{</a>
<a name="ln453">	CALLED();</a>
<a name="ln454"> </a>
<a name="ln455">	// is this our output?</a>
<a name="ln456">	if (what != fOutput.source) {</a>
<a name="ln457">		TRACE(&quot;SoundPlayNode::Disconnect returning\n&quot;);</a>
<a name="ln458">		return;</a>
<a name="ln459">	}</a>
<a name="ln460"> </a>
<a name="ln461">	// Make sure that our connection is the one being disconnected</a>
<a name="ln462">	if (where == fOutput.destination &amp;&amp; what == fOutput.source) {</a>
<a name="ln463">		fOutput.destination = media_destination::null;</a>
<a name="ln464">		fOutput.format.type = B_MEDIA_RAW_AUDIO;</a>
<a name="ln465">		fOutput.format.u.raw_audio = media_multi_audio_format::wildcard;</a>
<a name="ln466">		delete fBufferGroup;</a>
<a name="ln467">		fBufferGroup = NULL;</a>
<a name="ln468">	} else {</a>
<a name="ln469">		fprintf(stderr, &quot;\tDisconnect() called with wrong source/destination &quot;</a>
<a name="ln470">			&quot;(%&quot; B_PRId32 &quot;/%&quot; B_PRId32 &quot;), ours is (%&quot; B_PRId32 &quot;/%&quot; B_PRId32</a>
<a name="ln471">			&quot;)\n&quot;, what.id, where.id, fOutput.source.id,</a>
<a name="ln472">			fOutput.destination.id);</a>
<a name="ln473">	}</a>
<a name="ln474">}</a>
<a name="ln475"> </a>
<a name="ln476"> </a>
<a name="ln477">void</a>
<a name="ln478">SoundPlayNode::LateNoticeReceived(const media_source&amp; what, bigtime_t howMuch,</a>
<a name="ln479">	bigtime_t performanceTime)</a>
<a name="ln480">{</a>
<a name="ln481">	CALLED();</a>
<a name="ln482"> </a>
<a name="ln483">	TRACE(&quot;SoundPlayNode::LateNoticeReceived, %&quot; B_PRId64 &quot; too late at %&quot;</a>
<a name="ln484">		B_PRId64 &quot;\n&quot;, howMuch, performanceTime);</a>
<a name="ln485"> </a>
<a name="ln486">	// is this our output?</a>
<a name="ln487">	if (what != fOutput.source) {</a>
<a name="ln488">		TRACE(&quot;SoundPlayNode::LateNoticeReceived returning\n&quot;);</a>
<a name="ln489">		return;</a>
<a name="ln490">	}</a>
<a name="ln491"> </a>
<a name="ln492">	if (RunMode() != B_DROP_DATA) {</a>
<a name="ln493">		// We're late, and our run mode dictates that we try to produce buffers</a>
<a name="ln494">		// earlier in order to catch up.  This argues that the downstream nodes are</a>
<a name="ln495">		// not properly reporting their latency, but there's not much we can do about</a>
<a name="ln496">		// that at the moment, so we try to start producing buffers earlier to</a>
<a name="ln497">		// compensate.</a>
<a name="ln498"> </a>
<a name="ln499">		fInternalLatency += howMuch;</a>
<a name="ln500"> </a>
<a name="ln501">		if (fInternalLatency &gt; 30000)	// avoid getting a too high latency</a>
<a name="ln502">			fInternalLatency = 30000;</a>
<a name="ln503"> </a>
<a name="ln504">		SetEventLatency(fLatency + fInternalLatency);</a>
<a name="ln505">		TRACE(&quot;SoundPlayNode::LateNoticeReceived: increasing latency to %&quot;</a>
<a name="ln506">			B_PRId64 &quot;\n&quot;, fLatency + fInternalLatency);</a>
<a name="ln507">	} else {</a>
<a name="ln508">		// The other run modes dictate various strategies for sacrificing data quality</a>
<a name="ln509">		// in the interests of timely data delivery.  The way *we* do this is to skip</a>
<a name="ln510">		// a buffer, which catches us up in time by one buffer duration.</a>
<a name="ln511"> </a>
<a name="ln512">		size_t nFrames = fOutput.format.u.raw_audio.buffer_size</a>
<a name="ln513">			/ ((fOutput.format.u.raw_audio.format &amp; media_raw_audio_format::B_AUDIO_SIZE_MASK)</a>
<a name="ln514">			* fOutput.format.u.raw_audio.channel_count);</a>
<a name="ln515"> </a>
<a name="ln516">		fFramesSent += nFrames;</a>
<a name="ln517"> </a>
<a name="ln518">		TRACE(&quot;SoundPlayNode::LateNoticeReceived: skipping a buffer to try to catch up\n&quot;);</a>
<a name="ln519">	}</a>
<a name="ln520">}</a>
<a name="ln521"> </a>
<a name="ln522"> </a>
<a name="ln523">void</a>
<a name="ln524">SoundPlayNode::EnableOutput(const media_source&amp; what, bool enabled,</a>
<a name="ln525">	int32* /* deprecated */)</a>
<a name="ln526">{</a>
<a name="ln527">	CALLED();</a>
<a name="ln528"> </a>
<a name="ln529">	// If I had more than one output, I'd have to walk my list of output</a>
<a name="ln530">	// records to see which one matched the given source, and then</a>
<a name="ln531">	// enable/disable that one.</a>
<a name="ln532">	// But this node only has one output, so I just make sure the given source</a>
<a name="ln533">	// matches, then set the enable state accordingly.</a>
<a name="ln534"> </a>
<a name="ln535">	// is this our output?</a>
<a name="ln536">	if (what != fOutput.source) {</a>
<a name="ln537">		fprintf(stderr, &quot;SoundPlayNode::EnableOutput returning\n&quot;);</a>
<a name="ln538">		return;</a>
<a name="ln539">	}</a>
<a name="ln540"> </a>
<a name="ln541">	fOutputEnabled = enabled;</a>
<a name="ln542">}</a>
<a name="ln543"> </a>
<a name="ln544"> </a>
<a name="ln545">void</a>
<a name="ln546">SoundPlayNode::AdditionalBufferRequested(const media_source&amp; source,</a>
<a name="ln547">	media_buffer_id previousBuffer, bigtime_t previousTime,</a>
<a name="ln548">	const media_seek_tag* previousTag)</a>
<a name="ln549">{</a>
<a name="ln550">	CALLED();</a>
<a name="ln551">	// we don't support offline mode</a>
<a name="ln552">	return;</a>
<a name="ln553">}</a>
<a name="ln554"> </a>
<a name="ln555"> </a>
<a name="ln556">void</a>
<a name="ln557">SoundPlayNode::LatencyChanged(const media_source&amp; source,</a>
<a name="ln558">	const media_destination&amp; destination, bigtime_t newLatency, uint32 flags)</a>
<a name="ln559">{</a>
<a name="ln560">	CALLED();</a>
<a name="ln561"> </a>
<a name="ln562">	TRACE(&quot;SoundPlayNode::LatencyChanged: new_latency %&quot; B_PRId64 &quot;\n&quot;,</a>
<a name="ln563">		newLatency);</a>
<a name="ln564"> </a>
<a name="ln565">	// something downstream changed latency, so we need to start producing</a>
<a name="ln566">	// buffers earlier (or later) than we were previously.  Make sure that the</a>
<a name="ln567">	// connection that changed is ours, and adjust to the new downstream</a>
<a name="ln568">	// latency if so.</a>
<a name="ln569">	if (source == fOutput.source &amp;&amp; destination == fOutput.destination) {</a>
<a name="ln570">		fLatency = newLatency;</a>
<a name="ln571">		SetEventLatency(fLatency + fInternalLatency);</a>
<a name="ln572">	} else {</a>
<a name="ln573">		TRACE(&quot;SoundPlayNode::LatencyChanged: ignored\n&quot;);</a>
<a name="ln574">	}</a>
<a name="ln575">}</a>
<a name="ln576"> </a>
<a name="ln577"> </a>
<a name="ln578">// #pragma mark - implementation for BMediaEventLooper</a>
<a name="ln579"> </a>
<a name="ln580"> </a>
<a name="ln581">void</a>
<a name="ln582">SoundPlayNode::HandleEvent(const media_timed_event* event, bigtime_t lateness,</a>
<a name="ln583">	bool realTimeEvent)</a>
<a name="ln584">{</a>
<a name="ln585">	CALLED();</a>
<a name="ln586">	switch (event-&gt;type) {</a>
<a name="ln587">		case BTimedEventQueue::B_START:</a>
<a name="ln588">			HandleStart(event,lateness,realTimeEvent);</a>
<a name="ln589">			break;</a>
<a name="ln590">		case BTimedEventQueue::B_SEEK:</a>
<a name="ln591">			HandleSeek(event,lateness,realTimeEvent);</a>
<a name="ln592">			break;</a>
<a name="ln593">		case BTimedEventQueue::B_WARP:</a>
<a name="ln594">			HandleWarp(event,lateness,realTimeEvent);</a>
<a name="ln595">			break;</a>
<a name="ln596">		case BTimedEventQueue::B_STOP:</a>
<a name="ln597">			HandleStop(event,lateness,realTimeEvent);</a>
<a name="ln598">			break;</a>
<a name="ln599">		case BTimedEventQueue::B_HANDLE_BUFFER:</a>
<a name="ln600">			// we don't get any buffers</a>
<a name="ln601">			break;</a>
<a name="ln602">		case SEND_NEW_BUFFER_EVENT:</a>
<a name="ln603">			if (RunState() == BMediaEventLooper::B_STARTED)</a>
<a name="ln604">				SendNewBuffer(event, lateness, realTimeEvent);</a>
<a name="ln605">			break;</a>
<a name="ln606">		case BTimedEventQueue::B_DATA_STATUS:</a>
<a name="ln607">			HandleDataStatus(event,lateness,realTimeEvent);</a>
<a name="ln608">			break;</a>
<a name="ln609">		case BTimedEventQueue::B_PARAMETER:</a>
<a name="ln610">			HandleParameter(event,lateness,realTimeEvent);</a>
<a name="ln611">			break;</a>
<a name="ln612">		default:</a>
<a name="ln613">			fprintf(stderr,&quot; unknown event type: %&quot; B_PRId32 &quot;\n&quot;, event-&gt;type);</a>
<a name="ln614">			break;</a>
<a name="ln615">	}</a>
<a name="ln616">}</a>
<a name="ln617"> </a>
<a name="ln618"> </a>
<a name="ln619">// #pragma mark - protected methods</a>
<a name="ln620"> </a>
<a name="ln621"> </a>
<a name="ln622">// how should we handle late buffers?  drop them?</a>
<a name="ln623">// notify the producer?</a>
<a name="ln624">status_t</a>
<a name="ln625">SoundPlayNode::SendNewBuffer(const media_timed_event* event,</a>
<a name="ln626">	bigtime_t lateness, bool realTimeEvent)</a>
<a name="ln627">{</a>
<a name="ln628">	CALLED();</a>
<a name="ln629">	// TRACE(&quot;latency = %12Ld, event = %12Ld, sched = %5Ld, arrive at %12Ld, now %12Ld, current lateness %12Ld\n&quot;, EventLatency() + SchedulingLatency(), EventLatency(), SchedulingLatency(), event-&gt;event_time, TimeSource()-&gt;Now(), lateness);</a>
<a name="ln630"> </a>
<a name="ln631">	// make sure we're both started *and* connected before delivering a buffer</a>
<a name="ln632">	if (RunState() != BMediaEventLooper::B_STARTED</a>
<a name="ln633">		|| fOutput.destination == media_destination::null)</a>
<a name="ln634">		return B_OK;</a>
<a name="ln635"> </a>
<a name="ln636">	// The event-&gt;event_time is the time at which the buffer we are preparing</a>
<a name="ln637">	// here should arrive at it's destination. The MediaEventLooper should have</a>
<a name="ln638">	// scheduled us early enough (based on EventLatency() and the</a>
<a name="ln639">	// SchedulingLatency()) to make this possible.</a>
<a name="ln640">	// lateness is independent of EventLatency()!</a>
<a name="ln641"> </a>
<a name="ln642">	if (lateness &gt; (BufferDuration() / 3) ) {</a>
<a name="ln643">		TRACE(&quot;SoundPlayNode::SendNewBuffer, event scheduled much too late, &quot;</a>
<a name="ln644">			&quot;lateness is %&quot; B_PRId64 &quot;\n&quot;, lateness);</a>
<a name="ln645">	}</a>
<a name="ln646"> </a>
<a name="ln647">	// skip buffer creation if output not enabled</a>
<a name="ln648">	if (fOutputEnabled) {</a>
<a name="ln649"> </a>
<a name="ln650">		// Get the next buffer of data</a>
<a name="ln651">		BBuffer* buffer = FillNextBuffer(event-&gt;event_time);</a>
<a name="ln652"> </a>
<a name="ln653">		if (buffer) {</a>
<a name="ln654"> </a>
<a name="ln655">			// If we are ready way too early, decrase internal latency</a>
<a name="ln656">/*</a>
<a name="ln657">			bigtime_t how_early = event-&gt;event_time - TimeSource()-&gt;Now() - fLatency - fInternalLatency;</a>
<a name="ln658">			if (how_early &gt; 5000) {</a>
<a name="ln659"> </a>
<a name="ln660">				TRACE(&quot;SoundPlayNode::SendNewBuffer, event scheduled too early, how_early is %Ld\n&quot;, how_early);</a>
<a name="ln661"> </a>
<a name="ln662">				if (fTooEarlyCount++ == 5) {</a>
<a name="ln663">					fInternalLatency -= how_early;</a>
<a name="ln664">					if (fInternalLatency &lt; 500)</a>
<a name="ln665">						fInternalLatency = 500;</a>
<a name="ln666">					TRACE(&quot;SoundPlayNode::SendNewBuffer setting internal latency to %Ld\n&quot;, fInternalLatency);</a>
<a name="ln667">					SetEventLatency(fLatency + fInternalLatency);</a>
<a name="ln668">					fTooEarlyCount = 0;</a>
<a name="ln669">				}</a>
<a name="ln670">			}</a>
<a name="ln671">*/</a>
<a name="ln672">			// send the buffer downstream if and only if output is enabled</a>
<a name="ln673">			if (SendBuffer(buffer, fOutput.source, fOutput.destination)</a>
<a name="ln674">					!= B_OK) {</a>
<a name="ln675">				// we need to recycle the buffer</a>
<a name="ln676">				// if the call to SendBuffer() fails</a>
<a name="ln677">				TRACE(&quot;SoundPlayNode::SendNewBuffer: Buffer sending &quot;</a>
<a name="ln678">					&quot;failed\n&quot;);</a>
<a name="ln679">				buffer-&gt;Recycle();</a>
<a name="ln680">			}</a>
<a name="ln681">		}</a>
<a name="ln682">	}</a>
<a name="ln683"> </a>
<a name="ln684">	// track how much media we've delivered so far</a>
<a name="ln685">	size_t nFrames = fOutput.format.u.raw_audio.buffer_size</a>
<a name="ln686">		/ ((fOutput.format.u.raw_audio.format</a>
<a name="ln687">			&amp; media_raw_audio_format::B_AUDIO_SIZE_MASK)</a>
<a name="ln688">		* fOutput.format.u.raw_audio.channel_count);</a>
<a name="ln689">	fFramesSent += nFrames;</a>
<a name="ln690"> </a>
<a name="ln691">	// The buffer is on its way; now schedule the next one to go</a>
<a name="ln692">	// nextEvent is the time at which the buffer should arrive at it's</a>
<a name="ln693">	// destination</a>
<a name="ln694">	bigtime_t nextEvent = fStartTime + bigtime_t((1000000LL * fFramesSent)</a>
<a name="ln695">		/ (int32)fOutput.format.u.raw_audio.frame_rate);</a>
<a name="ln696">	media_timed_event nextBufferEvent(nextEvent, SEND_NEW_BUFFER_EVENT);</a>
<a name="ln697">	EventQueue()-&gt;AddEvent(nextBufferEvent);</a>
<a name="ln698"> </a>
<a name="ln699">	return B_OK;</a>
<a name="ln700">}</a>
<a name="ln701"> </a>
<a name="ln702"> </a>
<a name="ln703">status_t</a>
<a name="ln704">SoundPlayNode::HandleDataStatus(const media_timed_event* event,</a>
<a name="ln705">	bigtime_t lateness, bool realTimeEvent)</a>
<a name="ln706">{</a>
<a name="ln707">	TRACE(&quot;SoundPlayNode::HandleDataStatus status: %&quot; B_PRId32 &quot;, lateness: %&quot;</a>
<a name="ln708">		B_PRId64 &quot;\n&quot;, event-&gt;data, lateness);</a>
<a name="ln709"> </a>
<a name="ln710">	switch (event-&gt;data) {</a>
<a name="ln711">		case B_DATA_NOT_AVAILABLE:</a>
<a name="ln712">			break;</a>
<a name="ln713">		case B_DATA_AVAILABLE:</a>
<a name="ln714">			break;</a>
<a name="ln715">		case B_PRODUCER_STOPPED:</a>
<a name="ln716">			break;</a>
<a name="ln717">		default:</a>
<a name="ln718">			break;</a>
<a name="ln719">	}</a>
<a name="ln720">	return B_OK;</a>
<a name="ln721">}</a>
<a name="ln722"> </a>
<a name="ln723"> </a>
<a name="ln724">status_t</a>
<a name="ln725">SoundPlayNode::HandleStart(const media_timed_event* event, bigtime_t lateness,</a>
<a name="ln726">	bool realTimeEvent)</a>
<a name="ln727">{</a>
<a name="ln728">	CALLED();</a>
<a name="ln729">	// don't do anything if we're already running</a>
<a name="ln730">	if (RunState() != B_STARTED) {</a>
<a name="ln731">		// We want to start sending buffers now, so we set up the buffer-sending</a>
<a name="ln732">		// bookkeeping and fire off the first &quot;produce a buffer&quot; event.</a>
<a name="ln733"> </a>
<a name="ln734">		fFramesSent = 0;</a>
<a name="ln735">		fStartTime = event-&gt;event_time;</a>
<a name="ln736">		media_timed_event firstBufferEvent(event-&gt;event_time,</a>
<a name="ln737">			SEND_NEW_BUFFER_EVENT);</a>
<a name="ln738"> </a>
<a name="ln739">		// Alternatively, we could call HandleEvent() directly with this event,</a>
<a name="ln740">		// to avoid a trip through the event queue, like this:</a>
<a name="ln741">		//</a>
<a name="ln742">		//		this-&gt;HandleEvent(&amp;firstBufferEvent, 0, false);</a>
<a name="ln743">		//</a>
<a name="ln744">		EventQueue()-&gt;AddEvent(firstBufferEvent);</a>
<a name="ln745">	}</a>
<a name="ln746">	return B_OK;</a>
<a name="ln747">}</a>
<a name="ln748"> </a>
<a name="ln749"> </a>
<a name="ln750">status_t</a>
<a name="ln751">SoundPlayNode::HandleSeek(const media_timed_event* event, bigtime_t lateness,</a>
<a name="ln752">	bool realTimeEvent)</a>
<a name="ln753">{</a>
<a name="ln754">	CALLED();</a>
<a name="ln755">	TRACE(&quot;SoundPlayNode::HandleSeek(t=%&quot; B_PRId64 &quot;, d=%&quot; B_PRId32 &quot;, bd=%&quot;</a>
<a name="ln756">		B_PRId64 &quot;)\n&quot;, event-&gt;event_time, event-&gt;data, event-&gt;bigdata);</a>
<a name="ln757">	return B_OK;</a>
<a name="ln758">}</a>
<a name="ln759"> </a>
<a name="ln760"> </a>
<a name="ln761">status_t</a>
<a name="ln762">SoundPlayNode::HandleWarp(const media_timed_event* event, bigtime_t lateness,</a>
<a name="ln763">	bool realTimeEvent)</a>
<a name="ln764">{</a>
<a name="ln765">	CALLED();</a>
<a name="ln766">	return B_OK;</a>
<a name="ln767">}</a>
<a name="ln768"> </a>
<a name="ln769"> </a>
<a name="ln770">status_t</a>
<a name="ln771">SoundPlayNode::HandleStop(const media_timed_event* event, bigtime_t lateness,</a>
<a name="ln772">	bool realTimeEvent)</a>
<a name="ln773">{</a>
<a name="ln774">	CALLED();</a>
<a name="ln775">	// flush the queue so downstreamers don't get any more</a>
<a name="ln776">	EventQueue()-&gt;FlushEvents(0, BTimedEventQueue::B_ALWAYS, true,</a>
<a name="ln777">		SEND_NEW_BUFFER_EVENT);</a>
<a name="ln778"> </a>
<a name="ln779">	return B_OK;</a>
<a name="ln780">}</a>
<a name="ln781"> </a>
<a name="ln782"> </a>
<a name="ln783">status_t</a>
<a name="ln784">SoundPlayNode::HandleParameter(const media_timed_event* event,</a>
<a name="ln785">	bigtime_t lateness, bool realTimeEvent)</a>
<a name="ln786">{</a>
<a name="ln787">	CALLED();</a>
<a name="ln788">	return B_OK;</a>
<a name="ln789">}</a>
<a name="ln790"> </a>
<a name="ln791"> </a>
<a name="ln792">status_t</a>
<a name="ln793">SoundPlayNode::AllocateBuffers()</a>
<a name="ln794">{</a>
<a name="ln795">	CALLED();</a>
<a name="ln796"> </a>
<a name="ln797">	// allocate enough buffers to span our downstream latency, plus one</a>
<a name="ln798">	size_t size = fOutput.format.u.raw_audio.buffer_size;</a>
<a name="ln799">	int32 count = int32(fLatency / BufferDuration() + 1 + 1);</a>
<a name="ln800"> </a>
<a name="ln801">	TRACE(&quot;SoundPlayNode::AllocateBuffers: latency = %&quot; B_PRId64 &quot;, buffer &quot;</a>
<a name="ln802">		&quot;duration = %&quot; B_PRId64 &quot;, count %&quot; B_PRId32 &quot;\n&quot;, fLatency,</a>
<a name="ln803">		BufferDuration(), count);</a>
<a name="ln804"> </a>
<a name="ln805">	if (count &lt; 3)</a>
<a name="ln806">		count = 3;</a>
<a name="ln807"> </a>
<a name="ln808">	TRACE(&quot;SoundPlayNode::AllocateBuffers: creating group of %&quot; B_PRId32</a>
<a name="ln809">		&quot; buffers, size = %&quot; B_PRIuSIZE &quot;\n&quot;, count, size);</a>
<a name="ln810"> </a>
<a name="ln811">	fBufferGroup = new BBufferGroup(size, count);</a>
<a name="ln812">	if (fBufferGroup-&gt;InitCheck() != B_OK) {</a>
<a name="ln813">		ERROR(&quot;SoundPlayNode::AllocateBuffers: BufferGroup::InitCheck() &quot;</a>
<a name="ln814">			&quot;failed\n&quot;);</a>
<a name="ln815">	}</a>
<a name="ln816"> </a>
<a name="ln817">	return fBufferGroup-&gt;InitCheck();</a>
<a name="ln818">}</a>
<a name="ln819"> </a>
<a name="ln820"> </a>
<a name="ln821">BBuffer*</a>
<a name="ln822">SoundPlayNode::FillNextBuffer(bigtime_t eventTime)</a>
<a name="ln823">{</a>
<a name="ln824">	CALLED();</a>
<a name="ln825"> </a>
<a name="ln826">	// get a buffer from our buffer group</a>
<a name="ln827">	BBuffer* buffer = fBufferGroup-&gt;RequestBuffer(</a>
<a name="ln828">		fOutput.format.u.raw_audio.buffer_size, BufferDuration() / 2);</a>
<a name="ln829"> </a>
<a name="ln830">	// If we fail to get a buffer (for example, if the request times out), we</a>
<a name="ln831">	// skip this buffer and go on to the next, to avoid locking up the control</a>
<a name="ln832">	// thread</a>
<a name="ln833">	if (buffer == NULL) {</a>
<a name="ln834">		ERROR(&quot;SoundPlayNode::FillNextBuffer: RequestBuffer failed\n&quot;);</a>
<a name="ln835">		return NULL;</a>
<a name="ln836">	}</a>
<a name="ln837"> </a>
<a name="ln838">	if (fPlayer-&gt;HasData()) {</a>
<a name="ln839">		fPlayer-&gt;PlayBuffer(buffer-&gt;Data(),</a>
<a name="ln840">			fOutput.format.u.raw_audio.buffer_size, fOutput.format.u.raw_audio);</a>
<a name="ln841">	} else</a>
<a name="ln842">		memset(buffer-&gt;Data(), 0, fOutput.format.u.raw_audio.buffer_size);</a>
<a name="ln843"> </a>
<a name="ln844">	// fill in the buffer header</a>
<a name="ln845">	media_header* header = buffer-&gt;Header();</a>
<a name="ln846">	header-&gt;type = B_MEDIA_RAW_AUDIO;</a>
<a name="ln847">	header-&gt;size_used = fOutput.format.u.raw_audio.buffer_size;</a>
<a name="ln848">	header-&gt;time_source = TimeSource()-&gt;ID();</a>
<a name="ln849">	header-&gt;start_time = eventTime;</a>
<a name="ln850"> </a>
<a name="ln851">	return buffer;</a>
<a name="ln852">}</a>
<a name="ln853"> </a>
<a name="ln854"> </a>
<a name="ln855">}	// namespace BPrivate</a>

</code></pre>
<div class="balloon" rel="32"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v730/" target="_blank">V730</a> Not all members of a class are initialized inside the constructor. Consider inspecting: fLatency, fInternalLatency, fStartTime.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
