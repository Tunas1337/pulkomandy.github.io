
<html>
<head>

  <meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
  <title>iflib.c</title>

  <link rel="stylesheet" href="../style.css"/>
  <script src="../jquery-3.2.1.min.js"></script>
</head>
<body>

<pre><code class = "cpp">
<a name="ln1">/*-</a>
<a name="ln2"> * Copyright (c) 2014-2018, Matthew Macy &lt;mmacy@mattmacy.io&gt;</a>
<a name="ln3"> * All rights reserved.</a>
<a name="ln4"> *</a>
<a name="ln5"> * Redistribution and use in source and binary forms, with or without</a>
<a name="ln6"> * modification, are permitted provided that the following conditions are met:</a>
<a name="ln7"> *</a>
<a name="ln8"> *  1. Redistributions of source code must retain the above copyright notice,</a>
<a name="ln9"> *     this list of conditions and the following disclaimer.</a>
<a name="ln10"> *</a>
<a name="ln11"> *  2. Neither the name of Matthew Macy nor the names of its</a>
<a name="ln12"> *     contributors may be used to endorse or promote products derived from</a>
<a name="ln13"> *     this software without specific prior written permission.</a>
<a name="ln14"> *</a>
<a name="ln15"> * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS &quot;AS IS&quot;</a>
<a name="ln16"> * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE</a>
<a name="ln17"> * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE</a>
<a name="ln18"> * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE</a>
<a name="ln19"> * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR</a>
<a name="ln20"> * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF</a>
<a name="ln21"> * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS</a>
<a name="ln22"> * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN</a>
<a name="ln23"> * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)</a>
<a name="ln24"> * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE</a>
<a name="ln25"> * POSSIBILITY OF SUCH DAMAGE.</a>
<a name="ln26"> */</a>
<a name="ln27"> </a>
<a name="ln28">#include &lt;sys/cdefs.h&gt;</a>
<a name="ln29">#include &lt;stdlib.h&gt;</a>
<a name="ln30">__FBSDID(&quot;$FreeBSD$&quot;);</a>
<a name="ln31"> </a>
<a name="ln32">#ifndef __HAIKU__</a>
<a name="ln33">#include &quot;opt_inet.h&quot;</a>
<a name="ln34">#include &quot;opt_inet6.h&quot;</a>
<a name="ln35">#include &quot;opt_acpi.h&quot;</a>
<a name="ln36">#include &quot;opt_sched.h&quot;</a>
<a name="ln37">#endif</a>
<a name="ln38"> </a>
<a name="ln39">#include &lt;sys/param.h&gt;</a>
<a name="ln40">#include &lt;sys/types.h&gt;</a>
<a name="ln41">#include &lt;sys/bus.h&gt;</a>
<a name="ln42">#include &lt;sys/eventhandler.h&gt;</a>
<a name="ln43">#ifndef __HAIKU__</a>
<a name="ln44">#include &lt;sys/jail.h&gt;</a>
<a name="ln45">#endif</a>
<a name="ln46">#include &lt;sys/kernel.h&gt;</a>
<a name="ln47">#include &lt;sys/lock.h&gt;</a>
<a name="ln48">#include &lt;sys/md5.h&gt;</a>
<a name="ln49">#include &lt;sys/mutex.h&gt;</a>
<a name="ln50">#include &lt;sys/sx.h&gt;</a>
<a name="ln51">#include &lt;sys/module.h&gt;</a>
<a name="ln52">#include &lt;sys/kobj.h&gt;</a>
<a name="ln53">#include &lt;sys/rman.h&gt;</a>
<a name="ln54">#include &lt;sys/proc.h&gt;</a>
<a name="ln55">#include &lt;sys/sbuf.h&gt;</a>
<a name="ln56">#include &lt;sys/smp.h&gt;</a>
<a name="ln57">#include &lt;sys/socket.h&gt;</a>
<a name="ln58">#include &lt;sys/sockio.h&gt;</a>
<a name="ln59">#include &lt;sys/sysctl.h&gt;</a>
<a name="ln60">#include &lt;sys/syslog.h&gt;</a>
<a name="ln61">#include &lt;sys/taskqueue.h&gt;</a>
<a name="ln62">#include &lt;sys/limits.h&gt;</a>
<a name="ln63"> </a>
<a name="ln64">#include &lt;net/if.h&gt;</a>
<a name="ln65">#include &lt;net/if_var.h&gt;</a>
<a name="ln66">#include &lt;net/if_types.h&gt;</a>
<a name="ln67">#include &lt;net/if_media.h&gt;</a>
<a name="ln68">#include &lt;net/bpf.h&gt;</a>
<a name="ln69">#include &lt;net/ethernet.h&gt;</a>
<a name="ln70">#include &lt;net/if_vlan_var.h&gt;</a>
<a name="ln71">#include &lt;net/mp_ring.h&gt;</a>
<a name="ln72">#include &lt;net/vnet.h&gt;</a>
<a name="ln73"> </a>
<a name="ln74">#include &lt;netinet/in.h&gt;</a>
<a name="ln75">#ifndef __HAIKU__</a>
<a name="ln76">#include &lt;netinet/in_pcb.h&gt;</a>
<a name="ln77">#include &lt;netinet/tcp_lro.h&gt;</a>
<a name="ln78">#include &lt;netinet/in_systm.h&gt;</a>
<a name="ln79">#endif</a>
<a name="ln80">#include &lt;netinet/if_ether.h&gt;</a>
<a name="ln81">#include &lt;netinet/ip.h&gt;</a>
<a name="ln82">#include &lt;netinet/ip6.h&gt;</a>
<a name="ln83">#include &lt;netinet/tcp.h&gt;</a>
<a name="ln84">#include &lt;netinet/ip_var.h&gt;</a>
<a name="ln85">#include &lt;netinet/netdump/netdump.h&gt;</a>
<a name="ln86">#ifndef __HAIKU__</a>
<a name="ln87">#include &lt;netinet6/ip6_var.h&gt;</a>
<a name="ln88">#endif</a>
<a name="ln89"> </a>
<a name="ln90">#include &lt;machine/bus.h&gt;</a>
<a name="ln91">#ifndef __HAIKU__</a>
<a name="ln92">#include &lt;machine/in_cksum.h&gt;</a>
<a name="ln93">#endif</a>
<a name="ln94"> </a>
<a name="ln95">#include &lt;vm/vm.h&gt;</a>
<a name="ln96">#include &lt;vm/pmap.h&gt;</a>
<a name="ln97"> </a>
<a name="ln98">#include &lt;dev/led/led.h&gt;</a>
<a name="ln99">#include &lt;dev/pci/pcireg.h&gt;</a>
<a name="ln100">#include &lt;dev/pci/pcivar.h&gt;</a>
<a name="ln101">#ifndef __HAIKU__</a>
<a name="ln102">#include &lt;dev/pci/pci_private.h&gt;</a>
<a name="ln103">#endif</a>
<a name="ln104"> </a>
<a name="ln105">#include &lt;net/iflib.h&gt;</a>
<a name="ln106">#include &lt;net/iflib_private.h&gt;</a>
<a name="ln107"> </a>
<a name="ln108">#include &lt;ifdi_if.h&gt;</a>
<a name="ln109">#include &lt;device_if.h&gt;</a>
<a name="ln110"> </a>
<a name="ln111">#ifdef PCI_IOV</a>
<a name="ln112">#include &lt;dev/pci/pci_iov.h&gt;</a>
<a name="ln113">#endif</a>
<a name="ln114"> </a>
<a name="ln115">#include &lt;sys/bitstring.h&gt;</a>
<a name="ln116">/*</a>
<a name="ln117"> * enable accounting of every mbuf as it comes in to and goes out of</a>
<a name="ln118"> * iflib's software descriptor references</a>
<a name="ln119"> */</a>
<a name="ln120">#define MEMORY_LOGGING 0</a>
<a name="ln121">/*</a>
<a name="ln122"> * Enable mbuf vectors for compressing long mbuf chains</a>
<a name="ln123"> */</a>
<a name="ln124"> </a>
<a name="ln125">/*</a>
<a name="ln126"> * NB:</a>
<a name="ln127"> * - Prefetching in tx cleaning should perhaps be a tunable. The distance ahead</a>
<a name="ln128"> *   we prefetch needs to be determined by the time spent in m_free vis a vis</a>
<a name="ln129"> *   the cost of a prefetch. This will of course vary based on the workload:</a>
<a name="ln130"> *      - NFLX's m_free path is dominated by vm-based M_EXT manipulation which</a>
<a name="ln131"> *        is quite expensive, thus suggesting very little prefetch.</a>
<a name="ln132"> *      - small packet forwarding which is just returning a single mbuf to</a>
<a name="ln133"> *        UMA will typically be very fast vis a vis the cost of a memory</a>
<a name="ln134"> *        access.</a>
<a name="ln135"> */</a>
<a name="ln136"> </a>
<a name="ln137"> </a>
<a name="ln138">/*</a>
<a name="ln139"> * File organization:</a>
<a name="ln140"> *  - private structures</a>
<a name="ln141"> *  - iflib private utility functions</a>
<a name="ln142"> *  - ifnet functions</a>
<a name="ln143"> *  - vlan registry and other exported functions</a>
<a name="ln144"> *  - iflib public core functions</a>
<a name="ln145"> *</a>
<a name="ln146"> *</a>
<a name="ln147"> */</a>
<a name="ln148">MALLOC_DEFINE(M_IFLIB, &quot;iflib&quot;, &quot;ifnet library&quot;);</a>
<a name="ln149"> </a>
<a name="ln150">struct iflib_txq;</a>
<a name="ln151">typedef struct iflib_txq *iflib_txq_t;</a>
<a name="ln152">struct iflib_rxq;</a>
<a name="ln153">typedef struct iflib_rxq *iflib_rxq_t;</a>
<a name="ln154">struct iflib_fl;</a>
<a name="ln155">typedef struct iflib_fl *iflib_fl_t;</a>
<a name="ln156"> </a>
<a name="ln157">struct iflib_ctx;</a>
<a name="ln158"> </a>
<a name="ln159">static void iru_init(if_rxd_update_t iru, iflib_rxq_t rxq, uint8_t flid);</a>
<a name="ln160">static void iflib_timer(void *arg);</a>
<a name="ln161"> </a>
<a name="ln162">typedef struct iflib_filter_info {</a>
<a name="ln163">	driver_filter_t *ifi_filter;</a>
<a name="ln164">	void *ifi_filter_arg;</a>
<a name="ln165">	struct grouptask *ifi_task;</a>
<a name="ln166">	void *ifi_ctx;</a>
<a name="ln167">} *iflib_filter_info_t;</a>
<a name="ln168"> </a>
<a name="ln169">struct iflib_ctx {</a>
<a name="ln170">	KOBJ_FIELDS;</a>
<a name="ln171">	/*</a>
<a name="ln172">	 * Pointer to hardware driver's softc</a>
<a name="ln173">	 */</a>
<a name="ln174">	void *ifc_softc;</a>
<a name="ln175">	device_t ifc_dev;</a>
<a name="ln176">	if_t ifc_ifp;</a>
<a name="ln177"> </a>
<a name="ln178">#ifndef __HAIKU__</a>
<a name="ln179">	cpuset_t ifc_cpus;</a>
<a name="ln180">#endif</a>
<a name="ln181">	if_shared_ctx_t ifc_sctx;</a>
<a name="ln182">	struct if_softc_ctx ifc_softc_ctx;</a>
<a name="ln183"> </a>
<a name="ln184">	struct sx ifc_ctx_sx;</a>
<a name="ln185">	struct mtx ifc_state_mtx;</a>
<a name="ln186"> </a>
<a name="ln187">	iflib_txq_t ifc_txqs;</a>
<a name="ln188">	iflib_rxq_t ifc_rxqs;</a>
<a name="ln189">	uint32_t ifc_if_flags;</a>
<a name="ln190">	uint32_t ifc_flags;</a>
<a name="ln191">	uint32_t ifc_max_fl_buf_size;</a>
<a name="ln192">	uint32_t ifc_rx_mbuf_sz;</a>
<a name="ln193"> </a>
<a name="ln194">	int ifc_link_state;</a>
<a name="ln195">	int ifc_link_irq;</a>
<a name="ln196">	int ifc_watchdog_events;</a>
<a name="ln197">	struct cdev *ifc_led_dev;</a>
<a name="ln198">	struct resource *ifc_msix_mem;</a>
<a name="ln199"> </a>
<a name="ln200">	struct if_irq ifc_legacy_irq;</a>
<a name="ln201">	struct grouptask ifc_admin_task;</a>
<a name="ln202">	struct grouptask ifc_vflr_task;</a>
<a name="ln203">	struct iflib_filter_info ifc_filter_info;</a>
<a name="ln204">	struct ifmedia	ifc_media;</a>
<a name="ln205"> </a>
<a name="ln206">	struct sysctl_oid *ifc_sysctl_node;</a>
<a name="ln207">	uint16_t ifc_sysctl_ntxqs;</a>
<a name="ln208">	uint16_t ifc_sysctl_nrxqs;</a>
<a name="ln209">	uint16_t ifc_sysctl_qs_eq_override;</a>
<a name="ln210">	uint16_t ifc_sysctl_rx_budget;</a>
<a name="ln211">	uint16_t ifc_sysctl_tx_abdicate;</a>
<a name="ln212"> </a>
<a name="ln213">	qidx_t ifc_sysctl_ntxds[8];</a>
<a name="ln214">	qidx_t ifc_sysctl_nrxds[8];</a>
<a name="ln215">	struct if_txrx ifc_txrx;</a>
<a name="ln216">#define isc_txd_encap  ifc_txrx.ift_txd_encap</a>
<a name="ln217">#define isc_txd_flush  ifc_txrx.ift_txd_flush</a>
<a name="ln218">#define isc_txd_credits_update  ifc_txrx.ift_txd_credits_update</a>
<a name="ln219">#define isc_rxd_available ifc_txrx.ift_rxd_available</a>
<a name="ln220">#define isc_rxd_pkt_get ifc_txrx.ift_rxd_pkt_get</a>
<a name="ln221">#define isc_rxd_refill ifc_txrx.ift_rxd_refill</a>
<a name="ln222">#define isc_rxd_flush ifc_txrx.ift_rxd_flush</a>
<a name="ln223">#define isc_rxd_refill ifc_txrx.ift_rxd_refill</a>
<a name="ln224">#define isc_rxd_refill ifc_txrx.ift_rxd_refill</a>
<a name="ln225">#define isc_legacy_intr ifc_txrx.ift_legacy_intr</a>
<a name="ln226">	eventhandler_tag ifc_vlan_attach_event;</a>
<a name="ln227">	eventhandler_tag ifc_vlan_detach_event;</a>
<a name="ln228">	struct ether_addr ifc_mac;</a>
<a name="ln229">	char ifc_mtx_name[16];</a>
<a name="ln230">};</a>
<a name="ln231"> </a>
<a name="ln232"> </a>
<a name="ln233">void *</a>
<a name="ln234">iflib_get_softc(if_ctx_t ctx)</a>
<a name="ln235">{</a>
<a name="ln236"> </a>
<a name="ln237">	return (ctx-&gt;ifc_softc);</a>
<a name="ln238">}</a>
<a name="ln239"> </a>
<a name="ln240">device_t</a>
<a name="ln241">iflib_get_dev(if_ctx_t ctx)</a>
<a name="ln242">{</a>
<a name="ln243"> </a>
<a name="ln244">	return (ctx-&gt;ifc_dev);</a>
<a name="ln245">}</a>
<a name="ln246"> </a>
<a name="ln247">if_t</a>
<a name="ln248">iflib_get_ifp(if_ctx_t ctx)</a>
<a name="ln249">{</a>
<a name="ln250"> </a>
<a name="ln251">	return (ctx-&gt;ifc_ifp);</a>
<a name="ln252">}</a>
<a name="ln253"> </a>
<a name="ln254">struct ifmedia *</a>
<a name="ln255">iflib_get_media(if_ctx_t ctx)</a>
<a name="ln256">{</a>
<a name="ln257"> </a>
<a name="ln258">	return (&amp;ctx-&gt;ifc_media);</a>
<a name="ln259">}</a>
<a name="ln260"> </a>
<a name="ln261">uint32_t</a>
<a name="ln262">iflib_get_flags(if_ctx_t ctx)</a>
<a name="ln263">{</a>
<a name="ln264">	return (ctx-&gt;ifc_flags);</a>
<a name="ln265">}</a>
<a name="ln266"> </a>
<a name="ln267">void</a>
<a name="ln268">iflib_set_mac(if_ctx_t ctx, uint8_t mac[ETHER_ADDR_LEN])</a>
<a name="ln269">{</a>
<a name="ln270"> </a>
<a name="ln271">	bcopy(mac, ctx-&gt;ifc_mac.octet, ETHER_ADDR_LEN);</a>
<a name="ln272">}</a>
<a name="ln273"> </a>
<a name="ln274">if_softc_ctx_t</a>
<a name="ln275">iflib_get_softc_ctx(if_ctx_t ctx)</a>
<a name="ln276">{</a>
<a name="ln277"> </a>
<a name="ln278">	return (&amp;ctx-&gt;ifc_softc_ctx);</a>
<a name="ln279">}</a>
<a name="ln280"> </a>
<a name="ln281">if_shared_ctx_t</a>
<a name="ln282">iflib_get_sctx(if_ctx_t ctx)</a>
<a name="ln283">{</a>
<a name="ln284"> </a>
<a name="ln285">	return (ctx-&gt;ifc_sctx);</a>
<a name="ln286">}</a>
<a name="ln287"> </a>
<a name="ln288">#define IP_ALIGNED(m) ((((uintptr_t)(m)-&gt;m_data) &amp; 0x3) == 0x2)</a>
<a name="ln289">#define CACHE_PTR_INCREMENT (CACHE_LINE_SIZE/sizeof(void*))</a>
<a name="ln290">#define CACHE_PTR_NEXT(ptr) ((void *)(((uintptr_t)(ptr)+CACHE_LINE_SIZE-1) &amp; (CACHE_LINE_SIZE-1)))</a>
<a name="ln291"> </a>
<a name="ln292">#define LINK_ACTIVE(ctx) ((ctx)-&gt;ifc_link_state == LINK_STATE_UP)</a>
<a name="ln293">#define CTX_IS_VF(ctx) ((ctx)-&gt;ifc_sctx-&gt;isc_flags &amp; IFLIB_IS_VF)</a>
<a name="ln294"> </a>
<a name="ln295">typedef struct iflib_sw_rx_desc_array {</a>
<a name="ln296">	bus_dmamap_t	*ifsd_map;         /* bus_dma maps for packet */</a>
<a name="ln297">	struct mbuf	**ifsd_m;           /* pkthdr mbufs */</a>
<a name="ln298">	caddr_t		*ifsd_cl;          /* direct cluster pointer for rx */</a>
<a name="ln299">	bus_addr_t	*ifsd_ba;          /* bus addr of cluster for rx */</a>
<a name="ln300">} iflib_rxsd_array_t;</a>
<a name="ln301"> </a>
<a name="ln302">typedef struct iflib_sw_tx_desc_array {</a>
<a name="ln303">	bus_dmamap_t    *ifsd_map;         /* bus_dma maps for packet */</a>
<a name="ln304">	bus_dmamap_t	*ifsd_tso_map;     /* bus_dma maps for TSO packet */</a>
<a name="ln305">	struct mbuf    **ifsd_m;           /* pkthdr mbufs */</a>
<a name="ln306">} if_txsd_vec_t;</a>
<a name="ln307"> </a>
<a name="ln308"> </a>
<a name="ln309">/* magic number that should be high enough for any hardware */</a>
<a name="ln310">#define IFLIB_MAX_TX_SEGS		128</a>
<a name="ln311">#define IFLIB_RX_COPY_THRESH		128</a>
<a name="ln312">#define IFLIB_MAX_RX_REFRESH		32</a>
<a name="ln313">/* The minimum descriptors per second before we start coalescing */</a>
<a name="ln314">#define IFLIB_MIN_DESC_SEC		16384</a>
<a name="ln315">#define IFLIB_DEFAULT_TX_UPDATE_FREQ	16</a>
<a name="ln316">#define IFLIB_QUEUE_IDLE		0</a>
<a name="ln317">#define IFLIB_QUEUE_HUNG		1</a>
<a name="ln318">#define IFLIB_QUEUE_WORKING		2</a>
<a name="ln319">/* maximum number of txqs that can share an rx interrupt */</a>
<a name="ln320">#define IFLIB_MAX_TX_SHARED_INTR	4</a>
<a name="ln321"> </a>
<a name="ln322">/* this should really scale with ring size - this is a fairly arbitrary value */</a>
<a name="ln323">#define TX_BATCH_SIZE			32</a>
<a name="ln324"> </a>
<a name="ln325">#define IFLIB_RESTART_BUDGET		8</a>
<a name="ln326"> </a>
<a name="ln327"> </a>
<a name="ln328">#define CSUM_OFFLOAD		(CSUM_IP_TSO|CSUM_IP6_TSO|CSUM_IP| \</a>
<a name="ln329">				 CSUM_IP_UDP|CSUM_IP_TCP|CSUM_IP_SCTP| \</a>
<a name="ln330">				 CSUM_IP6_UDP|CSUM_IP6_TCP|CSUM_IP6_SCTP)</a>
<a name="ln331">struct iflib_txq {</a>
<a name="ln332">	qidx_t		ift_in_use;</a>
<a name="ln333">	qidx_t		ift_cidx;</a>
<a name="ln334">	qidx_t		ift_cidx_processed;</a>
<a name="ln335">	qidx_t		ift_pidx;</a>
<a name="ln336">	uint8_t		ift_gen;</a>
<a name="ln337">	uint8_t		ift_br_offset;</a>
<a name="ln338">	uint16_t	ift_npending;</a>
<a name="ln339">	uint16_t	ift_db_pending;</a>
<a name="ln340">	uint16_t	ift_rs_pending;</a>
<a name="ln341">	/* implicit pad */</a>
<a name="ln342">	uint8_t		ift_txd_size[8];</a>
<a name="ln343">	uint64_t	ift_processed;</a>
<a name="ln344">	uint64_t	ift_cleaned;</a>
<a name="ln345">	uint64_t	ift_cleaned_prev;</a>
<a name="ln346">#if MEMORY_LOGGING</a>
<a name="ln347">	uint64_t	ift_enqueued;</a>
<a name="ln348">	uint64_t	ift_dequeued;</a>
<a name="ln349">#endif</a>
<a name="ln350">	uint64_t	ift_no_tx_dma_setup;</a>
<a name="ln351">	uint64_t	ift_no_desc_avail;</a>
<a name="ln352">	uint64_t	ift_mbuf_defrag_failed;</a>
<a name="ln353">	uint64_t	ift_mbuf_defrag;</a>
<a name="ln354">	uint64_t	ift_map_failed;</a>
<a name="ln355">	uint64_t	ift_txd_encap_efbig;</a>
<a name="ln356">	uint64_t	ift_pullups;</a>
<a name="ln357">	uint64_t	ift_last_timer_tick;</a>
<a name="ln358"> </a>
<a name="ln359">	struct mtx	ift_mtx;</a>
<a name="ln360">	struct mtx	ift_db_mtx;</a>
<a name="ln361"> </a>
<a name="ln362">	/* constant values */</a>
<a name="ln363">	if_ctx_t	ift_ctx;</a>
<a name="ln364">	struct ifmp_ring        *ift_br;</a>
<a name="ln365">	struct grouptask	ift_task;</a>
<a name="ln366">	qidx_t		ift_size;</a>
<a name="ln367">	uint16_t	ift_id;</a>
<a name="ln368">	struct callout	ift_timer;</a>
<a name="ln369"> </a>
<a name="ln370">	if_txsd_vec_t	ift_sds;</a>
<a name="ln371">	uint8_t		ift_qstatus;</a>
<a name="ln372">	uint8_t		ift_closed;</a>
<a name="ln373">	uint8_t		ift_update_freq;</a>
<a name="ln374">	struct iflib_filter_info ift_filter_info;</a>
<a name="ln375">	bus_dma_tag_t	ift_buf_tag;</a>
<a name="ln376">	bus_dma_tag_t	ift_tso_buf_tag;</a>
<a name="ln377">	iflib_dma_info_t	ift_ifdi;</a>
<a name="ln378">#define MTX_NAME_LEN 16</a>
<a name="ln379">	char                    ift_mtx_name[MTX_NAME_LEN];</a>
<a name="ln380">	char                    ift_db_mtx_name[MTX_NAME_LEN];</a>
<a name="ln381">	bus_dma_segment_t	ift_segs[IFLIB_MAX_TX_SEGS]  __aligned(CACHE_LINE_SIZE);</a>
<a name="ln382">#ifdef IFLIB_DIAGNOSTICS</a>
<a name="ln383">	uint64_t ift_cpu_exec_count[256];</a>
<a name="ln384">#endif</a>
<a name="ln385">} __aligned(CACHE_LINE_SIZE);</a>
<a name="ln386"> </a>
<a name="ln387">struct iflib_fl {</a>
<a name="ln388">	qidx_t		ifl_cidx;</a>
<a name="ln389">	qidx_t		ifl_pidx;</a>
<a name="ln390">	qidx_t		ifl_credits;</a>
<a name="ln391">	uint8_t		ifl_gen;</a>
<a name="ln392">	uint8_t		ifl_rxd_size;</a>
<a name="ln393">#if MEMORY_LOGGING</a>
<a name="ln394">	uint64_t	ifl_m_enqueued;</a>
<a name="ln395">	uint64_t	ifl_m_dequeued;</a>
<a name="ln396">	uint64_t	ifl_cl_enqueued;</a>
<a name="ln397">	uint64_t	ifl_cl_dequeued;</a>
<a name="ln398">#endif</a>
<a name="ln399">	/* implicit pad */</a>
<a name="ln400"> </a>
<a name="ln401">	bitstr_t 	*ifl_rx_bitmap;</a>
<a name="ln402">	qidx_t		ifl_fragidx;</a>
<a name="ln403">	/* constant */</a>
<a name="ln404">	qidx_t		ifl_size;</a>
<a name="ln405">	uint16_t	ifl_buf_size;</a>
<a name="ln406">	uint16_t	ifl_cltype;</a>
<a name="ln407">#ifndef __HAIKU__</a>
<a name="ln408">	uma_zone_t	ifl_zone;</a>
<a name="ln409">#endif</a>
<a name="ln410">	iflib_rxsd_array_t	ifl_sds;</a>
<a name="ln411">	iflib_rxq_t	ifl_rxq;</a>
<a name="ln412">	uint8_t		ifl_id;</a>
<a name="ln413">	bus_dma_tag_t	ifl_buf_tag;</a>
<a name="ln414">	iflib_dma_info_t	ifl_ifdi;</a>
<a name="ln415">	uint64_t	ifl_bus_addrs[IFLIB_MAX_RX_REFRESH] __aligned(CACHE_LINE_SIZE);</a>
<a name="ln416">	caddr_t		ifl_vm_addrs[IFLIB_MAX_RX_REFRESH];</a>
<a name="ln417">	qidx_t	ifl_rxd_idxs[IFLIB_MAX_RX_REFRESH];</a>
<a name="ln418">}  __aligned(CACHE_LINE_SIZE);</a>
<a name="ln419"> </a>
<a name="ln420">static inline qidx_t</a>
<a name="ln421">get_inuse(int size, qidx_t cidx, qidx_t pidx, uint8_t gen)</a>
<a name="ln422">{</a>
<a name="ln423">	qidx_t used;</a>
<a name="ln424"> </a>
<a name="ln425">	if (pidx &gt; cidx)</a>
<a name="ln426">		used = pidx - cidx;</a>
<a name="ln427">	else if (pidx &lt; cidx)</a>
<a name="ln428">		used = size - cidx + pidx;</a>
<a name="ln429">	else if (gen == 0 &amp;&amp; pidx == cidx)</a>
<a name="ln430">		used = 0;</a>
<a name="ln431">	else if (gen == 1 &amp;&amp; pidx == cidx)</a>
<a name="ln432">		used = size;</a>
<a name="ln433">	else</a>
<a name="ln434">		panic(&quot;bad state&quot;);</a>
<a name="ln435"> </a>
<a name="ln436">	return (used);</a>
<a name="ln437">}</a>
<a name="ln438"> </a>
<a name="ln439">#define TXQ_AVAIL(txq) (txq-&gt;ift_size - get_inuse(txq-&gt;ift_size, txq-&gt;ift_cidx, txq-&gt;ift_pidx, txq-&gt;ift_gen))</a>
<a name="ln440"> </a>
<a name="ln441">#define IDXDIFF(head, tail, wrap) \</a>
<a name="ln442">	((head) &gt;= (tail) ? (head) - (tail) : (wrap) - (tail) + (head))</a>
<a name="ln443"> </a>
<a name="ln444">struct iflib_rxq {</a>
<a name="ln445">	/* If there is a separate completion queue -</a>
<a name="ln446">	 * these are the cq cidx and pidx. Otherwise</a>
<a name="ln447">	 * these are unused.</a>
<a name="ln448">	 */</a>
<a name="ln449">	qidx_t		ifr_size;</a>
<a name="ln450">	qidx_t		ifr_cq_cidx;</a>
<a name="ln451">	qidx_t		ifr_cq_pidx;</a>
<a name="ln452">	uint8_t		ifr_cq_gen;</a>
<a name="ln453">	uint8_t		ifr_fl_offset;</a>
<a name="ln454"> </a>
<a name="ln455">	if_ctx_t	ifr_ctx;</a>
<a name="ln456">	iflib_fl_t	ifr_fl;</a>
<a name="ln457">	uint64_t	ifr_rx_irq;</a>
<a name="ln458">	uint16_t	ifr_id;</a>
<a name="ln459">	uint8_t		ifr_lro_enabled;</a>
<a name="ln460">	uint8_t		ifr_nfl;</a>
<a name="ln461">	uint8_t		ifr_ntxqirq;</a>
<a name="ln462">	uint8_t		ifr_txqid[IFLIB_MAX_TX_SHARED_INTR];</a>
<a name="ln463">#ifndef __HAIKU__</a>
<a name="ln464">	struct lro_ctrl			ifr_lc;</a>
<a name="ln465">#endif</a>
<a name="ln466">	struct grouptask        ifr_task;</a>
<a name="ln467">	struct iflib_filter_info ifr_filter_info;</a>
<a name="ln468">	iflib_dma_info_t		ifr_ifdi;</a>
<a name="ln469"> </a>
<a name="ln470">	/* dynamically allocate if any drivers need a value substantially larger than this */</a>
<a name="ln471">	struct if_rxd_frag	ifr_frags[IFLIB_MAX_RX_SEGS] __aligned(CACHE_LINE_SIZE);</a>
<a name="ln472">#ifdef IFLIB_DIAGNOSTICS</a>
<a name="ln473">	uint64_t ifr_cpu_exec_count[256];</a>
<a name="ln474">#endif</a>
<a name="ln475">}  __aligned(CACHE_LINE_SIZE);</a>
<a name="ln476"> </a>
<a name="ln477">typedef struct if_rxsd {</a>
<a name="ln478">	caddr_t *ifsd_cl;</a>
<a name="ln479">	struct mbuf **ifsd_m;</a>
<a name="ln480">	iflib_fl_t ifsd_fl;</a>
<a name="ln481">	qidx_t ifsd_cidx;</a>
<a name="ln482">} *if_rxsd_t;</a>
<a name="ln483"> </a>
<a name="ln484">/* multiple of word size */</a>
<a name="ln485">#ifdef __LP64__</a>
<a name="ln486">#define PKT_INFO_SIZE	6</a>
<a name="ln487">#define RXD_INFO_SIZE	5</a>
<a name="ln488">#define PKT_TYPE uint64_t</a>
<a name="ln489">#else</a>
<a name="ln490">#define PKT_INFO_SIZE	11</a>
<a name="ln491">#define RXD_INFO_SIZE	8</a>
<a name="ln492">#define PKT_TYPE uint32_t</a>
<a name="ln493">#endif</a>
<a name="ln494">#define PKT_LOOP_BOUND  ((PKT_INFO_SIZE/3)*3)</a>
<a name="ln495">#define RXD_LOOP_BOUND  ((RXD_INFO_SIZE/4)*4)</a>
<a name="ln496"> </a>
<a name="ln497">typedef struct if_pkt_info_pad {</a>
<a name="ln498">	PKT_TYPE pkt_val[PKT_INFO_SIZE];</a>
<a name="ln499">} *if_pkt_info_pad_t;</a>
<a name="ln500">typedef struct if_rxd_info_pad {</a>
<a name="ln501">	PKT_TYPE rxd_val[RXD_INFO_SIZE];</a>
<a name="ln502">} *if_rxd_info_pad_t;</a>
<a name="ln503"> </a>
<a name="ln504">CTASSERT(sizeof(struct if_pkt_info_pad) == sizeof(struct if_pkt_info));</a>
<a name="ln505">CTASSERT(sizeof(struct if_rxd_info_pad) == sizeof(struct if_rxd_info));</a>
<a name="ln506"> </a>
<a name="ln507"> </a>
<a name="ln508">static inline void</a>
<a name="ln509">pkt_info_zero(if_pkt_info_t pi)</a>
<a name="ln510">{</a>
<a name="ln511">	if_pkt_info_pad_t pi_pad;</a>
<a name="ln512"> </a>
<a name="ln513">	pi_pad = (if_pkt_info_pad_t)pi;</a>
<a name="ln514">	pi_pad-&gt;pkt_val[0] = 0; pi_pad-&gt;pkt_val[1] = 0; pi_pad-&gt;pkt_val[2] = 0;</a>
<a name="ln515">	pi_pad-&gt;pkt_val[3] = 0; pi_pad-&gt;pkt_val[4] = 0; pi_pad-&gt;pkt_val[5] = 0;</a>
<a name="ln516">#ifndef __LP64__</a>
<a name="ln517">	pi_pad-&gt;pkt_val[6] = 0; pi_pad-&gt;pkt_val[7] = 0; pi_pad-&gt;pkt_val[8] = 0;</a>
<a name="ln518">	pi_pad-&gt;pkt_val[9] = 0; pi_pad-&gt;pkt_val[10] = 0;</a>
<a name="ln519">#endif	</a>
<a name="ln520">}</a>
<a name="ln521"> </a>
<a name="ln522">#ifndef __HAIKU__</a>
<a name="ln523">static device_method_t iflib_pseudo_methods[] = {</a>
<a name="ln524">	DEVMETHOD(device_attach, noop_attach),</a>
<a name="ln525">	DEVMETHOD(device_detach, iflib_pseudo_detach),</a>
<a name="ln526">	DEVMETHOD_END</a>
<a name="ln527">};</a>
<a name="ln528"> </a>
<a name="ln529">driver_t iflib_pseudodriver = {</a>
<a name="ln530">	&quot;iflib_pseudo&quot;, iflib_pseudo_methods, sizeof(struct iflib_ctx),</a>
<a name="ln531">};</a>
<a name="ln532">#endif</a>
<a name="ln533"> </a>
<a name="ln534">static inline void</a>
<a name="ln535">rxd_info_zero(if_rxd_info_t ri)</a>
<a name="ln536">{</a>
<a name="ln537">	if_rxd_info_pad_t ri_pad;</a>
<a name="ln538">	int i;</a>
<a name="ln539"> </a>
<a name="ln540">	ri_pad = (if_rxd_info_pad_t)ri;</a>
<a name="ln541">	for (i = 0; i &lt; RXD_LOOP_BOUND; i += 4) {</a>
<a name="ln542">		ri_pad-&gt;rxd_val[i] = 0;</a>
<a name="ln543">		ri_pad-&gt;rxd_val[i+1] = 0;</a>
<a name="ln544">		ri_pad-&gt;rxd_val[i+2] = 0;</a>
<a name="ln545">		ri_pad-&gt;rxd_val[i+3] = 0;</a>
<a name="ln546">	}</a>
<a name="ln547">#ifdef __LP64__</a>
<a name="ln548">	ri_pad-&gt;rxd_val[RXD_INFO_SIZE-1] = 0;</a>
<a name="ln549">#endif</a>
<a name="ln550">}</a>
<a name="ln551"> </a>
<a name="ln552">/*</a>
<a name="ln553"> * Only allow a single packet to take up most 1/nth of the tx ring</a>
<a name="ln554"> */</a>
<a name="ln555">#define MAX_SINGLE_PACKET_FRACTION 12</a>
<a name="ln556">#define IF_BAD_DMA (bus_addr_t)-1</a>
<a name="ln557"> </a>
<a name="ln558">#define CTX_ACTIVE(ctx) ((if_getdrvflags((ctx)-&gt;ifc_ifp) &amp; IFF_DRV_RUNNING))</a>
<a name="ln559"> </a>
<a name="ln560">#define CTX_LOCK_INIT(_sc)  sx_init(&amp;(_sc)-&gt;ifc_ctx_sx, &quot;iflib ctx lock&quot;)</a>
<a name="ln561">#define CTX_LOCK(ctx) sx_xlock(&amp;(ctx)-&gt;ifc_ctx_sx)</a>
<a name="ln562">#define CTX_UNLOCK(ctx) sx_xunlock(&amp;(ctx)-&gt;ifc_ctx_sx)</a>
<a name="ln563">#define CTX_LOCK_DESTROY(ctx) sx_destroy(&amp;(ctx)-&gt;ifc_ctx_sx)</a>
<a name="ln564"> </a>
<a name="ln565"> </a>
<a name="ln566">#define STATE_LOCK_INIT(_sc, _name)  mtx_init(&amp;(_sc)-&gt;ifc_state_mtx, _name, &quot;iflib state lock&quot;, MTX_DEF)</a>
<a name="ln567">#define STATE_LOCK(ctx) mtx_lock(&amp;(ctx)-&gt;ifc_state_mtx)</a>
<a name="ln568">#define STATE_UNLOCK(ctx) mtx_unlock(&amp;(ctx)-&gt;ifc_state_mtx)</a>
<a name="ln569">#define STATE_LOCK_DESTROY(ctx) mtx_destroy(&amp;(ctx)-&gt;ifc_state_mtx)</a>
<a name="ln570"> </a>
<a name="ln571"> </a>
<a name="ln572"> </a>
<a name="ln573">#define CALLOUT_LOCK(txq)	mtx_lock(&amp;txq-&gt;ift_mtx)</a>
<a name="ln574">#define CALLOUT_UNLOCK(txq) 	mtx_unlock(&amp;txq-&gt;ift_mtx)</a>
<a name="ln575"> </a>
<a name="ln576">void</a>
<a name="ln577">iflib_set_detach(if_ctx_t ctx)</a>
<a name="ln578">{</a>
<a name="ln579">	STATE_LOCK(ctx);</a>
<a name="ln580">	ctx-&gt;ifc_flags |= IFC_IN_DETACH;</a>
<a name="ln581">	STATE_UNLOCK(ctx);</a>
<a name="ln582">}</a>
<a name="ln583"> </a>
<a name="ln584">/* Our boot-time initialization hook */</a>
<a name="ln585">static int	iflib_module_event_handler(module_t, int, void *);</a>
<a name="ln586"> </a>
<a name="ln587">#ifndef __HAIKU__</a>
<a name="ln588">static moduledata_t iflib_moduledata = {</a>
<a name="ln589">	&quot;iflib&quot;,</a>
<a name="ln590">	iflib_module_event_handler,</a>
<a name="ln591">	NULL</a>
<a name="ln592">};</a>
<a name="ln593">#endif</a>
<a name="ln594"> </a>
<a name="ln595">DECLARE_MODULE(iflib, iflib_moduledata, SI_SUB_INIT_IF, SI_ORDER_ANY);</a>
<a name="ln596">MODULE_VERSION(iflib, 1);</a>
<a name="ln597"> </a>
<a name="ln598">MODULE_DEPEND(iflib, pci, 1, 1, 1);</a>
<a name="ln599">MODULE_DEPEND(iflib, ether, 1, 1, 1);</a>
<a name="ln600"> </a>
<a name="ln601">TASKQGROUP_DEFINE(if_io_tqg, mp_ncpus, 1);</a>
<a name="ln602">TASKQGROUP_DEFINE(if_config_tqg, 1, 1);</a>
<a name="ln603"> </a>
<a name="ln604">#ifndef IFLIB_DEBUG_COUNTERS</a>
<a name="ln605">#ifdef INVARIANTS</a>
<a name="ln606">#define IFLIB_DEBUG_COUNTERS 1</a>
<a name="ln607">#else</a>
<a name="ln608">#define IFLIB_DEBUG_COUNTERS 0</a>
<a name="ln609">#endif /* !INVARIANTS */</a>
<a name="ln610">#endif</a>
<a name="ln611"> </a>
<a name="ln612">static SYSCTL_NODE(_net, OID_AUTO, iflib, CTLFLAG_RD, 0,</a>
<a name="ln613">                   &quot;iflib driver parameters&quot;);</a>
<a name="ln614"> </a>
<a name="ln615">/*</a>
<a name="ln616"> * XXX need to ensure that this can't accidentally cause the head to be moved backwards </a>
<a name="ln617"> */</a>
<a name="ln618">static int iflib_min_tx_latency = 0;</a>
<a name="ln619">SYSCTL_INT(_net_iflib, OID_AUTO, min_tx_latency, CTLFLAG_RW,</a>
<a name="ln620">		   &amp;iflib_min_tx_latency, 0, &quot;minimize transmit latency at the possible expense of throughput&quot;);</a>
<a name="ln621">static int iflib_no_tx_batch = 0;</a>
<a name="ln622">SYSCTL_INT(_net_iflib, OID_AUTO, no_tx_batch, CTLFLAG_RW,</a>
<a name="ln623">		   &amp;iflib_no_tx_batch, 0, &quot;minimize transmit latency at the possible expense of throughput&quot;);</a>
<a name="ln624"> </a>
<a name="ln625"> </a>
<a name="ln626">#if IFLIB_DEBUG_COUNTERS</a>
<a name="ln627"> </a>
<a name="ln628">static int iflib_tx_seen;</a>
<a name="ln629">static int iflib_tx_sent;</a>
<a name="ln630">static int iflib_tx_encap;</a>
<a name="ln631">static int iflib_rx_allocs;</a>
<a name="ln632">static int iflib_fl_refills;</a>
<a name="ln633">static int iflib_fl_refills_large;</a>
<a name="ln634">static int iflib_tx_frees;</a>
<a name="ln635"> </a>
<a name="ln636">SYSCTL_INT(_net_iflib, OID_AUTO, tx_seen, CTLFLAG_RD,</a>
<a name="ln637">		   &amp;iflib_tx_seen, 0, &quot;# tx mbufs seen&quot;);</a>
<a name="ln638">SYSCTL_INT(_net_iflib, OID_AUTO, tx_sent, CTLFLAG_RD,</a>
<a name="ln639">		   &amp;iflib_tx_sent, 0, &quot;# tx mbufs sent&quot;);</a>
<a name="ln640">SYSCTL_INT(_net_iflib, OID_AUTO, tx_encap, CTLFLAG_RD,</a>
<a name="ln641">		   &amp;iflib_tx_encap, 0, &quot;# tx mbufs encapped&quot;);</a>
<a name="ln642">SYSCTL_INT(_net_iflib, OID_AUTO, tx_frees, CTLFLAG_RD,</a>
<a name="ln643">		   &amp;iflib_tx_frees, 0, &quot;# tx frees&quot;);</a>
<a name="ln644">SYSCTL_INT(_net_iflib, OID_AUTO, rx_allocs, CTLFLAG_RD,</a>
<a name="ln645">		   &amp;iflib_rx_allocs, 0, &quot;# rx allocations&quot;);</a>
<a name="ln646">SYSCTL_INT(_net_iflib, OID_AUTO, fl_refills, CTLFLAG_RD,</a>
<a name="ln647">		   &amp;iflib_fl_refills, 0, &quot;# refills&quot;);</a>
<a name="ln648">SYSCTL_INT(_net_iflib, OID_AUTO, fl_refills_large, CTLFLAG_RD,</a>
<a name="ln649">		   &amp;iflib_fl_refills_large, 0, &quot;# large refills&quot;);</a>
<a name="ln650"> </a>
<a name="ln651"> </a>
<a name="ln652">static int iflib_txq_drain_flushing;</a>
<a name="ln653">static int iflib_txq_drain_oactive;</a>
<a name="ln654">static int iflib_txq_drain_notready;</a>
<a name="ln655"> </a>
<a name="ln656">SYSCTL_INT(_net_iflib, OID_AUTO, txq_drain_flushing, CTLFLAG_RD,</a>
<a name="ln657">		   &amp;iflib_txq_drain_flushing, 0, &quot;# drain flushes&quot;);</a>
<a name="ln658">SYSCTL_INT(_net_iflib, OID_AUTO, txq_drain_oactive, CTLFLAG_RD,</a>
<a name="ln659">		   &amp;iflib_txq_drain_oactive, 0, &quot;# drain oactives&quot;);</a>
<a name="ln660">SYSCTL_INT(_net_iflib, OID_AUTO, txq_drain_notready, CTLFLAG_RD,</a>
<a name="ln661">		   &amp;iflib_txq_drain_notready, 0, &quot;# drain notready&quot;);</a>
<a name="ln662"> </a>
<a name="ln663"> </a>
<a name="ln664">static int iflib_encap_load_mbuf_fail;</a>
<a name="ln665">static int iflib_encap_pad_mbuf_fail;</a>
<a name="ln666">static int iflib_encap_txq_avail_fail;</a>
<a name="ln667">static int iflib_encap_txd_encap_fail;</a>
<a name="ln668"> </a>
<a name="ln669">SYSCTL_INT(_net_iflib, OID_AUTO, encap_load_mbuf_fail, CTLFLAG_RD,</a>
<a name="ln670">		   &amp;iflib_encap_load_mbuf_fail, 0, &quot;# busdma load failures&quot;);</a>
<a name="ln671">SYSCTL_INT(_net_iflib, OID_AUTO, encap_pad_mbuf_fail, CTLFLAG_RD,</a>
<a name="ln672">		   &amp;iflib_encap_pad_mbuf_fail, 0, &quot;# runt frame pad failures&quot;);</a>
<a name="ln673">SYSCTL_INT(_net_iflib, OID_AUTO, encap_txq_avail_fail, CTLFLAG_RD,</a>
<a name="ln674">		   &amp;iflib_encap_txq_avail_fail, 0, &quot;# txq avail failures&quot;);</a>
<a name="ln675">SYSCTL_INT(_net_iflib, OID_AUTO, encap_txd_encap_fail, CTLFLAG_RD,</a>
<a name="ln676">		   &amp;iflib_encap_txd_encap_fail, 0, &quot;# driver encap failures&quot;);</a>
<a name="ln677"> </a>
<a name="ln678">static int iflib_task_fn_rxs;</a>
<a name="ln679">static int iflib_rx_intr_enables;</a>
<a name="ln680">static int iflib_fast_intrs;</a>
<a name="ln681">static int iflib_rx_unavail;</a>
<a name="ln682">static int iflib_rx_ctx_inactive;</a>
<a name="ln683">static int iflib_rx_if_input;</a>
<a name="ln684">static int iflib_rx_mbuf_null;</a>
<a name="ln685">static int iflib_rxd_flush;</a>
<a name="ln686"> </a>
<a name="ln687">static int iflib_verbose_debug;</a>
<a name="ln688"> </a>
<a name="ln689">SYSCTL_INT(_net_iflib, OID_AUTO, task_fn_rx, CTLFLAG_RD,</a>
<a name="ln690">		   &amp;iflib_task_fn_rxs, 0, &quot;# task_fn_rx calls&quot;);</a>
<a name="ln691">SYSCTL_INT(_net_iflib, OID_AUTO, rx_intr_enables, CTLFLAG_RD,</a>
<a name="ln692">		   &amp;iflib_rx_intr_enables, 0, &quot;# rx intr enables&quot;);</a>
<a name="ln693">SYSCTL_INT(_net_iflib, OID_AUTO, fast_intrs, CTLFLAG_RD,</a>
<a name="ln694">		   &amp;iflib_fast_intrs, 0, &quot;# fast_intr calls&quot;);</a>
<a name="ln695">SYSCTL_INT(_net_iflib, OID_AUTO, rx_unavail, CTLFLAG_RD,</a>
<a name="ln696">		   &amp;iflib_rx_unavail, 0, &quot;# times rxeof called with no available data&quot;);</a>
<a name="ln697">SYSCTL_INT(_net_iflib, OID_AUTO, rx_ctx_inactive, CTLFLAG_RD,</a>
<a name="ln698">		   &amp;iflib_rx_ctx_inactive, 0, &quot;# times rxeof called with inactive context&quot;);</a>
<a name="ln699">SYSCTL_INT(_net_iflib, OID_AUTO, rx_if_input, CTLFLAG_RD,</a>
<a name="ln700">		   &amp;iflib_rx_if_input, 0, &quot;# times rxeof called if_input&quot;);</a>
<a name="ln701">SYSCTL_INT(_net_iflib, OID_AUTO, rx_mbuf_null, CTLFLAG_RD,</a>
<a name="ln702">		   &amp;iflib_rx_mbuf_null, 0, &quot;# times rxeof got null mbuf&quot;);</a>
<a name="ln703">SYSCTL_INT(_net_iflib, OID_AUTO, rxd_flush, CTLFLAG_RD,</a>
<a name="ln704">	         &amp;iflib_rxd_flush, 0, &quot;# times rxd_flush called&quot;);</a>
<a name="ln705">SYSCTL_INT(_net_iflib, OID_AUTO, verbose_debug, CTLFLAG_RW,</a>
<a name="ln706">		   &amp;iflib_verbose_debug, 0, &quot;enable verbose debugging&quot;);</a>
<a name="ln707"> </a>
<a name="ln708">#define DBG_COUNTER_INC(name) atomic_add_int(&amp;(iflib_ ## name), 1)</a>
<a name="ln709">static void</a>
<a name="ln710">iflib_debug_reset(void)</a>
<a name="ln711">{</a>
<a name="ln712">	iflib_tx_seen = iflib_tx_sent = iflib_tx_encap = iflib_rx_allocs =</a>
<a name="ln713">		iflib_fl_refills = iflib_fl_refills_large = iflib_tx_frees =</a>
<a name="ln714">		iflib_txq_drain_flushing = iflib_txq_drain_oactive =</a>
<a name="ln715">		iflib_txq_drain_notready =</a>
<a name="ln716">		iflib_encap_load_mbuf_fail = iflib_encap_pad_mbuf_fail =</a>
<a name="ln717">		iflib_encap_txq_avail_fail = iflib_encap_txd_encap_fail =</a>
<a name="ln718">		iflib_task_fn_rxs = iflib_rx_intr_enables = iflib_fast_intrs =</a>
<a name="ln719">		iflib_rx_unavail =</a>
<a name="ln720">		iflib_rx_ctx_inactive = iflib_rx_if_input =</a>
<a name="ln721">		iflib_rx_mbuf_null = iflib_rxd_flush = 0;</a>
<a name="ln722">}</a>
<a name="ln723"> </a>
<a name="ln724">#else</a>
<a name="ln725">#define DBG_COUNTER_INC(name)</a>
<a name="ln726">static void iflib_debug_reset(void) {}</a>
<a name="ln727">#endif</a>
<a name="ln728"> </a>
<a name="ln729">#define IFLIB_DEBUG 0</a>
<a name="ln730"> </a>
<a name="ln731">static void iflib_tx_structures_free(if_ctx_t ctx);</a>
<a name="ln732">static void iflib_rx_structures_free(if_ctx_t ctx);</a>
<a name="ln733">static int iflib_queues_alloc(if_ctx_t ctx);</a>
<a name="ln734">static int iflib_tx_credits_update(if_ctx_t ctx, iflib_txq_t txq);</a>
<a name="ln735">static int iflib_rxd_avail(if_ctx_t ctx, iflib_rxq_t rxq, qidx_t cidx, qidx_t budget);</a>
<a name="ln736">static int iflib_qset_structures_setup(if_ctx_t ctx);</a>
<a name="ln737">static int iflib_msix_init(if_ctx_t ctx);</a>
<a name="ln738">static int iflib_legacy_setup(if_ctx_t ctx, driver_filter_t filter, void *filterarg, int *rid, const char *str);</a>
<a name="ln739">static void iflib_txq_check_drain(iflib_txq_t txq, int budget);</a>
<a name="ln740">static uint32_t iflib_txq_can_drain(struct ifmp_ring *);</a>
<a name="ln741">#ifdef ALTQ</a>
<a name="ln742">static void iflib_altq_if_start(if_t ifp);</a>
<a name="ln743">static int iflib_altq_if_transmit(if_t ifp, struct mbuf *m);</a>
<a name="ln744">#endif</a>
<a name="ln745">static int iflib_register(if_ctx_t);</a>
<a name="ln746">static void iflib_init_locked(if_ctx_t ctx);</a>
<a name="ln747">static void iflib_add_device_sysctl_pre(if_ctx_t ctx);</a>
<a name="ln748">static void iflib_add_device_sysctl_post(if_ctx_t ctx);</a>
<a name="ln749">static void iflib_ifmp_purge(iflib_txq_t txq);</a>
<a name="ln750">static void _iflib_pre_assert(if_softc_ctx_t scctx);</a>
<a name="ln751">static void iflib_if_init_locked(if_ctx_t ctx);</a>
<a name="ln752">static void iflib_free_intr_mem(if_ctx_t ctx);</a>
<a name="ln753">#ifndef __NO_STRICT_ALIGNMENT</a>
<a name="ln754">static struct mbuf * iflib_fixup_rx(struct mbuf *m);</a>
<a name="ln755">#endif</a>
<a name="ln756"> </a>
<a name="ln757">NETDUMP_DEFINE(iflib);</a>
<a name="ln758"> </a>
<a name="ln759">#ifdef DEV_NETMAP</a>
<a name="ln760">#include &lt;sys/selinfo.h&gt;</a>
<a name="ln761">#include &lt;net/netmap.h&gt;</a>
<a name="ln762">#include &lt;dev/netmap/netmap_kern.h&gt;</a>
<a name="ln763"> </a>
<a name="ln764">MODULE_DEPEND(iflib, netmap, 1, 1, 1);</a>
<a name="ln765"> </a>
<a name="ln766">static int netmap_fl_refill(iflib_rxq_t rxq, struct netmap_kring *kring, uint32_t nm_i, bool init);</a>
<a name="ln767"> </a>
<a name="ln768">/*</a>
<a name="ln769"> * device-specific sysctl variables:</a>
<a name="ln770"> *</a>
<a name="ln771"> * iflib_crcstrip: 0: keep CRC in rx frames (default), 1: strip it.</a>
<a name="ln772"> *	During regular operations the CRC is stripped, but on some</a>
<a name="ln773"> *	hardware reception of frames not multiple of 64 is slower,</a>
<a name="ln774"> *	so using crcstrip=0 helps in benchmarks.</a>
<a name="ln775"> *</a>
<a name="ln776"> * iflib_rx_miss, iflib_rx_miss_bufs:</a>
<a name="ln777"> *	count packets that might be missed due to lost interrupts.</a>
<a name="ln778"> */</a>
<a name="ln779">SYSCTL_DECL(_dev_netmap);</a>
<a name="ln780">/*</a>
<a name="ln781"> * The xl driver by default strips CRCs and we do not override it.</a>
<a name="ln782"> */</a>
<a name="ln783"> </a>
<a name="ln784">int iflib_crcstrip = 1;</a>
<a name="ln785">SYSCTL_INT(_dev_netmap, OID_AUTO, iflib_crcstrip,</a>
<a name="ln786">    CTLFLAG_RW, &amp;iflib_crcstrip, 1, &quot;strip CRC on rx frames&quot;);</a>
<a name="ln787"> </a>
<a name="ln788">int iflib_rx_miss, iflib_rx_miss_bufs;</a>
<a name="ln789">SYSCTL_INT(_dev_netmap, OID_AUTO, iflib_rx_miss,</a>
<a name="ln790">    CTLFLAG_RW, &amp;iflib_rx_miss, 0, &quot;potentially missed rx intr&quot;);</a>
<a name="ln791">SYSCTL_INT(_dev_netmap, OID_AUTO, iflib_rx_miss_bufs,</a>
<a name="ln792">    CTLFLAG_RW, &amp;iflib_rx_miss_bufs, 0, &quot;potentially missed rx intr bufs&quot;);</a>
<a name="ln793"> </a>
<a name="ln794">/*</a>
<a name="ln795"> * Register/unregister. We are already under netmap lock.</a>
<a name="ln796"> * Only called on the first register or the last unregister.</a>
<a name="ln797"> */</a>
<a name="ln798">static int</a>
<a name="ln799">iflib_netmap_register(struct netmap_adapter *na, int onoff)</a>
<a name="ln800">{</a>
<a name="ln801">	struct ifnet *ifp = na-&gt;ifp;</a>
<a name="ln802">	if_ctx_t ctx = ifp-&gt;if_softc;</a>
<a name="ln803">	int status;</a>
<a name="ln804"> </a>
<a name="ln805">	CTX_LOCK(ctx);</a>
<a name="ln806">	IFDI_INTR_DISABLE(ctx);</a>
<a name="ln807"> </a>
<a name="ln808">	/* Tell the stack that the interface is no longer active */</a>
<a name="ln809">	ifp-&gt;if_drv_flags &amp;= ~(IFF_DRV_RUNNING | IFF_DRV_OACTIVE);</a>
<a name="ln810"> </a>
<a name="ln811">	if (!CTX_IS_VF(ctx))</a>
<a name="ln812">		IFDI_CRCSTRIP_SET(ctx, onoff, iflib_crcstrip);</a>
<a name="ln813"> </a>
<a name="ln814">	/* enable or disable flags and callbacks in na and ifp */</a>
<a name="ln815">	if (onoff) {</a>
<a name="ln816">		nm_set_native_flags(na);</a>
<a name="ln817">	} else {</a>
<a name="ln818">		nm_clear_native_flags(na);</a>
<a name="ln819">	}</a>
<a name="ln820">	iflib_stop(ctx);</a>
<a name="ln821">	iflib_init_locked(ctx);</a>
<a name="ln822">	IFDI_CRCSTRIP_SET(ctx, onoff, iflib_crcstrip); // XXX why twice ?</a>
<a name="ln823">	status = ifp-&gt;if_drv_flags &amp; IFF_DRV_RUNNING ? 0 : 1;</a>
<a name="ln824">	if (status)</a>
<a name="ln825">		nm_clear_native_flags(na);</a>
<a name="ln826">	CTX_UNLOCK(ctx);</a>
<a name="ln827">	return (status);</a>
<a name="ln828">}</a>
<a name="ln829"> </a>
<a name="ln830">static int</a>
<a name="ln831">netmap_fl_refill(iflib_rxq_t rxq, struct netmap_kring *kring, uint32_t nm_i, bool init)</a>
<a name="ln832">{</a>
<a name="ln833">	struct netmap_adapter *na = kring-&gt;na;</a>
<a name="ln834">	u_int const lim = kring-&gt;nkr_num_slots - 1;</a>
<a name="ln835">	u_int head = kring-&gt;rhead;</a>
<a name="ln836">	struct netmap_ring *ring = kring-&gt;ring;</a>
<a name="ln837">	bus_dmamap_t *map;</a>
<a name="ln838">	struct if_rxd_update iru;</a>
<a name="ln839">	if_ctx_t ctx = rxq-&gt;ifr_ctx;</a>
<a name="ln840">	iflib_fl_t fl = &amp;rxq-&gt;ifr_fl[0];</a>
<a name="ln841">	uint32_t refill_pidx, nic_i;</a>
<a name="ln842">#if IFLIB_DEBUG_COUNTERS</a>
<a name="ln843">	int rf_count = 0;</a>
<a name="ln844">#endif</a>
<a name="ln845"> </a>
<a name="ln846">	if (nm_i == head &amp;&amp; __predict_true(!init))</a>
<a name="ln847">		return 0;</a>
<a name="ln848">	iru_init(&amp;iru, rxq, 0 /* flid */);</a>
<a name="ln849">	map = fl-&gt;ifl_sds.ifsd_map;</a>
<a name="ln850">	refill_pidx = netmap_idx_k2n(kring, nm_i);</a>
<a name="ln851">	/*</a>
<a name="ln852">	 * IMPORTANT: we must leave one free slot in the ring,</a>
<a name="ln853">	 * so move head back by one unit</a>
<a name="ln854">	 */</a>
<a name="ln855">	head = nm_prev(head, lim);</a>
<a name="ln856">	nic_i = UINT_MAX;</a>
<a name="ln857">	DBG_COUNTER_INC(fl_refills);</a>
<a name="ln858">	while (nm_i != head) {</a>
<a name="ln859">#if IFLIB_DEBUG_COUNTERS</a>
<a name="ln860">		if (++rf_count == 9)</a>
<a name="ln861">			DBG_COUNTER_INC(fl_refills_large);</a>
<a name="ln862">#endif</a>
<a name="ln863">		for (int tmp_pidx = 0; tmp_pidx &lt; IFLIB_MAX_RX_REFRESH &amp;&amp; nm_i != head; tmp_pidx++) {</a>
<a name="ln864">			struct netmap_slot *slot = &amp;ring-&gt;slot[nm_i];</a>
<a name="ln865">			void *addr = PNMB(na, slot, &amp;fl-&gt;ifl_bus_addrs[tmp_pidx]);</a>
<a name="ln866">			uint32_t nic_i_dma = refill_pidx;</a>
<a name="ln867">			nic_i = netmap_idx_k2n(kring, nm_i);</a>
<a name="ln868"> </a>
<a name="ln869">			MPASS(tmp_pidx &lt; IFLIB_MAX_RX_REFRESH);</a>
<a name="ln870"> </a>
<a name="ln871">			if (addr == NETMAP_BUF_BASE(na)) /* bad buf */</a>
<a name="ln872">			        return netmap_ring_reinit(kring);</a>
<a name="ln873"> </a>
<a name="ln874">			fl-&gt;ifl_vm_addrs[tmp_pidx] = addr;</a>
<a name="ln875">			if (__predict_false(init)) {</a>
<a name="ln876">				netmap_load_map(na, fl-&gt;ifl_buf_tag,</a>
<a name="ln877">				    map[nic_i], addr);</a>
<a name="ln878">			} else if (slot-&gt;flags &amp; NS_BUF_CHANGED) {</a>
<a name="ln879">				/* buffer has changed, reload map */</a>
<a name="ln880">				netmap_reload_map(na, fl-&gt;ifl_buf_tag,</a>
<a name="ln881">				    map[nic_i], addr);</a>
<a name="ln882">			}</a>
<a name="ln883">			slot-&gt;flags &amp;= ~NS_BUF_CHANGED;</a>
<a name="ln884"> </a>
<a name="ln885">			nm_i = nm_next(nm_i, lim);</a>
<a name="ln886">			fl-&gt;ifl_rxd_idxs[tmp_pidx] = nic_i = nm_next(nic_i, lim);</a>
<a name="ln887">			if (nm_i != head &amp;&amp; tmp_pidx &lt; IFLIB_MAX_RX_REFRESH-1)</a>
<a name="ln888">				continue;</a>
<a name="ln889"> </a>
<a name="ln890">			iru.iru_pidx = refill_pidx;</a>
<a name="ln891">			iru.iru_count = tmp_pidx+1;</a>
<a name="ln892">			ctx-&gt;isc_rxd_refill(ctx-&gt;ifc_softc, &amp;iru);</a>
<a name="ln893">			refill_pidx = nic_i;</a>
<a name="ln894">			for (int n = 0; n &lt; iru.iru_count; n++) {</a>
<a name="ln895">				bus_dmamap_sync(fl-&gt;ifl_buf_tag, map[nic_i_dma],</a>
<a name="ln896">						BUS_DMASYNC_PREREAD);</a>
<a name="ln897">				/* XXX - change this to not use the netmap func*/</a>
<a name="ln898">				nic_i_dma = nm_next(nic_i_dma, lim);</a>
<a name="ln899">			}</a>
<a name="ln900">		}</a>
<a name="ln901">	}</a>
<a name="ln902">	kring-&gt;nr_hwcur = head;</a>
<a name="ln903"> </a>
<a name="ln904">	bus_dmamap_sync(fl-&gt;ifl_ifdi-&gt;idi_tag, fl-&gt;ifl_ifdi-&gt;idi_map,</a>
<a name="ln905">	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);</a>
<a name="ln906">	if (__predict_true(nic_i != UINT_MAX)) {</a>
<a name="ln907">		ctx-&gt;isc_rxd_flush(ctx-&gt;ifc_softc, rxq-&gt;ifr_id, fl-&gt;ifl_id, nic_i);</a>
<a name="ln908">		DBG_COUNTER_INC(rxd_flush);</a>
<a name="ln909">	}</a>
<a name="ln910">	return (0);</a>
<a name="ln911">}</a>
<a name="ln912"> </a>
<a name="ln913">/*</a>
<a name="ln914"> * Reconcile kernel and user view of the transmit ring.</a>
<a name="ln915"> *</a>
<a name="ln916"> * All information is in the kring.</a>
<a name="ln917"> * Userspace wants to send packets up to the one before kring-&gt;rhead,</a>
<a name="ln918"> * kernel knows kring-&gt;nr_hwcur is the first unsent packet.</a>
<a name="ln919"> *</a>
<a name="ln920"> * Here we push packets out (as many as possible), and possibly</a>
<a name="ln921"> * reclaim buffers from previously completed transmission.</a>
<a name="ln922"> *</a>
<a name="ln923"> * The caller (netmap) guarantees that there is only one instance</a>
<a name="ln924"> * running at any time. Any interference with other driver</a>
<a name="ln925"> * methods should be handled by the individual drivers.</a>
<a name="ln926"> */</a>
<a name="ln927">static int</a>
<a name="ln928">iflib_netmap_txsync(struct netmap_kring *kring, int flags)</a>
<a name="ln929">{</a>
<a name="ln930">	struct netmap_adapter *na = kring-&gt;na;</a>
<a name="ln931">	struct ifnet *ifp = na-&gt;ifp;</a>
<a name="ln932">	struct netmap_ring *ring = kring-&gt;ring;</a>
<a name="ln933">	u_int nm_i;	/* index into the netmap kring */</a>
<a name="ln934">	u_int nic_i;	/* index into the NIC ring */</a>
<a name="ln935">	u_int n;</a>
<a name="ln936">	u_int const lim = kring-&gt;nkr_num_slots - 1;</a>
<a name="ln937">	u_int const head = kring-&gt;rhead;</a>
<a name="ln938">	struct if_pkt_info pi;</a>
<a name="ln939"> </a>
<a name="ln940">	/*</a>
<a name="ln941">	 * interrupts on every tx packet are expensive so request</a>
<a name="ln942">	 * them every half ring, or where NS_REPORT is set</a>
<a name="ln943">	 */</a>
<a name="ln944">	u_int report_frequency = kring-&gt;nkr_num_slots &gt;&gt; 1;</a>
<a name="ln945">	/* device-specific */</a>
<a name="ln946">	if_ctx_t ctx = ifp-&gt;if_softc;</a>
<a name="ln947">	iflib_txq_t txq = &amp;ctx-&gt;ifc_txqs[kring-&gt;ring_id];</a>
<a name="ln948"> </a>
<a name="ln949">	bus_dmamap_sync(txq-&gt;ift_ifdi-&gt;idi_tag, txq-&gt;ift_ifdi-&gt;idi_map,</a>
<a name="ln950">	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);</a>
<a name="ln951"> </a>
<a name="ln952">	/*</a>
<a name="ln953">	 * First part: process new packets to send.</a>
<a name="ln954">	 * nm_i is the current index in the netmap kring,</a>
<a name="ln955">	 * nic_i is the corresponding index in the NIC ring.</a>
<a name="ln956">	 *</a>
<a name="ln957">	 * If we have packets to send (nm_i != head)</a>
<a name="ln958">	 * iterate over the netmap ring, fetch length and update</a>
<a name="ln959">	 * the corresponding slot in the NIC ring. Some drivers also</a>
<a name="ln960">	 * need to update the buffer's physical address in the NIC slot</a>
<a name="ln961">	 * even NS_BUF_CHANGED is not set (PNMB computes the addresses).</a>
<a name="ln962">	 *</a>
<a name="ln963">	 * The netmap_reload_map() calls is especially expensive,</a>
<a name="ln964">	 * even when (as in this case) the tag is 0, so do only</a>
<a name="ln965">	 * when the buffer has actually changed.</a>
<a name="ln966">	 *</a>
<a name="ln967">	 * If possible do not set the report/intr bit on all slots,</a>
<a name="ln968">	 * but only a few times per ring or when NS_REPORT is set.</a>
<a name="ln969">	 *</a>
<a name="ln970">	 * Finally, on 10G and faster drivers, it might be useful</a>
<a name="ln971">	 * to prefetch the next slot and txr entry.</a>
<a name="ln972">	 */</a>
<a name="ln973"> </a>
<a name="ln974">	nm_i = kring-&gt;nr_hwcur;</a>
<a name="ln975">	if (nm_i != head) {	/* we have new packets to send */</a>
<a name="ln976">		pkt_info_zero(&amp;pi);</a>
<a name="ln977">		pi.ipi_segs = txq-&gt;ift_segs;</a>
<a name="ln978">		pi.ipi_qsidx = kring-&gt;ring_id;</a>
<a name="ln979">		nic_i = netmap_idx_k2n(kring, nm_i);</a>
<a name="ln980"> </a>
<a name="ln981">		__builtin_prefetch(&amp;ring-&gt;slot[nm_i]);</a>
<a name="ln982">		__builtin_prefetch(&amp;txq-&gt;ift_sds.ifsd_m[nic_i]);</a>
<a name="ln983">		__builtin_prefetch(&amp;txq-&gt;ift_sds.ifsd_map[nic_i]);</a>
<a name="ln984"> </a>
<a name="ln985">		for (n = 0; nm_i != head; n++) {</a>
<a name="ln986">			struct netmap_slot *slot = &amp;ring-&gt;slot[nm_i];</a>
<a name="ln987">			u_int len = slot-&gt;len;</a>
<a name="ln988">			uint64_t paddr;</a>
<a name="ln989">			void *addr = PNMB(na, slot, &amp;paddr);</a>
<a name="ln990">			int flags = (slot-&gt;flags &amp; NS_REPORT ||</a>
<a name="ln991">				nic_i == 0 || nic_i == report_frequency) ?</a>
<a name="ln992">				IPI_TX_INTR : 0;</a>
<a name="ln993"> </a>
<a name="ln994">			/* device-specific */</a>
<a name="ln995">			pi.ipi_len = len;</a>
<a name="ln996">			pi.ipi_segs[0].ds_addr = paddr;</a>
<a name="ln997">			pi.ipi_segs[0].ds_len = len;</a>
<a name="ln998">			pi.ipi_nsegs = 1;</a>
<a name="ln999">			pi.ipi_ndescs = 0;</a>
<a name="ln1000">			pi.ipi_pidx = nic_i;</a>
<a name="ln1001">			pi.ipi_flags = flags;</a>
<a name="ln1002"> </a>
<a name="ln1003">			/* Fill the slot in the NIC ring. */</a>
<a name="ln1004">			ctx-&gt;isc_txd_encap(ctx-&gt;ifc_softc, &amp;pi);</a>
<a name="ln1005">			DBG_COUNTER_INC(tx_encap);</a>
<a name="ln1006"> </a>
<a name="ln1007">			/* prefetch for next round */</a>
<a name="ln1008">			__builtin_prefetch(&amp;ring-&gt;slot[nm_i + 1]);</a>
<a name="ln1009">			__builtin_prefetch(&amp;txq-&gt;ift_sds.ifsd_m[nic_i + 1]);</a>
<a name="ln1010">			__builtin_prefetch(&amp;txq-&gt;ift_sds.ifsd_map[nic_i + 1]);</a>
<a name="ln1011"> </a>
<a name="ln1012">			NM_CHECK_ADDR_LEN(na, addr, len);</a>
<a name="ln1013"> </a>
<a name="ln1014">			if (slot-&gt;flags &amp; NS_BUF_CHANGED) {</a>
<a name="ln1015">				/* buffer has changed, reload map */</a>
<a name="ln1016">				netmap_reload_map(na, txq-&gt;ift_buf_tag,</a>
<a name="ln1017">				    txq-&gt;ift_sds.ifsd_map[nic_i], addr);</a>
<a name="ln1018">			}</a>
<a name="ln1019">			/* make sure changes to the buffer are synced */</a>
<a name="ln1020">			bus_dmamap_sync(txq-&gt;ift_buf_tag,</a>
<a name="ln1021">			    txq-&gt;ift_sds.ifsd_map[nic_i],</a>
<a name="ln1022">			    BUS_DMASYNC_PREWRITE);</a>
<a name="ln1023"> </a>
<a name="ln1024">			slot-&gt;flags &amp;= ~(NS_REPORT | NS_BUF_CHANGED);</a>
<a name="ln1025">			nm_i = nm_next(nm_i, lim);</a>
<a name="ln1026">			nic_i = nm_next(nic_i, lim);</a>
<a name="ln1027">		}</a>
<a name="ln1028">		kring-&gt;nr_hwcur = nm_i;</a>
<a name="ln1029"> </a>
<a name="ln1030">		/* synchronize the NIC ring */</a>
<a name="ln1031">		bus_dmamap_sync(txq-&gt;ift_ifdi-&gt;idi_tag, txq-&gt;ift_ifdi-&gt;idi_map,</a>
<a name="ln1032">		    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);</a>
<a name="ln1033"> </a>
<a name="ln1034">		/* (re)start the tx unit up to slot nic_i (excluded) */</a>
<a name="ln1035">		ctx-&gt;isc_txd_flush(ctx-&gt;ifc_softc, txq-&gt;ift_id, nic_i);</a>
<a name="ln1036">	}</a>
<a name="ln1037"> </a>
<a name="ln1038">	/*</a>
<a name="ln1039">	 * Second part: reclaim buffers for completed transmissions.</a>
<a name="ln1040">	 *</a>
<a name="ln1041">	 * If there are unclaimed buffers, attempt to reclaim them.</a>
<a name="ln1042">	 * If none are reclaimed, and TX IRQs are not in use, do an initial</a>
<a name="ln1043">	 * minimal delay, then trigger the tx handler which will spin in the</a>
<a name="ln1044">	 * group task queue.</a>
<a name="ln1045">	 */</a>
<a name="ln1046">	if (kring-&gt;nr_hwtail != nm_prev(kring-&gt;nr_hwcur, lim)) {</a>
<a name="ln1047">		if (iflib_tx_credits_update(ctx, txq)) {</a>
<a name="ln1048">			/* some tx completed, increment avail */</a>
<a name="ln1049">			nic_i = txq-&gt;ift_cidx_processed;</a>
<a name="ln1050">			kring-&gt;nr_hwtail = nm_prev(netmap_idx_n2k(kring, nic_i), lim);</a>
<a name="ln1051">		}</a>
<a name="ln1052">	}</a>
<a name="ln1053">	if (!(ctx-&gt;ifc_flags &amp; IFC_NETMAP_TX_IRQ))</a>
<a name="ln1054">		if (kring-&gt;nr_hwtail != nm_prev(kring-&gt;nr_hwcur, lim)) {</a>
<a name="ln1055">			callout_reset_on(&amp;txq-&gt;ift_timer, hz &lt; 2000 ? 1 : hz / 1000,</a>
<a name="ln1056">			    iflib_timer, txq, txq-&gt;ift_timer.c_cpu);</a>
<a name="ln1057">	}</a>
<a name="ln1058">	return (0);</a>
<a name="ln1059">}</a>
<a name="ln1060"> </a>
<a name="ln1061">/*</a>
<a name="ln1062"> * Reconcile kernel and user view of the receive ring.</a>
<a name="ln1063"> * Same as for the txsync, this routine must be efficient.</a>
<a name="ln1064"> * The caller guarantees a single invocations, but races against</a>
<a name="ln1065"> * the rest of the driver should be handled here.</a>
<a name="ln1066"> *</a>
<a name="ln1067"> * On call, kring-&gt;rhead is the first packet that userspace wants</a>
<a name="ln1068"> * to keep, and kring-&gt;rcur is the wakeup point.</a>
<a name="ln1069"> * The kernel has previously reported packets up to kring-&gt;rtail.</a>
<a name="ln1070"> *</a>
<a name="ln1071"> * If (flags &amp; NAF_FORCE_READ) also check for incoming packets irrespective</a>
<a name="ln1072"> * of whether or not we received an interrupt.</a>
<a name="ln1073"> */</a>
<a name="ln1074">static int</a>
<a name="ln1075">iflib_netmap_rxsync(struct netmap_kring *kring, int flags)</a>
<a name="ln1076">{</a>
<a name="ln1077">	struct netmap_adapter *na = kring-&gt;na;</a>
<a name="ln1078">	struct netmap_ring *ring = kring-&gt;ring;</a>
<a name="ln1079">	iflib_fl_t fl;</a>
<a name="ln1080">	uint32_t nm_i;	/* index into the netmap ring */</a>
<a name="ln1081">	uint32_t nic_i;	/* index into the NIC ring */</a>
<a name="ln1082">	u_int i, n;</a>
<a name="ln1083">	u_int const lim = kring-&gt;nkr_num_slots - 1;</a>
<a name="ln1084">	u_int const head = kring-&gt;rhead;</a>
<a name="ln1085">	int force_update = (flags &amp; NAF_FORCE_READ) || kring-&gt;nr_kflags &amp; NKR_PENDINTR;</a>
<a name="ln1086">	struct if_rxd_info ri;</a>
<a name="ln1087"> </a>
<a name="ln1088">	struct ifnet *ifp = na-&gt;ifp;</a>
<a name="ln1089">	if_ctx_t ctx = ifp-&gt;if_softc;</a>
<a name="ln1090">	iflib_rxq_t rxq = &amp;ctx-&gt;ifc_rxqs[kring-&gt;ring_id];</a>
<a name="ln1091">	if (head &gt; lim)</a>
<a name="ln1092">		return netmap_ring_reinit(kring);</a>
<a name="ln1093"> </a>
<a name="ln1094">	/*</a>
<a name="ln1095">	 * XXX netmap_fl_refill() only ever (re)fills free list 0 so far.</a>
<a name="ln1096">	 */</a>
<a name="ln1097"> </a>
<a name="ln1098">	for (i = 0, fl = rxq-&gt;ifr_fl; i &lt; rxq-&gt;ifr_nfl; i++, fl++) {</a>
<a name="ln1099">		bus_dmamap_sync(fl-&gt;ifl_ifdi-&gt;idi_tag, fl-&gt;ifl_ifdi-&gt;idi_map,</a>
<a name="ln1100">		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);</a>
<a name="ln1101">	}</a>
<a name="ln1102"> </a>
<a name="ln1103">	/*</a>
<a name="ln1104">	 * First part: import newly received packets.</a>
<a name="ln1105">	 *</a>
<a name="ln1106">	 * nm_i is the index of the next free slot in the netmap ring,</a>
<a name="ln1107">	 * nic_i is the index of the next received packet in the NIC ring,</a>
<a name="ln1108">	 * and they may differ in case if_init() has been called while</a>
<a name="ln1109">	 * in netmap mode. For the receive ring we have</a>
<a name="ln1110">	 *</a>
<a name="ln1111">	 *	nic_i = rxr-&gt;next_check;</a>
<a name="ln1112">	 *	nm_i = kring-&gt;nr_hwtail (previous)</a>
<a name="ln1113">	 * and</a>
<a name="ln1114">	 *	nm_i == (nic_i + kring-&gt;nkr_hwofs) % ring_size</a>
<a name="ln1115">	 *</a>
<a name="ln1116">	 * rxr-&gt;next_check is set to 0 on a ring reinit</a>
<a name="ln1117">	 */</a>
<a name="ln1118">	if (netmap_no_pendintr || force_update) {</a>
<a name="ln1119">		int crclen = iflib_crcstrip ? 0 : 4;</a>
<a name="ln1120">		int error, avail;</a>
<a name="ln1121"> </a>
<a name="ln1122">		for (i = 0; i &lt; rxq-&gt;ifr_nfl; i++) {</a>
<a name="ln1123">			fl = &amp;rxq-&gt;ifr_fl[i];</a>
<a name="ln1124">			nic_i = fl-&gt;ifl_cidx;</a>
<a name="ln1125">			nm_i = netmap_idx_n2k(kring, nic_i);</a>
<a name="ln1126">			avail = ctx-&gt;isc_rxd_available(ctx-&gt;ifc_softc,</a>
<a name="ln1127">			    rxq-&gt;ifr_id, nic_i, USHRT_MAX);</a>
<a name="ln1128">			for (n = 0; avail &gt; 0; n++, avail--) {</a>
<a name="ln1129">				rxd_info_zero(&amp;ri);</a>
<a name="ln1130">				ri.iri_frags = rxq-&gt;ifr_frags;</a>
<a name="ln1131">				ri.iri_qsidx = kring-&gt;ring_id;</a>
<a name="ln1132">				ri.iri_ifp = ctx-&gt;ifc_ifp;</a>
<a name="ln1133">				ri.iri_cidx = nic_i;</a>
<a name="ln1134"> </a>
<a name="ln1135">				error = ctx-&gt;isc_rxd_pkt_get(ctx-&gt;ifc_softc, &amp;ri);</a>
<a name="ln1136">				ring-&gt;slot[nm_i].len = error ? 0 : ri.iri_len - crclen;</a>
<a name="ln1137">				ring-&gt;slot[nm_i].flags = 0;</a>
<a name="ln1138">				bus_dmamap_sync(fl-&gt;ifl_buf_tag,</a>
<a name="ln1139">				    fl-&gt;ifl_sds.ifsd_map[nic_i], BUS_DMASYNC_POSTREAD);</a>
<a name="ln1140">				nm_i = nm_next(nm_i, lim);</a>
<a name="ln1141">				nic_i = nm_next(nic_i, lim);</a>
<a name="ln1142">			}</a>
<a name="ln1143">			if (n) { /* update the state variables */</a>
<a name="ln1144">				if (netmap_no_pendintr &amp;&amp; !force_update) {</a>
<a name="ln1145">					/* diagnostics */</a>
<a name="ln1146">					iflib_rx_miss ++;</a>
<a name="ln1147">					iflib_rx_miss_bufs += n;</a>
<a name="ln1148">				}</a>
<a name="ln1149">				fl-&gt;ifl_cidx = nic_i;</a>
<a name="ln1150">				kring-&gt;nr_hwtail = nm_i;</a>
<a name="ln1151">			}</a>
<a name="ln1152">			kring-&gt;nr_kflags &amp;= ~NKR_PENDINTR;</a>
<a name="ln1153">		}</a>
<a name="ln1154">	}</a>
<a name="ln1155">	/*</a>
<a name="ln1156">	 * Second part: skip past packets that userspace has released.</a>
<a name="ln1157">	 * (kring-&gt;nr_hwcur to head excluded),</a>
<a name="ln1158">	 * and make the buffers available for reception.</a>
<a name="ln1159">	 * As usual nm_i is the index in the netmap ring,</a>
<a name="ln1160">	 * nic_i is the index in the NIC ring, and</a>
<a name="ln1161">	 * nm_i == (nic_i + kring-&gt;nkr_hwofs) % ring_size</a>
<a name="ln1162">	 */</a>
<a name="ln1163">	/* XXX not sure how this will work with multiple free lists */</a>
<a name="ln1164">	nm_i = kring-&gt;nr_hwcur;</a>
<a name="ln1165"> </a>
<a name="ln1166">	return (netmap_fl_refill(rxq, kring, nm_i, false));</a>
<a name="ln1167">}</a>
<a name="ln1168"> </a>
<a name="ln1169">static void</a>
<a name="ln1170">iflib_netmap_intr(struct netmap_adapter *na, int onoff)</a>
<a name="ln1171">{</a>
<a name="ln1172">	struct ifnet *ifp = na-&gt;ifp;</a>
<a name="ln1173">	if_ctx_t ctx = ifp-&gt;if_softc;</a>
<a name="ln1174"> </a>
<a name="ln1175">	CTX_LOCK(ctx);</a>
<a name="ln1176">	if (onoff) {</a>
<a name="ln1177">		IFDI_INTR_ENABLE(ctx);</a>
<a name="ln1178">	} else {</a>
<a name="ln1179">		IFDI_INTR_DISABLE(ctx);</a>
<a name="ln1180">	}</a>
<a name="ln1181">	CTX_UNLOCK(ctx);</a>
<a name="ln1182">}</a>
<a name="ln1183"> </a>
<a name="ln1184"> </a>
<a name="ln1185">static int</a>
<a name="ln1186">iflib_netmap_attach(if_ctx_t ctx)</a>
<a name="ln1187">{</a>
<a name="ln1188">	struct netmap_adapter na;</a>
<a name="ln1189">	if_softc_ctx_t scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln1190"> </a>
<a name="ln1191">	bzero(&amp;na, sizeof(na));</a>
<a name="ln1192"> </a>
<a name="ln1193">	na.ifp = ctx-&gt;ifc_ifp;</a>
<a name="ln1194">	na.na_flags = NAF_BDG_MAYSLEEP;</a>
<a name="ln1195">	MPASS(ctx-&gt;ifc_softc_ctx.isc_ntxqsets);</a>
<a name="ln1196">	MPASS(ctx-&gt;ifc_softc_ctx.isc_nrxqsets);</a>
<a name="ln1197"> </a>
<a name="ln1198">	na.num_tx_desc = scctx-&gt;isc_ntxd[0];</a>
<a name="ln1199">	na.num_rx_desc = scctx-&gt;isc_nrxd[0];</a>
<a name="ln1200">	na.nm_txsync = iflib_netmap_txsync;</a>
<a name="ln1201">	na.nm_rxsync = iflib_netmap_rxsync;</a>
<a name="ln1202">	na.nm_register = iflib_netmap_register;</a>
<a name="ln1203">	na.nm_intr = iflib_netmap_intr;</a>
<a name="ln1204">	na.num_tx_rings = ctx-&gt;ifc_softc_ctx.isc_ntxqsets;</a>
<a name="ln1205">	na.num_rx_rings = ctx-&gt;ifc_softc_ctx.isc_nrxqsets;</a>
<a name="ln1206">	return (netmap_attach(&amp;na));</a>
<a name="ln1207">}</a>
<a name="ln1208"> </a>
<a name="ln1209">static void</a>
<a name="ln1210">iflib_netmap_txq_init(if_ctx_t ctx, iflib_txq_t txq)</a>
<a name="ln1211">{</a>
<a name="ln1212">	struct netmap_adapter *na = NA(ctx-&gt;ifc_ifp);</a>
<a name="ln1213">	struct netmap_slot *slot;</a>
<a name="ln1214">	int i;</a>
<a name="ln1215"> </a>
<a name="ln1216">	slot = netmap_reset(na, NR_TX, txq-&gt;ift_id, 0);</a>
<a name="ln1217">	if (slot == NULL)</a>
<a name="ln1218">		return;</a>
<a name="ln1219"> </a>
<a name="ln1220">	for (i = 0; i &lt; ctx-&gt;ifc_softc_ctx.isc_ntxd[0]; i++) {</a>
<a name="ln1221"> </a>
<a name="ln1222">		/*</a>
<a name="ln1223">		 * In netmap mode, set the map for the packet buffer.</a>
<a name="ln1224">		 * NOTE: Some drivers (not this one) also need to set</a>
<a name="ln1225">		 * the physical buffer address in the NIC ring.</a>
<a name="ln1226">		 * netmap_idx_n2k() maps a nic index, i, into the corresponding</a>
<a name="ln1227">		 * netmap slot index, si</a>
<a name="ln1228">		 */</a>
<a name="ln1229">		int si = netmap_idx_n2k(na-&gt;tx_rings[txq-&gt;ift_id], i);</a>
<a name="ln1230">		netmap_load_map(na, txq-&gt;ift_buf_tag, txq-&gt;ift_sds.ifsd_map[i],</a>
<a name="ln1231">		    NMB(na, slot + si));</a>
<a name="ln1232">	}</a>
<a name="ln1233">}</a>
<a name="ln1234"> </a>
<a name="ln1235">static void</a>
<a name="ln1236">iflib_netmap_rxq_init(if_ctx_t ctx, iflib_rxq_t rxq)</a>
<a name="ln1237">{</a>
<a name="ln1238">	struct netmap_adapter *na = NA(ctx-&gt;ifc_ifp);</a>
<a name="ln1239">	struct netmap_kring *kring = na-&gt;rx_rings[rxq-&gt;ifr_id];</a>
<a name="ln1240">	struct netmap_slot *slot;</a>
<a name="ln1241">	uint32_t nm_i;</a>
<a name="ln1242"> </a>
<a name="ln1243">	slot = netmap_reset(na, NR_RX, rxq-&gt;ifr_id, 0);</a>
<a name="ln1244">	if (slot == NULL)</a>
<a name="ln1245">		return;</a>
<a name="ln1246">	nm_i = netmap_idx_n2k(kring, 0);</a>
<a name="ln1247">	netmap_fl_refill(rxq, kring, nm_i, true);</a>
<a name="ln1248">}</a>
<a name="ln1249"> </a>
<a name="ln1250">static void</a>
<a name="ln1251">iflib_netmap_timer_adjust(if_ctx_t ctx, iflib_txq_t txq, uint32_t *reset_on)</a>
<a name="ln1252">{</a>
<a name="ln1253">	struct netmap_kring *kring;</a>
<a name="ln1254">	uint16_t txqid;</a>
<a name="ln1255"> </a>
<a name="ln1256">	txqid = txq-&gt;ift_id;</a>
<a name="ln1257">	kring = NA(ctx-&gt;ifc_ifp)-&gt;tx_rings[txqid];</a>
<a name="ln1258"> </a>
<a name="ln1259">	if (kring-&gt;nr_hwcur != nm_next(kring-&gt;nr_hwtail, kring-&gt;nkr_num_slots - 1)) {</a>
<a name="ln1260">		bus_dmamap_sync(txq-&gt;ift_ifdi-&gt;idi_tag, txq-&gt;ift_ifdi-&gt;idi_map,</a>
<a name="ln1261">		    BUS_DMASYNC_POSTREAD);</a>
<a name="ln1262">		if (ctx-&gt;isc_txd_credits_update(ctx-&gt;ifc_softc, txqid, false))</a>
<a name="ln1263">			netmap_tx_irq(ctx-&gt;ifc_ifp, txqid);</a>
<a name="ln1264">		if (!(ctx-&gt;ifc_flags &amp; IFC_NETMAP_TX_IRQ)) {</a>
<a name="ln1265">			if (hz &lt; 2000)</a>
<a name="ln1266">				*reset_on = 1;</a>
<a name="ln1267">			else</a>
<a name="ln1268">				*reset_on = hz / 1000;</a>
<a name="ln1269">		}</a>
<a name="ln1270">	}</a>
<a name="ln1271">}</a>
<a name="ln1272"> </a>
<a name="ln1273">#define iflib_netmap_detach(ifp) netmap_detach(ifp)</a>
<a name="ln1274"> </a>
<a name="ln1275">#else</a>
<a name="ln1276">#define iflib_netmap_txq_init(ctx, txq)</a>
<a name="ln1277">#define iflib_netmap_rxq_init(ctx, rxq)</a>
<a name="ln1278">#define iflib_netmap_detach(ifp)</a>
<a name="ln1279"> </a>
<a name="ln1280">#define iflib_netmap_attach(ctx) (0)</a>
<a name="ln1281">#define netmap_rx_irq(ifp, qid, budget) (0)</a>
<a name="ln1282">#define netmap_tx_irq(ifp, qid) do {} while (0)</a>
<a name="ln1283">#define iflib_netmap_timer_adjust(ctx, txq, reset_on)</a>
<a name="ln1284"> </a>
<a name="ln1285">#endif</a>
<a name="ln1286"> </a>
<a name="ln1287">#if (defined(__i386__) || defined(__amd64__)) &amp;&amp; !defined(__HAIKU__)</a>
<a name="ln1288">static __inline void</a>
<a name="ln1289">prefetch(void *x)</a>
<a name="ln1290">{</a>
<a name="ln1291">	__asm volatile(&quot;prefetcht0 %0&quot; :: &quot;m&quot; (*(unsigned long *)x));</a>
<a name="ln1292">}</a>
<a name="ln1293">static __inline void</a>
<a name="ln1294">prefetch2cachelines(void *x)</a>
<a name="ln1295">{</a>
<a name="ln1296">	__asm volatile(&quot;prefetcht0 %0&quot; :: &quot;m&quot; (*(unsigned long *)x));</a>
<a name="ln1297">#if (CACHE_LINE_SIZE &lt; 128)</a>
<a name="ln1298">	__asm volatile(&quot;prefetcht0 %0&quot; :: &quot;m&quot; (*(((unsigned long *)x)+CACHE_LINE_SIZE/(sizeof(unsigned long)))));</a>
<a name="ln1299">#endif</a>
<a name="ln1300">}</a>
<a name="ln1301">#else</a>
<a name="ln1302">#define prefetch(x)</a>
<a name="ln1303">#define prefetch2cachelines(x)</a>
<a name="ln1304">#endif</a>
<a name="ln1305"> </a>
<a name="ln1306">static void</a>
<a name="ln1307">iru_init(if_rxd_update_t iru, iflib_rxq_t rxq, uint8_t flid)</a>
<a name="ln1308">{</a>
<a name="ln1309">	iflib_fl_t fl;</a>
<a name="ln1310"> </a>
<a name="ln1311">	fl = &amp;rxq-&gt;ifr_fl[flid];</a>
<a name="ln1312">	iru-&gt;iru_paddrs = fl-&gt;ifl_bus_addrs;</a>
<a name="ln1313">	iru-&gt;iru_vaddrs = &amp;fl-&gt;ifl_vm_addrs[0];</a>
<a name="ln1314">	iru-&gt;iru_idxs = fl-&gt;ifl_rxd_idxs;</a>
<a name="ln1315">	iru-&gt;iru_qsidx = rxq-&gt;ifr_id;</a>
<a name="ln1316">	iru-&gt;iru_buf_size = fl-&gt;ifl_buf_size;</a>
<a name="ln1317">	iru-&gt;iru_flidx = fl-&gt;ifl_id;</a>
<a name="ln1318">}</a>
<a name="ln1319"> </a>
<a name="ln1320">static void</a>
<a name="ln1321">_iflib_dmamap_cb(void *arg, bus_dma_segment_t *segs, int nseg, int err)</a>
<a name="ln1322">{</a>
<a name="ln1323">	if (err)</a>
<a name="ln1324">		return;</a>
<a name="ln1325">	*(bus_addr_t *) arg = segs[0].ds_addr;</a>
<a name="ln1326">}</a>
<a name="ln1327"> </a>
<a name="ln1328">int</a>
<a name="ln1329">iflib_dma_alloc_align(if_ctx_t ctx, int size, int align, iflib_dma_info_t dma, int mapflags)</a>
<a name="ln1330">{</a>
<a name="ln1331">	int err;</a>
<a name="ln1332">	device_t dev = ctx-&gt;ifc_dev;</a>
<a name="ln1333"> </a>
<a name="ln1334">	err = bus_dma_tag_create(bus_get_dma_tag(dev),	/* parent */</a>
<a name="ln1335">				align, 0,		/* alignment, bounds */</a>
<a name="ln1336">				BUS_SPACE_MAXADDR,	/* lowaddr */</a>
<a name="ln1337">				BUS_SPACE_MAXADDR,	/* highaddr */</a>
<a name="ln1338">				NULL, NULL,		/* filter, filterarg */</a>
<a name="ln1339">				size,			/* maxsize */</a>
<a name="ln1340">				1,			/* nsegments */</a>
<a name="ln1341">				size,			/* maxsegsize */</a>
<a name="ln1342">				BUS_DMA_ALLOCNOW,	/* flags */</a>
<a name="ln1343">				NULL,			/* lockfunc */</a>
<a name="ln1344">				NULL,			/* lockarg */</a>
<a name="ln1345">				&amp;dma-&gt;idi_tag);</a>
<a name="ln1346">	if (err) {</a>
<a name="ln1347">		device_printf(dev,</a>
<a name="ln1348">		    &quot;%s: bus_dma_tag_create failed: %d\n&quot;,</a>
<a name="ln1349">		    __func__, err);</a>
<a name="ln1350">		goto fail_0;</a>
<a name="ln1351">	}</a>
<a name="ln1352"> </a>
<a name="ln1353">	err = bus_dmamem_alloc(dma-&gt;idi_tag, (void**) &amp;dma-&gt;idi_vaddr,</a>
<a name="ln1354">	    BUS_DMA_NOWAIT | BUS_DMA_COHERENT | BUS_DMA_ZERO, &amp;dma-&gt;idi_map);</a>
<a name="ln1355">	if (err) {</a>
<a name="ln1356">		device_printf(dev,</a>
<a name="ln1357">		    &quot;%s: bus_dmamem_alloc(%ju) failed: %d\n&quot;,</a>
<a name="ln1358">		    __func__, (uintmax_t)size, err);</a>
<a name="ln1359">		goto fail_1;</a>
<a name="ln1360">	}</a>
<a name="ln1361"> </a>
<a name="ln1362">	dma-&gt;idi_paddr = IF_BAD_DMA;</a>
<a name="ln1363">	err = bus_dmamap_load(dma-&gt;idi_tag, dma-&gt;idi_map, dma-&gt;idi_vaddr,</a>
<a name="ln1364">	    size, _iflib_dmamap_cb, &amp;dma-&gt;idi_paddr, mapflags | BUS_DMA_NOWAIT);</a>
<a name="ln1365">	if (err || dma-&gt;idi_paddr == IF_BAD_DMA) {</a>
<a name="ln1366">		device_printf(dev,</a>
<a name="ln1367">		    &quot;%s: bus_dmamap_load failed: %d\n&quot;,</a>
<a name="ln1368">		    __func__, err);</a>
<a name="ln1369">		goto fail_2;</a>
<a name="ln1370">	}</a>
<a name="ln1371"> </a>
<a name="ln1372">	dma-&gt;idi_size = size;</a>
<a name="ln1373">	return (0);</a>
<a name="ln1374"> </a>
<a name="ln1375">fail_2:</a>
<a name="ln1376">	bus_dmamem_free(dma-&gt;idi_tag, dma-&gt;idi_vaddr, dma-&gt;idi_map);</a>
<a name="ln1377">fail_1:</a>
<a name="ln1378">	bus_dma_tag_destroy(dma-&gt;idi_tag);</a>
<a name="ln1379">fail_0:</a>
<a name="ln1380">	dma-&gt;idi_tag = NULL;</a>
<a name="ln1381"> </a>
<a name="ln1382">	return (err);</a>
<a name="ln1383">}</a>
<a name="ln1384"> </a>
<a name="ln1385">int</a>
<a name="ln1386">iflib_dma_alloc(if_ctx_t ctx, int size, iflib_dma_info_t dma, int mapflags)</a>
<a name="ln1387">{</a>
<a name="ln1388">	if_shared_ctx_t sctx = ctx-&gt;ifc_sctx;</a>
<a name="ln1389"> </a>
<a name="ln1390">	KASSERT(sctx-&gt;isc_q_align != 0, (&quot;alignment value not initialized&quot;));</a>
<a name="ln1391"> </a>
<a name="ln1392">	return (iflib_dma_alloc_align(ctx, size, sctx-&gt;isc_q_align, dma, mapflags));</a>
<a name="ln1393">}</a>
<a name="ln1394"> </a>
<a name="ln1395">int</a>
<a name="ln1396">iflib_dma_alloc_multi(if_ctx_t ctx, int *sizes, iflib_dma_info_t *dmalist, int mapflags, int count)</a>
<a name="ln1397">{</a>
<a name="ln1398">	int i, err;</a>
<a name="ln1399">	iflib_dma_info_t *dmaiter;</a>
<a name="ln1400"> </a>
<a name="ln1401">	dmaiter = dmalist;</a>
<a name="ln1402">	for (i = 0; i &lt; count; i++, dmaiter++) {</a>
<a name="ln1403">		if ((err = iflib_dma_alloc(ctx, sizes[i], *dmaiter, mapflags)) != 0)</a>
<a name="ln1404">			break;</a>
<a name="ln1405">	}</a>
<a name="ln1406">	if (err)</a>
<a name="ln1407">		iflib_dma_free_multi(dmalist, i);</a>
<a name="ln1408">	return (err);</a>
<a name="ln1409">}</a>
<a name="ln1410"> </a>
<a name="ln1411">void</a>
<a name="ln1412">iflib_dma_free(iflib_dma_info_t dma)</a>
<a name="ln1413">{</a>
<a name="ln1414">	if (dma-&gt;idi_tag == NULL)</a>
<a name="ln1415">		return;</a>
<a name="ln1416">	if (dma-&gt;idi_paddr != IF_BAD_DMA) {</a>
<a name="ln1417">		bus_dmamap_sync(dma-&gt;idi_tag, dma-&gt;idi_map,</a>
<a name="ln1418">		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);</a>
<a name="ln1419">		bus_dmamap_unload(dma-&gt;idi_tag, dma-&gt;idi_map);</a>
<a name="ln1420">		dma-&gt;idi_paddr = IF_BAD_DMA;</a>
<a name="ln1421">	}</a>
<a name="ln1422">	if (dma-&gt;idi_vaddr != NULL) {</a>
<a name="ln1423">		bus_dmamem_free(dma-&gt;idi_tag, dma-&gt;idi_vaddr, dma-&gt;idi_map);</a>
<a name="ln1424">		dma-&gt;idi_vaddr = NULL;</a>
<a name="ln1425">	}</a>
<a name="ln1426">	bus_dma_tag_destroy(dma-&gt;idi_tag);</a>
<a name="ln1427">	dma-&gt;idi_tag = NULL;</a>
<a name="ln1428">}</a>
<a name="ln1429"> </a>
<a name="ln1430">void</a>
<a name="ln1431">iflib_dma_free_multi(iflib_dma_info_t *dmalist, int count)</a>
<a name="ln1432">{</a>
<a name="ln1433">	int i;</a>
<a name="ln1434">	iflib_dma_info_t *dmaiter = dmalist;</a>
<a name="ln1435"> </a>
<a name="ln1436">	for (i = 0; i &lt; count; i++, dmaiter++)</a>
<a name="ln1437">		iflib_dma_free(*dmaiter);</a>
<a name="ln1438">}</a>
<a name="ln1439"> </a>
<a name="ln1440">#ifdef EARLY_AP_STARTUP</a>
<a name="ln1441">static const int iflib_started = 1;</a>
<a name="ln1442">#else</a>
<a name="ln1443">/*</a>
<a name="ln1444"> * We used to abuse the smp_started flag to decide if the queues have been</a>
<a name="ln1445"> * fully initialized (by late taskqgroup_adjust() calls in a SYSINIT()).</a>
<a name="ln1446"> * That gave bad races, since the SYSINIT() runs strictly after smp_started</a>
<a name="ln1447"> * is set.  Run a SYSINIT() strictly after that to just set a usable</a>
<a name="ln1448"> * completion flag.</a>
<a name="ln1449"> */</a>
<a name="ln1450"> </a>
<a name="ln1451">static int iflib_started;</a>
<a name="ln1452"> </a>
<a name="ln1453">static void</a>
<a name="ln1454">iflib_record_started(void *arg)</a>
<a name="ln1455">{</a>
<a name="ln1456">	iflib_started = 1;</a>
<a name="ln1457">}</a>
<a name="ln1458"> </a>
<a name="ln1459">SYSINIT(iflib_record_started, SI_SUB_SMP + 1, SI_ORDER_FIRST,</a>
<a name="ln1460">	iflib_record_started, NULL);</a>
<a name="ln1461">#endif</a>
<a name="ln1462"> </a>
<a name="ln1463">static int</a>
<a name="ln1464">iflib_fast_intr(void *arg)</a>
<a name="ln1465">{</a>
<a name="ln1466">	iflib_filter_info_t info = arg;</a>
<a name="ln1467">	struct grouptask *gtask = info-&gt;ifi_task;</a>
<a name="ln1468">	int result;</a>
<a name="ln1469"> </a>
<a name="ln1470">	if (!iflib_started)</a>
<a name="ln1471">		return (FILTER_STRAY);</a>
<a name="ln1472"> </a>
<a name="ln1473">	DBG_COUNTER_INC(fast_intrs);</a>
<a name="ln1474">	if (info-&gt;ifi_filter != NULL) {</a>
<a name="ln1475">		result = info-&gt;ifi_filter(info-&gt;ifi_filter_arg);</a>
<a name="ln1476">		if ((result &amp; FILTER_SCHEDULE_THREAD) == 0)</a>
<a name="ln1477">			return (result);</a>
<a name="ln1478">	}</a>
<a name="ln1479"> </a>
<a name="ln1480">	GROUPTASK_ENQUEUE(gtask);</a>
<a name="ln1481">	return (FILTER_SCHEDULE_THREAD);</a>
<a name="ln1482">}</a>
<a name="ln1483"> </a>
<a name="ln1484">static int</a>
<a name="ln1485">iflib_fast_intr_rxtx(void *arg)</a>
<a name="ln1486">{</a>
<a name="ln1487">	iflib_filter_info_t info = arg;</a>
<a name="ln1488">	struct grouptask *gtask = info-&gt;ifi_task;</a>
<a name="ln1489">	if_ctx_t ctx;</a>
<a name="ln1490">	iflib_rxq_t rxq = (iflib_rxq_t)info-&gt;ifi_ctx;</a>
<a name="ln1491">	iflib_txq_t txq;</a>
<a name="ln1492">	void *sc;</a>
<a name="ln1493">	int i, cidx, result;</a>
<a name="ln1494">	qidx_t txqid;</a>
<a name="ln1495"> </a>
<a name="ln1496">	if (!iflib_started)</a>
<a name="ln1497">		return (FILTER_STRAY);</a>
<a name="ln1498"> </a>
<a name="ln1499">	DBG_COUNTER_INC(fast_intrs);</a>
<a name="ln1500">	if (info-&gt;ifi_filter != NULL) {</a>
<a name="ln1501">		result = info-&gt;ifi_filter(info-&gt;ifi_filter_arg);</a>
<a name="ln1502">		if ((result &amp; FILTER_SCHEDULE_THREAD) == 0)</a>
<a name="ln1503">			return (result);</a>
<a name="ln1504">	}</a>
<a name="ln1505"> </a>
<a name="ln1506">	ctx = rxq-&gt;ifr_ctx;</a>
<a name="ln1507">	sc = ctx-&gt;ifc_softc;</a>
<a name="ln1508">	MPASS(rxq-&gt;ifr_ntxqirq);</a>
<a name="ln1509">	for (i = 0; i &lt; rxq-&gt;ifr_ntxqirq; i++) {</a>
<a name="ln1510">		txqid = rxq-&gt;ifr_txqid[i];</a>
<a name="ln1511">		txq = &amp;ctx-&gt;ifc_txqs[txqid];</a>
<a name="ln1512">		bus_dmamap_sync(txq-&gt;ift_ifdi-&gt;idi_tag, txq-&gt;ift_ifdi-&gt;idi_map,</a>
<a name="ln1513">		    BUS_DMASYNC_POSTREAD);</a>
<a name="ln1514">		if (!ctx-&gt;isc_txd_credits_update(sc, txqid, false)) {</a>
<a name="ln1515">			IFDI_TX_QUEUE_INTR_ENABLE(ctx, txqid);</a>
<a name="ln1516">			continue;</a>
<a name="ln1517">		}</a>
<a name="ln1518">		GROUPTASK_ENQUEUE(&amp;txq-&gt;ift_task);</a>
<a name="ln1519">	}</a>
<a name="ln1520">	if (ctx-&gt;ifc_sctx-&gt;isc_flags &amp; IFLIB_HAS_RXCQ)</a>
<a name="ln1521">		cidx = rxq-&gt;ifr_cq_cidx;</a>
<a name="ln1522">	else</a>
<a name="ln1523">		cidx = rxq-&gt;ifr_fl[0].ifl_cidx;</a>
<a name="ln1524">	if (iflib_rxd_avail(ctx, rxq, cidx, 1))</a>
<a name="ln1525">		GROUPTASK_ENQUEUE(gtask);</a>
<a name="ln1526">	else {</a>
<a name="ln1527">		IFDI_RX_QUEUE_INTR_ENABLE(ctx, rxq-&gt;ifr_id);</a>
<a name="ln1528">		DBG_COUNTER_INC(rx_intr_enables);</a>
<a name="ln1529">	}</a>
<a name="ln1530">	return (FILTER_SCHEDULE_THREAD);</a>
<a name="ln1531">}</a>
<a name="ln1532"> </a>
<a name="ln1533"> </a>
<a name="ln1534">static int</a>
<a name="ln1535">iflib_fast_intr_ctx(void *arg)</a>
<a name="ln1536">{</a>
<a name="ln1537">	iflib_filter_info_t info = arg;</a>
<a name="ln1538">	struct grouptask *gtask = info-&gt;ifi_task;</a>
<a name="ln1539">	int result;</a>
<a name="ln1540"> </a>
<a name="ln1541">	if (!iflib_started)</a>
<a name="ln1542">		return (FILTER_STRAY);</a>
<a name="ln1543"> </a>
<a name="ln1544">	DBG_COUNTER_INC(fast_intrs);</a>
<a name="ln1545">	if (info-&gt;ifi_filter != NULL) {</a>
<a name="ln1546">		result = info-&gt;ifi_filter(info-&gt;ifi_filter_arg);</a>
<a name="ln1547">		if ((result &amp; FILTER_SCHEDULE_THREAD) == 0)</a>
<a name="ln1548">			return (result);</a>
<a name="ln1549">	}</a>
<a name="ln1550"> </a>
<a name="ln1551">	GROUPTASK_ENQUEUE(gtask);</a>
<a name="ln1552">	return (FILTER_SCHEDULE_THREAD);</a>
<a name="ln1553">}</a>
<a name="ln1554"> </a>
<a name="ln1555">static int</a>
<a name="ln1556">_iflib_irq_alloc(if_ctx_t ctx, if_irq_t irq, int rid,</a>
<a name="ln1557">		 driver_filter_t filter, driver_intr_t handler, void *arg,</a>
<a name="ln1558">		 const char *name)</a>
<a name="ln1559">{</a>
<a name="ln1560">	int rc, flags;</a>
<a name="ln1561">	struct resource *res;</a>
<a name="ln1562">	void *tag = NULL;</a>
<a name="ln1563">	device_t dev = ctx-&gt;ifc_dev;</a>
<a name="ln1564"> </a>
<a name="ln1565">	flags = RF_ACTIVE;</a>
<a name="ln1566">	if (ctx-&gt;ifc_flags &amp; IFC_LEGACY)</a>
<a name="ln1567">		flags |= RF_SHAREABLE;</a>
<a name="ln1568">	MPASS(rid &lt; 512);</a>
<a name="ln1569">	irq-&gt;ii_rid = rid;</a>
<a name="ln1570">	res = bus_alloc_resource_any(dev, SYS_RES_IRQ, &amp;irq-&gt;ii_rid, flags);</a>
<a name="ln1571">	if (res == NULL) {</a>
<a name="ln1572">		device_printf(dev,</a>
<a name="ln1573">		    &quot;failed to allocate IRQ for rid %d, name %s.\n&quot;, rid, name);</a>
<a name="ln1574">		return (ENOMEM);</a>
<a name="ln1575">	}</a>
<a name="ln1576">	irq-&gt;ii_res = res;</a>
<a name="ln1577">	KASSERT(filter == NULL || handler == NULL, (&quot;filter and handler can't both be non-NULL&quot;));</a>
<a name="ln1578">	rc = bus_setup_intr(dev, res, INTR_MPSAFE | INTR_TYPE_NET,</a>
<a name="ln1579">						filter, handler, arg, &amp;tag);</a>
<a name="ln1580">	if (rc != 0) {</a>
<a name="ln1581">		device_printf(dev,</a>
<a name="ln1582">		    &quot;failed to setup interrupt for rid %d, name %s: %d\n&quot;,</a>
<a name="ln1583">					  rid, name ? name : &quot;unknown&quot;, rc);</a>
<a name="ln1584">		return (rc);</a>
<a name="ln1585">	} else if (name)</a>
<a name="ln1586">		bus_describe_intr(dev, res, tag, &quot;%s&quot;, name);</a>
<a name="ln1587"> </a>
<a name="ln1588">	irq-&gt;ii_tag = tag;</a>
<a name="ln1589">	return (0);</a>
<a name="ln1590">}</a>
<a name="ln1591"> </a>
<a name="ln1592"> </a>
<a name="ln1593">/*********************************************************************</a>
<a name="ln1594"> *</a>
<a name="ln1595"> *  Allocate DMA resources for TX buffers as well as memory for the TX</a>
<a name="ln1596"> *  mbuf map.  TX DMA maps (non-TSO/TSO) and TX mbuf map are kept in a</a>
<a name="ln1597"> *  iflib_sw_tx_desc_array structure, storing all the information that</a>
<a name="ln1598"> *  is needed to transmit a packet on the wire.  This is called only</a>
<a name="ln1599"> *  once at attach, setup is done every reset.</a>
<a name="ln1600"> *</a>
<a name="ln1601"> **********************************************************************/</a>
<a name="ln1602">static int</a>
<a name="ln1603">iflib_txsd_alloc(iflib_txq_t txq)</a>
<a name="ln1604">{</a>
<a name="ln1605">	if_ctx_t ctx = txq-&gt;ift_ctx;</a>
<a name="ln1606">	if_shared_ctx_t sctx = ctx-&gt;ifc_sctx;</a>
<a name="ln1607">	if_softc_ctx_t scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln1608">	device_t dev = ctx-&gt;ifc_dev;</a>
<a name="ln1609">	bus_size_t tsomaxsize;</a>
<a name="ln1610">	int err, nsegments, ntsosegments;</a>
<a name="ln1611">	bool tso;</a>
<a name="ln1612">	int i;</a>
<a name="ln1613"> </a>
<a name="ln1614">	nsegments = scctx-&gt;isc_tx_nsegments;</a>
<a name="ln1615">	ntsosegments = scctx-&gt;isc_tx_tso_segments_max;</a>
<a name="ln1616">	tsomaxsize = scctx-&gt;isc_tx_tso_size_max;</a>
<a name="ln1617">	if (if_getcapabilities(ctx-&gt;ifc_ifp) &amp; IFCAP_VLAN_MTU)</a>
<a name="ln1618">		tsomaxsize += sizeof(struct ether_vlan_header);</a>
<a name="ln1619">	MPASS(scctx-&gt;isc_ntxd[0] &gt; 0);</a>
<a name="ln1620">	MPASS(scctx-&gt;isc_ntxd[txq-&gt;ift_br_offset] &gt; 0);</a>
<a name="ln1621">	MPASS(nsegments &gt; 0);</a>
<a name="ln1622">	if (if_getcapabilities(ctx-&gt;ifc_ifp) &amp; IFCAP_TSO) {</a>
<a name="ln1623">		MPASS(ntsosegments &gt; 0);</a>
<a name="ln1624">		MPASS(sctx-&gt;isc_tso_maxsize &gt;= tsomaxsize);</a>
<a name="ln1625">	}</a>
<a name="ln1626"> </a>
<a name="ln1627">	/*</a>
<a name="ln1628">	 * Set up DMA tags for TX buffers.</a>
<a name="ln1629">	 */</a>
<a name="ln1630">	if ((err = bus_dma_tag_create(bus_get_dma_tag(dev),</a>
<a name="ln1631">			       1, 0,			/* alignment, bounds */</a>
<a name="ln1632">			       BUS_SPACE_MAXADDR,	/* lowaddr */</a>
<a name="ln1633">			       BUS_SPACE_MAXADDR,	/* highaddr */</a>
<a name="ln1634">			       NULL, NULL,		/* filter, filterarg */</a>
<a name="ln1635">			       sctx-&gt;isc_tx_maxsize,		/* maxsize */</a>
<a name="ln1636">			       nsegments,	/* nsegments */</a>
<a name="ln1637">			       sctx-&gt;isc_tx_maxsegsize,	/* maxsegsize */</a>
<a name="ln1638">			       0,			/* flags */</a>
<a name="ln1639">			       NULL,			/* lockfunc */</a>
<a name="ln1640">			       NULL,			/* lockfuncarg */</a>
<a name="ln1641">			       &amp;txq-&gt;ift_buf_tag))) {</a>
<a name="ln1642">		device_printf(dev,&quot;Unable to allocate TX DMA tag: %d\n&quot;, err);</a>
<a name="ln1643">		device_printf(dev,&quot;maxsize: %ju nsegments: %d maxsegsize: %ju\n&quot;,</a>
<a name="ln1644">		    (uintmax_t)sctx-&gt;isc_tx_maxsize, nsegments, (uintmax_t)sctx-&gt;isc_tx_maxsegsize);</a>
<a name="ln1645">		goto fail;</a>
<a name="ln1646">	}</a>
<a name="ln1647">	tso = (if_getcapabilities(ctx-&gt;ifc_ifp) &amp; IFCAP_TSO) != 0;</a>
<a name="ln1648">	if (tso &amp;&amp; (err = bus_dma_tag_create(bus_get_dma_tag(dev),</a>
<a name="ln1649">			       1, 0,			/* alignment, bounds */</a>
<a name="ln1650">			       BUS_SPACE_MAXADDR,	/* lowaddr */</a>
<a name="ln1651">			       BUS_SPACE_MAXADDR,	/* highaddr */</a>
<a name="ln1652">			       NULL, NULL,		/* filter, filterarg */</a>
<a name="ln1653">			       tsomaxsize,		/* maxsize */</a>
<a name="ln1654">			       ntsosegments,	/* nsegments */</a>
<a name="ln1655">			       sctx-&gt;isc_tso_maxsegsize,/* maxsegsize */</a>
<a name="ln1656">			       0,			/* flags */</a>
<a name="ln1657">			       NULL,			/* lockfunc */</a>
<a name="ln1658">			       NULL,			/* lockfuncarg */</a>
<a name="ln1659">			       &amp;txq-&gt;ift_tso_buf_tag))) {</a>
<a name="ln1660">		device_printf(dev, &quot;Unable to allocate TSO TX DMA tag: %d\n&quot;,</a>
<a name="ln1661">		    err);</a>
<a name="ln1662">		goto fail;</a>
<a name="ln1663">	}</a>
<a name="ln1664"> </a>
<a name="ln1665">	/* Allocate memory for the TX mbuf map. */</a>
<a name="ln1666">	if (!(txq-&gt;ift_sds.ifsd_m =</a>
<a name="ln1667">	    (struct mbuf **) malloc(sizeof(struct mbuf *) *</a>
<a name="ln1668">	    scctx-&gt;isc_ntxd[txq-&gt;ift_br_offset], M_IFLIB, M_NOWAIT | M_ZERO))) {</a>
<a name="ln1669">		device_printf(dev, &quot;Unable to allocate TX mbuf map memory\n&quot;);</a>
<a name="ln1670">		err = ENOMEM;</a>
<a name="ln1671">		goto fail;</a>
<a name="ln1672">	}</a>
<a name="ln1673"> </a>
<a name="ln1674">	/*</a>
<a name="ln1675">	 * Create the DMA maps for TX buffers.</a>
<a name="ln1676">	 */</a>
<a name="ln1677">	if ((txq-&gt;ift_sds.ifsd_map = (bus_dmamap_t *)malloc(</a>
<a name="ln1678">	    sizeof(bus_dmamap_t) * scctx-&gt;isc_ntxd[txq-&gt;ift_br_offset],</a>
<a name="ln1679">	    M_IFLIB, M_NOWAIT | M_ZERO)) == NULL) {</a>
<a name="ln1680">		device_printf(dev,</a>
<a name="ln1681">		    &quot;Unable to allocate TX buffer DMA map memory\n&quot;);</a>
<a name="ln1682">		err = ENOMEM;</a>
<a name="ln1683">		goto fail;</a>
<a name="ln1684">	}</a>
<a name="ln1685">	if (tso &amp;&amp; (txq-&gt;ift_sds.ifsd_tso_map = (bus_dmamap_t *)malloc(</a>
<a name="ln1686">	    sizeof(bus_dmamap_t) * scctx-&gt;isc_ntxd[txq-&gt;ift_br_offset],</a>
<a name="ln1687">	    M_IFLIB, M_NOWAIT | M_ZERO)) == NULL) {</a>
<a name="ln1688">		device_printf(dev,</a>
<a name="ln1689">		    &quot;Unable to allocate TSO TX buffer map memory\n&quot;);</a>
<a name="ln1690">		err = ENOMEM;</a>
<a name="ln1691">		goto fail;</a>
<a name="ln1692">	}</a>
<a name="ln1693">	for (i = 0; i &lt; scctx-&gt;isc_ntxd[txq-&gt;ift_br_offset]; i++) {</a>
<a name="ln1694">		err = bus_dmamap_create(txq-&gt;ift_buf_tag, 0,</a>
<a name="ln1695">		    &amp;txq-&gt;ift_sds.ifsd_map[i]);</a>
<a name="ln1696">		if (err != 0) {</a>
<a name="ln1697">			device_printf(dev, &quot;Unable to create TX DMA map\n&quot;);</a>
<a name="ln1698">			goto fail;</a>
<a name="ln1699">		}</a>
<a name="ln1700">		if (!tso)</a>
<a name="ln1701">			continue;</a>
<a name="ln1702">		err = bus_dmamap_create(txq-&gt;ift_tso_buf_tag, 0,</a>
<a name="ln1703">		    &amp;txq-&gt;ift_sds.ifsd_tso_map[i]);</a>
<a name="ln1704">		if (err != 0) {</a>
<a name="ln1705">			device_printf(dev, &quot;Unable to create TSO TX DMA map\n&quot;);</a>
<a name="ln1706">			goto fail;</a>
<a name="ln1707">		}</a>
<a name="ln1708">	}</a>
<a name="ln1709">	return (0);</a>
<a name="ln1710">fail:</a>
<a name="ln1711">	/* We free all, it handles case where we are in the middle */</a>
<a name="ln1712">	iflib_tx_structures_free(ctx);</a>
<a name="ln1713">	return (err);</a>
<a name="ln1714">}</a>
<a name="ln1715"> </a>
<a name="ln1716">static void</a>
<a name="ln1717">iflib_txsd_destroy(if_ctx_t ctx, iflib_txq_t txq, int i)</a>
<a name="ln1718">{</a>
<a name="ln1719">	bus_dmamap_t map;</a>
<a name="ln1720"> </a>
<a name="ln1721">	map = NULL;</a>
<a name="ln1722">	if (txq-&gt;ift_sds.ifsd_map != NULL)</a>
<a name="ln1723">		map = txq-&gt;ift_sds.ifsd_map[i];</a>
<a name="ln1724">	if (map != NULL) {</a>
<a name="ln1725">		bus_dmamap_sync(txq-&gt;ift_buf_tag, map, BUS_DMASYNC_POSTWRITE);</a>
<a name="ln1726">		bus_dmamap_unload(txq-&gt;ift_buf_tag, map);</a>
<a name="ln1727">		bus_dmamap_destroy(txq-&gt;ift_buf_tag, map);</a>
<a name="ln1728">		txq-&gt;ift_sds.ifsd_map[i] = NULL;</a>
<a name="ln1729">	}</a>
<a name="ln1730"> </a>
<a name="ln1731">	map = NULL;</a>
<a name="ln1732">	if (txq-&gt;ift_sds.ifsd_tso_map != NULL)</a>
<a name="ln1733">		map = txq-&gt;ift_sds.ifsd_tso_map[i];</a>
<a name="ln1734">	if (map != NULL) {</a>
<a name="ln1735">		bus_dmamap_sync(txq-&gt;ift_tso_buf_tag, map,</a>
<a name="ln1736">		    BUS_DMASYNC_POSTWRITE);</a>
<a name="ln1737">		bus_dmamap_unload(txq-&gt;ift_tso_buf_tag, map);</a>
<a name="ln1738">		bus_dmamap_destroy(txq-&gt;ift_tso_buf_tag, map);</a>
<a name="ln1739">		txq-&gt;ift_sds.ifsd_tso_map[i] = NULL;</a>
<a name="ln1740">	}</a>
<a name="ln1741">}</a>
<a name="ln1742"> </a>
<a name="ln1743">static void</a>
<a name="ln1744">iflib_txq_destroy(iflib_txq_t txq)</a>
<a name="ln1745">{</a>
<a name="ln1746">	if_ctx_t ctx = txq-&gt;ift_ctx;</a>
<a name="ln1747">	int i;</a>
<a name="ln1748"> </a>
<a name="ln1749">	for (i = 0; i &lt; txq-&gt;ift_size; i++)</a>
<a name="ln1750">		iflib_txsd_destroy(ctx, txq, i);</a>
<a name="ln1751">	if (txq-&gt;ift_sds.ifsd_map != NULL) {</a>
<a name="ln1752">		free(txq-&gt;ift_sds.ifsd_map, M_IFLIB);</a>
<a name="ln1753">		txq-&gt;ift_sds.ifsd_map = NULL;</a>
<a name="ln1754">	}</a>
<a name="ln1755">	if (txq-&gt;ift_sds.ifsd_tso_map != NULL) {</a>
<a name="ln1756">		free(txq-&gt;ift_sds.ifsd_tso_map, M_IFLIB);</a>
<a name="ln1757">		txq-&gt;ift_sds.ifsd_tso_map = NULL;</a>
<a name="ln1758">	}</a>
<a name="ln1759">	if (txq-&gt;ift_sds.ifsd_m != NULL) {</a>
<a name="ln1760">		free(txq-&gt;ift_sds.ifsd_m, M_IFLIB);</a>
<a name="ln1761">		txq-&gt;ift_sds.ifsd_m = NULL;</a>
<a name="ln1762">	}</a>
<a name="ln1763">	if (txq-&gt;ift_buf_tag != NULL) {</a>
<a name="ln1764">		bus_dma_tag_destroy(txq-&gt;ift_buf_tag);</a>
<a name="ln1765">		txq-&gt;ift_buf_tag = NULL;</a>
<a name="ln1766">	}</a>
<a name="ln1767">	if (txq-&gt;ift_tso_buf_tag != NULL) {</a>
<a name="ln1768">		bus_dma_tag_destroy(txq-&gt;ift_tso_buf_tag);</a>
<a name="ln1769">		txq-&gt;ift_tso_buf_tag = NULL;</a>
<a name="ln1770">	}</a>
<a name="ln1771">}</a>
<a name="ln1772"> </a>
<a name="ln1773">static void</a>
<a name="ln1774">iflib_txsd_free(if_ctx_t ctx, iflib_txq_t txq, int i)</a>
<a name="ln1775">{</a>
<a name="ln1776">	struct mbuf **mp;</a>
<a name="ln1777"> </a>
<a name="ln1778">	mp = &amp;txq-&gt;ift_sds.ifsd_m[i];</a>
<a name="ln1779">	if (*mp == NULL)</a>
<a name="ln1780">		return;</a>
<a name="ln1781"> </a>
<a name="ln1782">	if (txq-&gt;ift_sds.ifsd_map != NULL) {</a>
<a name="ln1783">		bus_dmamap_sync(txq-&gt;ift_buf_tag,</a>
<a name="ln1784">		    txq-&gt;ift_sds.ifsd_map[i], BUS_DMASYNC_POSTWRITE);</a>
<a name="ln1785">		bus_dmamap_unload(txq-&gt;ift_buf_tag, txq-&gt;ift_sds.ifsd_map[i]);</a>
<a name="ln1786">	}</a>
<a name="ln1787">	if (txq-&gt;ift_sds.ifsd_tso_map != NULL) {</a>
<a name="ln1788">		bus_dmamap_sync(txq-&gt;ift_tso_buf_tag,</a>
<a name="ln1789">		    txq-&gt;ift_sds.ifsd_tso_map[i], BUS_DMASYNC_POSTWRITE);</a>
<a name="ln1790">		bus_dmamap_unload(txq-&gt;ift_tso_buf_tag,</a>
<a name="ln1791">		    txq-&gt;ift_sds.ifsd_tso_map[i]);</a>
<a name="ln1792">	}</a>
<a name="ln1793">	m_free(*mp);</a>
<a name="ln1794">	DBG_COUNTER_INC(tx_frees);</a>
<a name="ln1795">	*mp = NULL;</a>
<a name="ln1796">}</a>
<a name="ln1797"> </a>
<a name="ln1798">static int</a>
<a name="ln1799">iflib_txq_setup(iflib_txq_t txq)</a>
<a name="ln1800">{</a>
<a name="ln1801">	if_ctx_t ctx = txq-&gt;ift_ctx;</a>
<a name="ln1802">	if_softc_ctx_t scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln1803">	if_shared_ctx_t sctx = ctx-&gt;ifc_sctx;</a>
<a name="ln1804">	iflib_dma_info_t di;</a>
<a name="ln1805">	int i;</a>
<a name="ln1806"> </a>
<a name="ln1807">	/* Set number of descriptors available */</a>
<a name="ln1808">	txq-&gt;ift_qstatus = IFLIB_QUEUE_IDLE;</a>
<a name="ln1809">	/* XXX make configurable */</a>
<a name="ln1810">	txq-&gt;ift_update_freq = IFLIB_DEFAULT_TX_UPDATE_FREQ;</a>
<a name="ln1811"> </a>
<a name="ln1812">	/* Reset indices */</a>
<a name="ln1813">	txq-&gt;ift_cidx_processed = 0;</a>
<a name="ln1814">	txq-&gt;ift_pidx = txq-&gt;ift_cidx = txq-&gt;ift_npending = 0;</a>
<a name="ln1815">	txq-&gt;ift_size = scctx-&gt;isc_ntxd[txq-&gt;ift_br_offset];</a>
<a name="ln1816"> </a>
<a name="ln1817">	for (i = 0, di = txq-&gt;ift_ifdi; i &lt; sctx-&gt;isc_ntxqs; i++, di++)</a>
<a name="ln1818">		bzero((void *)di-&gt;idi_vaddr, di-&gt;idi_size);</a>
<a name="ln1819"> </a>
<a name="ln1820">	IFDI_TXQ_SETUP(ctx, txq-&gt;ift_id);</a>
<a name="ln1821">	for (i = 0, di = txq-&gt;ift_ifdi; i &lt; sctx-&gt;isc_ntxqs; i++, di++)</a>
<a name="ln1822">		bus_dmamap_sync(di-&gt;idi_tag, di-&gt;idi_map,</a>
<a name="ln1823">		    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);</a>
<a name="ln1824">	return (0);</a>
<a name="ln1825">}</a>
<a name="ln1826"> </a>
<a name="ln1827">/*********************************************************************</a>
<a name="ln1828"> *</a>
<a name="ln1829"> *  Allocate DMA resources for RX buffers as well as memory for the RX</a>
<a name="ln1830"> *  mbuf map, direct RX cluster pointer map and RX cluster bus address</a>
<a name="ln1831"> *  map.  RX DMA map, RX mbuf map, direct RX cluster pointer map and</a>
<a name="ln1832"> *  RX cluster map are kept in a iflib_sw_rx_desc_array structure.</a>
<a name="ln1833"> *  Since we use use one entry in iflib_sw_rx_desc_array per received</a>
<a name="ln1834"> *  packet, the maximum number of entries we'll need is equal to the</a>
<a name="ln1835"> *  number of hardware receive descriptors that we've allocated.</a>
<a name="ln1836"> *</a>
<a name="ln1837"> **********************************************************************/</a>
<a name="ln1838">static int</a>
<a name="ln1839">iflib_rxsd_alloc(iflib_rxq_t rxq)</a>
<a name="ln1840">{</a>
<a name="ln1841">	if_ctx_t ctx = rxq-&gt;ifr_ctx;</a>
<a name="ln1842">	if_shared_ctx_t sctx = ctx-&gt;ifc_sctx;</a>
<a name="ln1843">	if_softc_ctx_t scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln1844">	device_t dev = ctx-&gt;ifc_dev;</a>
<a name="ln1845">	iflib_fl_t fl;</a>
<a name="ln1846">	int			err;</a>
<a name="ln1847">	int i;</a>
<a name="ln1848"> </a>
<a name="ln1849">	MPASS(scctx-&gt;isc_nrxd[0] &gt; 0);</a>
<a name="ln1850">	MPASS(scctx-&gt;isc_nrxd[rxq-&gt;ifr_fl_offset] &gt; 0);</a>
<a name="ln1851"> </a>
<a name="ln1852">	fl = rxq-&gt;ifr_fl;</a>
<a name="ln1853">	for (i = 0; i &lt;  rxq-&gt;ifr_nfl; i++, fl++) {</a>
<a name="ln1854">		fl-&gt;ifl_size = scctx-&gt;isc_nrxd[rxq-&gt;ifr_fl_offset]; /* this isn't necessarily the same */</a>
<a name="ln1855">		/* Set up DMA tag for RX buffers. */</a>
<a name="ln1856">		err = bus_dma_tag_create(bus_get_dma_tag(dev), /* parent */</a>
<a name="ln1857">					 1, 0,			/* alignment, bounds */</a>
<a name="ln1858">					 BUS_SPACE_MAXADDR,	/* lowaddr */</a>
<a name="ln1859">					 BUS_SPACE_MAXADDR,	/* highaddr */</a>
<a name="ln1860">					 NULL, NULL,		/* filter, filterarg */</a>
<a name="ln1861">					 sctx-&gt;isc_rx_maxsize,	/* maxsize */</a>
<a name="ln1862">					 sctx-&gt;isc_rx_nsegments,	/* nsegments */</a>
<a name="ln1863">					 sctx-&gt;isc_rx_maxsegsize,	/* maxsegsize */</a>
<a name="ln1864">					 0,			/* flags */</a>
<a name="ln1865">					 NULL,			/* lockfunc */</a>
<a name="ln1866">					 NULL,			/* lockarg */</a>
<a name="ln1867">					 &amp;fl-&gt;ifl_buf_tag);</a>
<a name="ln1868">		if (err) {</a>
<a name="ln1869">			device_printf(dev,</a>
<a name="ln1870">			    &quot;Unable to allocate RX DMA tag: %d\n&quot;, err);</a>
<a name="ln1871">			goto fail;</a>
<a name="ln1872">		}</a>
<a name="ln1873"> </a>
<a name="ln1874">		/* Allocate memory for the RX mbuf map. */</a>
<a name="ln1875">		if (!(fl-&gt;ifl_sds.ifsd_m =</a>
<a name="ln1876">		      (struct mbuf **) malloc(sizeof(struct mbuf *) *</a>
<a name="ln1877">					      scctx-&gt;isc_nrxd[rxq-&gt;ifr_fl_offset], M_IFLIB, M_NOWAIT | M_ZERO))) {</a>
<a name="ln1878">			device_printf(dev,</a>
<a name="ln1879">			    &quot;Unable to allocate RX mbuf map memory\n&quot;);</a>
<a name="ln1880">			err = ENOMEM;</a>
<a name="ln1881">			goto fail;</a>
<a name="ln1882">		}</a>
<a name="ln1883"> </a>
<a name="ln1884">		/* Allocate memory for the direct RX cluster pointer map. */</a>
<a name="ln1885">		if (!(fl-&gt;ifl_sds.ifsd_cl =</a>
<a name="ln1886">		      (caddr_t *) malloc(sizeof(caddr_t) *</a>
<a name="ln1887">					      scctx-&gt;isc_nrxd[rxq-&gt;ifr_fl_offset], M_IFLIB, M_NOWAIT | M_ZERO))) {</a>
<a name="ln1888">			device_printf(dev,</a>
<a name="ln1889">			    &quot;Unable to allocate RX cluster map memory\n&quot;);</a>
<a name="ln1890">			err = ENOMEM;</a>
<a name="ln1891">			goto fail;</a>
<a name="ln1892">		}</a>
<a name="ln1893"> </a>
<a name="ln1894">		/* Allocate memory for the RX cluster bus address map. */</a>
<a name="ln1895">		if (!(fl-&gt;ifl_sds.ifsd_ba =</a>
<a name="ln1896">		      (bus_addr_t *) malloc(sizeof(bus_addr_t) *</a>
<a name="ln1897">					      scctx-&gt;isc_nrxd[rxq-&gt;ifr_fl_offset], M_IFLIB, M_NOWAIT | M_ZERO))) {</a>
<a name="ln1898">			device_printf(dev,</a>
<a name="ln1899">			    &quot;Unable to allocate RX bus address map memory\n&quot;);</a>
<a name="ln1900">			err = ENOMEM;</a>
<a name="ln1901">			goto fail;</a>
<a name="ln1902">		}</a>
<a name="ln1903"> </a>
<a name="ln1904">		/*</a>
<a name="ln1905">		 * Create the DMA maps for RX buffers.</a>
<a name="ln1906">		 */</a>
<a name="ln1907">		if (!(fl-&gt;ifl_sds.ifsd_map =</a>
<a name="ln1908">		      (bus_dmamap_t *) malloc(sizeof(bus_dmamap_t) * scctx-&gt;isc_nrxd[rxq-&gt;ifr_fl_offset], M_IFLIB, M_NOWAIT | M_ZERO))) {</a>
<a name="ln1909">			device_printf(dev,</a>
<a name="ln1910">			    &quot;Unable to allocate RX buffer DMA map memory\n&quot;);</a>
<a name="ln1911">			err = ENOMEM;</a>
<a name="ln1912">			goto fail;</a>
<a name="ln1913">		}</a>
<a name="ln1914">		{</a>
<a name="ln1915">		int i;</a>
<a name="ln1916">		for (i = 0; i &lt; scctx-&gt;isc_nrxd[rxq-&gt;ifr_fl_offset]; i++) {</a>
<a name="ln1917">			err = bus_dmamap_create(fl-&gt;ifl_buf_tag, 0,</a>
<a name="ln1918">			    &amp;fl-&gt;ifl_sds.ifsd_map[i]);</a>
<a name="ln1919">			if (err != 0) {</a>
<a name="ln1920">				device_printf(dev, &quot;Unable to create RX buffer DMA map\n&quot;);</a>
<a name="ln1921">				goto fail;</a>
<a name="ln1922">			}</a>
<a name="ln1923">		}</a>
<a name="ln1924">		}</a>
<a name="ln1925">	}</a>
<a name="ln1926">	return (0);</a>
<a name="ln1927"> </a>
<a name="ln1928">fail:</a>
<a name="ln1929">	iflib_rx_structures_free(ctx);</a>
<a name="ln1930">	return (err);</a>
<a name="ln1931">}</a>
<a name="ln1932"> </a>
<a name="ln1933"> </a>
<a name="ln1934">/*</a>
<a name="ln1935"> * Internal service routines</a>
<a name="ln1936"> */</a>
<a name="ln1937"> </a>
<a name="ln1938">struct rxq_refill_cb_arg {</a>
<a name="ln1939">	int               error;</a>
<a name="ln1940">	bus_dma_segment_t seg;</a>
<a name="ln1941">	int               nseg;</a>
<a name="ln1942">};</a>
<a name="ln1943"> </a>
<a name="ln1944">static void</a>
<a name="ln1945">_rxq_refill_cb(void *arg, bus_dma_segment_t *segs, int nseg, int error)</a>
<a name="ln1946">{</a>
<a name="ln1947">	struct rxq_refill_cb_arg *cb_arg = arg;</a>
<a name="ln1948"> </a>
<a name="ln1949">	cb_arg-&gt;error = error;</a>
<a name="ln1950">	cb_arg-&gt;seg = segs[0];</a>
<a name="ln1951">	cb_arg-&gt;nseg = nseg;</a>
<a name="ln1952">}</a>
<a name="ln1953"> </a>
<a name="ln1954">/**</a>
<a name="ln1955"> *	rxq_refill - refill an rxq  free-buffer list</a>
<a name="ln1956"> *	@ctx: the iflib context</a>
<a name="ln1957"> *	@rxq: the free-list to refill</a>
<a name="ln1958"> *	@n: the number of new buffers to allocate</a>
<a name="ln1959"> *</a>
<a name="ln1960"> *	(Re)populate an rxq free-buffer list with up to @n new packet buffers.</a>
<a name="ln1961"> *	The caller must assure that @n does not exceed the queue's capacity.</a>
<a name="ln1962"> */</a>
<a name="ln1963">static void</a>
<a name="ln1964">_iflib_fl_refill(if_ctx_t ctx, iflib_fl_t fl, int count)</a>
<a name="ln1965">{</a>
<a name="ln1966">	struct if_rxd_update iru;</a>
<a name="ln1967">	struct rxq_refill_cb_arg cb_arg;</a>
<a name="ln1968">	struct mbuf *m;</a>
<a name="ln1969">	caddr_t cl, *sd_cl;</a>
<a name="ln1970">	struct mbuf **sd_m;</a>
<a name="ln1971">	bus_dmamap_t *sd_map;</a>
<a name="ln1972">	bus_addr_t bus_addr, *sd_ba;</a>
<a name="ln1973">	int err, frag_idx, i, idx, n, pidx;</a>
<a name="ln1974">	qidx_t credits;</a>
<a name="ln1975"> </a>
<a name="ln1976">	sd_m = fl-&gt;ifl_sds.ifsd_m;</a>
<a name="ln1977">	sd_map = fl-&gt;ifl_sds.ifsd_map;</a>
<a name="ln1978">	sd_cl = fl-&gt;ifl_sds.ifsd_cl;</a>
<a name="ln1979">	sd_ba = fl-&gt;ifl_sds.ifsd_ba;</a>
<a name="ln1980">	pidx = fl-&gt;ifl_pidx;</a>
<a name="ln1981">	idx = pidx;</a>
<a name="ln1982">	frag_idx = fl-&gt;ifl_fragidx;</a>
<a name="ln1983">	credits = fl-&gt;ifl_credits;</a>
<a name="ln1984"> </a>
<a name="ln1985">	i = 0;</a>
<a name="ln1986">	n = count;</a>
<a name="ln1987">	MPASS(n &gt; 0);</a>
<a name="ln1988">	MPASS(credits + n &lt;= fl-&gt;ifl_size);</a>
<a name="ln1989"> </a>
<a name="ln1990">	if (pidx &lt; fl-&gt;ifl_cidx)</a>
<a name="ln1991">		MPASS(pidx + n &lt;= fl-&gt;ifl_cidx);</a>
<a name="ln1992">	if (pidx == fl-&gt;ifl_cidx &amp;&amp; (credits &lt; fl-&gt;ifl_size))</a>
<a name="ln1993">		MPASS(fl-&gt;ifl_gen == 0);</a>
<a name="ln1994">	if (pidx &gt; fl-&gt;ifl_cidx)</a>
<a name="ln1995">		MPASS(n &lt;= fl-&gt;ifl_size - pidx + fl-&gt;ifl_cidx);</a>
<a name="ln1996"> </a>
<a name="ln1997">	DBG_COUNTER_INC(fl_refills);</a>
<a name="ln1998">	if (n &gt; 8)</a>
<a name="ln1999">		DBG_COUNTER_INC(fl_refills_large);</a>
<a name="ln2000">	iru_init(&amp;iru, fl-&gt;ifl_rxq, fl-&gt;ifl_id);</a>
<a name="ln2001">	while (n--) {</a>
<a name="ln2002">		/*</a>
<a name="ln2003">		 * We allocate an uninitialized mbuf + cluster, mbuf is</a>
<a name="ln2004">		 * initialized after rx.</a>
<a name="ln2005">		 *</a>
<a name="ln2006">		 * If the cluster is still set then we know a minimum sized packet was received</a>
<a name="ln2007">		 */</a>
<a name="ln2008">		bit_ffc_at(fl-&gt;ifl_rx_bitmap, frag_idx, fl-&gt;ifl_size,</a>
<a name="ln2009">		    &amp;frag_idx);</a>
<a name="ln2010">		if (frag_idx &lt; 0)</a>
<a name="ln2011">			bit_ffc(fl-&gt;ifl_rx_bitmap, fl-&gt;ifl_size, &amp;frag_idx);</a>
<a name="ln2012">		MPASS(frag_idx &gt;= 0);</a>
<a name="ln2013">		if ((cl = sd_cl[frag_idx]) == NULL) {</a>
<a name="ln2014">			if ((cl = m_cljget(NULL, M_NOWAIT, fl-&gt;ifl_buf_size)) == NULL)</a>
<a name="ln2015">				break;</a>
<a name="ln2016"> </a>
<a name="ln2017">			cb_arg.error = 0;</a>
<a name="ln2018">			MPASS(sd_map != NULL);</a>
<a name="ln2019">			err = bus_dmamap_load(fl-&gt;ifl_buf_tag, sd_map[frag_idx],</a>
<a name="ln2020">			    cl, fl-&gt;ifl_buf_size, _rxq_refill_cb, &amp;cb_arg,</a>
<a name="ln2021">			    BUS_DMA_NOWAIT);</a>
<a name="ln2022">			if (err != 0 || cb_arg.error) {</a>
<a name="ln2023">				/*</a>
<a name="ln2024">				 * !zone_pack ?</a>
<a name="ln2025">				 */</a>
<a name="ln2026">#ifndef __HAIKU__</a>
<a name="ln2027">				if (fl-&gt;ifl_zone == zone_pack)</a>
<a name="ln2028">					uma_zfree(fl-&gt;ifl_zone, cl);</a>
<a name="ln2029">#endif</a>
<a name="ln2030">				break;</a>
<a name="ln2031">			}</a>
<a name="ln2032"> </a>
<a name="ln2033">			sd_ba[frag_idx] =  bus_addr = cb_arg.seg.ds_addr;</a>
<a name="ln2034">			sd_cl[frag_idx] = cl;</a>
<a name="ln2035">#if MEMORY_LOGGING</a>
<a name="ln2036">			fl-&gt;ifl_cl_enqueued++;</a>
<a name="ln2037">#endif</a>
<a name="ln2038">		} else {</a>
<a name="ln2039">			bus_addr = sd_ba[frag_idx];</a>
<a name="ln2040">		}</a>
<a name="ln2041">		bus_dmamap_sync(fl-&gt;ifl_buf_tag, sd_map[frag_idx],</a>
<a name="ln2042">		    BUS_DMASYNC_PREREAD);</a>
<a name="ln2043"> </a>
<a name="ln2044">		MPASS(sd_m[frag_idx] == NULL);</a>
<a name="ln2045">		if ((m = m_gethdr(M_NOWAIT, MT_NOINIT)) == NULL) {</a>
<a name="ln2046">			break;</a>
<a name="ln2047">		}</a>
<a name="ln2048">		sd_m[frag_idx] = m;</a>
<a name="ln2049">		bit_set(fl-&gt;ifl_rx_bitmap, frag_idx);</a>
<a name="ln2050">#if MEMORY_LOGGING</a>
<a name="ln2051">		fl-&gt;ifl_m_enqueued++;</a>
<a name="ln2052">#endif</a>
<a name="ln2053"> </a>
<a name="ln2054">		DBG_COUNTER_INC(rx_allocs);</a>
<a name="ln2055">		fl-&gt;ifl_rxd_idxs[i] = frag_idx;</a>
<a name="ln2056">		fl-&gt;ifl_bus_addrs[i] = bus_addr;</a>
<a name="ln2057">		fl-&gt;ifl_vm_addrs[i] = cl;</a>
<a name="ln2058">		credits++;</a>
<a name="ln2059">		i++;</a>
<a name="ln2060">		MPASS(credits &lt;= fl-&gt;ifl_size);</a>
<a name="ln2061">		if (++idx == fl-&gt;ifl_size) {</a>
<a name="ln2062">			fl-&gt;ifl_gen = 1;</a>
<a name="ln2063">			idx = 0;</a>
<a name="ln2064">		}</a>
<a name="ln2065">		if (n == 0 || i == IFLIB_MAX_RX_REFRESH) {</a>
<a name="ln2066">			iru.iru_pidx = pidx;</a>
<a name="ln2067">			iru.iru_count = i;</a>
<a name="ln2068">			ctx-&gt;isc_rxd_refill(ctx-&gt;ifc_softc, &amp;iru);</a>
<a name="ln2069">			i = 0;</a>
<a name="ln2070">			pidx = idx;</a>
<a name="ln2071">			fl-&gt;ifl_pidx = idx;</a>
<a name="ln2072">			fl-&gt;ifl_credits = credits;</a>
<a name="ln2073">		}</a>
<a name="ln2074">	}</a>
<a name="ln2075"> </a>
<a name="ln2076">	if (i) {</a>
<a name="ln2077">		iru.iru_pidx = pidx;</a>
<a name="ln2078">		iru.iru_count = i;</a>
<a name="ln2079">		ctx-&gt;isc_rxd_refill(ctx-&gt;ifc_softc, &amp;iru);</a>
<a name="ln2080">		fl-&gt;ifl_pidx = idx;</a>
<a name="ln2081">		fl-&gt;ifl_credits = credits;</a>
<a name="ln2082">	}</a>
<a name="ln2083">	DBG_COUNTER_INC(rxd_flush);</a>
<a name="ln2084">	if (fl-&gt;ifl_pidx == 0)</a>
<a name="ln2085">		pidx = fl-&gt;ifl_size - 1;</a>
<a name="ln2086">	else</a>
<a name="ln2087">		pidx = fl-&gt;ifl_pidx - 1;</a>
<a name="ln2088"> </a>
<a name="ln2089">	bus_dmamap_sync(fl-&gt;ifl_ifdi-&gt;idi_tag, fl-&gt;ifl_ifdi-&gt;idi_map,</a>
<a name="ln2090">	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);</a>
<a name="ln2091">	ctx-&gt;isc_rxd_flush(ctx-&gt;ifc_softc, fl-&gt;ifl_rxq-&gt;ifr_id, fl-&gt;ifl_id, pidx);</a>
<a name="ln2092">	fl-&gt;ifl_fragidx = frag_idx;</a>
<a name="ln2093">}</a>
<a name="ln2094"> </a>
<a name="ln2095">static __inline void</a>
<a name="ln2096">__iflib_fl_refill_lt(if_ctx_t ctx, iflib_fl_t fl, int max)</a>
<a name="ln2097">{</a>
<a name="ln2098">	/* we avoid allowing pidx to catch up with cidx as it confuses ixl */</a>
<a name="ln2099">	int32_t reclaimable = fl-&gt;ifl_size - fl-&gt;ifl_credits - 1;</a>
<a name="ln2100">#ifdef INVARIANTS</a>
<a name="ln2101">	int32_t delta = fl-&gt;ifl_size - get_inuse(fl-&gt;ifl_size, fl-&gt;ifl_cidx, fl-&gt;ifl_pidx, fl-&gt;ifl_gen) - 1;</a>
<a name="ln2102">#endif</a>
<a name="ln2103"> </a>
<a name="ln2104">	MPASS(fl-&gt;ifl_credits &lt;= fl-&gt;ifl_size);</a>
<a name="ln2105">	MPASS(reclaimable == delta);</a>
<a name="ln2106"> </a>
<a name="ln2107">	if (reclaimable &gt; 0)</a>
<a name="ln2108">		_iflib_fl_refill(ctx, fl, min(max, reclaimable));</a>
<a name="ln2109">}</a>
<a name="ln2110"> </a>
<a name="ln2111">uint8_t</a>
<a name="ln2112">iflib_in_detach(if_ctx_t ctx)</a>
<a name="ln2113">{</a>
<a name="ln2114">	bool in_detach;</a>
<a name="ln2115">	STATE_LOCK(ctx);</a>
<a name="ln2116">	in_detach = !!(ctx-&gt;ifc_flags &amp; IFC_IN_DETACH);</a>
<a name="ln2117">	STATE_UNLOCK(ctx);</a>
<a name="ln2118">	return (in_detach);</a>
<a name="ln2119">}</a>
<a name="ln2120"> </a>
<a name="ln2121">static void</a>
<a name="ln2122">iflib_fl_bufs_free(iflib_fl_t fl)</a>
<a name="ln2123">{</a>
<a name="ln2124">	iflib_dma_info_t idi = fl-&gt;ifl_ifdi;</a>
<a name="ln2125">	bus_dmamap_t sd_map;</a>
<a name="ln2126">	uint32_t i;</a>
<a name="ln2127"> </a>
<a name="ln2128">	for (i = 0; i &lt; fl-&gt;ifl_size; i++) {</a>
<a name="ln2129">		struct mbuf **sd_m = &amp;fl-&gt;ifl_sds.ifsd_m[i];</a>
<a name="ln2130">		caddr_t *sd_cl = &amp;fl-&gt;ifl_sds.ifsd_cl[i];</a>
<a name="ln2131"> </a>
<a name="ln2132">		if (*sd_cl != NULL) {</a>
<a name="ln2133">			sd_map = fl-&gt;ifl_sds.ifsd_map[i];</a>
<a name="ln2134">			bus_dmamap_sync(fl-&gt;ifl_buf_tag, sd_map,</a>
<a name="ln2135">			    BUS_DMASYNC_POSTREAD);</a>
<a name="ln2136">			bus_dmamap_unload(fl-&gt;ifl_buf_tag, sd_map);</a>
<a name="ln2137">			if (*sd_cl != NULL) {</a>
<a name="ln2138">#ifndef __HAIKU__</a>
<a name="ln2139">				uma_zfree(fl-&gt;ifl_zone, *sd_cl);</a>
<a name="ln2140">#else</a>
<a name="ln2141">				struct mbuf* mb = m_get(0, MT_DATA);</a>
<a name="ln2142">				m_cljset(mb, *sd_cl, fl-&gt;ifl_cltype);</a>
<a name="ln2143">				m_free(mb);</a>
<a name="ln2144">#endif</a>
<a name="ln2145">			}</a>
<a name="ln2146">			// XXX: Should this get moved out?</a>
<a name="ln2147">			if (iflib_in_detach(fl-&gt;ifl_rxq-&gt;ifr_ctx))</a>
<a name="ln2148">				bus_dmamap_destroy(fl-&gt;ifl_buf_tag, sd_map);</a>
<a name="ln2149">			if (*sd_m != NULL) {</a>
<a name="ln2150">				m_init(*sd_m, M_NOWAIT, MT_DATA, 0);</a>
<a name="ln2151">#ifndef __HAIKU__</a>
<a name="ln2152">				uma_zfree(zone_mbuf, *sd_m);</a>
<a name="ln2153">#else</a>
<a name="ln2154">				m_free(*sd_m);</a>
<a name="ln2155">#endif</a>
<a name="ln2156">			}</a>
<a name="ln2157">		} else {</a>
<a name="ln2158">			MPASS(*sd_cl == NULL);</a>
<a name="ln2159">			MPASS(*sd_m == NULL);</a>
<a name="ln2160">		}</a>
<a name="ln2161">#if MEMORY_LOGGING</a>
<a name="ln2162">		fl-&gt;ifl_m_dequeued++;</a>
<a name="ln2163">		fl-&gt;ifl_cl_dequeued++;</a>
<a name="ln2164">#endif</a>
<a name="ln2165">		*sd_cl = NULL;</a>
<a name="ln2166">		*sd_m = NULL;</a>
<a name="ln2167">	}</a>
<a name="ln2168">#ifdef INVARIANTS</a>
<a name="ln2169">	for (i = 0; i &lt; fl-&gt;ifl_size; i++) {</a>
<a name="ln2170">		MPASS(fl-&gt;ifl_sds.ifsd_cl[i] == NULL);</a>
<a name="ln2171">		MPASS(fl-&gt;ifl_sds.ifsd_m[i] == NULL);</a>
<a name="ln2172">	}</a>
<a name="ln2173">#endif</a>
<a name="ln2174">	/*</a>
<a name="ln2175">	 * Reset free list values</a>
<a name="ln2176">	 */</a>
<a name="ln2177">	fl-&gt;ifl_credits = fl-&gt;ifl_cidx = fl-&gt;ifl_pidx = fl-&gt;ifl_gen = fl-&gt;ifl_fragidx = 0;</a>
<a name="ln2178">	bzero(idi-&gt;idi_vaddr, idi-&gt;idi_size);</a>
<a name="ln2179">}</a>
<a name="ln2180"> </a>
<a name="ln2181">/*********************************************************************</a>
<a name="ln2182"> *</a>
<a name="ln2183"> *  Initialize a receive ring and its buffers.</a>
<a name="ln2184"> *</a>
<a name="ln2185"> **********************************************************************/</a>
<a name="ln2186">static int</a>
<a name="ln2187">iflib_fl_setup(iflib_fl_t fl)</a>
<a name="ln2188">{</a>
<a name="ln2189">	iflib_rxq_t rxq = fl-&gt;ifl_rxq;</a>
<a name="ln2190">	if_ctx_t ctx = rxq-&gt;ifr_ctx;</a>
<a name="ln2191"> </a>
<a name="ln2192">	bit_nclear(fl-&gt;ifl_rx_bitmap, 0, fl-&gt;ifl_size - 1);</a>
<a name="ln2193">	/*</a>
<a name="ln2194">	** Free current RX buffer structs and their mbufs</a>
<a name="ln2195">	*/</a>
<a name="ln2196">	iflib_fl_bufs_free(fl);</a>
<a name="ln2197">	/* Now replenish the mbufs */</a>
<a name="ln2198">	MPASS(fl-&gt;ifl_credits == 0);</a>
<a name="ln2199">	fl-&gt;ifl_buf_size = ctx-&gt;ifc_rx_mbuf_sz;</a>
<a name="ln2200">	if (fl-&gt;ifl_buf_size &gt; ctx-&gt;ifc_max_fl_buf_size)</a>
<a name="ln2201">		ctx-&gt;ifc_max_fl_buf_size = fl-&gt;ifl_buf_size;</a>
<a name="ln2202">	fl-&gt;ifl_cltype = m_gettype(fl-&gt;ifl_buf_size);</a>
<a name="ln2203">#ifndef __HAIKU__</a>
<a name="ln2204">	fl-&gt;ifl_zone = m_getzone(fl-&gt;ifl_buf_size);</a>
<a name="ln2205">#endif</a>
<a name="ln2206"> </a>
<a name="ln2207"> </a>
<a name="ln2208">	/* avoid pre-allocating zillions of clusters to an idle card</a>
<a name="ln2209">	 * potentially speeding up attach</a>
<a name="ln2210">	 */</a>
<a name="ln2211">	_iflib_fl_refill(ctx, fl, min(128, fl-&gt;ifl_size));</a>
<a name="ln2212">	MPASS(min(128, fl-&gt;ifl_size) == fl-&gt;ifl_credits);</a>
<a name="ln2213">	if (min(128, fl-&gt;ifl_size) != fl-&gt;ifl_credits)</a>
<a name="ln2214">		return (ENOBUFS);</a>
<a name="ln2215">	/*</a>
<a name="ln2216">	 * handle failure</a>
<a name="ln2217">	 */</a>
<a name="ln2218">	MPASS(rxq != NULL);</a>
<a name="ln2219">	MPASS(fl-&gt;ifl_ifdi != NULL);</a>
<a name="ln2220">	bus_dmamap_sync(fl-&gt;ifl_ifdi-&gt;idi_tag, fl-&gt;ifl_ifdi-&gt;idi_map,</a>
<a name="ln2221">	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);</a>
<a name="ln2222">	return (0);</a>
<a name="ln2223">}</a>
<a name="ln2224"> </a>
<a name="ln2225">/*********************************************************************</a>
<a name="ln2226"> *</a>
<a name="ln2227"> *  Free receive ring data structures</a>
<a name="ln2228"> *</a>
<a name="ln2229"> **********************************************************************/</a>
<a name="ln2230">static void</a>
<a name="ln2231">iflib_rx_sds_free(iflib_rxq_t rxq)</a>
<a name="ln2232">{</a>
<a name="ln2233">	iflib_fl_t fl;</a>
<a name="ln2234">	int i, j;</a>
<a name="ln2235"> </a>
<a name="ln2236">	if (rxq-&gt;ifr_fl != NULL) {</a>
<a name="ln2237">		for (i = 0; i &lt; rxq-&gt;ifr_nfl; i++) {</a>
<a name="ln2238">			fl = &amp;rxq-&gt;ifr_fl[i];</a>
<a name="ln2239">			if (fl-&gt;ifl_buf_tag != NULL) {</a>
<a name="ln2240">				if (fl-&gt;ifl_sds.ifsd_map != NULL) {</a>
<a name="ln2241">					for (j = 0; j &lt; fl-&gt;ifl_size; j++) {</a>
<a name="ln2242">						if (fl-&gt;ifl_sds.ifsd_map[j] ==</a>
<a name="ln2243">						    NULL)</a>
<a name="ln2244">							continue;</a>
<a name="ln2245">						bus_dmamap_sync(</a>
<a name="ln2246">						    fl-&gt;ifl_buf_tag,</a>
<a name="ln2247">						    fl-&gt;ifl_sds.ifsd_map[j],</a>
<a name="ln2248">						    BUS_DMASYNC_POSTREAD);</a>
<a name="ln2249">						bus_dmamap_unload(</a>
<a name="ln2250">						    fl-&gt;ifl_buf_tag,</a>
<a name="ln2251">						    fl-&gt;ifl_sds.ifsd_map[j]);</a>
<a name="ln2252">					}</a>
<a name="ln2253">				}</a>
<a name="ln2254">				bus_dma_tag_destroy(fl-&gt;ifl_buf_tag);</a>
<a name="ln2255">				fl-&gt;ifl_buf_tag = NULL;</a>
<a name="ln2256">			}</a>
<a name="ln2257">			free(fl-&gt;ifl_sds.ifsd_m, M_IFLIB);</a>
<a name="ln2258">			free(fl-&gt;ifl_sds.ifsd_cl, M_IFLIB);</a>
<a name="ln2259">			free(fl-&gt;ifl_sds.ifsd_ba, M_IFLIB);</a>
<a name="ln2260">			free(fl-&gt;ifl_sds.ifsd_map, M_IFLIB);</a>
<a name="ln2261">			fl-&gt;ifl_sds.ifsd_m = NULL;</a>
<a name="ln2262">			fl-&gt;ifl_sds.ifsd_cl = NULL;</a>
<a name="ln2263">			fl-&gt;ifl_sds.ifsd_ba = NULL;</a>
<a name="ln2264">			fl-&gt;ifl_sds.ifsd_map = NULL;</a>
<a name="ln2265">		}</a>
<a name="ln2266">		free(rxq-&gt;ifr_fl, M_IFLIB);</a>
<a name="ln2267">		rxq-&gt;ifr_fl = NULL;</a>
<a name="ln2268">		rxq-&gt;ifr_cq_gen = rxq-&gt;ifr_cq_cidx = rxq-&gt;ifr_cq_pidx = 0;</a>
<a name="ln2269">	}</a>
<a name="ln2270">}</a>
<a name="ln2271"> </a>
<a name="ln2272">/*</a>
<a name="ln2273"> * MI independent logic</a>
<a name="ln2274"> *</a>
<a name="ln2275"> */</a>
<a name="ln2276">static void</a>
<a name="ln2277">iflib_timer(void *arg)</a>
<a name="ln2278">{</a>
<a name="ln2279">	iflib_txq_t txq = arg;</a>
<a name="ln2280">	if_ctx_t ctx = txq-&gt;ift_ctx;</a>
<a name="ln2281">	if_softc_ctx_t sctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln2282">	uint64_t this_tick = ticks;</a>
<a name="ln2283">	uint32_t reset_on = hz / 2;</a>
<a name="ln2284"> </a>
<a name="ln2285">	if (!(if_getdrvflags(ctx-&gt;ifc_ifp) &amp; IFF_DRV_RUNNING))</a>
<a name="ln2286">		return;</a>
<a name="ln2287">	/*</a>
<a name="ln2288">	** Check on the state of the TX queue(s), this</a>
<a name="ln2289">	** can be done without the lock because its RO</a>
<a name="ln2290">	** and the HUNG state will be static if set.</a>
<a name="ln2291">	*/</a>
<a name="ln2292">	if (this_tick - txq-&gt;ift_last_timer_tick &gt;= hz / 2) {</a>
<a name="ln2293">		txq-&gt;ift_last_timer_tick = this_tick;</a>
<a name="ln2294">		IFDI_TIMER(ctx, txq-&gt;ift_id);</a>
<a name="ln2295">		if ((txq-&gt;ift_qstatus == IFLIB_QUEUE_HUNG) &amp;&amp;</a>
<a name="ln2296">		    ((txq-&gt;ift_cleaned_prev == txq-&gt;ift_cleaned) ||</a>
<a name="ln2297">		     (sctx-&gt;isc_pause_frames == 0)))</a>
<a name="ln2298">			goto hung;</a>
<a name="ln2299"> </a>
<a name="ln2300">		if (ifmp_ring_is_stalled(txq-&gt;ift_br))</a>
<a name="ln2301">			txq-&gt;ift_qstatus = IFLIB_QUEUE_HUNG;</a>
<a name="ln2302">		txq-&gt;ift_cleaned_prev = txq-&gt;ift_cleaned;</a>
<a name="ln2303">	}</a>
<a name="ln2304">#ifdef DEV_NETMAP</a>
<a name="ln2305">	if (if_getcapenable(ctx-&gt;ifc_ifp) &amp; IFCAP_NETMAP)</a>
<a name="ln2306">		iflib_netmap_timer_adjust(ctx, txq, &amp;reset_on);</a>
<a name="ln2307">#endif</a>
<a name="ln2308">	/* handle any laggards */</a>
<a name="ln2309">	if (txq-&gt;ift_db_pending)</a>
<a name="ln2310">		GROUPTASK_ENQUEUE(&amp;txq-&gt;ift_task);</a>
<a name="ln2311"> </a>
<a name="ln2312">	sctx-&gt;isc_pause_frames = 0;</a>
<a name="ln2313">	if (if_getdrvflags(ctx-&gt;ifc_ifp) &amp; IFF_DRV_RUNNING) </a>
<a name="ln2314">		callout_reset_on(&amp;txq-&gt;ift_timer, reset_on, iflib_timer, txq, txq-&gt;ift_timer.c_cpu);</a>
<a name="ln2315">	return;</a>
<a name="ln2316"> hung:</a>
<a name="ln2317">	device_printf(ctx-&gt;ifc_dev,  &quot;TX(%d) desc avail = %d, pidx = %d\n&quot;,</a>
<a name="ln2318">				  txq-&gt;ift_id, TXQ_AVAIL(txq), txq-&gt;ift_pidx);</a>
<a name="ln2319">	STATE_LOCK(ctx);</a>
<a name="ln2320">	if_setdrvflagbits(ctx-&gt;ifc_ifp, IFF_DRV_OACTIVE, IFF_DRV_RUNNING);</a>
<a name="ln2321">	ctx-&gt;ifc_flags |= (IFC_DO_WATCHDOG|IFC_DO_RESET);</a>
<a name="ln2322">	iflib_admin_intr_deferred(ctx);</a>
<a name="ln2323">	STATE_UNLOCK(ctx);</a>
<a name="ln2324">}</a>
<a name="ln2325"> </a>
<a name="ln2326">static void</a>
<a name="ln2327">iflib_calc_rx_mbuf_sz(if_ctx_t ctx)</a>
<a name="ln2328">{</a>
<a name="ln2329">	if_softc_ctx_t sctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln2330"> </a>
<a name="ln2331">	/*</a>
<a name="ln2332">	 * XXX don't set the max_frame_size to larger</a>
<a name="ln2333">	 * than the hardware can handle</a>
<a name="ln2334">	 */</a>
<a name="ln2335">	if (sctx-&gt;isc_max_frame_size &lt;= MCLBYTES)</a>
<a name="ln2336">		ctx-&gt;ifc_rx_mbuf_sz = MCLBYTES;</a>
<a name="ln2337">	else</a>
<a name="ln2338">		ctx-&gt;ifc_rx_mbuf_sz = MJUMPAGESIZE;</a>
<a name="ln2339">}</a>
<a name="ln2340"> </a>
<a name="ln2341">uint32_t</a>
<a name="ln2342">iflib_get_rx_mbuf_sz(if_ctx_t ctx)</a>
<a name="ln2343">{</a>
<a name="ln2344">	return (ctx-&gt;ifc_rx_mbuf_sz);</a>
<a name="ln2345">}</a>
<a name="ln2346"> </a>
<a name="ln2347">static void</a>
<a name="ln2348">iflib_init_locked(if_ctx_t ctx)</a>
<a name="ln2349">{</a>
<a name="ln2350">	if_softc_ctx_t sctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln2351">	if_softc_ctx_t scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln2352">	if_t ifp = ctx-&gt;ifc_ifp;</a>
<a name="ln2353">	iflib_fl_t fl;</a>
<a name="ln2354">	iflib_txq_t txq;</a>
<a name="ln2355">	iflib_rxq_t rxq;</a>
<a name="ln2356">	int i, j, tx_ip_csum_flags, tx_ip6_csum_flags;</a>
<a name="ln2357"> </a>
<a name="ln2358"> </a>
<a name="ln2359">	if_setdrvflagbits(ifp, IFF_DRV_OACTIVE, IFF_DRV_RUNNING);</a>
<a name="ln2360">	IFDI_INTR_DISABLE(ctx);</a>
<a name="ln2361"> </a>
<a name="ln2362">	tx_ip_csum_flags = scctx-&gt;isc_tx_csum_flags &amp; (CSUM_IP | CSUM_TCP | CSUM_UDP | CSUM_SCTP);</a>
<a name="ln2363">	tx_ip6_csum_flags = scctx-&gt;isc_tx_csum_flags &amp; (CSUM_IP6_TCP | CSUM_IP6_UDP | CSUM_IP6_SCTP);</a>
<a name="ln2364">	/* Set hardware offload abilities */</a>
<a name="ln2365">	if_clearhwassist(ifp);</a>
<a name="ln2366">	if (if_getcapenable(ifp) &amp; IFCAP_TXCSUM)</a>
<a name="ln2367">		if_sethwassistbits(ifp, tx_ip_csum_flags, 0);</a>
<a name="ln2368">	if (if_getcapenable(ifp) &amp; IFCAP_TXCSUM_IPV6)</a>
<a name="ln2369">		if_sethwassistbits(ifp,  tx_ip6_csum_flags, 0);</a>
<a name="ln2370">	if (if_getcapenable(ifp) &amp; IFCAP_TSO4)</a>
<a name="ln2371">		if_sethwassistbits(ifp, CSUM_IP_TSO, 0);</a>
<a name="ln2372">	if (if_getcapenable(ifp) &amp; IFCAP_TSO6)</a>
<a name="ln2373">		if_sethwassistbits(ifp, CSUM_IP6_TSO, 0);</a>
<a name="ln2374"> </a>
<a name="ln2375">	for (i = 0, txq = ctx-&gt;ifc_txqs; i &lt; sctx-&gt;isc_ntxqsets; i++, txq++) {</a>
<a name="ln2376">		CALLOUT_LOCK(txq);</a>
<a name="ln2377">		callout_stop(&amp;txq-&gt;ift_timer);</a>
<a name="ln2378">		CALLOUT_UNLOCK(txq);</a>
<a name="ln2379">		iflib_netmap_txq_init(ctx, txq);</a>
<a name="ln2380">	}</a>
<a name="ln2381"> </a>
<a name="ln2382">	/*</a>
<a name="ln2383">	 * Calculate a suitable Rx mbuf size prior to calling IFDI_INIT, so</a>
<a name="ln2384">	 * that drivers can use the value when setting up the hardware receive</a>
<a name="ln2385">	 * buffers.</a>
<a name="ln2386">	 */</a>
<a name="ln2387">	iflib_calc_rx_mbuf_sz(ctx);</a>
<a name="ln2388"> </a>
<a name="ln2389">#ifdef INVARIANTS</a>
<a name="ln2390">	i = if_getdrvflags(ifp);</a>
<a name="ln2391">#endif</a>
<a name="ln2392">	IFDI_INIT(ctx);</a>
<a name="ln2393">	MPASS(if_getdrvflags(ifp) == i);</a>
<a name="ln2394">	for (i = 0, rxq = ctx-&gt;ifc_rxqs; i &lt; sctx-&gt;isc_nrxqsets; i++, rxq++) {</a>
<a name="ln2395">		/* XXX this should really be done on a per-queue basis */</a>
<a name="ln2396">		if (if_getcapenable(ifp) &amp; IFCAP_NETMAP) {</a>
<a name="ln2397">			MPASS(rxq-&gt;ifr_id == i);</a>
<a name="ln2398">			iflib_netmap_rxq_init(ctx, rxq);</a>
<a name="ln2399">			continue;</a>
<a name="ln2400">		}</a>
<a name="ln2401">		for (j = 0, fl = rxq-&gt;ifr_fl; j &lt; rxq-&gt;ifr_nfl; j++, fl++) {</a>
<a name="ln2402">			if (iflib_fl_setup(fl)) {</a>
<a name="ln2403">				device_printf(ctx-&gt;ifc_dev, &quot;freelist setup failed - check cluster settings\n&quot;);</a>
<a name="ln2404">				goto done;</a>
<a name="ln2405">			}</a>
<a name="ln2406">		}</a>
<a name="ln2407">	}</a>
<a name="ln2408">done:</a>
<a name="ln2409">	if_setdrvflagbits(ctx-&gt;ifc_ifp, IFF_DRV_RUNNING, IFF_DRV_OACTIVE);</a>
<a name="ln2410">	IFDI_INTR_ENABLE(ctx);</a>
<a name="ln2411">	txq = ctx-&gt;ifc_txqs;</a>
<a name="ln2412">	for (i = 0; i &lt; sctx-&gt;isc_ntxqsets; i++, txq++)</a>
<a name="ln2413">		callout_reset_on(&amp;txq-&gt;ift_timer, hz/2, iflib_timer, txq,</a>
<a name="ln2414">			txq-&gt;ift_timer.c_cpu);</a>
<a name="ln2415">}</a>
<a name="ln2416"> </a>
<a name="ln2417">static int</a>
<a name="ln2418">iflib_media_change(if_t ifp)</a>
<a name="ln2419">{</a>
<a name="ln2420">	if_ctx_t ctx = if_getsoftc(ifp);</a>
<a name="ln2421">	int err;</a>
<a name="ln2422"> </a>
<a name="ln2423">	CTX_LOCK(ctx);</a>
<a name="ln2424">	if ((err = IFDI_MEDIA_CHANGE(ctx)) == 0)</a>
<a name="ln2425">		iflib_init_locked(ctx);</a>
<a name="ln2426">	CTX_UNLOCK(ctx);</a>
<a name="ln2427">	return (err);</a>
<a name="ln2428">}</a>
<a name="ln2429"> </a>
<a name="ln2430">static void</a>
<a name="ln2431">iflib_media_status(if_t ifp, struct ifmediareq *ifmr)</a>
<a name="ln2432">{</a>
<a name="ln2433">	if_ctx_t ctx = if_getsoftc(ifp);</a>
<a name="ln2434"> </a>
<a name="ln2435">	CTX_LOCK(ctx);</a>
<a name="ln2436">	IFDI_UPDATE_ADMIN_STATUS(ctx);</a>
<a name="ln2437">	IFDI_MEDIA_STATUS(ctx, ifmr);</a>
<a name="ln2438">	CTX_UNLOCK(ctx);</a>
<a name="ln2439">}</a>
<a name="ln2440"> </a>
<a name="ln2441">void</a>
<a name="ln2442">iflib_stop(if_ctx_t ctx)</a>
<a name="ln2443">{</a>
<a name="ln2444">	iflib_txq_t txq = ctx-&gt;ifc_txqs;</a>
<a name="ln2445">	iflib_rxq_t rxq = ctx-&gt;ifc_rxqs;</a>
<a name="ln2446">	if_softc_ctx_t scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln2447">	if_shared_ctx_t sctx = ctx-&gt;ifc_sctx;</a>
<a name="ln2448">	iflib_dma_info_t di;</a>
<a name="ln2449">	iflib_fl_t fl;</a>
<a name="ln2450">	int i, j;</a>
<a name="ln2451"> </a>
<a name="ln2452">	/* Tell the stack that the interface is no longer active */</a>
<a name="ln2453">	if_setdrvflagbits(ctx-&gt;ifc_ifp, IFF_DRV_OACTIVE, IFF_DRV_RUNNING);</a>
<a name="ln2454"> </a>
<a name="ln2455">	IFDI_INTR_DISABLE(ctx);</a>
<a name="ln2456">	DELAY(1000);</a>
<a name="ln2457">	IFDI_STOP(ctx);</a>
<a name="ln2458">	DELAY(1000);</a>
<a name="ln2459"> </a>
<a name="ln2460">	iflib_debug_reset();</a>
<a name="ln2461">	/* Wait for current tx queue users to exit to disarm watchdog timer. */</a>
<a name="ln2462">	for (i = 0; i &lt; scctx-&gt;isc_ntxqsets; i++, txq++) {</a>
<a name="ln2463">		/* make sure all transmitters have completed before proceeding XXX */</a>
<a name="ln2464"> </a>
<a name="ln2465">		CALLOUT_LOCK(txq);</a>
<a name="ln2466">		callout_stop(&amp;txq-&gt;ift_timer);</a>
<a name="ln2467">		CALLOUT_UNLOCK(txq);</a>
<a name="ln2468"> </a>
<a name="ln2469">		/* clean any enqueued buffers */</a>
<a name="ln2470">		iflib_ifmp_purge(txq);</a>
<a name="ln2471">		/* Free any existing tx buffers. */</a>
<a name="ln2472">		for (j = 0; j &lt; txq-&gt;ift_size; j++) {</a>
<a name="ln2473">			iflib_txsd_free(ctx, txq, j);</a>
<a name="ln2474">		}</a>
<a name="ln2475">		txq-&gt;ift_processed = txq-&gt;ift_cleaned = txq-&gt;ift_cidx_processed = 0;</a>
<a name="ln2476">		txq-&gt;ift_in_use = txq-&gt;ift_gen = txq-&gt;ift_cidx = txq-&gt;ift_pidx = txq-&gt;ift_no_desc_avail = 0;</a>
<a name="ln2477">		txq-&gt;ift_closed = txq-&gt;ift_mbuf_defrag = txq-&gt;ift_mbuf_defrag_failed = 0;</a>
<a name="ln2478">		txq-&gt;ift_no_tx_dma_setup = txq-&gt;ift_txd_encap_efbig = txq-&gt;ift_map_failed = 0;</a>
<a name="ln2479">		txq-&gt;ift_pullups = 0;</a>
<a name="ln2480">		ifmp_ring_reset_stats(txq-&gt;ift_br);</a>
<a name="ln2481">		for (j = 0, di = txq-&gt;ift_ifdi; j &lt; sctx-&gt;isc_ntxqs; j++, di++)</a>
<a name="ln2482">			bzero((void *)di-&gt;idi_vaddr, di-&gt;idi_size);</a>
<a name="ln2483">	}</a>
<a name="ln2484">	for (i = 0; i &lt; scctx-&gt;isc_nrxqsets; i++, rxq++) {</a>
<a name="ln2485">		/* make sure all transmitters have completed before proceeding XXX */</a>
<a name="ln2486"> </a>
<a name="ln2487">		rxq-&gt;ifr_cq_gen = rxq-&gt;ifr_cq_cidx = rxq-&gt;ifr_cq_pidx = 0;</a>
<a name="ln2488">		for (j = 0, di = rxq-&gt;ifr_ifdi; j &lt; sctx-&gt;isc_nrxqs; j++, di++)</a>
<a name="ln2489">			bzero((void *)di-&gt;idi_vaddr, di-&gt;idi_size);</a>
<a name="ln2490">		/* also resets the free lists pidx/cidx */</a>
<a name="ln2491">		for (j = 0, fl = rxq-&gt;ifr_fl; j &lt; rxq-&gt;ifr_nfl; j++, fl++)</a>
<a name="ln2492">			iflib_fl_bufs_free(fl);</a>
<a name="ln2493">	}</a>
<a name="ln2494">}</a>
<a name="ln2495"> </a>
<a name="ln2496">static inline caddr_t</a>
<a name="ln2497">calc_next_rxd(iflib_fl_t fl, int cidx)</a>
<a name="ln2498">{</a>
<a name="ln2499">	qidx_t size;</a>
<a name="ln2500">	int nrxd;</a>
<a name="ln2501">	caddr_t start, end, cur, next;</a>
<a name="ln2502"> </a>
<a name="ln2503">	nrxd = fl-&gt;ifl_size;</a>
<a name="ln2504">	size = fl-&gt;ifl_rxd_size;</a>
<a name="ln2505">	start = fl-&gt;ifl_ifdi-&gt;idi_vaddr;</a>
<a name="ln2506"> </a>
<a name="ln2507">	if (__predict_false(size == 0))</a>
<a name="ln2508">		return (start);</a>
<a name="ln2509">	cur = start + size*cidx;</a>
<a name="ln2510">	end = start + size*nrxd;</a>
<a name="ln2511">	next = CACHE_PTR_NEXT(cur);</a>
<a name="ln2512">	return (next &lt; end ? next : start);</a>
<a name="ln2513">}</a>
<a name="ln2514"> </a>
<a name="ln2515">static inline void</a>
<a name="ln2516">prefetch_pkts(iflib_fl_t fl, int cidx)</a>
<a name="ln2517">{</a>
<a name="ln2518">	int nextptr;</a>
<a name="ln2519">	int nrxd = fl-&gt;ifl_size;</a>
<a name="ln2520">	caddr_t next_rxd;</a>
<a name="ln2521"> </a>
<a name="ln2522"> </a>
<a name="ln2523">	nextptr = (cidx + CACHE_PTR_INCREMENT) &amp; (nrxd-1);</a>
<a name="ln2524">	prefetch(&amp;fl-&gt;ifl_sds.ifsd_m[nextptr]);</a>
<a name="ln2525">	prefetch(&amp;fl-&gt;ifl_sds.ifsd_cl[nextptr]);</a>
<a name="ln2526">	next_rxd = calc_next_rxd(fl, cidx);</a>
<a name="ln2527">	prefetch(next_rxd);</a>
<a name="ln2528">	prefetch(fl-&gt;ifl_sds.ifsd_m[(cidx + 1) &amp; (nrxd-1)]);</a>
<a name="ln2529">	prefetch(fl-&gt;ifl_sds.ifsd_m[(cidx + 2) &amp; (nrxd-1)]);</a>
<a name="ln2530">	prefetch(fl-&gt;ifl_sds.ifsd_m[(cidx + 3) &amp; (nrxd-1)]);</a>
<a name="ln2531">	prefetch(fl-&gt;ifl_sds.ifsd_m[(cidx + 4) &amp; (nrxd-1)]);</a>
<a name="ln2532">	prefetch(fl-&gt;ifl_sds.ifsd_cl[(cidx + 1) &amp; (nrxd-1)]);</a>
<a name="ln2533">	prefetch(fl-&gt;ifl_sds.ifsd_cl[(cidx + 2) &amp; (nrxd-1)]);</a>
<a name="ln2534">	prefetch(fl-&gt;ifl_sds.ifsd_cl[(cidx + 3) &amp; (nrxd-1)]);</a>
<a name="ln2535">	prefetch(fl-&gt;ifl_sds.ifsd_cl[(cidx + 4) &amp; (nrxd-1)]);</a>
<a name="ln2536">}</a>
<a name="ln2537"> </a>
<a name="ln2538">static void</a>
<a name="ln2539">rxd_frag_to_sd(iflib_rxq_t rxq, if_rxd_frag_t irf, int unload, if_rxsd_t sd)</a>
<a name="ln2540">{</a>
<a name="ln2541">	int flid, cidx;</a>
<a name="ln2542">	bus_dmamap_t map;</a>
<a name="ln2543">	iflib_fl_t fl;</a>
<a name="ln2544">	int next;</a>
<a name="ln2545"> </a>
<a name="ln2546">	map = NULL;</a>
<a name="ln2547">	flid = irf-&gt;irf_flid;</a>
<a name="ln2548">	cidx = irf-&gt;irf_idx;</a>
<a name="ln2549">	fl = &amp;rxq-&gt;ifr_fl[flid];</a>
<a name="ln2550">	sd-&gt;ifsd_fl = fl;</a>
<a name="ln2551">	sd-&gt;ifsd_cidx = cidx;</a>
<a name="ln2552">	sd-&gt;ifsd_m = &amp;fl-&gt;ifl_sds.ifsd_m[cidx];</a>
<a name="ln2553">	sd-&gt;ifsd_cl = &amp;fl-&gt;ifl_sds.ifsd_cl[cidx];</a>
<a name="ln2554">	fl-&gt;ifl_credits--;</a>
<a name="ln2555">#if MEMORY_LOGGING</a>
<a name="ln2556">	fl-&gt;ifl_m_dequeued++;</a>
<a name="ln2557">#endif</a>
<a name="ln2558">	if (rxq-&gt;ifr_ctx-&gt;ifc_flags &amp; IFC_PREFETCH)</a>
<a name="ln2559">		prefetch_pkts(fl, cidx);</a>
<a name="ln2560">	next = (cidx + CACHE_PTR_INCREMENT) &amp; (fl-&gt;ifl_size-1);</a>
<a name="ln2561">	prefetch(&amp;fl-&gt;ifl_sds.ifsd_map[next]);</a>
<a name="ln2562">	map = fl-&gt;ifl_sds.ifsd_map[cidx];</a>
<a name="ln2563">	next = (cidx + CACHE_LINE_SIZE) &amp; (fl-&gt;ifl_size-1);</a>
<a name="ln2564"> </a>
<a name="ln2565">	/* not valid assert if bxe really does SGE from non-contiguous elements */</a>
<a name="ln2566">	MPASS(fl-&gt;ifl_cidx == cidx);</a>
<a name="ln2567">	bus_dmamap_sync(fl-&gt;ifl_buf_tag, map, BUS_DMASYNC_POSTREAD);</a>
<a name="ln2568">	if (unload)</a>
<a name="ln2569">		bus_dmamap_unload(fl-&gt;ifl_buf_tag, map);</a>
<a name="ln2570">	fl-&gt;ifl_cidx = (fl-&gt;ifl_cidx + 1) &amp; (fl-&gt;ifl_size-1);</a>
<a name="ln2571">	if (__predict_false(fl-&gt;ifl_cidx == 0))</a>
<a name="ln2572">		fl-&gt;ifl_gen = 0;</a>
<a name="ln2573">	bit_clear(fl-&gt;ifl_rx_bitmap, cidx);</a>
<a name="ln2574">}</a>
<a name="ln2575"> </a>
<a name="ln2576">static struct mbuf *</a>
<a name="ln2577">assemble_segments(iflib_rxq_t rxq, if_rxd_info_t ri, if_rxsd_t sd)</a>
<a name="ln2578">{</a>
<a name="ln2579">	int i, padlen , flags;</a>
<a name="ln2580">	struct mbuf *m, *mh, *mt;</a>
<a name="ln2581">	caddr_t cl;</a>
<a name="ln2582"> </a>
<a name="ln2583">	i = 0;</a>
<a name="ln2584">	mh = NULL;</a>
<a name="ln2585">	do {</a>
<a name="ln2586">		rxd_frag_to_sd(rxq, &amp;ri-&gt;iri_frags[i], TRUE, sd);</a>
<a name="ln2587"> </a>
<a name="ln2588">		MPASS(*sd-&gt;ifsd_cl != NULL);</a>
<a name="ln2589">		MPASS(*sd-&gt;ifsd_m != NULL);</a>
<a name="ln2590"> </a>
<a name="ln2591">		/* Don't include zero-length frags */</a>
<a name="ln2592">		if (ri-&gt;iri_frags[i].irf_len == 0) {</a>
<a name="ln2593">			/* XXX we can save the cluster here, but not the mbuf */</a>
<a name="ln2594">			m_init(*sd-&gt;ifsd_m, M_NOWAIT, MT_DATA, 0);</a>
<a name="ln2595">			m_free(*sd-&gt;ifsd_m);</a>
<a name="ln2596">			*sd-&gt;ifsd_m = NULL;</a>
<a name="ln2597">			continue;</a>
<a name="ln2598">		}</a>
<a name="ln2599">		m = *sd-&gt;ifsd_m;</a>
<a name="ln2600">		*sd-&gt;ifsd_m = NULL;</a>
<a name="ln2601">		if (mh == NULL) {</a>
<a name="ln2602">			flags = M_PKTHDR|M_EXT;</a>
<a name="ln2603">			mh = mt = m;</a>
<a name="ln2604">			padlen = ri-&gt;iri_pad;</a>
<a name="ln2605">		} else {</a>
<a name="ln2606">			flags = M_EXT;</a>
<a name="ln2607">			mt-&gt;m_next = m;</a>
<a name="ln2608">			mt = m;</a>
<a name="ln2609">			/* assuming padding is only on the first fragment */</a>
<a name="ln2610">			padlen = 0;</a>
<a name="ln2611">		}</a>
<a name="ln2612">		cl = *sd-&gt;ifsd_cl;</a>
<a name="ln2613">		*sd-&gt;ifsd_cl = NULL;</a>
<a name="ln2614"> </a>
<a name="ln2615">		/* Can these two be made one ? */</a>
<a name="ln2616">		m_init(m, M_NOWAIT, MT_DATA, flags);</a>
<a name="ln2617">		m_cljset(m, cl, sd-&gt;ifsd_fl-&gt;ifl_cltype);</a>
<a name="ln2618">		/*</a>
<a name="ln2619">		 * These must follow m_init and m_cljset</a>
<a name="ln2620">		 */</a>
<a name="ln2621">		m-&gt;m_data += padlen;</a>
<a name="ln2622">		ri-&gt;iri_len -= padlen;</a>
<a name="ln2623">		m-&gt;m_len = ri-&gt;iri_frags[i].irf_len;</a>
<a name="ln2624">	} while (++i &lt; ri-&gt;iri_nfrags);</a>
<a name="ln2625"> </a>
<a name="ln2626">	return (mh);</a>
<a name="ln2627">}</a>
<a name="ln2628"> </a>
<a name="ln2629">/*</a>
<a name="ln2630"> * Process one software descriptor</a>
<a name="ln2631"> */</a>
<a name="ln2632">static struct mbuf *</a>
<a name="ln2633">iflib_rxd_pkt_get(iflib_rxq_t rxq, if_rxd_info_t ri)</a>
<a name="ln2634">{</a>
<a name="ln2635">	struct if_rxsd sd;</a>
<a name="ln2636">	struct mbuf *m;</a>
<a name="ln2637"> </a>
<a name="ln2638">	/* should I merge this back in now that the two paths are basically duplicated? */</a>
<a name="ln2639">	if (ri-&gt;iri_nfrags == 1 &amp;&amp;</a>
<a name="ln2640">	    ri-&gt;iri_frags[0].irf_len &lt;= MIN(IFLIB_RX_COPY_THRESH, MHLEN)) {</a>
<a name="ln2641">		rxd_frag_to_sd(rxq, &amp;ri-&gt;iri_frags[0], FALSE, &amp;sd);</a>
<a name="ln2642">		m = *sd.ifsd_m;</a>
<a name="ln2643">		*sd.ifsd_m = NULL;</a>
<a name="ln2644">		m_init(m, M_NOWAIT, MT_DATA, M_PKTHDR);</a>
<a name="ln2645">#ifndef __NO_STRICT_ALIGNMENT</a>
<a name="ln2646">		if (!IP_ALIGNED(m))</a>
<a name="ln2647">			m-&gt;m_data += 2;</a>
<a name="ln2648">#endif</a>
<a name="ln2649">		memcpy(m-&gt;m_data, *sd.ifsd_cl, ri-&gt;iri_len);</a>
<a name="ln2650">		m-&gt;m_len = ri-&gt;iri_frags[0].irf_len;</a>
<a name="ln2651">       } else {</a>
<a name="ln2652">		m = assemble_segments(rxq, ri, &amp;sd);</a>
<a name="ln2653">	}</a>
<a name="ln2654">	m-&gt;m_pkthdr.len = ri-&gt;iri_len;</a>
<a name="ln2655">	m-&gt;m_pkthdr.rcvif = ri-&gt;iri_ifp;</a>
<a name="ln2656">	m-&gt;m_flags |= ri-&gt;iri_flags;</a>
<a name="ln2657">	m-&gt;m_pkthdr.ether_vtag = ri-&gt;iri_vtag;</a>
<a name="ln2658">	m-&gt;m_pkthdr.flowid = ri-&gt;iri_flowid;</a>
<a name="ln2659">	M_HASHTYPE_SET(m, ri-&gt;iri_rsstype);</a>
<a name="ln2660">	m-&gt;m_pkthdr.csum_flags = ri-&gt;iri_csum_flags;</a>
<a name="ln2661">	m-&gt;m_pkthdr.csum_data = ri-&gt;iri_csum_data;</a>
<a name="ln2662">	return (m);</a>
<a name="ln2663">}</a>
<a name="ln2664"> </a>
<a name="ln2665">#if defined(INET6) || defined(INET)</a>
<a name="ln2666">static void</a>
<a name="ln2667">iflib_get_ip_forwarding(struct lro_ctrl *lc, bool *v4, bool *v6)</a>
<a name="ln2668">{</a>
<a name="ln2669">	CURVNET_SET(lc-&gt;ifp-&gt;if_vnet);</a>
<a name="ln2670">#if defined(INET6)</a>
<a name="ln2671">	*v6 = VNET(ip6_forwarding);</a>
<a name="ln2672">#endif</a>
<a name="ln2673">#if defined(INET)</a>
<a name="ln2674">	*v4 = VNET(ipforwarding);</a>
<a name="ln2675">#endif</a>
<a name="ln2676">	CURVNET_RESTORE();</a>
<a name="ln2677">}</a>
<a name="ln2678"> </a>
<a name="ln2679">/*</a>
<a name="ln2680"> * Returns true if it's possible this packet could be LROed.</a>
<a name="ln2681"> * if it returns false, it is guaranteed that tcp_lro_rx()</a>
<a name="ln2682"> * would not return zero.</a>
<a name="ln2683"> */</a>
<a name="ln2684">static bool</a>
<a name="ln2685">iflib_check_lro_possible(struct mbuf *m, bool v4_forwarding, bool v6_forwarding)</a>
<a name="ln2686">{</a>
<a name="ln2687">#ifndef __HAIKU__</a>
<a name="ln2688">	struct ether_header *eh;</a>
<a name="ln2689">	uint16_t eh_type;</a>
<a name="ln2690"> </a>
<a name="ln2691">	eh = mtod(m, struct ether_header *);</a>
<a name="ln2692">	eh_type = ntohs(eh-&gt;ether_type);</a>
<a name="ln2693">	switch (eh_type) {</a>
<a name="ln2694">#if defined(INET6)</a>
<a name="ln2695">		case ETHERTYPE_IPV6:</a>
<a name="ln2696">			return !v6_forwarding;</a>
<a name="ln2697">#endif</a>
<a name="ln2698">#if defined (INET)</a>
<a name="ln2699">		case ETHERTYPE_IP:</a>
<a name="ln2700">			return !v4_forwarding;</a>
<a name="ln2701">#endif</a>
<a name="ln2702">	}</a>
<a name="ln2703">#endif</a>
<a name="ln2704"> </a>
<a name="ln2705">	return false;</a>
<a name="ln2706">}</a>
<a name="ln2707">#else</a>
<a name="ln2708">static void</a>
<a name="ln2709">iflib_get_ip_forwarding(struct lro_ctrl *lc __unused, bool *v4 __unused, bool *v6 __unused)</a>
<a name="ln2710">{</a>
<a name="ln2711">}</a>
<a name="ln2712">#endif</a>
<a name="ln2713"> </a>
<a name="ln2714">static bool</a>
<a name="ln2715">iflib_rxeof(iflib_rxq_t rxq, qidx_t budget)</a>
<a name="ln2716">{</a>
<a name="ln2717">	if_ctx_t ctx = rxq-&gt;ifr_ctx;</a>
<a name="ln2718">	if_shared_ctx_t sctx = ctx-&gt;ifc_sctx;</a>
<a name="ln2719">	if_softc_ctx_t scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln2720">	int avail, i;</a>
<a name="ln2721">	qidx_t *cidxp;</a>
<a name="ln2722">	struct if_rxd_info ri;</a>
<a name="ln2723">	int err, budget_left, rx_bytes, rx_pkts;</a>
<a name="ln2724">	iflib_fl_t fl;</a>
<a name="ln2725">	struct ifnet *ifp;</a>
<a name="ln2726">	int lro_enabled;</a>
<a name="ln2727">	bool v4_forwarding, v6_forwarding, lro_possible;</a>
<a name="ln2728"> </a>
<a name="ln2729">	/*</a>
<a name="ln2730">	 * XXX early demux data packets so that if_input processing only handles</a>
<a name="ln2731">	 * acks in interrupt context</a>
<a name="ln2732">	 */</a>
<a name="ln2733">	struct mbuf *m, *mh, *mt, *mf;</a>
<a name="ln2734"> </a>
<a name="ln2735">	lro_possible = v4_forwarding = v6_forwarding = false;</a>
<a name="ln2736">	ifp = ctx-&gt;ifc_ifp;</a>
<a name="ln2737">	mh = mt = NULL;</a>
<a name="ln2738">	MPASS(budget &gt; 0);</a>
<a name="ln2739">	rx_pkts	= rx_bytes = 0;</a>
<a name="ln2740">	if (sctx-&gt;isc_flags &amp; IFLIB_HAS_RXCQ)</a>
<a name="ln2741">		cidxp = &amp;rxq-&gt;ifr_cq_cidx;</a>
<a name="ln2742">	else</a>
<a name="ln2743">		cidxp = &amp;rxq-&gt;ifr_fl[0].ifl_cidx;</a>
<a name="ln2744">	if ((avail = iflib_rxd_avail(ctx, rxq, *cidxp, budget)) == 0) {</a>
<a name="ln2745">		for (i = 0, fl = &amp;rxq-&gt;ifr_fl[0]; i &lt; sctx-&gt;isc_nfl; i++, fl++)</a>
<a name="ln2746">			__iflib_fl_refill_lt(ctx, fl, budget + 8);</a>
<a name="ln2747">		DBG_COUNTER_INC(rx_unavail);</a>
<a name="ln2748">		return (false);</a>
<a name="ln2749">	}</a>
<a name="ln2750"> </a>
<a name="ln2751">	for (budget_left = budget; budget_left &gt; 0 &amp;&amp; avail &gt; 0;) {</a>
<a name="ln2752">		if (__predict_false(!CTX_ACTIVE(ctx))) {</a>
<a name="ln2753">			DBG_COUNTER_INC(rx_ctx_inactive);</a>
<a name="ln2754">			break;</a>
<a name="ln2755">		}</a>
<a name="ln2756">		/*</a>
<a name="ln2757">		 * Reset client set fields to their default values</a>
<a name="ln2758">		 */</a>
<a name="ln2759">		rxd_info_zero(&amp;ri);</a>
<a name="ln2760">		ri.iri_qsidx = rxq-&gt;ifr_id;</a>
<a name="ln2761">		ri.iri_cidx = *cidxp;</a>
<a name="ln2762">		ri.iri_ifp = ifp;</a>
<a name="ln2763">		ri.iri_frags = rxq-&gt;ifr_frags;</a>
<a name="ln2764">		err = ctx-&gt;isc_rxd_pkt_get(ctx-&gt;ifc_softc, &amp;ri);</a>
<a name="ln2765"> </a>
<a name="ln2766">		if (err)</a>
<a name="ln2767">			goto err;</a>
<a name="ln2768">		if (sctx-&gt;isc_flags &amp; IFLIB_HAS_RXCQ) {</a>
<a name="ln2769">			*cidxp = ri.iri_cidx;</a>
<a name="ln2770">			/* Update our consumer index */</a>
<a name="ln2771">			/* XXX NB: shurd - check if this is still safe */</a>
<a name="ln2772">			while (rxq-&gt;ifr_cq_cidx &gt;= scctx-&gt;isc_nrxd[0]) {</a>
<a name="ln2773">				rxq-&gt;ifr_cq_cidx -= scctx-&gt;isc_nrxd[0];</a>
<a name="ln2774">				rxq-&gt;ifr_cq_gen = 0;</a>
<a name="ln2775">			}</a>
<a name="ln2776">			/* was this only a completion queue message? */</a>
<a name="ln2777">			if (__predict_false(ri.iri_nfrags == 0))</a>
<a name="ln2778">				continue;</a>
<a name="ln2779">		}</a>
<a name="ln2780">		MPASS(ri.iri_nfrags != 0);</a>
<a name="ln2781">		MPASS(ri.iri_len != 0);</a>
<a name="ln2782"> </a>
<a name="ln2783">		/* will advance the cidx on the corresponding free lists */</a>
<a name="ln2784">		m = iflib_rxd_pkt_get(rxq, &amp;ri);</a>
<a name="ln2785">		avail--;</a>
<a name="ln2786">		budget_left--;</a>
<a name="ln2787">		if (avail == 0 &amp;&amp; budget_left)</a>
<a name="ln2788">			avail = iflib_rxd_avail(ctx, rxq, *cidxp, budget_left);</a>
<a name="ln2789"> </a>
<a name="ln2790">		if (__predict_false(m == NULL)) {</a>
<a name="ln2791">			DBG_COUNTER_INC(rx_mbuf_null);</a>
<a name="ln2792">			continue;</a>
<a name="ln2793">		}</a>
<a name="ln2794">		/* imm_pkt: -- cxgb */</a>
<a name="ln2795">		if (mh == NULL)</a>
<a name="ln2796">			mh = mt = m;</a>
<a name="ln2797">		else {</a>
<a name="ln2798">			mt-&gt;m_nextpkt = m;</a>
<a name="ln2799">			mt = m;</a>
<a name="ln2800">		}</a>
<a name="ln2801">	}</a>
<a name="ln2802">	/* make sure that we can refill faster than drain */</a>
<a name="ln2803">	for (i = 0, fl = &amp;rxq-&gt;ifr_fl[0]; i &lt; sctx-&gt;isc_nfl; i++, fl++)</a>
<a name="ln2804">		__iflib_fl_refill_lt(ctx, fl, budget + 8);</a>
<a name="ln2805"> </a>
<a name="ln2806">	lro_enabled = (if_getcapenable(ifp) &amp; IFCAP_LRO);</a>
<a name="ln2807">#ifndef __HAIKU__</a>
<a name="ln2808">	if (lro_enabled)</a>
<a name="ln2809">		iflib_get_ip_forwarding(&amp;rxq-&gt;ifr_lc, &amp;v4_forwarding, &amp;v6_forwarding);</a>
<a name="ln2810">#endif</a>
<a name="ln2811">	mt = mf = NULL;</a>
<a name="ln2812">	while (mh != NULL) {</a>
<a name="ln2813">		m = mh;</a>
<a name="ln2814">		mh = mh-&gt;m_nextpkt;</a>
<a name="ln2815">		m-&gt;m_nextpkt = NULL;</a>
<a name="ln2816">#ifndef __NO_STRICT_ALIGNMENT</a>
<a name="ln2817">		if (!IP_ALIGNED(m) &amp;&amp; (m = iflib_fixup_rx(m)) == NULL)</a>
<a name="ln2818">			continue;</a>
<a name="ln2819">#endif</a>
<a name="ln2820">		rx_bytes += m-&gt;m_pkthdr.len;</a>
<a name="ln2821">		rx_pkts++;</a>
<a name="ln2822">#ifndef __HAIKU__</a>
<a name="ln2823">#if defined(INET6) || defined(INET)</a>
<a name="ln2824">		if (lro_enabled) {</a>
<a name="ln2825">			if (!lro_possible) {</a>
<a name="ln2826">				lro_possible = iflib_check_lro_possible(m, v4_forwarding, v6_forwarding);</a>
<a name="ln2827">				if (lro_possible &amp;&amp; mf != NULL) {</a>
<a name="ln2828">					ifp-&gt;if_input(ifp, mf);</a>
<a name="ln2829">					DBG_COUNTER_INC(rx_if_input);</a>
<a name="ln2830">					mt = mf = NULL;</a>
<a name="ln2831">				}</a>
<a name="ln2832">			}</a>
<a name="ln2833">			if ((m-&gt;m_pkthdr.csum_flags &amp; (CSUM_L4_CALC|CSUM_L4_VALID)) ==</a>
<a name="ln2834">			    (CSUM_L4_CALC|CSUM_L4_VALID)) {</a>
<a name="ln2835">				if (lro_possible &amp;&amp; tcp_lro_rx(&amp;rxq-&gt;ifr_lc, m, 0) == 0)</a>
<a name="ln2836">					continue;</a>
<a name="ln2837">			}</a>
<a name="ln2838">		}</a>
<a name="ln2839">#endif</a>
<a name="ln2840">		if (lro_possible) {</a>
<a name="ln2841">			ifp-&gt;if_input(ifp, m);</a>
<a name="ln2842">			DBG_COUNTER_INC(rx_if_input);</a>
<a name="ln2843">			continue;</a>
<a name="ln2844">		}</a>
<a name="ln2845">#else /* __HAIKU __*/</a>
<a name="ln2846">		if (mf != NULL) {</a>
<a name="ln2847">			ifp-&gt;if_input(ifp, mf);</a>
<a name="ln2848">			DBG_COUNTER_INC(rx_if_input);</a>
<a name="ln2849">			mt = mf = NULL;</a>
<a name="ln2850">		}</a>
<a name="ln2851">		ifp-&gt;if_input(ifp, m);</a>
<a name="ln2852">		DBG_COUNTER_INC(rx_if_input);</a>
<a name="ln2853">		continue;</a>
<a name="ln2854">#endif</a>
<a name="ln2855"> </a>
<a name="ln2856">		if (mf == NULL)</a>
<a name="ln2857">			mf = m;</a>
<a name="ln2858">		if (mt != NULL)</a>
<a name="ln2859">			mt-&gt;m_nextpkt = m;</a>
<a name="ln2860">		mt = m;</a>
<a name="ln2861">	}</a>
<a name="ln2862">	if (mf != NULL) {</a>
<a name="ln2863">		ifp-&gt;if_input(ifp, mf);</a>
<a name="ln2864">		DBG_COUNTER_INC(rx_if_input);</a>
<a name="ln2865">	}</a>
<a name="ln2866"> </a>
<a name="ln2867">	if_inc_counter(ifp, IFCOUNTER_IBYTES, rx_bytes);</a>
<a name="ln2868">	if_inc_counter(ifp, IFCOUNTER_IPACKETS, rx_pkts);</a>
<a name="ln2869"> </a>
<a name="ln2870">	/*</a>
<a name="ln2871">	 * Flush any outstanding LRO work</a>
<a name="ln2872">	 */</a>
<a name="ln2873">#if defined(INET6) || defined(INET)</a>
<a name="ln2874">#ifndef __HAIKU__</a>
<a name="ln2875">	tcp_lro_flush_all(&amp;rxq-&gt;ifr_lc);</a>
<a name="ln2876">#endif</a>
<a name="ln2877">#endif</a>
<a name="ln2878">	if (avail)</a>
<a name="ln2879">		return true;</a>
<a name="ln2880">	return (iflib_rxd_avail(ctx, rxq, *cidxp, 1));</a>
<a name="ln2881">err:</a>
<a name="ln2882">	STATE_LOCK(ctx);</a>
<a name="ln2883">	ctx-&gt;ifc_flags |= IFC_DO_RESET;</a>
<a name="ln2884">	iflib_admin_intr_deferred(ctx);</a>
<a name="ln2885">	STATE_UNLOCK(ctx);</a>
<a name="ln2886">	return (false);</a>
<a name="ln2887">}</a>
<a name="ln2888"> </a>
<a name="ln2889">#define TXD_NOTIFY_COUNT(txq) (((txq)-&gt;ift_size / (txq)-&gt;ift_update_freq)-1)</a>
<a name="ln2890">static inline qidx_t</a>
<a name="ln2891">txq_max_db_deferred(iflib_txq_t txq, qidx_t in_use)</a>
<a name="ln2892">{</a>
<a name="ln2893">	qidx_t notify_count = TXD_NOTIFY_COUNT(txq);</a>
<a name="ln2894">	qidx_t minthresh = txq-&gt;ift_size / 8;</a>
<a name="ln2895">	if (in_use &gt; 4*minthresh)</a>
<a name="ln2896">		return (notify_count);</a>
<a name="ln2897">	if (in_use &gt; 2*minthresh)</a>
<a name="ln2898">		return (notify_count &gt;&gt; 1);</a>
<a name="ln2899">	if (in_use &gt; minthresh)</a>
<a name="ln2900">		return (notify_count &gt;&gt; 3);</a>
<a name="ln2901">	return (0);</a>
<a name="ln2902">}</a>
<a name="ln2903"> </a>
<a name="ln2904">static inline qidx_t</a>
<a name="ln2905">txq_max_rs_deferred(iflib_txq_t txq)</a>
<a name="ln2906">{</a>
<a name="ln2907">	qidx_t notify_count = TXD_NOTIFY_COUNT(txq);</a>
<a name="ln2908">	qidx_t minthresh = txq-&gt;ift_size / 8;</a>
<a name="ln2909">	if (txq-&gt;ift_in_use &gt; 4*minthresh)</a>
<a name="ln2910">		return (notify_count);</a>
<a name="ln2911">	if (txq-&gt;ift_in_use &gt; 2*minthresh)</a>
<a name="ln2912">		return (notify_count &gt;&gt; 1);</a>
<a name="ln2913">	if (txq-&gt;ift_in_use &gt; minthresh)</a>
<a name="ln2914">		return (notify_count &gt;&gt; 2);</a>
<a name="ln2915">	return (2);</a>
<a name="ln2916">}</a>
<a name="ln2917"> </a>
<a name="ln2918">#define M_CSUM_FLAGS(m) ((m)-&gt;m_pkthdr.csum_flags)</a>
<a name="ln2919">#define M_HAS_VLANTAG(m) (m-&gt;m_flags &amp; M_VLANTAG)</a>
<a name="ln2920"> </a>
<a name="ln2921">#define TXQ_MAX_DB_DEFERRED(txq, in_use) txq_max_db_deferred((txq), (in_use))</a>
<a name="ln2922">#define TXQ_MAX_RS_DEFERRED(txq) txq_max_rs_deferred(txq)</a>
<a name="ln2923">#define TXQ_MAX_DB_CONSUMED(size) (size &gt;&gt; 4)</a>
<a name="ln2924"> </a>
<a name="ln2925">/* forward compatibility for cxgb */</a>
<a name="ln2926">#define FIRST_QSET(ctx) 0</a>
<a name="ln2927">#define NTXQSETS(ctx) ((ctx)-&gt;ifc_softc_ctx.isc_ntxqsets)</a>
<a name="ln2928">#define NRXQSETS(ctx) ((ctx)-&gt;ifc_softc_ctx.isc_nrxqsets)</a>
<a name="ln2929">#define QIDX(ctx, m) ((((m)-&gt;m_pkthdr.flowid &amp; ctx-&gt;ifc_softc_ctx.isc_rss_table_mask) % NTXQSETS(ctx)) + FIRST_QSET(ctx))</a>
<a name="ln2930">#define DESC_RECLAIMABLE(q) ((int)((q)-&gt;ift_processed - (q)-&gt;ift_cleaned - (q)-&gt;ift_ctx-&gt;ifc_softc_ctx.isc_tx_nsegments))</a>
<a name="ln2931"> </a>
<a name="ln2932">/* XXX we should be setting this to something other than zero */</a>
<a name="ln2933">#define RECLAIM_THRESH(ctx) ((ctx)-&gt;ifc_sctx-&gt;isc_tx_reclaim_thresh)</a>
<a name="ln2934">#define	MAX_TX_DESC(ctx) max((ctx)-&gt;ifc_softc_ctx.isc_tx_tso_segments_max, \</a>
<a name="ln2935">    (ctx)-&gt;ifc_softc_ctx.isc_tx_nsegments)</a>
<a name="ln2936"> </a>
<a name="ln2937">static inline bool</a>
<a name="ln2938">iflib_txd_db_check(if_ctx_t ctx, iflib_txq_t txq, int ring, qidx_t in_use)</a>
<a name="ln2939">{</a>
<a name="ln2940">	qidx_t dbval, max;</a>
<a name="ln2941">	bool rang;</a>
<a name="ln2942"> </a>
<a name="ln2943">	rang = false;</a>
<a name="ln2944">	max = TXQ_MAX_DB_DEFERRED(txq, in_use);</a>
<a name="ln2945">	if (ring || txq-&gt;ift_db_pending &gt;= max) {</a>
<a name="ln2946">		dbval = txq-&gt;ift_npending ? txq-&gt;ift_npending : txq-&gt;ift_pidx;</a>
<a name="ln2947">		bus_dmamap_sync(txq-&gt;ift_ifdi-&gt;idi_tag, txq-&gt;ift_ifdi-&gt;idi_map,</a>
<a name="ln2948">		    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);</a>
<a name="ln2949">		ctx-&gt;isc_txd_flush(ctx-&gt;ifc_softc, txq-&gt;ift_id, dbval);</a>
<a name="ln2950">		txq-&gt;ift_db_pending = txq-&gt;ift_npending = 0;</a>
<a name="ln2951">		rang = true;</a>
<a name="ln2952">	}</a>
<a name="ln2953">	return (rang);</a>
<a name="ln2954">}</a>
<a name="ln2955"> </a>
<a name="ln2956">#ifdef PKT_DEBUG</a>
<a name="ln2957">static void</a>
<a name="ln2958">print_pkt(if_pkt_info_t pi)</a>
<a name="ln2959">{</a>
<a name="ln2960">	printf(&quot;pi len:  %d qsidx: %d nsegs: %d ndescs: %d flags: %x pidx: %d\n&quot;,</a>
<a name="ln2961">	       pi-&gt;ipi_len, pi-&gt;ipi_qsidx, pi-&gt;ipi_nsegs, pi-&gt;ipi_ndescs, pi-&gt;ipi_flags, pi-&gt;ipi_pidx);</a>
<a name="ln2962">	printf(&quot;pi new_pidx: %d csum_flags: %lx tso_segsz: %d mflags: %x vtag: %d\n&quot;,</a>
<a name="ln2963">	       pi-&gt;ipi_new_pidx, pi-&gt;ipi_csum_flags, pi-&gt;ipi_tso_segsz, pi-&gt;ipi_mflags, pi-&gt;ipi_vtag);</a>
<a name="ln2964">	printf(&quot;pi etype: %d ehdrlen: %d ip_hlen: %d ipproto: %d\n&quot;,</a>
<a name="ln2965">	       pi-&gt;ipi_etype, pi-&gt;ipi_ehdrlen, pi-&gt;ipi_ip_hlen, pi-&gt;ipi_ipproto);</a>
<a name="ln2966">}</a>
<a name="ln2967">#endif</a>
<a name="ln2968"> </a>
<a name="ln2969">#define IS_TSO4(pi) ((pi)-&gt;ipi_csum_flags &amp; CSUM_IP_TSO)</a>
<a name="ln2970">#define IS_TX_OFFLOAD4(pi) ((pi)-&gt;ipi_csum_flags &amp; (CSUM_IP_TCP | CSUM_IP_TSO))</a>
<a name="ln2971">#define IS_TSO6(pi) ((pi)-&gt;ipi_csum_flags &amp; CSUM_IP6_TSO)</a>
<a name="ln2972">#define IS_TX_OFFLOAD6(pi) ((pi)-&gt;ipi_csum_flags &amp; (CSUM_IP6_TCP | CSUM_IP6_TSO))</a>
<a name="ln2973"> </a>
<a name="ln2974">static int</a>
<a name="ln2975">iflib_parse_header(iflib_txq_t txq, if_pkt_info_t pi, struct mbuf **mp)</a>
<a name="ln2976">{</a>
<a name="ln2977">	if_shared_ctx_t sctx = txq-&gt;ift_ctx-&gt;ifc_sctx;</a>
<a name="ln2978">	struct ether_vlan_header *eh;</a>
<a name="ln2979">	struct mbuf *m;</a>
<a name="ln2980"> </a>
<a name="ln2981">	m = *mp;</a>
<a name="ln2982">	if ((sctx-&gt;isc_flags &amp; IFLIB_NEED_SCRATCH) &amp;&amp;</a>
<a name="ln2983">	    M_WRITABLE(m) == 0) {</a>
<a name="ln2984">		if ((m = m_dup(m, M_NOWAIT)) == NULL) {</a>
<a name="ln2985">			return (ENOMEM);</a>
<a name="ln2986">		} else {</a>
<a name="ln2987">			m_freem(*mp);</a>
<a name="ln2988">			DBG_COUNTER_INC(tx_frees);</a>
<a name="ln2989">			*mp = m;</a>
<a name="ln2990">		}</a>
<a name="ln2991">	}</a>
<a name="ln2992"> </a>
<a name="ln2993">	/*</a>
<a name="ln2994">	 * Determine where frame payload starts.</a>
<a name="ln2995">	 * Jump over vlan headers if already present,</a>
<a name="ln2996">	 * helpful for QinQ too.</a>
<a name="ln2997">	 */</a>
<a name="ln2998">	if (__predict_false(m-&gt;m_len &lt; sizeof(*eh))) {</a>
<a name="ln2999">		txq-&gt;ift_pullups++;</a>
<a name="ln3000">		if (__predict_false((m = m_pullup(m, sizeof(*eh))) == NULL))</a>
<a name="ln3001">			return (ENOMEM);</a>
<a name="ln3002">	}</a>
<a name="ln3003">	eh = mtod(m, struct ether_vlan_header *);</a>
<a name="ln3004">	if (eh-&gt;evl_encap_proto == htons(ETHERTYPE_VLAN)) {</a>
<a name="ln3005">		pi-&gt;ipi_etype = ntohs(eh-&gt;evl_proto);</a>
<a name="ln3006">		pi-&gt;ipi_ehdrlen = ETHER_HDR_LEN + ETHER_VLAN_ENCAP_LEN;</a>
<a name="ln3007">	} else {</a>
<a name="ln3008">		pi-&gt;ipi_etype = ntohs(eh-&gt;evl_encap_proto);</a>
<a name="ln3009">		pi-&gt;ipi_ehdrlen = ETHER_HDR_LEN;</a>
<a name="ln3010">	}</a>
<a name="ln3011"> </a>
<a name="ln3012">	switch (pi-&gt;ipi_etype) {</a>
<a name="ln3013">#ifdef INET</a>
<a name="ln3014">	case ETHERTYPE_IP:</a>
<a name="ln3015">	{</a>
<a name="ln3016">		struct mbuf *n;</a>
<a name="ln3017">		struct ip *ip = NULL;</a>
<a name="ln3018">		struct tcphdr *th = NULL;</a>
<a name="ln3019">		int minthlen;</a>
<a name="ln3020"> </a>
<a name="ln3021">		minthlen = min(m-&gt;m_pkthdr.len, pi-&gt;ipi_ehdrlen + sizeof(*ip) + sizeof(*th));</a>
<a name="ln3022">		if (__predict_false(m-&gt;m_len &lt; minthlen)) {</a>
<a name="ln3023">			/*</a>
<a name="ln3024">			 * if this code bloat is causing too much of a hit</a>
<a name="ln3025">			 * move it to a separate function and mark it noinline</a>
<a name="ln3026">			 */</a>
<a name="ln3027">			if (m-&gt;m_len == pi-&gt;ipi_ehdrlen) {</a>
<a name="ln3028">				n = m-&gt;m_next;</a>
<a name="ln3029">				MPASS(n);</a>
<a name="ln3030">				if (n-&gt;m_len &gt;= sizeof(*ip))  {</a>
<a name="ln3031">					ip = (struct ip *)n-&gt;m_data;</a>
<a name="ln3032">					if (n-&gt;m_len &gt;= (ip-&gt;ip_hl &lt;&lt; 2) + sizeof(*th))</a>
<a name="ln3033">						th = (struct tcphdr *)((caddr_t)ip + (ip-&gt;ip_hl &lt;&lt; 2));</a>
<a name="ln3034">				} else {</a>
<a name="ln3035">					txq-&gt;ift_pullups++;</a>
<a name="ln3036">					if (__predict_false((m = m_pullup(m, minthlen)) == NULL))</a>
<a name="ln3037">						return (ENOMEM);</a>
<a name="ln3038">					ip = (struct ip *)(m-&gt;m_data + pi-&gt;ipi_ehdrlen);</a>
<a name="ln3039">				}</a>
<a name="ln3040">			} else {</a>
<a name="ln3041">				txq-&gt;ift_pullups++;</a>
<a name="ln3042">				if (__predict_false((m = m_pullup(m, minthlen)) == NULL))</a>
<a name="ln3043">					return (ENOMEM);</a>
<a name="ln3044">				ip = (struct ip *)(m-&gt;m_data + pi-&gt;ipi_ehdrlen);</a>
<a name="ln3045">				if (m-&gt;m_len &gt;= (ip-&gt;ip_hl &lt;&lt; 2) + sizeof(*th))</a>
<a name="ln3046">					th = (struct tcphdr *)((caddr_t)ip + (ip-&gt;ip_hl &lt;&lt; 2));</a>
<a name="ln3047">			}</a>
<a name="ln3048">		} else {</a>
<a name="ln3049">			ip = (struct ip *)(m-&gt;m_data + pi-&gt;ipi_ehdrlen);</a>
<a name="ln3050">			if (m-&gt;m_len &gt;= (ip-&gt;ip_hl &lt;&lt; 2) + sizeof(*th))</a>
<a name="ln3051">				th = (struct tcphdr *)((caddr_t)ip + (ip-&gt;ip_hl &lt;&lt; 2));</a>
<a name="ln3052">		}</a>
<a name="ln3053">		pi-&gt;ipi_ip_hlen = ip-&gt;ip_hl &lt;&lt; 2;</a>
<a name="ln3054">		pi-&gt;ipi_ipproto = ip-&gt;ip_p;</a>
<a name="ln3055">		pi-&gt;ipi_flags |= IPI_TX_IPV4;</a>
<a name="ln3056"> </a>
<a name="ln3057">		/* TCP checksum offload may require TCP header length */</a>
<a name="ln3058">		if (IS_TX_OFFLOAD4(pi)) {</a>
<a name="ln3059">			if (__predict_true(pi-&gt;ipi_ipproto == IPPROTO_TCP)) {</a>
<a name="ln3060">				if (__predict_false(th == NULL)) {</a>
<a name="ln3061">					txq-&gt;ift_pullups++;</a>
<a name="ln3062">					if (__predict_false((m = m_pullup(m, (ip-&gt;ip_hl &lt;&lt; 2) + sizeof(*th))) == NULL))</a>
<a name="ln3063">						return (ENOMEM);</a>
<a name="ln3064">					th = (struct tcphdr *)((caddr_t)ip + pi-&gt;ipi_ip_hlen);</a>
<a name="ln3065">				}</a>
<a name="ln3066">				pi-&gt;ipi_tcp_hflags = th-&gt;th_flags;</a>
<a name="ln3067">				pi-&gt;ipi_tcp_hlen = th-&gt;th_off &lt;&lt; 2;</a>
<a name="ln3068">				pi-&gt;ipi_tcp_seq = th-&gt;th_seq;</a>
<a name="ln3069">			}</a>
<a name="ln3070">			if (IS_TSO4(pi)) {</a>
<a name="ln3071">				if (__predict_false(ip-&gt;ip_p != IPPROTO_TCP))</a>
<a name="ln3072">					return (ENXIO);</a>
<a name="ln3073">				/*</a>
<a name="ln3074">				 * TSO always requires hardware checksum offload.</a>
<a name="ln3075">				 */</a>
<a name="ln3076">				pi-&gt;ipi_csum_flags |= (CSUM_IP_TCP | CSUM_IP);</a>
<a name="ln3077">				th-&gt;th_sum = in_pseudo(ip-&gt;ip_src.s_addr,</a>
<a name="ln3078">						       ip-&gt;ip_dst.s_addr, htons(IPPROTO_TCP));</a>
<a name="ln3079">				pi-&gt;ipi_tso_segsz = m-&gt;m_pkthdr.tso_segsz;</a>
<a name="ln3080">				if (sctx-&gt;isc_flags &amp; IFLIB_TSO_INIT_IP) {</a>
<a name="ln3081">					ip-&gt;ip_sum = 0;</a>
<a name="ln3082">					ip-&gt;ip_len = htons(pi-&gt;ipi_ip_hlen + pi-&gt;ipi_tcp_hlen + pi-&gt;ipi_tso_segsz);</a>
<a name="ln3083">				}</a>
<a name="ln3084">			}</a>
<a name="ln3085">		}</a>
<a name="ln3086">		if ((sctx-&gt;isc_flags &amp; IFLIB_NEED_ZERO_CSUM) &amp;&amp; (pi-&gt;ipi_csum_flags &amp; CSUM_IP))</a>
<a name="ln3087">                       ip-&gt;ip_sum = 0;</a>
<a name="ln3088"> </a>
<a name="ln3089">		break;</a>
<a name="ln3090">	}</a>
<a name="ln3091">#endif</a>
<a name="ln3092">#ifdef INET6</a>
<a name="ln3093">	case ETHERTYPE_IPV6:</a>
<a name="ln3094">	{</a>
<a name="ln3095">		struct ip6_hdr *ip6 = (struct ip6_hdr *)(m-&gt;m_data + pi-&gt;ipi_ehdrlen);</a>
<a name="ln3096">		struct tcphdr *th;</a>
<a name="ln3097">		pi-&gt;ipi_ip_hlen = sizeof(struct ip6_hdr);</a>
<a name="ln3098"> </a>
<a name="ln3099">		if (__predict_false(m-&gt;m_len &lt; pi-&gt;ipi_ehdrlen + sizeof(struct ip6_hdr))) {</a>
<a name="ln3100">			txq-&gt;ift_pullups++;</a>
<a name="ln3101">			if (__predict_false((m = m_pullup(m, pi-&gt;ipi_ehdrlen + sizeof(struct ip6_hdr))) == NULL))</a>
<a name="ln3102">				return (ENOMEM);</a>
<a name="ln3103">		}</a>
<a name="ln3104">		th = (struct tcphdr *)((caddr_t)ip6 + pi-&gt;ipi_ip_hlen);</a>
<a name="ln3105"> </a>
<a name="ln3106">		/* XXX-BZ this will go badly in case of ext hdrs. */</a>
<a name="ln3107">		pi-&gt;ipi_ipproto = ip6-&gt;ip6_nxt;</a>
<a name="ln3108">		pi-&gt;ipi_flags |= IPI_TX_IPV6;</a>
<a name="ln3109"> </a>
<a name="ln3110">		/* TCP checksum offload may require TCP header length */</a>
<a name="ln3111">		if (IS_TX_OFFLOAD6(pi)) {</a>
<a name="ln3112">			if (pi-&gt;ipi_ipproto == IPPROTO_TCP) {</a>
<a name="ln3113">				if (__predict_false(m-&gt;m_len &lt; pi-&gt;ipi_ehdrlen + sizeof(struct ip6_hdr) + sizeof(struct tcphdr))) {</a>
<a name="ln3114">					txq-&gt;ift_pullups++;</a>
<a name="ln3115">					if (__predict_false((m = m_pullup(m, pi-&gt;ipi_ehdrlen + sizeof(struct ip6_hdr) + sizeof(struct tcphdr))) == NULL))</a>
<a name="ln3116">						return (ENOMEM);</a>
<a name="ln3117">				}</a>
<a name="ln3118">				pi-&gt;ipi_tcp_hflags = th-&gt;th_flags;</a>
<a name="ln3119">				pi-&gt;ipi_tcp_hlen = th-&gt;th_off &lt;&lt; 2;</a>
<a name="ln3120">				pi-&gt;ipi_tcp_seq = th-&gt;th_seq;</a>
<a name="ln3121">			}</a>
<a name="ln3122">			if (IS_TSO6(pi)) {</a>
<a name="ln3123">				if (__predict_false(ip6-&gt;ip6_nxt != IPPROTO_TCP))</a>
<a name="ln3124">					return (ENXIO);</a>
<a name="ln3125">				/*</a>
<a name="ln3126">				 * TSO always requires hardware checksum offload.</a>
<a name="ln3127">				 */</a>
<a name="ln3128">				pi-&gt;ipi_csum_flags |= CSUM_IP6_TCP;</a>
<a name="ln3129">				th-&gt;th_sum = in6_cksum_pseudo(ip6, 0, IPPROTO_TCP, 0);</a>
<a name="ln3130">				pi-&gt;ipi_tso_segsz = m-&gt;m_pkthdr.tso_segsz;</a>
<a name="ln3131">			}</a>
<a name="ln3132">		}</a>
<a name="ln3133">		break;</a>
<a name="ln3134">	}</a>
<a name="ln3135">#endif</a>
<a name="ln3136">	default:</a>
<a name="ln3137">		pi-&gt;ipi_csum_flags &amp;= ~CSUM_OFFLOAD;</a>
<a name="ln3138">		pi-&gt;ipi_ip_hlen = 0;</a>
<a name="ln3139">		break;</a>
<a name="ln3140">	}</a>
<a name="ln3141">	*mp = m;</a>
<a name="ln3142"> </a>
<a name="ln3143">	return (0);</a>
<a name="ln3144">}</a>
<a name="ln3145"> </a>
<a name="ln3146">/*</a>
<a name="ln3147"> * If dodgy hardware rejects the scatter gather chain we've handed it</a>
<a name="ln3148"> * we'll need to remove the mbuf chain from ifsg_m[] before we can add the</a>
<a name="ln3149"> * m_defrag'd mbufs</a>
<a name="ln3150"> */</a>
<a name="ln3151">static __noinline struct mbuf *</a>
<a name="ln3152">iflib_remove_mbuf(iflib_txq_t txq)</a>
<a name="ln3153">{</a>
<a name="ln3154">	int ntxd, pidx;</a>
<a name="ln3155">	struct mbuf *m, **ifsd_m;</a>
<a name="ln3156"> </a>
<a name="ln3157">	ifsd_m = txq-&gt;ift_sds.ifsd_m;</a>
<a name="ln3158">	ntxd = txq-&gt;ift_size;</a>
<a name="ln3159">	pidx = txq-&gt;ift_pidx &amp; (ntxd - 1);</a>
<a name="ln3160">	ifsd_m = txq-&gt;ift_sds.ifsd_m;</a>
<a name="ln3161">	m = ifsd_m[pidx];</a>
<a name="ln3162">	ifsd_m[pidx] = NULL;</a>
<a name="ln3163">	bus_dmamap_unload(txq-&gt;ift_buf_tag, txq-&gt;ift_sds.ifsd_map[pidx]);</a>
<a name="ln3164">	if (txq-&gt;ift_sds.ifsd_tso_map != NULL)</a>
<a name="ln3165">		bus_dmamap_unload(txq-&gt;ift_tso_buf_tag,</a>
<a name="ln3166">		    txq-&gt;ift_sds.ifsd_tso_map[pidx]);</a>
<a name="ln3167">#if MEMORY_LOGGING</a>
<a name="ln3168">	txq-&gt;ift_dequeued++;</a>
<a name="ln3169">#endif</a>
<a name="ln3170">	return (m);</a>
<a name="ln3171">}</a>
<a name="ln3172"> </a>
<a name="ln3173">static inline caddr_t</a>
<a name="ln3174">calc_next_txd(iflib_txq_t txq, int cidx, uint8_t qid)</a>
<a name="ln3175">{</a>
<a name="ln3176">	qidx_t size;</a>
<a name="ln3177">	int ntxd;</a>
<a name="ln3178">	caddr_t start, end, cur, next;</a>
<a name="ln3179"> </a>
<a name="ln3180">	ntxd = txq-&gt;ift_size;</a>
<a name="ln3181">	size = txq-&gt;ift_txd_size[qid];</a>
<a name="ln3182">	start = txq-&gt;ift_ifdi[qid].idi_vaddr;</a>
<a name="ln3183"> </a>
<a name="ln3184">	if (__predict_false(size == 0))</a>
<a name="ln3185">		return (start);</a>
<a name="ln3186">	cur = start + size*cidx;</a>
<a name="ln3187">	end = start + size*ntxd;</a>
<a name="ln3188">	next = CACHE_PTR_NEXT(cur);</a>
<a name="ln3189">	return (next &lt; end ? next : start);</a>
<a name="ln3190">}</a>
<a name="ln3191"> </a>
<a name="ln3192">/*</a>
<a name="ln3193"> * Pad an mbuf to ensure a minimum ethernet frame size.</a>
<a name="ln3194"> * min_frame_size is the frame size (less CRC) to pad the mbuf to</a>
<a name="ln3195"> */</a>
<a name="ln3196">static __noinline int</a>
<a name="ln3197">iflib_ether_pad(device_t dev, struct mbuf **m_head, uint16_t min_frame_size)</a>
<a name="ln3198">{</a>
<a name="ln3199">	/*</a>
<a name="ln3200">	 * 18 is enough bytes to pad an ARP packet to 46 bytes, and</a>
<a name="ln3201">	 * and ARP message is the smallest common payload I can think of</a>
<a name="ln3202">	 */</a>
<a name="ln3203">	static char pad[18];	/* just zeros */</a>
<a name="ln3204">	int n;</a>
<a name="ln3205">	struct mbuf *new_head;</a>
<a name="ln3206"> </a>
<a name="ln3207">	if (!M_WRITABLE(*m_head)) {</a>
<a name="ln3208">		new_head = m_dup(*m_head, M_NOWAIT);</a>
<a name="ln3209">		if (new_head == NULL) {</a>
<a name="ln3210">			m_freem(*m_head);</a>
<a name="ln3211">			device_printf(dev, &quot;cannot pad short frame, m_dup() failed&quot;);</a>
<a name="ln3212">			DBG_COUNTER_INC(encap_pad_mbuf_fail);</a>
<a name="ln3213">			DBG_COUNTER_INC(tx_frees);</a>
<a name="ln3214">			return ENOMEM;</a>
<a name="ln3215">		}</a>
<a name="ln3216">		m_freem(*m_head);</a>
<a name="ln3217">		*m_head = new_head;</a>
<a name="ln3218">	}</a>
<a name="ln3219"> </a>
<a name="ln3220">	for (n = min_frame_size - (*m_head)-&gt;m_pkthdr.len;</a>
<a name="ln3221">	     n &gt; 0; n -= sizeof(pad))</a>
<a name="ln3222">		if (!m_append(*m_head, min(n, sizeof(pad)), pad))</a>
<a name="ln3223">			break;</a>
<a name="ln3224"> </a>
<a name="ln3225">	if (n &gt; 0) {</a>
<a name="ln3226">		m_freem(*m_head);</a>
<a name="ln3227">		device_printf(dev, &quot;cannot pad short frame\n&quot;);</a>
<a name="ln3228">		DBG_COUNTER_INC(encap_pad_mbuf_fail);</a>
<a name="ln3229">		DBG_COUNTER_INC(tx_frees);</a>
<a name="ln3230">		return (ENOBUFS);</a>
<a name="ln3231">	}</a>
<a name="ln3232"> </a>
<a name="ln3233">	return 0;</a>
<a name="ln3234">}</a>
<a name="ln3235"> </a>
<a name="ln3236">static int</a>
<a name="ln3237">iflib_encap(iflib_txq_t txq, struct mbuf **m_headp)</a>
<a name="ln3238">{</a>
<a name="ln3239">	if_ctx_t		ctx;</a>
<a name="ln3240">	if_shared_ctx_t		sctx;</a>
<a name="ln3241">	if_softc_ctx_t		scctx;</a>
<a name="ln3242">	bus_dma_tag_t		buf_tag;</a>
<a name="ln3243">	bus_dma_segment_t	*segs;</a>
<a name="ln3244">	struct mbuf		*m_head, **ifsd_m;</a>
<a name="ln3245">	void			*next_txd;</a>
<a name="ln3246">	bus_dmamap_t		map;</a>
<a name="ln3247">	struct if_pkt_info	pi;</a>
<a name="ln3248">	int remap = 0;</a>
<a name="ln3249">	int err, nsegs, ndesc, max_segs, pidx, cidx, next, ntxd;</a>
<a name="ln3250"> </a>
<a name="ln3251">	ctx = txq-&gt;ift_ctx;</a>
<a name="ln3252">	sctx = ctx-&gt;ifc_sctx;</a>
<a name="ln3253">	scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln3254">	segs = txq-&gt;ift_segs;</a>
<a name="ln3255">	ntxd = txq-&gt;ift_size;</a>
<a name="ln3256">	m_head = *m_headp;</a>
<a name="ln3257">	map = NULL;</a>
<a name="ln3258"> </a>
<a name="ln3259">	/*</a>
<a name="ln3260">	 * If we're doing TSO the next descriptor to clean may be quite far ahead</a>
<a name="ln3261">	 */</a>
<a name="ln3262">	cidx = txq-&gt;ift_cidx;</a>
<a name="ln3263">	pidx = txq-&gt;ift_pidx;</a>
<a name="ln3264">	if (ctx-&gt;ifc_flags &amp; IFC_PREFETCH) {</a>
<a name="ln3265">		next = (cidx + CACHE_PTR_INCREMENT) &amp; (ntxd-1);</a>
<a name="ln3266">		if (!(ctx-&gt;ifc_flags &amp; IFLIB_HAS_TXCQ)) {</a>
<a name="ln3267">			next_txd = calc_next_txd(txq, cidx, 0);</a>
<a name="ln3268">			prefetch(next_txd);</a>
<a name="ln3269">		}</a>
<a name="ln3270"> </a>
<a name="ln3271">		/* prefetch the next cache line of mbuf pointers and flags */</a>
<a name="ln3272">		prefetch(&amp;txq-&gt;ift_sds.ifsd_m[next]);</a>
<a name="ln3273">		prefetch(&amp;txq-&gt;ift_sds.ifsd_map[next]);</a>
<a name="ln3274">		next = (cidx + CACHE_LINE_SIZE) &amp; (ntxd-1);</a>
<a name="ln3275">	}</a>
<a name="ln3276">	map = txq-&gt;ift_sds.ifsd_map[pidx];</a>
<a name="ln3277">	ifsd_m = txq-&gt;ift_sds.ifsd_m;</a>
<a name="ln3278"> </a>
<a name="ln3279">	if (m_head-&gt;m_pkthdr.csum_flags &amp; CSUM_TSO) {</a>
<a name="ln3280">		buf_tag = txq-&gt;ift_tso_buf_tag;</a>
<a name="ln3281">		max_segs = scctx-&gt;isc_tx_tso_segments_max;</a>
<a name="ln3282">		map = txq-&gt;ift_sds.ifsd_tso_map[pidx];</a>
<a name="ln3283">		MPASS(buf_tag != NULL);</a>
<a name="ln3284">		MPASS(max_segs &gt; 0);</a>
<a name="ln3285">	} else {</a>
<a name="ln3286">		buf_tag = txq-&gt;ift_buf_tag;</a>
<a name="ln3287">		max_segs = scctx-&gt;isc_tx_nsegments;</a>
<a name="ln3288">		map = txq-&gt;ift_sds.ifsd_map[pidx];</a>
<a name="ln3289">	}</a>
<a name="ln3290">	if ((sctx-&gt;isc_flags &amp; IFLIB_NEED_ETHER_PAD) &amp;&amp;</a>
<a name="ln3291">	    __predict_false(m_head-&gt;m_pkthdr.len &lt; scctx-&gt;isc_min_frame_size)) {</a>
<a name="ln3292">		err = iflib_ether_pad(ctx-&gt;ifc_dev, m_headp, scctx-&gt;isc_min_frame_size);</a>
<a name="ln3293">		if (err) {</a>
<a name="ln3294">			DBG_COUNTER_INC(encap_txd_encap_fail);</a>
<a name="ln3295">			return err;</a>
<a name="ln3296">		}</a>
<a name="ln3297">	}</a>
<a name="ln3298">	m_head = *m_headp;</a>
<a name="ln3299"> </a>
<a name="ln3300">	pkt_info_zero(&amp;pi);</a>
<a name="ln3301">	pi.ipi_mflags = (m_head-&gt;m_flags &amp; (M_VLANTAG|M_BCAST|M_MCAST));</a>
<a name="ln3302">	pi.ipi_pidx = pidx;</a>
<a name="ln3303">	pi.ipi_qsidx = txq-&gt;ift_id;</a>
<a name="ln3304">	pi.ipi_len = m_head-&gt;m_pkthdr.len;</a>
<a name="ln3305">	pi.ipi_csum_flags = m_head-&gt;m_pkthdr.csum_flags;</a>
<a name="ln3306">	pi.ipi_vtag = (m_head-&gt;m_flags &amp; M_VLANTAG) ? m_head-&gt;m_pkthdr.ether_vtag : 0;</a>
<a name="ln3307"> </a>
<a name="ln3308">	/* deliberate bitwise OR to make one condition */</a>
<a name="ln3309">	if (__predict_true((pi.ipi_csum_flags | pi.ipi_vtag))) {</a>
<a name="ln3310">		if (__predict_false((err = iflib_parse_header(txq, &amp;pi, m_headp)) != 0)) {</a>
<a name="ln3311">			DBG_COUNTER_INC(encap_txd_encap_fail);</a>
<a name="ln3312">			return (err);</a>
<a name="ln3313">		}</a>
<a name="ln3314">		m_head = *m_headp;</a>
<a name="ln3315">	}</a>
<a name="ln3316"> </a>
<a name="ln3317">retry:</a>
<a name="ln3318">	err = bus_dmamap_load_mbuf_sg(buf_tag, map, m_head, segs, &amp;nsegs,</a>
<a name="ln3319">	    BUS_DMA_NOWAIT);</a>
<a name="ln3320">defrag:</a>
<a name="ln3321">	if (__predict_false(err)) {</a>
<a name="ln3322">		switch (err) {</a>
<a name="ln3323">		case EFBIG:</a>
<a name="ln3324">			/* try collapse once and defrag once */</a>
<a name="ln3325">			if (remap == 0) {</a>
<a name="ln3326">				m_head = m_collapse(*m_headp, M_NOWAIT, max_segs);</a>
<a name="ln3327">				/* try defrag if collapsing fails */</a>
<a name="ln3328">				if (m_head == NULL)</a>
<a name="ln3329">					remap++;</a>
<a name="ln3330">			}</a>
<a name="ln3331">			if (remap == 1) {</a>
<a name="ln3332">				txq-&gt;ift_mbuf_defrag++;</a>
<a name="ln3333">				m_head = m_defrag(*m_headp, M_NOWAIT);</a>
<a name="ln3334">			}</a>
<a name="ln3335">			/*</a>
<a name="ln3336">			 * remap should never be &gt;1 unless bus_dmamap_load_mbuf_sg</a>
<a name="ln3337">			 * failed to map an mbuf that was run through m_defrag</a>
<a name="ln3338">			 */</a>
<a name="ln3339">			MPASS(remap &lt;= 1);</a>
<a name="ln3340">			if (__predict_false(m_head == NULL || remap &gt; 1))</a>
<a name="ln3341">				goto defrag_failed;</a>
<a name="ln3342">			remap++;</a>
<a name="ln3343">			*m_headp = m_head;</a>
<a name="ln3344">			goto retry;</a>
<a name="ln3345">			break;</a>
<a name="ln3346">		case ENOMEM:</a>
<a name="ln3347">			txq-&gt;ift_no_tx_dma_setup++;</a>
<a name="ln3348">			break;</a>
<a name="ln3349">		default:</a>
<a name="ln3350">			txq-&gt;ift_no_tx_dma_setup++;</a>
<a name="ln3351">			m_freem(*m_headp);</a>
<a name="ln3352">			DBG_COUNTER_INC(tx_frees);</a>
<a name="ln3353">			*m_headp = NULL;</a>
<a name="ln3354">			break;</a>
<a name="ln3355">		}</a>
<a name="ln3356">		txq-&gt;ift_map_failed++;</a>
<a name="ln3357">		DBG_COUNTER_INC(encap_load_mbuf_fail);</a>
<a name="ln3358">		DBG_COUNTER_INC(encap_txd_encap_fail);</a>
<a name="ln3359">		return (err);</a>
<a name="ln3360">	}</a>
<a name="ln3361">	ifsd_m[pidx] = m_head;</a>
<a name="ln3362">	/*</a>
<a name="ln3363">	 * XXX assumes a 1 to 1 relationship between segments and</a>
<a name="ln3364">	 *        descriptors - this does not hold true on all drivers, e.g.</a>
<a name="ln3365">	 *        cxgb</a>
<a name="ln3366">	 */</a>
<a name="ln3367">	if (__predict_false(nsegs + 2 &gt; TXQ_AVAIL(txq))) {</a>
<a name="ln3368">		txq-&gt;ift_no_desc_avail++;</a>
<a name="ln3369">		bus_dmamap_unload(buf_tag, map);</a>
<a name="ln3370">		DBG_COUNTER_INC(encap_txq_avail_fail);</a>
<a name="ln3371">		DBG_COUNTER_INC(encap_txd_encap_fail);</a>
<a name="ln3372">		if ((txq-&gt;ift_task.gt_task.ta_flags &amp; TASK_ENQUEUED) == 0)</a>
<a name="ln3373">			GROUPTASK_ENQUEUE(&amp;txq-&gt;ift_task);</a>
<a name="ln3374">		return (ENOBUFS);</a>
<a name="ln3375">	}</a>
<a name="ln3376">	/*</a>
<a name="ln3377">	 * On Intel cards we can greatly reduce the number of TX interrupts</a>
<a name="ln3378">	 * we see by only setting report status on every Nth descriptor.</a>
<a name="ln3379">	 * However, this also means that the driver will need to keep track</a>
<a name="ln3380">	 * of the descriptors that RS was set on to check them for the DD bit.</a>
<a name="ln3381">	 */</a>
<a name="ln3382">	txq-&gt;ift_rs_pending += nsegs + 1;</a>
<a name="ln3383">	if (txq-&gt;ift_rs_pending &gt; TXQ_MAX_RS_DEFERRED(txq) ||</a>
<a name="ln3384">	     iflib_no_tx_batch || (TXQ_AVAIL(txq) - nsegs) &lt;= MAX_TX_DESC(ctx) + 2) {</a>
<a name="ln3385">		pi.ipi_flags |= IPI_TX_INTR;</a>
<a name="ln3386">		txq-&gt;ift_rs_pending = 0;</a>
<a name="ln3387">	}</a>
<a name="ln3388"> </a>
<a name="ln3389">	pi.ipi_segs = segs;</a>
<a name="ln3390">	pi.ipi_nsegs = nsegs;</a>
<a name="ln3391"> </a>
<a name="ln3392">	MPASS(pidx &gt;= 0 &amp;&amp; pidx &lt; txq-&gt;ift_size);</a>
<a name="ln3393">#ifdef PKT_DEBUG</a>
<a name="ln3394">	print_pkt(&amp;pi);</a>
<a name="ln3395">#endif</a>
<a name="ln3396">	if ((err = ctx-&gt;isc_txd_encap(ctx-&gt;ifc_softc, &amp;pi)) == 0) {</a>
<a name="ln3397">		bus_dmamap_sync(buf_tag, map, BUS_DMASYNC_PREWRITE);</a>
<a name="ln3398">		DBG_COUNTER_INC(tx_encap);</a>
<a name="ln3399">		MPASS(pi.ipi_new_pidx &lt; txq-&gt;ift_size);</a>
<a name="ln3400"> </a>
<a name="ln3401">		ndesc = pi.ipi_new_pidx - pi.ipi_pidx;</a>
<a name="ln3402">		if (pi.ipi_new_pidx &lt; pi.ipi_pidx) {</a>
<a name="ln3403">			ndesc += txq-&gt;ift_size;</a>
<a name="ln3404">			txq-&gt;ift_gen = 1;</a>
<a name="ln3405">		}</a>
<a name="ln3406">		/*</a>
<a name="ln3407">		 * drivers can need as many as </a>
<a name="ln3408">		 * two sentinels</a>
<a name="ln3409">		 */</a>
<a name="ln3410">		MPASS(ndesc &lt;= pi.ipi_nsegs + 2);</a>
<a name="ln3411">		MPASS(pi.ipi_new_pidx != pidx);</a>
<a name="ln3412">		MPASS(ndesc &gt; 0);</a>
<a name="ln3413">		txq-&gt;ift_in_use += ndesc;</a>
<a name="ln3414"> </a>
<a name="ln3415">		/*</a>
<a name="ln3416">		 * We update the last software descriptor again here because there may</a>
<a name="ln3417">		 * be a sentinel and/or there may be more mbufs than segments</a>
<a name="ln3418">		 */</a>
<a name="ln3419">		txq-&gt;ift_pidx = pi.ipi_new_pidx;</a>
<a name="ln3420">		txq-&gt;ift_npending += pi.ipi_ndescs;</a>
<a name="ln3421">	} else {</a>
<a name="ln3422">		*m_headp = m_head = iflib_remove_mbuf(txq);</a>
<a name="ln3423">		if (err == EFBIG) {</a>
<a name="ln3424">			txq-&gt;ift_txd_encap_efbig++;</a>
<a name="ln3425">			if (remap &lt; 2) {</a>
<a name="ln3426">				remap = 1;</a>
<a name="ln3427">				goto defrag;</a>
<a name="ln3428">			}</a>
<a name="ln3429">		}</a>
<a name="ln3430">		goto defrag_failed;</a>
<a name="ln3431">	}</a>
<a name="ln3432">	/*</a>
<a name="ln3433">	 * err can't possibly be non-zero here, so we don't neet to test it</a>
<a name="ln3434">	 * to see if we need to DBG_COUNTER_INC(encap_txd_encap_fail).</a>
<a name="ln3435">	 */</a>
<a name="ln3436">	return (err);</a>
<a name="ln3437"> </a>
<a name="ln3438">defrag_failed:</a>
<a name="ln3439">	txq-&gt;ift_mbuf_defrag_failed++;</a>
<a name="ln3440">	txq-&gt;ift_map_failed++;</a>
<a name="ln3441">	m_freem(*m_headp);</a>
<a name="ln3442">	DBG_COUNTER_INC(tx_frees);</a>
<a name="ln3443">	*m_headp = NULL;</a>
<a name="ln3444">	DBG_COUNTER_INC(encap_txd_encap_fail);</a>
<a name="ln3445">	return (ENOMEM);</a>
<a name="ln3446">}</a>
<a name="ln3447"> </a>
<a name="ln3448">static void</a>
<a name="ln3449">iflib_tx_desc_free(iflib_txq_t txq, int n)</a>
<a name="ln3450">{</a>
<a name="ln3451">	uint32_t qsize, cidx, mask, gen;</a>
<a name="ln3452">	struct mbuf *m, **ifsd_m;</a>
<a name="ln3453">	bool do_prefetch;</a>
<a name="ln3454"> </a>
<a name="ln3455">	cidx = txq-&gt;ift_cidx;</a>
<a name="ln3456">	gen = txq-&gt;ift_gen;</a>
<a name="ln3457">	qsize = txq-&gt;ift_size;</a>
<a name="ln3458">	mask = qsize-1;</a>
<a name="ln3459">	ifsd_m = txq-&gt;ift_sds.ifsd_m;</a>
<a name="ln3460">	do_prefetch = (txq-&gt;ift_ctx-&gt;ifc_flags &amp; IFC_PREFETCH);</a>
<a name="ln3461"> </a>
<a name="ln3462">	while (n-- &gt; 0) {</a>
<a name="ln3463">		if (do_prefetch) {</a>
<a name="ln3464">			prefetch(ifsd_m[(cidx + 3) &amp; mask]);</a>
<a name="ln3465">			prefetch(ifsd_m[(cidx + 4) &amp; mask]);</a>
<a name="ln3466">		}</a>
<a name="ln3467">		if ((m = ifsd_m[cidx]) != NULL) {</a>
<a name="ln3468">			prefetch(&amp;ifsd_m[(cidx + CACHE_PTR_INCREMENT) &amp; mask]);</a>
<a name="ln3469">			if (m-&gt;m_pkthdr.csum_flags &amp; CSUM_TSO) {</a>
<a name="ln3470">				bus_dmamap_sync(txq-&gt;ift_tso_buf_tag,</a>
<a name="ln3471">				    txq-&gt;ift_sds.ifsd_tso_map[cidx],</a>
<a name="ln3472">				    BUS_DMASYNC_POSTWRITE);</a>
<a name="ln3473">				bus_dmamap_unload(txq-&gt;ift_tso_buf_tag,</a>
<a name="ln3474">				    txq-&gt;ift_sds.ifsd_tso_map[cidx]);</a>
<a name="ln3475">			} else {</a>
<a name="ln3476">				bus_dmamap_sync(txq-&gt;ift_buf_tag,</a>
<a name="ln3477">				    txq-&gt;ift_sds.ifsd_map[cidx],</a>
<a name="ln3478">				    BUS_DMASYNC_POSTWRITE);</a>
<a name="ln3479">				bus_dmamap_unload(txq-&gt;ift_buf_tag,</a>
<a name="ln3480">				    txq-&gt;ift_sds.ifsd_map[cidx]);</a>
<a name="ln3481">			}</a>
<a name="ln3482">			/* XXX we don't support any drivers that batch packets yet */</a>
<a name="ln3483">			MPASS(m-&gt;m_nextpkt == NULL);</a>
<a name="ln3484">			m_freem(m);</a>
<a name="ln3485">			ifsd_m[cidx] = NULL;</a>
<a name="ln3486">#if MEMORY_LOGGING</a>
<a name="ln3487">			txq-&gt;ift_dequeued++;</a>
<a name="ln3488">#endif</a>
<a name="ln3489">			DBG_COUNTER_INC(tx_frees);</a>
<a name="ln3490">		}</a>
<a name="ln3491">		if (__predict_false(++cidx == qsize)) {</a>
<a name="ln3492">			cidx = 0;</a>
<a name="ln3493">			gen = 0;</a>
<a name="ln3494">		}</a>
<a name="ln3495">	}</a>
<a name="ln3496">	txq-&gt;ift_cidx = cidx;</a>
<a name="ln3497">	txq-&gt;ift_gen = gen;</a>
<a name="ln3498">}</a>
<a name="ln3499"> </a>
<a name="ln3500">static __inline int</a>
<a name="ln3501">iflib_completed_tx_reclaim(iflib_txq_t txq, int thresh)</a>
<a name="ln3502">{</a>
<a name="ln3503">	int reclaim;</a>
<a name="ln3504">	if_ctx_t ctx = txq-&gt;ift_ctx;</a>
<a name="ln3505"> </a>
<a name="ln3506">	KASSERT(thresh &gt;= 0, (&quot;invalid threshold to reclaim&quot;));</a>
<a name="ln3507">	MPASS(thresh /*+ MAX_TX_DESC(txq-&gt;ift_ctx) */ &lt; txq-&gt;ift_size);</a>
<a name="ln3508"> </a>
<a name="ln3509">	/*</a>
<a name="ln3510">	 * Need a rate-limiting check so that this isn't called every time</a>
<a name="ln3511">	 */</a>
<a name="ln3512">	iflib_tx_credits_update(ctx, txq);</a>
<a name="ln3513">	reclaim = DESC_RECLAIMABLE(txq);</a>
<a name="ln3514"> </a>
<a name="ln3515">	if (reclaim &lt;= thresh /* + MAX_TX_DESC(txq-&gt;ift_ctx) */) {</a>
<a name="ln3516">#ifdef INVARIANTS</a>
<a name="ln3517">		if (iflib_verbose_debug) {</a>
<a name="ln3518">			printf(&quot;%s processed=%ju cleaned=%ju tx_nsegments=%d reclaim=%d thresh=%d\n&quot;, __FUNCTION__,</a>
<a name="ln3519">			       txq-&gt;ift_processed, txq-&gt;ift_cleaned, txq-&gt;ift_ctx-&gt;ifc_softc_ctx.isc_tx_nsegments,</a>
<a name="ln3520">			       reclaim, thresh);</a>
<a name="ln3521"> </a>
<a name="ln3522">		}</a>
<a name="ln3523">#endif</a>
<a name="ln3524">		return (0);</a>
<a name="ln3525">	}</a>
<a name="ln3526">	iflib_tx_desc_free(txq, reclaim);</a>
<a name="ln3527">	txq-&gt;ift_cleaned += reclaim;</a>
<a name="ln3528">	txq-&gt;ift_in_use -= reclaim;</a>
<a name="ln3529"> </a>
<a name="ln3530">	return (reclaim);</a>
<a name="ln3531">}</a>
<a name="ln3532"> </a>
<a name="ln3533">static struct mbuf **</a>
<a name="ln3534">_ring_peek_one(struct ifmp_ring *r, int cidx, int offset, int remaining)</a>
<a name="ln3535">{</a>
<a name="ln3536">	int next, size;</a>
<a name="ln3537">	struct mbuf **items;</a>
<a name="ln3538"> </a>
<a name="ln3539">	size = r-&gt;size;</a>
<a name="ln3540">	next = (cidx + CACHE_PTR_INCREMENT) &amp; (size-1);</a>
<a name="ln3541">	items = __DEVOLATILE(struct mbuf **, &amp;r-&gt;items[0]);</a>
<a name="ln3542"> </a>
<a name="ln3543">	prefetch(items[(cidx + offset) &amp; (size-1)]);</a>
<a name="ln3544">	if (remaining &gt; 1) {</a>
<a name="ln3545">		prefetch2cachelines(&amp;items[next]);</a>
<a name="ln3546">		prefetch2cachelines(items[(cidx + offset + 1) &amp; (size-1)]);</a>
<a name="ln3547">		prefetch2cachelines(items[(cidx + offset + 2) &amp; (size-1)]);</a>
<a name="ln3548">		prefetch2cachelines(items[(cidx + offset + 3) &amp; (size-1)]);</a>
<a name="ln3549">	}</a>
<a name="ln3550">	return (__DEVOLATILE(struct mbuf **, &amp;r-&gt;items[(cidx + offset) &amp; (size-1)]));</a>
<a name="ln3551">}</a>
<a name="ln3552"> </a>
<a name="ln3553">static void</a>
<a name="ln3554">iflib_txq_check_drain(iflib_txq_t txq, int budget)</a>
<a name="ln3555">{</a>
<a name="ln3556"> </a>
<a name="ln3557">	ifmp_ring_check_drainage(txq-&gt;ift_br, budget);</a>
<a name="ln3558">}</a>
<a name="ln3559"> </a>
<a name="ln3560">static uint32_t</a>
<a name="ln3561">iflib_txq_can_drain(struct ifmp_ring *r)</a>
<a name="ln3562">{</a>
<a name="ln3563">	iflib_txq_t txq = r-&gt;cookie;</a>
<a name="ln3564">	if_ctx_t ctx = txq-&gt;ift_ctx;</a>
<a name="ln3565"> </a>
<a name="ln3566">	if (TXQ_AVAIL(txq) &gt; MAX_TX_DESC(ctx) + 2)</a>
<a name="ln3567">		return (1);</a>
<a name="ln3568">	bus_dmamap_sync(txq-&gt;ift_ifdi-&gt;idi_tag, txq-&gt;ift_ifdi-&gt;idi_map,</a>
<a name="ln3569">	    BUS_DMASYNC_POSTREAD);</a>
<a name="ln3570">	return (ctx-&gt;isc_txd_credits_update(ctx-&gt;ifc_softc, txq-&gt;ift_id,</a>
<a name="ln3571">	    false));</a>
<a name="ln3572">}</a>
<a name="ln3573"> </a>
<a name="ln3574">static uint32_t</a>
<a name="ln3575">iflib_txq_drain(struct ifmp_ring *r, uint32_t cidx, uint32_t pidx)</a>
<a name="ln3576">{</a>
<a name="ln3577">	iflib_txq_t txq = r-&gt;cookie;</a>
<a name="ln3578">	if_ctx_t ctx = txq-&gt;ift_ctx;</a>
<a name="ln3579">	struct ifnet *ifp = ctx-&gt;ifc_ifp;</a>
<a name="ln3580">	struct mbuf **mp, *m;</a>
<a name="ln3581">	int i, count, consumed, pkt_sent, bytes_sent, mcast_sent, avail;</a>
<a name="ln3582">	int reclaimed, err, in_use_prev, desc_used;</a>
<a name="ln3583">	bool do_prefetch, ring, rang;</a>
<a name="ln3584"> </a>
<a name="ln3585">	if (__predict_false(!(if_getdrvflags(ifp) &amp; IFF_DRV_RUNNING) ||</a>
<a name="ln3586">			    !LINK_ACTIVE(ctx))) {</a>
<a name="ln3587">		DBG_COUNTER_INC(txq_drain_notready);</a>
<a name="ln3588">		return (0);</a>
<a name="ln3589">	}</a>
<a name="ln3590">	reclaimed = iflib_completed_tx_reclaim(txq, RECLAIM_THRESH(ctx));</a>
<a name="ln3591">	rang = iflib_txd_db_check(ctx, txq, reclaimed, txq-&gt;ift_in_use);</a>
<a name="ln3592">	avail = IDXDIFF(pidx, cidx, r-&gt;size);</a>
<a name="ln3593">	if (__predict_false(ctx-&gt;ifc_flags &amp; IFC_QFLUSH)) {</a>
<a name="ln3594">		DBG_COUNTER_INC(txq_drain_flushing);</a>
<a name="ln3595">		for (i = 0; i &lt; avail; i++) {</a>
<a name="ln3596">			if (__predict_true(r-&gt;items[(cidx + i) &amp; (r-&gt;size-1)] != (void *)txq))</a>
<a name="ln3597">				m_free(r-&gt;items[(cidx + i) &amp; (r-&gt;size-1)]);</a>
<a name="ln3598">			r-&gt;items[(cidx + i) &amp; (r-&gt;size-1)] = NULL;</a>
<a name="ln3599">		}</a>
<a name="ln3600">		return (avail);</a>
<a name="ln3601">	}</a>
<a name="ln3602"> </a>
<a name="ln3603">	if (__predict_false(if_getdrvflags(ctx-&gt;ifc_ifp) &amp; IFF_DRV_OACTIVE)) {</a>
<a name="ln3604">		txq-&gt;ift_qstatus = IFLIB_QUEUE_IDLE;</a>
<a name="ln3605">		CALLOUT_LOCK(txq);</a>
<a name="ln3606">		callout_stop(&amp;txq-&gt;ift_timer);</a>
<a name="ln3607">		CALLOUT_UNLOCK(txq);</a>
<a name="ln3608">		DBG_COUNTER_INC(txq_drain_oactive);</a>
<a name="ln3609">		return (0);</a>
<a name="ln3610">	}</a>
<a name="ln3611">	if (reclaimed)</a>
<a name="ln3612">		txq-&gt;ift_qstatus = IFLIB_QUEUE_IDLE;</a>
<a name="ln3613">	consumed = mcast_sent = bytes_sent = pkt_sent = 0;</a>
<a name="ln3614">	count = MIN(avail, TX_BATCH_SIZE);</a>
<a name="ln3615">#ifdef INVARIANTS</a>
<a name="ln3616">	if (iflib_verbose_debug)</a>
<a name="ln3617">		printf(&quot;%s avail=%d ifc_flags=%x txq_avail=%d &quot;, __FUNCTION__,</a>
<a name="ln3618">		       avail, ctx-&gt;ifc_flags, TXQ_AVAIL(txq));</a>
<a name="ln3619">#endif</a>
<a name="ln3620">	do_prefetch = (ctx-&gt;ifc_flags &amp; IFC_PREFETCH);</a>
<a name="ln3621">	avail = TXQ_AVAIL(txq);</a>
<a name="ln3622">	err = 0;</a>
<a name="ln3623">	for (desc_used = i = 0; i &lt; count &amp;&amp; avail &gt; MAX_TX_DESC(ctx) + 2; i++) {</a>
<a name="ln3624">		int rem = do_prefetch ? count - i : 0;</a>
<a name="ln3625"> </a>
<a name="ln3626">		mp = _ring_peek_one(r, cidx, i, rem);</a>
<a name="ln3627">		MPASS(mp != NULL &amp;&amp; *mp != NULL);</a>
<a name="ln3628">		if (__predict_false(*mp == (struct mbuf *)txq)) {</a>
<a name="ln3629">			consumed++;</a>
<a name="ln3630">			reclaimed++;</a>
<a name="ln3631">			continue;</a>
<a name="ln3632">		}</a>
<a name="ln3633">		in_use_prev = txq-&gt;ift_in_use;</a>
<a name="ln3634">		err = iflib_encap(txq, mp);</a>
<a name="ln3635">		if (__predict_false(err)) {</a>
<a name="ln3636">			/* no room - bail out */</a>
<a name="ln3637">			if (err == ENOBUFS)</a>
<a name="ln3638">				break;</a>
<a name="ln3639">			consumed++;</a>
<a name="ln3640">			/* we can't send this packet - skip it */</a>
<a name="ln3641">			continue;</a>
<a name="ln3642">		}</a>
<a name="ln3643">		consumed++;</a>
<a name="ln3644">		pkt_sent++;</a>
<a name="ln3645">		m = *mp;</a>
<a name="ln3646">		DBG_COUNTER_INC(tx_sent);</a>
<a name="ln3647">		bytes_sent += m-&gt;m_pkthdr.len;</a>
<a name="ln3648">		mcast_sent += !!(m-&gt;m_flags &amp; M_MCAST);</a>
<a name="ln3649">		avail = TXQ_AVAIL(txq);</a>
<a name="ln3650"> </a>
<a name="ln3651">		txq-&gt;ift_db_pending += (txq-&gt;ift_in_use - in_use_prev);</a>
<a name="ln3652">		desc_used += (txq-&gt;ift_in_use - in_use_prev);</a>
<a name="ln3653">		ETHER_BPF_MTAP(ifp, m);</a>
<a name="ln3654">		if (__predict_false(!(ifp-&gt;if_drv_flags &amp; IFF_DRV_RUNNING)))</a>
<a name="ln3655">			break;</a>
<a name="ln3656">		rang = iflib_txd_db_check(ctx, txq, false, in_use_prev);</a>
<a name="ln3657">	}</a>
<a name="ln3658"> </a>
<a name="ln3659">	/* deliberate use of bitwise or to avoid gratuitous short-circuit */</a>
<a name="ln3660">	ring = rang ? false  : (iflib_min_tx_latency | err) || (TXQ_AVAIL(txq) &lt; MAX_TX_DESC(ctx));</a>
<a name="ln3661">	iflib_txd_db_check(ctx, txq, ring, txq-&gt;ift_in_use);</a>
<a name="ln3662">	if_inc_counter(ifp, IFCOUNTER_OBYTES, bytes_sent);</a>
<a name="ln3663">	if_inc_counter(ifp, IFCOUNTER_OPACKETS, pkt_sent);</a>
<a name="ln3664">	if (mcast_sent)</a>
<a name="ln3665">		if_inc_counter(ifp, IFCOUNTER_OMCASTS, mcast_sent);</a>
<a name="ln3666">#ifdef INVARIANTS</a>
<a name="ln3667">	if (iflib_verbose_debug)</a>
<a name="ln3668">		printf(&quot;consumed=%d\n&quot;, consumed);</a>
<a name="ln3669">#endif</a>
<a name="ln3670">	return (consumed);</a>
<a name="ln3671">}</a>
<a name="ln3672"> </a>
<a name="ln3673">static uint32_t</a>
<a name="ln3674">iflib_txq_drain_always(struct ifmp_ring *r)</a>
<a name="ln3675">{</a>
<a name="ln3676">	return (1);</a>
<a name="ln3677">}</a>
<a name="ln3678"> </a>
<a name="ln3679">static uint32_t</a>
<a name="ln3680">iflib_txq_drain_free(struct ifmp_ring *r, uint32_t cidx, uint32_t pidx)</a>
<a name="ln3681">{</a>
<a name="ln3682">	int i, avail;</a>
<a name="ln3683">	struct mbuf **mp;</a>
<a name="ln3684">	iflib_txq_t txq;</a>
<a name="ln3685"> </a>
<a name="ln3686">	txq = r-&gt;cookie;</a>
<a name="ln3687"> </a>
<a name="ln3688">	txq-&gt;ift_qstatus = IFLIB_QUEUE_IDLE;</a>
<a name="ln3689">	CALLOUT_LOCK(txq);</a>
<a name="ln3690">	callout_stop(&amp;txq-&gt;ift_timer);</a>
<a name="ln3691">	CALLOUT_UNLOCK(txq);</a>
<a name="ln3692"> </a>
<a name="ln3693">	avail = IDXDIFF(pidx, cidx, r-&gt;size);</a>
<a name="ln3694">	for (i = 0; i &lt; avail; i++) {</a>
<a name="ln3695">		mp = _ring_peek_one(r, cidx, i, avail - i);</a>
<a name="ln3696">		if (__predict_false(*mp == (struct mbuf *)txq))</a>
<a name="ln3697">			continue;</a>
<a name="ln3698">		m_freem(*mp);</a>
<a name="ln3699">		DBG_COUNTER_INC(tx_frees);</a>
<a name="ln3700">	}</a>
<a name="ln3701">	MPASS(ifmp_ring_is_stalled(r) == 0);</a>
<a name="ln3702">	return (avail);</a>
<a name="ln3703">}</a>
<a name="ln3704"> </a>
<a name="ln3705">static void</a>
<a name="ln3706">iflib_ifmp_purge(iflib_txq_t txq)</a>
<a name="ln3707">{</a>
<a name="ln3708">	struct ifmp_ring *r;</a>
<a name="ln3709"> </a>
<a name="ln3710">	r = txq-&gt;ift_br;</a>
<a name="ln3711">	r-&gt;drain = iflib_txq_drain_free;</a>
<a name="ln3712">	r-&gt;can_drain = iflib_txq_drain_always;</a>
<a name="ln3713"> </a>
<a name="ln3714">	ifmp_ring_check_drainage(r, r-&gt;size);</a>
<a name="ln3715"> </a>
<a name="ln3716">	r-&gt;drain = iflib_txq_drain;</a>
<a name="ln3717">	r-&gt;can_drain = iflib_txq_can_drain;</a>
<a name="ln3718">}</a>
<a name="ln3719"> </a>
<a name="ln3720">static void</a>
<a name="ln3721">_task_fn_tx(void *context)</a>
<a name="ln3722">{</a>
<a name="ln3723">	iflib_txq_t txq = context;</a>
<a name="ln3724">	if_ctx_t ctx = txq-&gt;ift_ctx;</a>
<a name="ln3725">#if defined(ALTQ) || defined(DEV_NETMAP)</a>
<a name="ln3726">	if_t ifp = ctx-&gt;ifc_ifp;</a>
<a name="ln3727">#endif</a>
<a name="ln3728">	int abdicate = ctx-&gt;ifc_sysctl_tx_abdicate;</a>
<a name="ln3729"> </a>
<a name="ln3730">#ifdef IFLIB_DIAGNOSTICS</a>
<a name="ln3731">	txq-&gt;ift_cpu_exec_count[curcpu]++;</a>
<a name="ln3732">#endif</a>
<a name="ln3733">	if (!(if_getdrvflags(ctx-&gt;ifc_ifp) &amp; IFF_DRV_RUNNING))</a>
<a name="ln3734">		return;</a>
<a name="ln3735">#ifdef DEV_NETMAP</a>
<a name="ln3736">	if (if_getcapenable(ifp) &amp; IFCAP_NETMAP) {</a>
<a name="ln3737">		bus_dmamap_sync(txq-&gt;ift_ifdi-&gt;idi_tag, txq-&gt;ift_ifdi-&gt;idi_map,</a>
<a name="ln3738">		    BUS_DMASYNC_POSTREAD);</a>
<a name="ln3739">		if (ctx-&gt;isc_txd_credits_update(ctx-&gt;ifc_softc, txq-&gt;ift_id, false))</a>
<a name="ln3740">			netmap_tx_irq(ifp, txq-&gt;ift_id);</a>
<a name="ln3741">		IFDI_TX_QUEUE_INTR_ENABLE(ctx, txq-&gt;ift_id);</a>
<a name="ln3742">		return;</a>
<a name="ln3743">	}</a>
<a name="ln3744">#endif</a>
<a name="ln3745">#ifdef ALTQ</a>
<a name="ln3746">	if (ALTQ_IS_ENABLED(&amp;ifp-&gt;if_snd))</a>
<a name="ln3747">		iflib_altq_if_start(ifp);</a>
<a name="ln3748">#endif</a>
<a name="ln3749">	if (txq-&gt;ift_db_pending)</a>
<a name="ln3750">		ifmp_ring_enqueue(txq-&gt;ift_br, (void **)&amp;txq, 1, TX_BATCH_SIZE, abdicate);</a>
<a name="ln3751">	else if (!abdicate)</a>
<a name="ln3752">		ifmp_ring_check_drainage(txq-&gt;ift_br, TX_BATCH_SIZE);</a>
<a name="ln3753">	/*</a>
<a name="ln3754">	 * When abdicating, we always need to check drainage, not just when we don't enqueue</a>
<a name="ln3755">	 */</a>
<a name="ln3756">	if (abdicate)</a>
<a name="ln3757">		ifmp_ring_check_drainage(txq-&gt;ift_br, TX_BATCH_SIZE);</a>
<a name="ln3758">	if (ctx-&gt;ifc_flags &amp; IFC_LEGACY)</a>
<a name="ln3759">		IFDI_INTR_ENABLE(ctx);</a>
<a name="ln3760">	else {</a>
<a name="ln3761">#ifdef INVARIANTS</a>
<a name="ln3762">		int rc =</a>
<a name="ln3763">#endif</a>
<a name="ln3764">			IFDI_TX_QUEUE_INTR_ENABLE(ctx, txq-&gt;ift_id);</a>
<a name="ln3765">			KASSERT(rc != ENOTSUP, (&quot;MSI-X support requires queue_intr_enable, but not implemented in driver&quot;));</a>
<a name="ln3766">	}</a>
<a name="ln3767">}</a>
<a name="ln3768"> </a>
<a name="ln3769">static void</a>
<a name="ln3770">_task_fn_rx(void *context)</a>
<a name="ln3771">{</a>
<a name="ln3772">	iflib_rxq_t rxq = context;</a>
<a name="ln3773">	if_ctx_t ctx = rxq-&gt;ifr_ctx;</a>
<a name="ln3774">	bool more;</a>
<a name="ln3775">	uint16_t budget;</a>
<a name="ln3776"> </a>
<a name="ln3777">#ifdef IFLIB_DIAGNOSTICS</a>
<a name="ln3778">	rxq-&gt;ifr_cpu_exec_count[curcpu]++;</a>
<a name="ln3779">#endif</a>
<a name="ln3780">	DBG_COUNTER_INC(task_fn_rxs);</a>
<a name="ln3781">	if (__predict_false(!(if_getdrvflags(ctx-&gt;ifc_ifp) &amp; IFF_DRV_RUNNING)))</a>
<a name="ln3782">		return;</a>
<a name="ln3783">	more = true;</a>
<a name="ln3784">#ifdef DEV_NETMAP</a>
<a name="ln3785">	if (if_getcapenable(ctx-&gt;ifc_ifp) &amp; IFCAP_NETMAP) {</a>
<a name="ln3786">		u_int work = 0;</a>
<a name="ln3787">		if (netmap_rx_irq(ctx-&gt;ifc_ifp, rxq-&gt;ifr_id, &amp;work)) {</a>
<a name="ln3788">			more = false;</a>
<a name="ln3789">		}</a>
<a name="ln3790">	}</a>
<a name="ln3791">#endif</a>
<a name="ln3792">	budget = ctx-&gt;ifc_sysctl_rx_budget;</a>
<a name="ln3793">	if (budget == 0)</a>
<a name="ln3794">		budget = 16;	/* XXX */</a>
<a name="ln3795">	if (more == false || (more = iflib_rxeof(rxq, budget)) == false) {</a>
<a name="ln3796">		if (ctx-&gt;ifc_flags &amp; IFC_LEGACY)</a>
<a name="ln3797">			IFDI_INTR_ENABLE(ctx);</a>
<a name="ln3798">		else {</a>
<a name="ln3799">#ifdef INVARIANTS</a>
<a name="ln3800">			int rc =</a>
<a name="ln3801">#endif</a>
<a name="ln3802">				IFDI_RX_QUEUE_INTR_ENABLE(ctx, rxq-&gt;ifr_id);</a>
<a name="ln3803">			KASSERT(rc != ENOTSUP, (&quot;MSI-X support requires queue_intr_enable, but not implemented in driver&quot;));</a>
<a name="ln3804">			DBG_COUNTER_INC(rx_intr_enables);</a>
<a name="ln3805">		}</a>
<a name="ln3806">	}</a>
<a name="ln3807">	if (__predict_false(!(if_getdrvflags(ctx-&gt;ifc_ifp) &amp; IFF_DRV_RUNNING)))</a>
<a name="ln3808">		return;</a>
<a name="ln3809">	if (more)</a>
<a name="ln3810">		GROUPTASK_ENQUEUE(&amp;rxq-&gt;ifr_task);</a>
<a name="ln3811">}</a>
<a name="ln3812"> </a>
<a name="ln3813">static void</a>
<a name="ln3814">_task_fn_admin(void *context)</a>
<a name="ln3815">{</a>
<a name="ln3816">	if_ctx_t ctx = context;</a>
<a name="ln3817">	if_softc_ctx_t sctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln3818">	iflib_txq_t txq;</a>
<a name="ln3819">	int i;</a>
<a name="ln3820">	bool oactive, running, do_reset, do_watchdog, in_detach;</a>
<a name="ln3821">	uint32_t reset_on = hz / 2;</a>
<a name="ln3822"> </a>
<a name="ln3823">	STATE_LOCK(ctx);</a>
<a name="ln3824">	running = (if_getdrvflags(ctx-&gt;ifc_ifp) &amp; IFF_DRV_RUNNING);</a>
<a name="ln3825">	oactive = (if_getdrvflags(ctx-&gt;ifc_ifp) &amp; IFF_DRV_OACTIVE);</a>
<a name="ln3826">	do_reset = (ctx-&gt;ifc_flags &amp; IFC_DO_RESET);</a>
<a name="ln3827">	do_watchdog = (ctx-&gt;ifc_flags &amp; IFC_DO_WATCHDOG);</a>
<a name="ln3828">	in_detach = (ctx-&gt;ifc_flags &amp; IFC_IN_DETACH);</a>
<a name="ln3829">	ctx-&gt;ifc_flags &amp;= ~(IFC_DO_RESET|IFC_DO_WATCHDOG);</a>
<a name="ln3830">	STATE_UNLOCK(ctx);</a>
<a name="ln3831"> </a>
<a name="ln3832">	if ((!running &amp;&amp; !oactive) &amp;&amp; !(ctx-&gt;ifc_sctx-&gt;isc_flags &amp; IFLIB_ADMIN_ALWAYS_RUN))</a>
<a name="ln3833">		return;</a>
<a name="ln3834">	if (in_detach)</a>
<a name="ln3835">		return;</a>
<a name="ln3836"> </a>
<a name="ln3837">	CTX_LOCK(ctx);</a>
<a name="ln3838">	for (txq = ctx-&gt;ifc_txqs, i = 0; i &lt; sctx-&gt;isc_ntxqsets; i++, txq++) {</a>
<a name="ln3839">		CALLOUT_LOCK(txq);</a>
<a name="ln3840">		callout_stop(&amp;txq-&gt;ift_timer);</a>
<a name="ln3841">		CALLOUT_UNLOCK(txq);</a>
<a name="ln3842">	}</a>
<a name="ln3843">	if (do_watchdog) {</a>
<a name="ln3844">		ctx-&gt;ifc_watchdog_events++;</a>
<a name="ln3845">		IFDI_WATCHDOG_RESET(ctx);</a>
<a name="ln3846">	}</a>
<a name="ln3847">	IFDI_UPDATE_ADMIN_STATUS(ctx);</a>
<a name="ln3848">	for (txq = ctx-&gt;ifc_txqs, i = 0; i &lt; sctx-&gt;isc_ntxqsets; i++, txq++) {</a>
<a name="ln3849">#ifdef DEV_NETMAP</a>
<a name="ln3850">		reset_on = hz / 2;</a>
<a name="ln3851">		if (if_getcapenable(ctx-&gt;ifc_ifp) &amp; IFCAP_NETMAP)</a>
<a name="ln3852">			iflib_netmap_timer_adjust(ctx, txq, &amp;reset_on);</a>
<a name="ln3853">#endif</a>
<a name="ln3854">		callout_reset_on(&amp;txq-&gt;ift_timer, reset_on, iflib_timer, txq, txq-&gt;ift_timer.c_cpu);</a>
<a name="ln3855">	}</a>
<a name="ln3856">	IFDI_LINK_INTR_ENABLE(ctx);</a>
<a name="ln3857">	if (do_reset)</a>
<a name="ln3858">		iflib_if_init_locked(ctx);</a>
<a name="ln3859">	CTX_UNLOCK(ctx);</a>
<a name="ln3860"> </a>
<a name="ln3861">	if (LINK_ACTIVE(ctx) == 0)</a>
<a name="ln3862">		return;</a>
<a name="ln3863">	for (txq = ctx-&gt;ifc_txqs, i = 0; i &lt; sctx-&gt;isc_ntxqsets; i++, txq++)</a>
<a name="ln3864">		iflib_txq_check_drain(txq, IFLIB_RESTART_BUDGET);</a>
<a name="ln3865">}</a>
<a name="ln3866"> </a>
<a name="ln3867"> </a>
<a name="ln3868">static void</a>
<a name="ln3869">_task_fn_iov(void *context)</a>
<a name="ln3870">{</a>
<a name="ln3871">	if_ctx_t ctx = context;</a>
<a name="ln3872"> </a>
<a name="ln3873">	if (!(if_getdrvflags(ctx-&gt;ifc_ifp) &amp; IFF_DRV_RUNNING) &amp;&amp;</a>
<a name="ln3874">	    !(ctx-&gt;ifc_sctx-&gt;isc_flags &amp; IFLIB_ADMIN_ALWAYS_RUN))</a>
<a name="ln3875">		return;</a>
<a name="ln3876"> </a>
<a name="ln3877">	CTX_LOCK(ctx);</a>
<a name="ln3878">	IFDI_VFLR_HANDLE(ctx);</a>
<a name="ln3879">	CTX_UNLOCK(ctx);</a>
<a name="ln3880">}</a>
<a name="ln3881"> </a>
<a name="ln3882">static int</a>
<a name="ln3883">iflib_sysctl_int_delay(SYSCTL_HANDLER_ARGS)</a>
<a name="ln3884">{</a>
<a name="ln3885">	int err;</a>
<a name="ln3886">	if_int_delay_info_t info;</a>
<a name="ln3887">	if_ctx_t ctx;</a>
<a name="ln3888"> </a>
<a name="ln3889">	info = (if_int_delay_info_t)arg1;</a>
<a name="ln3890">	ctx = info-&gt;iidi_ctx;</a>
<a name="ln3891">	info-&gt;iidi_req = req;</a>
<a name="ln3892">	info-&gt;iidi_oidp = oidp;</a>
<a name="ln3893">	CTX_LOCK(ctx);</a>
<a name="ln3894">	err = IFDI_SYSCTL_INT_DELAY(ctx, info);</a>
<a name="ln3895">	CTX_UNLOCK(ctx);</a>
<a name="ln3896">	return (err);</a>
<a name="ln3897">}</a>
<a name="ln3898"> </a>
<a name="ln3899">/*********************************************************************</a>
<a name="ln3900"> *</a>
<a name="ln3901"> *  IFNET FUNCTIONS</a>
<a name="ln3902"> *</a>
<a name="ln3903"> **********************************************************************/</a>
<a name="ln3904"> </a>
<a name="ln3905">static void</a>
<a name="ln3906">iflib_if_init_locked(if_ctx_t ctx)</a>
<a name="ln3907">{</a>
<a name="ln3908">	iflib_stop(ctx);</a>
<a name="ln3909">	iflib_init_locked(ctx);</a>
<a name="ln3910">}</a>
<a name="ln3911"> </a>
<a name="ln3912"> </a>
<a name="ln3913">static void</a>
<a name="ln3914">iflib_if_init(void *arg)</a>
<a name="ln3915">{</a>
<a name="ln3916">	if_ctx_t ctx = arg;</a>
<a name="ln3917"> </a>
<a name="ln3918">	CTX_LOCK(ctx);</a>
<a name="ln3919">	iflib_if_init_locked(ctx);</a>
<a name="ln3920">	CTX_UNLOCK(ctx);</a>
<a name="ln3921">}</a>
<a name="ln3922"> </a>
<a name="ln3923">static int</a>
<a name="ln3924">iflib_if_transmit(if_t ifp, struct mbuf *m)</a>
<a name="ln3925">{</a>
<a name="ln3926">	if_ctx_t	ctx = if_getsoftc(ifp);</a>
<a name="ln3927"> </a>
<a name="ln3928">	iflib_txq_t txq;</a>
<a name="ln3929">	int err, qidx;</a>
<a name="ln3930">	int abdicate = ctx-&gt;ifc_sysctl_tx_abdicate;</a>
<a name="ln3931"> </a>
<a name="ln3932">	if (__predict_false((ifp-&gt;if_drv_flags &amp; IFF_DRV_RUNNING) == 0 || !LINK_ACTIVE(ctx))) {</a>
<a name="ln3933">		DBG_COUNTER_INC(tx_frees);</a>
<a name="ln3934">		m_freem(m);</a>
<a name="ln3935">		return (ENETDOWN);</a>
<a name="ln3936">	}</a>
<a name="ln3937"> </a>
<a name="ln3938">	MPASS(m-&gt;m_nextpkt == NULL);</a>
<a name="ln3939">	/* ALTQ-enabled interfaces always use queue 0. */</a>
<a name="ln3940">	qidx = 0;</a>
<a name="ln3941">	if ((NTXQSETS(ctx) &gt; 1) &amp;&amp; M_HASHTYPE_GET(m) &amp;&amp; !ALTQ_IS_ENABLED(&amp;ifp-&gt;if_snd))</a>
<a name="ln3942">		qidx = QIDX(ctx, m);</a>
<a name="ln3943">	/*</a>
<a name="ln3944">	 * XXX calculate buf_ring based on flowid (divvy up bits?)</a>
<a name="ln3945">	 */</a>
<a name="ln3946">	txq = &amp;ctx-&gt;ifc_txqs[qidx];</a>
<a name="ln3947"> </a>
<a name="ln3948">#ifdef DRIVER_BACKPRESSURE</a>
<a name="ln3949">	if (txq-&gt;ift_closed) {</a>
<a name="ln3950">		while (m != NULL) {</a>
<a name="ln3951">			next = m-&gt;m_nextpkt;</a>
<a name="ln3952">			m-&gt;m_nextpkt = NULL;</a>
<a name="ln3953">			m_freem(m);</a>
<a name="ln3954">			DBG_COUNTER_INC(tx_frees);</a>
<a name="ln3955">			m = next;</a>
<a name="ln3956">		}</a>
<a name="ln3957">		return (ENOBUFS);</a>
<a name="ln3958">	}</a>
<a name="ln3959">#endif</a>
<a name="ln3960">#ifdef notyet</a>
<a name="ln3961">	qidx = count = 0;</a>
<a name="ln3962">	mp = marr;</a>
<a name="ln3963">	next = m;</a>
<a name="ln3964">	do {</a>
<a name="ln3965">		count++;</a>
<a name="ln3966">		next = next-&gt;m_nextpkt;</a>
<a name="ln3967">	} while (next != NULL);</a>
<a name="ln3968"> </a>
<a name="ln3969">	if (count &gt; nitems(marr))</a>
<a name="ln3970">		if ((mp = malloc(count*sizeof(struct mbuf *), M_IFLIB, M_NOWAIT)) == NULL) {</a>
<a name="ln3971">			/* XXX check nextpkt */</a>
<a name="ln3972">			m_freem(m);</a>
<a name="ln3973">			/* XXX simplify for now */</a>
<a name="ln3974">			DBG_COUNTER_INC(tx_frees);</a>
<a name="ln3975">			return (ENOBUFS);</a>
<a name="ln3976">		}</a>
<a name="ln3977">	for (next = m, i = 0; next != NULL; i++) {</a>
<a name="ln3978">		mp[i] = next;</a>
<a name="ln3979">		next = next-&gt;m_nextpkt;</a>
<a name="ln3980">		mp[i]-&gt;m_nextpkt = NULL;</a>
<a name="ln3981">	}</a>
<a name="ln3982">#endif</a>
<a name="ln3983">	DBG_COUNTER_INC(tx_seen);</a>
<a name="ln3984">	err = ifmp_ring_enqueue(txq-&gt;ift_br, (void **)&amp;m, 1, TX_BATCH_SIZE, abdicate);</a>
<a name="ln3985"> </a>
<a name="ln3986">	if (abdicate)</a>
<a name="ln3987">		GROUPTASK_ENQUEUE(&amp;txq-&gt;ift_task);</a>
<a name="ln3988"> 	if (err) {</a>
<a name="ln3989">		if (!abdicate)</a>
<a name="ln3990">			GROUPTASK_ENQUEUE(&amp;txq-&gt;ift_task);</a>
<a name="ln3991">		/* support forthcoming later */</a>
<a name="ln3992">#ifdef DRIVER_BACKPRESSURE</a>
<a name="ln3993">		txq-&gt;ift_closed = TRUE;</a>
<a name="ln3994">#endif</a>
<a name="ln3995">		ifmp_ring_check_drainage(txq-&gt;ift_br, TX_BATCH_SIZE);</a>
<a name="ln3996">		m_freem(m);</a>
<a name="ln3997">		DBG_COUNTER_INC(tx_frees);</a>
<a name="ln3998">	}</a>
<a name="ln3999"> </a>
<a name="ln4000">	return (err);</a>
<a name="ln4001">}</a>
<a name="ln4002"> </a>
<a name="ln4003">#ifdef ALTQ</a>
<a name="ln4004">/*</a>
<a name="ln4005"> * The overall approach to integrating iflib with ALTQ is to continue to use</a>
<a name="ln4006"> * the iflib mp_ring machinery between the ALTQ queue(s) and the hardware</a>
<a name="ln4007"> * ring.  Technically, when using ALTQ, queueing to an intermediate mp_ring</a>
<a name="ln4008"> * is redundant/unnecessary, but doing so minimizes the amount of</a>
<a name="ln4009"> * ALTQ-specific code required in iflib.  It is assumed that the overhead of</a>
<a name="ln4010"> * redundantly queueing to an intermediate mp_ring is swamped by the</a>
<a name="ln4011"> * performance limitations inherent in using ALTQ.</a>
<a name="ln4012"> *</a>
<a name="ln4013"> * When ALTQ support is compiled in, all iflib drivers will use a transmit</a>
<a name="ln4014"> * routine, iflib_altq_if_transmit(), that checks if ALTQ is enabled for the</a>
<a name="ln4015"> * given interface.  If ALTQ is enabled for an interface, then all</a>
<a name="ln4016"> * transmitted packets for that interface will be submitted to the ALTQ</a>
<a name="ln4017"> * subsystem via IFQ_ENQUEUE().  We don't use the legacy if_transmit()</a>
<a name="ln4018"> * implementation because it uses IFQ_HANDOFF(), which will duplicatively</a>
<a name="ln4019"> * update stats that the iflib machinery handles, and which is sensitve to</a>
<a name="ln4020"> * the disused IFF_DRV_OACTIVE flag.  Additionally, iflib_altq_if_start()</a>
<a name="ln4021"> * will be installed as the start routine for use by ALTQ facilities that</a>
<a name="ln4022"> * need to trigger queue drains on a scheduled basis.</a>
<a name="ln4023"> *</a>
<a name="ln4024"> */</a>
<a name="ln4025">static void</a>
<a name="ln4026">iflib_altq_if_start(if_t ifp)</a>
<a name="ln4027">{</a>
<a name="ln4028">	struct ifaltq *ifq = &amp;ifp-&gt;if_snd;</a>
<a name="ln4029">	struct mbuf *m;</a>
<a name="ln4030">	</a>
<a name="ln4031">	IFQ_LOCK(ifq);</a>
<a name="ln4032">	IFQ_DEQUEUE_NOLOCK(ifq, m);</a>
<a name="ln4033">	while (m != NULL) {</a>
<a name="ln4034">		iflib_if_transmit(ifp, m);</a>
<a name="ln4035">		IFQ_DEQUEUE_NOLOCK(ifq, m);</a>
<a name="ln4036">	}</a>
<a name="ln4037">	IFQ_UNLOCK(ifq);</a>
<a name="ln4038">}</a>
<a name="ln4039"> </a>
<a name="ln4040">static int</a>
<a name="ln4041">iflib_altq_if_transmit(if_t ifp, struct mbuf *m)</a>
<a name="ln4042">{</a>
<a name="ln4043">	int err;</a>
<a name="ln4044"> </a>
<a name="ln4045">	if (ALTQ_IS_ENABLED(&amp;ifp-&gt;if_snd)) {</a>
<a name="ln4046">		IFQ_ENQUEUE(&amp;ifp-&gt;if_snd, m, err);</a>
<a name="ln4047">		if (err == 0)</a>
<a name="ln4048">			iflib_altq_if_start(ifp);</a>
<a name="ln4049">	} else</a>
<a name="ln4050">		err = iflib_if_transmit(ifp, m);</a>
<a name="ln4051"> </a>
<a name="ln4052">	return (err);</a>
<a name="ln4053">}</a>
<a name="ln4054">#endif /* ALTQ */</a>
<a name="ln4055"> </a>
<a name="ln4056">static void</a>
<a name="ln4057">iflib_if_qflush(if_t ifp)</a>
<a name="ln4058">{</a>
<a name="ln4059">	if_ctx_t ctx = if_getsoftc(ifp);</a>
<a name="ln4060">	iflib_txq_t txq = ctx-&gt;ifc_txqs;</a>
<a name="ln4061">	int i;</a>
<a name="ln4062"> </a>
<a name="ln4063">	STATE_LOCK(ctx);</a>
<a name="ln4064">	ctx-&gt;ifc_flags |= IFC_QFLUSH;</a>
<a name="ln4065">	STATE_UNLOCK(ctx);</a>
<a name="ln4066">	for (i = 0; i &lt; NTXQSETS(ctx); i++, txq++)</a>
<a name="ln4067">		while (!(ifmp_ring_is_idle(txq-&gt;ift_br) || ifmp_ring_is_stalled(txq-&gt;ift_br)))</a>
<a name="ln4068">			iflib_txq_check_drain(txq, 0);</a>
<a name="ln4069">	STATE_LOCK(ctx);</a>
<a name="ln4070">	ctx-&gt;ifc_flags &amp;= ~IFC_QFLUSH;</a>
<a name="ln4071">	STATE_UNLOCK(ctx);</a>
<a name="ln4072"> </a>
<a name="ln4073">	/*</a>
<a name="ln4074">	 * When ALTQ is enabled, this will also take care of purging the</a>
<a name="ln4075">	 * ALTQ queue(s).</a>
<a name="ln4076">	 */</a>
<a name="ln4077">	if_qflush(ifp);</a>
<a name="ln4078">}</a>
<a name="ln4079"> </a>
<a name="ln4080"> </a>
<a name="ln4081">#define IFCAP_FLAGS (IFCAP_HWCSUM_IPV6 | IFCAP_HWCSUM | IFCAP_LRO | \</a>
<a name="ln4082">		     IFCAP_TSO | IFCAP_VLAN_HWTAGGING | IFCAP_HWSTATS | \</a>
<a name="ln4083">		     IFCAP_VLAN_MTU | IFCAP_VLAN_HWFILTER | \</a>
<a name="ln4084">		     IFCAP_VLAN_HWTSO | IFCAP_VLAN_HWCSUM)</a>
<a name="ln4085"> </a>
<a name="ln4086">static int</a>
<a name="ln4087">iflib_if_ioctl(if_t ifp, u_long command, caddr_t data)</a>
<a name="ln4088">{</a>
<a name="ln4089">	if_ctx_t ctx = if_getsoftc(ifp);</a>
<a name="ln4090">	struct ifreq	*ifr = (struct ifreq *)data;</a>
<a name="ln4091">#if defined(INET) || defined(INET6)</a>
<a name="ln4092">	struct ifaddr	*ifa = (struct ifaddr *)data;</a>
<a name="ln4093">#endif</a>
<a name="ln4094">	bool		avoid_reset = FALSE;</a>
<a name="ln4095">	int		err = 0, reinit = 0, bits;</a>
<a name="ln4096"> </a>
<a name="ln4097">	switch (command) {</a>
<a name="ln4098">	case SIOCSIFADDR:</a>
<a name="ln4099">#ifdef INET</a>
<a name="ln4100">		if (ifa-&gt;ifa_addr-&gt;sa_family == AF_INET)</a>
<a name="ln4101">			avoid_reset = TRUE;</a>
<a name="ln4102">#endif</a>
<a name="ln4103">#ifdef INET6</a>
<a name="ln4104">		if (ifa-&gt;ifa_addr-&gt;sa_family == AF_INET6)</a>
<a name="ln4105">			avoid_reset = TRUE;</a>
<a name="ln4106">#endif</a>
<a name="ln4107">		/*</a>
<a name="ln4108">		** Calling init results in link renegotiation,</a>
<a name="ln4109">		** so we avoid doing it when possible.</a>
<a name="ln4110">		*/</a>
<a name="ln4111">		if (avoid_reset) {</a>
<a name="ln4112">			if_setflagbits(ifp, IFF_UP,0);</a>
<a name="ln4113">			if (!(if_getdrvflags(ifp) &amp; IFF_DRV_RUNNING))</a>
<a name="ln4114">				reinit = 1;</a>
<a name="ln4115">#ifdef INET</a>
<a name="ln4116">			if (!(if_getflags(ifp) &amp; IFF_NOARP))</a>
<a name="ln4117">				arp_ifinit(ifp, ifa);</a>
<a name="ln4118">#endif</a>
<a name="ln4119">		} else</a>
<a name="ln4120">			err = ether_ioctl(ifp, command, data);</a>
<a name="ln4121">		break;</a>
<a name="ln4122">	case SIOCSIFMTU:</a>
<a name="ln4123">		CTX_LOCK(ctx);</a>
<a name="ln4124">		if (ifr-&gt;ifr_mtu == if_getmtu(ifp)) {</a>
<a name="ln4125">			CTX_UNLOCK(ctx);</a>
<a name="ln4126">			break;</a>
<a name="ln4127">		}</a>
<a name="ln4128">		bits = if_getdrvflags(ifp);</a>
<a name="ln4129">		/* stop the driver and free any clusters before proceeding */</a>
<a name="ln4130">		iflib_stop(ctx);</a>
<a name="ln4131"> </a>
<a name="ln4132">		if ((err = IFDI_MTU_SET(ctx, ifr-&gt;ifr_mtu)) == 0) {</a>
<a name="ln4133">			STATE_LOCK(ctx);</a>
<a name="ln4134">			if (ifr-&gt;ifr_mtu &gt; ctx-&gt;ifc_max_fl_buf_size)</a>
<a name="ln4135">				ctx-&gt;ifc_flags |= IFC_MULTISEG;</a>
<a name="ln4136">			else</a>
<a name="ln4137">				ctx-&gt;ifc_flags &amp;= ~IFC_MULTISEG;</a>
<a name="ln4138">			STATE_UNLOCK(ctx);</a>
<a name="ln4139">			err = if_setmtu(ifp, ifr-&gt;ifr_mtu);</a>
<a name="ln4140">		}</a>
<a name="ln4141">		iflib_init_locked(ctx);</a>
<a name="ln4142">		STATE_LOCK(ctx);</a>
<a name="ln4143">		if_setdrvflags(ifp, bits);</a>
<a name="ln4144">		STATE_UNLOCK(ctx);</a>
<a name="ln4145">		CTX_UNLOCK(ctx);</a>
<a name="ln4146">		break;</a>
<a name="ln4147">	case SIOCSIFFLAGS:</a>
<a name="ln4148">		CTX_LOCK(ctx);</a>
<a name="ln4149">		if (if_getflags(ifp) &amp; IFF_UP) {</a>
<a name="ln4150">			if (if_getdrvflags(ifp) &amp; IFF_DRV_RUNNING) {</a>
<a name="ln4151">				if ((if_getflags(ifp) ^ ctx-&gt;ifc_if_flags) &amp;</a>
<a name="ln4152">				    (IFF_PROMISC | IFF_ALLMULTI)) {</a>
<a name="ln4153">					err = IFDI_PROMISC_SET(ctx, if_getflags(ifp));</a>
<a name="ln4154">				}</a>
<a name="ln4155">			} else</a>
<a name="ln4156">				reinit = 1;</a>
<a name="ln4157">		} else if (if_getdrvflags(ifp) &amp; IFF_DRV_RUNNING) {</a>
<a name="ln4158">			iflib_stop(ctx);</a>
<a name="ln4159">		}</a>
<a name="ln4160">		ctx-&gt;ifc_if_flags = if_getflags(ifp);</a>
<a name="ln4161">		CTX_UNLOCK(ctx);</a>
<a name="ln4162">		break;</a>
<a name="ln4163">	case SIOCADDMULTI:</a>
<a name="ln4164">	case SIOCDELMULTI:</a>
<a name="ln4165">		if (if_getdrvflags(ifp) &amp; IFF_DRV_RUNNING) {</a>
<a name="ln4166">			CTX_LOCK(ctx);</a>
<a name="ln4167">			IFDI_INTR_DISABLE(ctx);</a>
<a name="ln4168">			IFDI_MULTI_SET(ctx);</a>
<a name="ln4169">			IFDI_INTR_ENABLE(ctx);</a>
<a name="ln4170">			CTX_UNLOCK(ctx);</a>
<a name="ln4171">		}</a>
<a name="ln4172">		break;</a>
<a name="ln4173">	case SIOCSIFMEDIA:</a>
<a name="ln4174">		CTX_LOCK(ctx);</a>
<a name="ln4175">		IFDI_MEDIA_SET(ctx);</a>
<a name="ln4176">		CTX_UNLOCK(ctx);</a>
<a name="ln4177">		/* falls thru */</a>
<a name="ln4178">	case SIOCGIFMEDIA:</a>
<a name="ln4179">#ifndef __HAIKU__</a>
<a name="ln4180">	case SIOCGIFXMEDIA:</a>
<a name="ln4181">#endif</a>
<a name="ln4182">		err = ifmedia_ioctl(ifp, ifr, &amp;ctx-&gt;ifc_media, command);</a>
<a name="ln4183">		break;</a>
<a name="ln4184">#ifndef __HAIKU__</a>
<a name="ln4185">	case SIOCGI2C:</a>
<a name="ln4186">	{</a>
<a name="ln4187">		struct ifi2creq i2c;</a>
<a name="ln4188"> </a>
<a name="ln4189">		err = copyin(ifr_data_get_ptr(ifr), &amp;i2c, sizeof(i2c));</a>
<a name="ln4190">		if (err != 0)</a>
<a name="ln4191">			break;</a>
<a name="ln4192">		if (i2c.dev_addr != 0xA0 &amp;&amp; i2c.dev_addr != 0xA2) {</a>
<a name="ln4193">			err = EINVAL;</a>
<a name="ln4194">			break;</a>
<a name="ln4195">		}</a>
<a name="ln4196">		if (i2c.len &gt; sizeof(i2c.data)) {</a>
<a name="ln4197">			err = EINVAL;</a>
<a name="ln4198">			break;</a>
<a name="ln4199">		}</a>
<a name="ln4200"> </a>
<a name="ln4201">		if ((err = IFDI_I2C_REQ(ctx, &amp;i2c)) == 0)</a>
<a name="ln4202">			err = copyout(&amp;i2c, ifr_data_get_ptr(ifr),</a>
<a name="ln4203">			    sizeof(i2c));</a>
<a name="ln4204">		break;</a>
<a name="ln4205">	}</a>
<a name="ln4206">#endif</a>
<a name="ln4207">	case SIOCSIFCAP:</a>
<a name="ln4208">	{</a>
<a name="ln4209">		int mask, setmask, oldmask;</a>
<a name="ln4210"> </a>
<a name="ln4211">		oldmask = if_getcapenable(ifp);</a>
<a name="ln4212">		mask = ifr-&gt;ifr_reqcap ^ oldmask;</a>
<a name="ln4213">		mask &amp;= ctx-&gt;ifc_softc_ctx.isc_capabilities;</a>
<a name="ln4214">		setmask = 0;</a>
<a name="ln4215">#ifdef TCP_OFFLOAD</a>
<a name="ln4216">		setmask |= mask &amp; (IFCAP_TOE4|IFCAP_TOE6);</a>
<a name="ln4217">#endif</a>
<a name="ln4218">		setmask |= (mask &amp; IFCAP_FLAGS);</a>
<a name="ln4219">		setmask |= (mask &amp; IFCAP_WOL);</a>
<a name="ln4220"> </a>
<a name="ln4221">		/*</a>
<a name="ln4222">		 * If any RX csum has changed, change all the ones that</a>
<a name="ln4223">		 * are supported by the driver.</a>
<a name="ln4224">		 */</a>
<a name="ln4225">		if (setmask &amp; (IFCAP_RXCSUM | IFCAP_RXCSUM_IPV6)) {</a>
<a name="ln4226">			setmask |= ctx-&gt;ifc_softc_ctx.isc_capabilities &amp;</a>
<a name="ln4227">			    (IFCAP_RXCSUM | IFCAP_RXCSUM_IPV6);</a>
<a name="ln4228">		}</a>
<a name="ln4229"> </a>
<a name="ln4230">		/*</a>
<a name="ln4231">		 * want to ensure that traffic has stopped before we change any of the flags</a>
<a name="ln4232">		 */</a>
<a name="ln4233">		if (setmask) {</a>
<a name="ln4234">			CTX_LOCK(ctx);</a>
<a name="ln4235">			bits = if_getdrvflags(ifp);</a>
<a name="ln4236">			if (bits &amp; IFF_DRV_RUNNING &amp;&amp; setmask &amp; ~IFCAP_WOL)</a>
<a name="ln4237">				iflib_stop(ctx);</a>
<a name="ln4238">			STATE_LOCK(ctx);</a>
<a name="ln4239">			if_togglecapenable(ifp, setmask);</a>
<a name="ln4240">			STATE_UNLOCK(ctx);</a>
<a name="ln4241">			if (bits &amp; IFF_DRV_RUNNING &amp;&amp; setmask &amp; ~IFCAP_WOL)</a>
<a name="ln4242">				iflib_init_locked(ctx);</a>
<a name="ln4243">			STATE_LOCK(ctx);</a>
<a name="ln4244">			if_setdrvflags(ifp, bits);</a>
<a name="ln4245">			STATE_UNLOCK(ctx);</a>
<a name="ln4246">			CTX_UNLOCK(ctx);</a>
<a name="ln4247">		}</a>
<a name="ln4248">		if_vlancap(ifp);</a>
<a name="ln4249">		break;</a>
<a name="ln4250">	}</a>
<a name="ln4251">	case SIOCGPRIVATE_0:</a>
<a name="ln4252">	case SIOCSDRVSPEC:</a>
<a name="ln4253">	case SIOCGDRVSPEC:</a>
<a name="ln4254">		CTX_LOCK(ctx);</a>
<a name="ln4255">		err = IFDI_PRIV_IOCTL(ctx, command, data);</a>
<a name="ln4256">		CTX_UNLOCK(ctx);</a>
<a name="ln4257">		break;</a>
<a name="ln4258">	default:</a>
<a name="ln4259">		err = ether_ioctl(ifp, command, data);</a>
<a name="ln4260">		break;</a>
<a name="ln4261">	}</a>
<a name="ln4262">	if (reinit)</a>
<a name="ln4263">		iflib_if_init(ctx);</a>
<a name="ln4264">	return (err);</a>
<a name="ln4265">}</a>
<a name="ln4266"> </a>
<a name="ln4267">static uint64_t</a>
<a name="ln4268">iflib_if_get_counter(if_t ifp, ift_counter cnt)</a>
<a name="ln4269">{</a>
<a name="ln4270">	if_ctx_t ctx = if_getsoftc(ifp);</a>
<a name="ln4271"> </a>
<a name="ln4272">	return (IFDI_GET_COUNTER(ctx, cnt));</a>
<a name="ln4273">}</a>
<a name="ln4274"> </a>
<a name="ln4275">/*********************************************************************</a>
<a name="ln4276"> *</a>
<a name="ln4277"> *  OTHER FUNCTIONS EXPORTED TO THE STACK</a>
<a name="ln4278"> *</a>
<a name="ln4279"> **********************************************************************/</a>
<a name="ln4280"> </a>
<a name="ln4281">static void</a>
<a name="ln4282">iflib_vlan_register(void *arg, if_t ifp, uint16_t vtag)</a>
<a name="ln4283">{</a>
<a name="ln4284">	if_ctx_t ctx = if_getsoftc(ifp);</a>
<a name="ln4285"> </a>
<a name="ln4286">	if ((void *)ctx != arg)</a>
<a name="ln4287">		return;</a>
<a name="ln4288"> </a>
<a name="ln4289">	if ((vtag == 0) || (vtag &gt; 4095))</a>
<a name="ln4290">		return;</a>
<a name="ln4291"> </a>
<a name="ln4292">	CTX_LOCK(ctx);</a>
<a name="ln4293">	IFDI_VLAN_REGISTER(ctx, vtag);</a>
<a name="ln4294">	/* Re-init to load the changes */</a>
<a name="ln4295">	if (if_getcapenable(ifp) &amp; IFCAP_VLAN_HWFILTER)</a>
<a name="ln4296">		iflib_if_init_locked(ctx);</a>
<a name="ln4297">	CTX_UNLOCK(ctx);</a>
<a name="ln4298">}</a>
<a name="ln4299"> </a>
<a name="ln4300">static void</a>
<a name="ln4301">iflib_vlan_unregister(void *arg, if_t ifp, uint16_t vtag)</a>
<a name="ln4302">{</a>
<a name="ln4303">	if_ctx_t ctx = if_getsoftc(ifp);</a>
<a name="ln4304"> </a>
<a name="ln4305">	if ((void *)ctx != arg)</a>
<a name="ln4306">		return;</a>
<a name="ln4307"> </a>
<a name="ln4308">	if ((vtag == 0) || (vtag &gt; 4095))</a>
<a name="ln4309">		return;</a>
<a name="ln4310"> </a>
<a name="ln4311">	CTX_LOCK(ctx);</a>
<a name="ln4312">	IFDI_VLAN_UNREGISTER(ctx, vtag);</a>
<a name="ln4313">	/* Re-init to load the changes */</a>
<a name="ln4314">	if (if_getcapenable(ifp) &amp; IFCAP_VLAN_HWFILTER)</a>
<a name="ln4315">		iflib_if_init_locked(ctx);</a>
<a name="ln4316">	CTX_UNLOCK(ctx);</a>
<a name="ln4317">}</a>
<a name="ln4318"> </a>
<a name="ln4319">static void</a>
<a name="ln4320">iflib_led_func(void *arg, int onoff)</a>
<a name="ln4321">{</a>
<a name="ln4322">	if_ctx_t ctx = arg;</a>
<a name="ln4323"> </a>
<a name="ln4324">	CTX_LOCK(ctx);</a>
<a name="ln4325">	IFDI_LED_FUNC(ctx, onoff);</a>
<a name="ln4326">	CTX_UNLOCK(ctx);</a>
<a name="ln4327">}</a>
<a name="ln4328"> </a>
<a name="ln4329">/*********************************************************************</a>
<a name="ln4330"> *</a>
<a name="ln4331"> *  BUS FUNCTION DEFINITIONS</a>
<a name="ln4332"> *</a>
<a name="ln4333"> **********************************************************************/</a>
<a name="ln4334"> </a>
<a name="ln4335">int</a>
<a name="ln4336">iflib_device_probe(device_t dev)</a>
<a name="ln4337">{</a>
<a name="ln4338">	pci_vendor_info_t *ent;</a>
<a name="ln4339"> </a>
<a name="ln4340">	uint16_t	pci_vendor_id, pci_device_id;</a>
<a name="ln4341">	uint16_t	pci_subvendor_id, pci_subdevice_id;</a>
<a name="ln4342">	uint16_t	pci_rev_id;</a>
<a name="ln4343">	if_shared_ctx_t sctx;</a>
<a name="ln4344"> </a>
<a name="ln4345">	if ((sctx = DEVICE_REGISTER(dev)) == NULL || sctx-&gt;isc_magic != IFLIB_MAGIC)</a>
<a name="ln4346">		return (ENOTSUP);</a>
<a name="ln4347"> </a>
<a name="ln4348">	pci_vendor_id = pci_get_vendor(dev);</a>
<a name="ln4349">	pci_device_id = pci_get_device(dev);</a>
<a name="ln4350">	pci_subvendor_id = pci_get_subvendor(dev);</a>
<a name="ln4351">	pci_subdevice_id = pci_get_subdevice(dev);</a>
<a name="ln4352">	pci_rev_id = pci_get_revid(dev);</a>
<a name="ln4353">	if (sctx-&gt;isc_parse_devinfo != NULL)</a>
<a name="ln4354">		sctx-&gt;isc_parse_devinfo(&amp;pci_device_id, &amp;pci_subvendor_id, &amp;pci_subdevice_id, &amp;pci_rev_id);</a>
<a name="ln4355"> </a>
<a name="ln4356">	ent = sctx-&gt;isc_vendor_info;</a>
<a name="ln4357">	while (ent-&gt;pvi_vendor_id != 0) {</a>
<a name="ln4358">		if (pci_vendor_id != ent-&gt;pvi_vendor_id) {</a>
<a name="ln4359">			ent++;</a>
<a name="ln4360">			continue;</a>
<a name="ln4361">		}</a>
<a name="ln4362">		if ((pci_device_id == ent-&gt;pvi_device_id) &amp;&amp;</a>
<a name="ln4363">		    ((pci_subvendor_id == ent-&gt;pvi_subvendor_id) ||</a>
<a name="ln4364">		     (ent-&gt;pvi_subvendor_id == 0)) &amp;&amp;</a>
<a name="ln4365">		    ((pci_subdevice_id == ent-&gt;pvi_subdevice_id) ||</a>
<a name="ln4366">		     (ent-&gt;pvi_subdevice_id == 0)) &amp;&amp;</a>
<a name="ln4367">		    ((pci_rev_id == ent-&gt;pvi_rev_id) ||</a>
<a name="ln4368">		     (ent-&gt;pvi_rev_id == 0))) {</a>
<a name="ln4369"> </a>
<a name="ln4370">			device_set_desc_copy(dev, ent-&gt;pvi_name);</a>
<a name="ln4371">			/* this needs to be changed to zero if the bus probing code</a>
<a name="ln4372">			 * ever stops re-probing on best match because the sctx</a>
<a name="ln4373">			 * may have its values over written by register calls</a>
<a name="ln4374">			 * in subsequent probes</a>
<a name="ln4375">			 */</a>
<a name="ln4376">			return (BUS_PROBE_DEFAULT);</a>
<a name="ln4377">		}</a>
<a name="ln4378">		ent++;</a>
<a name="ln4379">	}</a>
<a name="ln4380">	return (ENXIO);</a>
<a name="ln4381">}</a>
<a name="ln4382"> </a>
<a name="ln4383">static void</a>
<a name="ln4384">iflib_reset_qvalues(if_ctx_t ctx)</a>
<a name="ln4385">{</a>
<a name="ln4386">	if_softc_ctx_t scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln4387">	if_shared_ctx_t sctx = ctx-&gt;ifc_sctx;</a>
<a name="ln4388">	device_t dev = ctx-&gt;ifc_dev;</a>
<a name="ln4389">	int i;</a>
<a name="ln4390"> </a>
<a name="ln4391">	scctx-&gt;isc_txrx_budget_bytes_max = IFLIB_MAX_TX_BYTES;</a>
<a name="ln4392">	scctx-&gt;isc_tx_qdepth = IFLIB_DEFAULT_TX_QDEPTH;</a>
<a name="ln4393">	/*</a>
<a name="ln4394">	 * XXX sanity check that ntxd &amp; nrxd are a power of 2</a>
<a name="ln4395">	 */</a>
<a name="ln4396">	if (ctx-&gt;ifc_sysctl_ntxqs != 0)</a>
<a name="ln4397">		scctx-&gt;isc_ntxqsets = ctx-&gt;ifc_sysctl_ntxqs;</a>
<a name="ln4398">	if (ctx-&gt;ifc_sysctl_nrxqs != 0)</a>
<a name="ln4399">		scctx-&gt;isc_nrxqsets = ctx-&gt;ifc_sysctl_nrxqs;</a>
<a name="ln4400"> </a>
<a name="ln4401">	for (i = 0; i &lt; sctx-&gt;isc_ntxqs; i++) {</a>
<a name="ln4402">		if (ctx-&gt;ifc_sysctl_ntxds[i] != 0)</a>
<a name="ln4403">			scctx-&gt;isc_ntxd[i] = ctx-&gt;ifc_sysctl_ntxds[i];</a>
<a name="ln4404">		else</a>
<a name="ln4405">			scctx-&gt;isc_ntxd[i] = sctx-&gt;isc_ntxd_default[i];</a>
<a name="ln4406">	}</a>
<a name="ln4407"> </a>
<a name="ln4408">	for (i = 0; i &lt; sctx-&gt;isc_nrxqs; i++) {</a>
<a name="ln4409">		if (ctx-&gt;ifc_sysctl_nrxds[i] != 0)</a>
<a name="ln4410">			scctx-&gt;isc_nrxd[i] = ctx-&gt;ifc_sysctl_nrxds[i];</a>
<a name="ln4411">		else</a>
<a name="ln4412">			scctx-&gt;isc_nrxd[i] = sctx-&gt;isc_nrxd_default[i];</a>
<a name="ln4413">	}</a>
<a name="ln4414"> </a>
<a name="ln4415">	for (i = 0; i &lt; sctx-&gt;isc_nrxqs; i++) {</a>
<a name="ln4416">		if (scctx-&gt;isc_nrxd[i] &lt; sctx-&gt;isc_nrxd_min[i]) {</a>
<a name="ln4417">			device_printf(dev, &quot;nrxd%d: %d less than nrxd_min %d - resetting to min\n&quot;,</a>
<a name="ln4418">				      i, scctx-&gt;isc_nrxd[i], sctx-&gt;isc_nrxd_min[i]);</a>
<a name="ln4419">			scctx-&gt;isc_nrxd[i] = sctx-&gt;isc_nrxd_min[i];</a>
<a name="ln4420">		}</a>
<a name="ln4421">		if (scctx-&gt;isc_nrxd[i] &gt; sctx-&gt;isc_nrxd_max[i]) {</a>
<a name="ln4422">			device_printf(dev, &quot;nrxd%d: %d greater than nrxd_max %d - resetting to max\n&quot;,</a>
<a name="ln4423">				      i, scctx-&gt;isc_nrxd[i], sctx-&gt;isc_nrxd_max[i]);</a>
<a name="ln4424">			scctx-&gt;isc_nrxd[i] = sctx-&gt;isc_nrxd_max[i];</a>
<a name="ln4425">		}</a>
<a name="ln4426">	}</a>
<a name="ln4427"> </a>
<a name="ln4428">	for (i = 0; i &lt; sctx-&gt;isc_ntxqs; i++) {</a>
<a name="ln4429">		if (scctx-&gt;isc_ntxd[i] &lt; sctx-&gt;isc_ntxd_min[i]) {</a>
<a name="ln4430">			device_printf(dev, &quot;ntxd%d: %d less than ntxd_min %d - resetting to min\n&quot;,</a>
<a name="ln4431">				      i, scctx-&gt;isc_ntxd[i], sctx-&gt;isc_ntxd_min[i]);</a>
<a name="ln4432">			scctx-&gt;isc_ntxd[i] = sctx-&gt;isc_ntxd_min[i];</a>
<a name="ln4433">		}</a>
<a name="ln4434">		if (scctx-&gt;isc_ntxd[i] &gt; sctx-&gt;isc_ntxd_max[i]) {</a>
<a name="ln4435">			device_printf(dev, &quot;ntxd%d: %d greater than ntxd_max %d - resetting to max\n&quot;,</a>
<a name="ln4436">				      i, scctx-&gt;isc_ntxd[i], sctx-&gt;isc_ntxd_max[i]);</a>
<a name="ln4437">			scctx-&gt;isc_ntxd[i] = sctx-&gt;isc_ntxd_max[i];</a>
<a name="ln4438">		}</a>
<a name="ln4439">	}</a>
<a name="ln4440">}</a>
<a name="ln4441"> </a>
<a name="ln4442">int</a>
<a name="ln4443">iflib_device_register(device_t dev, void *sc, if_shared_ctx_t sctx, if_ctx_t *ctxp)</a>
<a name="ln4444">{</a>
<a name="ln4445">	int err, rid, msix;</a>
<a name="ln4446">	if_ctx_t ctx;</a>
<a name="ln4447">	if_t ifp;</a>
<a name="ln4448">	if_softc_ctx_t scctx;</a>
<a name="ln4449">	int i;</a>
<a name="ln4450">	uint16_t main_txq;</a>
<a name="ln4451">	uint16_t main_rxq;</a>
<a name="ln4452"> </a>
<a name="ln4453"> </a>
<a name="ln4454">	ctx = malloc(sizeof(* ctx), M_IFLIB, M_WAITOK|M_ZERO);</a>
<a name="ln4455"> </a>
<a name="ln4456">	if (sc == NULL) {</a>
<a name="ln4457">		sc = malloc(sctx-&gt;isc_driver-&gt;size, M_IFLIB, M_WAITOK|M_ZERO);</a>
<a name="ln4458">		device_set_softc(dev, ctx);</a>
<a name="ln4459">		ctx-&gt;ifc_flags |= IFC_SC_ALLOCATED;</a>
<a name="ln4460">	}</a>
<a name="ln4461"> </a>
<a name="ln4462">	ctx-&gt;ifc_sctx = sctx;</a>
<a name="ln4463">	ctx-&gt;ifc_dev = dev;</a>
<a name="ln4464">	ctx-&gt;ifc_softc = sc;</a>
<a name="ln4465"> </a>
<a name="ln4466">	if ((err = iflib_register(ctx)) != 0) {</a>
<a name="ln4467">		device_printf(dev, &quot;iflib_register failed %d\n&quot;, err);</a>
<a name="ln4468">		goto fail_ctx_free;</a>
<a name="ln4469">	}</a>
<a name="ln4470">	iflib_add_device_sysctl_pre(ctx);</a>
<a name="ln4471"> </a>
<a name="ln4472">	scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln4473">	ifp = ctx-&gt;ifc_ifp;</a>
<a name="ln4474"> </a>
<a name="ln4475">	iflib_reset_qvalues(ctx);</a>
<a name="ln4476">	CTX_LOCK(ctx);</a>
<a name="ln4477">	if ((err = IFDI_ATTACH_PRE(ctx)) != 0) {</a>
<a name="ln4478">		device_printf(dev, &quot;IFDI_ATTACH_PRE failed %d\n&quot;, err);</a>
<a name="ln4479">		goto fail_unlock;</a>
<a name="ln4480">	}</a>
<a name="ln4481">	_iflib_pre_assert(scctx);</a>
<a name="ln4482">	ctx-&gt;ifc_txrx = *scctx-&gt;isc_txrx;</a>
<a name="ln4483"> </a>
<a name="ln4484">#ifdef INVARIANTS</a>
<a name="ln4485">	MPASS(scctx-&gt;isc_capabilities);</a>
<a name="ln4486">	if (scctx-&gt;isc_capabilities &amp; IFCAP_TXCSUM)</a>
<a name="ln4487">		MPASS(scctx-&gt;isc_tx_csum_flags);</a>
<a name="ln4488">#endif</a>
<a name="ln4489"> </a>
<a name="ln4490">	if_setcapabilities(ifp, scctx-&gt;isc_capabilities | IFCAP_HWSTATS);</a>
<a name="ln4491">	if_setcapenable(ifp, scctx-&gt;isc_capenable | IFCAP_HWSTATS);</a>
<a name="ln4492"> </a>
<a name="ln4493">	if (scctx-&gt;isc_ntxqsets == 0 || (scctx-&gt;isc_ntxqsets_max &amp;&amp; scctx-&gt;isc_ntxqsets_max &lt; scctx-&gt;isc_ntxqsets))</a>
<a name="ln4494">		scctx-&gt;isc_ntxqsets = scctx-&gt;isc_ntxqsets_max;</a>
<a name="ln4495">	if (scctx-&gt;isc_nrxqsets == 0 || (scctx-&gt;isc_nrxqsets_max &amp;&amp; scctx-&gt;isc_nrxqsets_max &lt; scctx-&gt;isc_nrxqsets))</a>
<a name="ln4496">		scctx-&gt;isc_nrxqsets = scctx-&gt;isc_nrxqsets_max;</a>
<a name="ln4497"> </a>
<a name="ln4498">	main_txq = (sctx-&gt;isc_flags &amp; IFLIB_HAS_TXCQ) ? 1 : 0;</a>
<a name="ln4499">	main_rxq = (sctx-&gt;isc_flags &amp; IFLIB_HAS_RXCQ) ? 1 : 0;</a>
<a name="ln4500"> </a>
<a name="ln4501">	/* XXX change for per-queue sizes */</a>
<a name="ln4502">	device_printf(dev, &quot;Using %d tx descriptors and %d rx descriptors\n&quot;,</a>
<a name="ln4503">	    scctx-&gt;isc_ntxd[main_txq], scctx-&gt;isc_nrxd[main_rxq]);</a>
<a name="ln4504">	for (i = 0; i &lt; sctx-&gt;isc_nrxqs; i++) {</a>
<a name="ln4505">		if (!powerof2(scctx-&gt;isc_nrxd[i])) {</a>
<a name="ln4506">			/* round down instead? */</a>
<a name="ln4507">			device_printf(dev, &quot;# rx descriptors must be a power of 2\n&quot;);</a>
<a name="ln4508">			err = EINVAL;</a>
<a name="ln4509">			goto fail_iflib_detach;</a>
<a name="ln4510">		}</a>
<a name="ln4511">	}</a>
<a name="ln4512">	for (i = 0; i &lt; sctx-&gt;isc_ntxqs; i++) {</a>
<a name="ln4513">		if (!powerof2(scctx-&gt;isc_ntxd[i])) {</a>
<a name="ln4514">			device_printf(dev,</a>
<a name="ln4515">			    &quot;# tx descriptors must be a power of 2&quot;);</a>
<a name="ln4516">			err = EINVAL;</a>
<a name="ln4517">			goto fail_iflib_detach;</a>
<a name="ln4518">		}</a>
<a name="ln4519">	}</a>
<a name="ln4520"> </a>
<a name="ln4521">	if (scctx-&gt;isc_tx_nsegments &gt; scctx-&gt;isc_ntxd[main_txq] /</a>
<a name="ln4522">	    MAX_SINGLE_PACKET_FRACTION)</a>
<a name="ln4523">		scctx-&gt;isc_tx_nsegments = max(1, scctx-&gt;isc_ntxd[main_txq] /</a>
<a name="ln4524">		    MAX_SINGLE_PACKET_FRACTION);</a>
<a name="ln4525">	if (scctx-&gt;isc_tx_tso_segments_max &gt; scctx-&gt;isc_ntxd[main_txq] /</a>
<a name="ln4526">	    MAX_SINGLE_PACKET_FRACTION)</a>
<a name="ln4527">		scctx-&gt;isc_tx_tso_segments_max = max(1,</a>
<a name="ln4528">		    scctx-&gt;isc_ntxd[main_txq] / MAX_SINGLE_PACKET_FRACTION);</a>
<a name="ln4529"> </a>
<a name="ln4530">	/* TSO parameters - dig these out of the data sheet - simply correspond to tag setup */</a>
<a name="ln4531">	if (if_getcapabilities(ifp) &amp; IFCAP_TSO) {</a>
<a name="ln4532">#ifndef __HAIKU__</a>
<a name="ln4533">		/*</a>
<a name="ln4534">		 * The stack can't handle a TSO size larger than IP_MAXPACKET,</a>
<a name="ln4535">		 * but some MACs do.</a>
<a name="ln4536">		 */</a>
<a name="ln4537">		if_sethwtsomax(ifp, min(scctx-&gt;isc_tx_tso_size_max,</a>
<a name="ln4538">		    IP_MAXPACKET));</a>
<a name="ln4539">		/*</a>
<a name="ln4540">		 * Take maximum number of m_pullup(9)'s in iflib_parse_header()</a>
<a name="ln4541">		 * into account.  In the worst case, each of these calls will</a>
<a name="ln4542">		 * add another mbuf and, thus, the requirement for another DMA</a>
<a name="ln4543">		 * segment.  So for best performance, it doesn't make sense to</a>
<a name="ln4544">		 * advertize a maximum of TSO segments that typically will</a>
<a name="ln4545">		 * require defragmentation in iflib_encap().</a>
<a name="ln4546">		 */</a>
<a name="ln4547">		if_sethwtsomaxsegcount(ifp, scctx-&gt;isc_tx_tso_segments_max - 3);</a>
<a name="ln4548">		if_sethwtsomaxsegsize(ifp, scctx-&gt;isc_tx_tso_segsize_max);</a>
<a name="ln4549">#endif</a>
<a name="ln4550">	}</a>
<a name="ln4551">	if (scctx-&gt;isc_rss_table_size == 0)</a>
<a name="ln4552">		scctx-&gt;isc_rss_table_size = 64;</a>
<a name="ln4553">	scctx-&gt;isc_rss_table_mask = scctx-&gt;isc_rss_table_size-1;</a>
<a name="ln4554"> </a>
<a name="ln4555">	GROUPTASK_INIT(&amp;ctx-&gt;ifc_admin_task, 0, _task_fn_admin, ctx);</a>
<a name="ln4556">	/* XXX format name */</a>
<a name="ln4557">	taskqgroup_attach(qgroup_if_config_tqg, &amp;ctx-&gt;ifc_admin_task, ctx,</a>
<a name="ln4558">	    NULL, NULL, &quot;admin&quot;);</a>
<a name="ln4559"> </a>
<a name="ln4560">#ifndef __HAIKU__</a>
<a name="ln4561">	/* Set up cpu set.  If it fails, use the set of all CPUs. */</a>
<a name="ln4562">	if (bus_get_cpus(dev, INTR_CPUS, sizeof(ctx-&gt;ifc_cpus), &amp;ctx-&gt;ifc_cpus) != 0) {</a>
<a name="ln4563">		device_printf(dev, &quot;Unable to fetch CPU list\n&quot;);</a>
<a name="ln4564">		CPU_COPY(&amp;all_cpus, &amp;ctx-&gt;ifc_cpus);</a>
<a name="ln4565">	}</a>
<a name="ln4566">	MPASS(CPU_COUNT(&amp;ctx-&gt;ifc_cpus) &gt; 0);</a>
<a name="ln4567">#endif</a>
<a name="ln4568"> </a>
<a name="ln4569">	/*</a>
<a name="ln4570">	** Now set up MSI or MSI-X, should return us the number of supported</a>
<a name="ln4571">	** vectors (will be 1 for a legacy interrupt and MSI).</a>
<a name="ln4572">	*/</a>
<a name="ln4573">	if (sctx-&gt;isc_flags &amp; IFLIB_SKIP_MSIX) {</a>
<a name="ln4574">		msix = scctx-&gt;isc_vectors;</a>
<a name="ln4575">	} else if (scctx-&gt;isc_msix_bar != 0)</a>
<a name="ln4576">	       /*</a>
<a name="ln4577">		* The simple fact that isc_msix_bar is not 0 does not mean we</a>
<a name="ln4578">		* we have a good value there that is known to work.</a>
<a name="ln4579">		*/</a>
<a name="ln4580">		msix = iflib_msix_init(ctx);</a>
<a name="ln4581">	else {</a>
<a name="ln4582">		scctx-&gt;isc_vectors = 1;</a>
<a name="ln4583">		scctx-&gt;isc_ntxqsets = 1;</a>
<a name="ln4584">		scctx-&gt;isc_nrxqsets = 1;</a>
<a name="ln4585">		scctx-&gt;isc_intr = IFLIB_INTR_LEGACY;</a>
<a name="ln4586">		msix = 0;</a>
<a name="ln4587">	}</a>
<a name="ln4588">	/* Get memory for the station queues */</a>
<a name="ln4589">	if ((err = iflib_queues_alloc(ctx))) {</a>
<a name="ln4590">		device_printf(dev, &quot;Unable to allocate queue memory\n&quot;);</a>
<a name="ln4591">		goto fail_intr_free;</a>
<a name="ln4592">	}</a>
<a name="ln4593"> </a>
<a name="ln4594">	if ((err = iflib_qset_structures_setup(ctx)))</a>
<a name="ln4595">		goto fail_queues;</a>
<a name="ln4596"> </a>
<a name="ln4597">	/*</a>
<a name="ln4598">	 * Group taskqueues aren't properly set up until SMP is started,</a>
<a name="ln4599">	 * so we disable interrupts until we can handle them post</a>
<a name="ln4600">	 * SI_SUB_SMP.</a>
<a name="ln4601">	 *</a>
<a name="ln4602">	 * XXX: disabling interrupts doesn't actually work, at least for</a>
<a name="ln4603">	 * the non-MSI case.  When they occur before SI_SUB_SMP completes,</a>
<a name="ln4604">	 * we do null handling and depend on this not causing too large an</a>
<a name="ln4605">	 * interrupt storm.</a>
<a name="ln4606">	 */</a>
<a name="ln4607">	IFDI_INTR_DISABLE(ctx);</a>
<a name="ln4608">	if (msix &gt; 1 &amp;&amp; (err = IFDI_MSIX_INTR_ASSIGN(ctx, msix)) != 0) {</a>
<a name="ln4609">		device_printf(dev, &quot;IFDI_MSIX_INTR_ASSIGN failed %d\n&quot;, err);</a>
<a name="ln4610">		goto fail_queues;</a>
<a name="ln4611">	}</a>
<a name="ln4612">	if (msix &lt;= 1) {</a>
<a name="ln4613">		rid = 0;</a>
<a name="ln4614">		if (scctx-&gt;isc_intr == IFLIB_INTR_MSI) {</a>
<a name="ln4615">			MPASS(msix == 1);</a>
<a name="ln4616">			rid = 1;</a>
<a name="ln4617">		}</a>
<a name="ln4618">		if ((err = iflib_legacy_setup(ctx, ctx-&gt;isc_legacy_intr, ctx-&gt;ifc_softc, &amp;rid, &quot;irq0&quot;)) != 0) {</a>
<a name="ln4619">			device_printf(dev, &quot;iflib_legacy_setup failed %d\n&quot;, err);</a>
<a name="ln4620">			goto fail_queues;</a>
<a name="ln4621">		}</a>
<a name="ln4622">	}</a>
<a name="ln4623"> </a>
<a name="ln4624">	ether_ifattach(ctx-&gt;ifc_ifp, ctx-&gt;ifc_mac.octet);</a>
<a name="ln4625"> </a>
<a name="ln4626">	if ((err = IFDI_ATTACH_POST(ctx)) != 0) {</a>
<a name="ln4627">		device_printf(dev, &quot;IFDI_ATTACH_POST failed %d\n&quot;, err);</a>
<a name="ln4628">		goto fail_detach;</a>
<a name="ln4629">	}</a>
<a name="ln4630"> </a>
<a name="ln4631">	/*</a>
<a name="ln4632">	 * Tell the upper layer(s) if IFCAP_VLAN_MTU is supported.</a>
<a name="ln4633">	 * This must appear after the call to ether_ifattach() because</a>
<a name="ln4634">	 * ether_ifattach() sets if_hdrlen to the default value.</a>
<a name="ln4635">	 */</a>
<a name="ln4636">	if (if_getcapabilities(ifp) &amp; IFCAP_VLAN_MTU)</a>
<a name="ln4637">		if_setifheaderlen(ifp, sizeof(struct ether_vlan_header));</a>
<a name="ln4638"> </a>
<a name="ln4639">	if ((err = iflib_netmap_attach(ctx))) {</a>
<a name="ln4640">		device_printf(ctx-&gt;ifc_dev, &quot;netmap attach failed: %d\n&quot;, err);</a>
<a name="ln4641">		goto fail_detach;</a>
<a name="ln4642">	}</a>
<a name="ln4643">	*ctxp = ctx;</a>
<a name="ln4644"> </a>
<a name="ln4645">	NETDUMP_SET(ctx-&gt;ifc_ifp, iflib);</a>
<a name="ln4646"> </a>
<a name="ln4647">	if_setgetcounterfn(ctx-&gt;ifc_ifp, iflib_if_get_counter);</a>
<a name="ln4648">	iflib_add_device_sysctl_post(ctx);</a>
<a name="ln4649">	ctx-&gt;ifc_flags |= IFC_INIT_DONE;</a>
<a name="ln4650">	CTX_UNLOCK(ctx);</a>
<a name="ln4651">	return (0);</a>
<a name="ln4652"> </a>
<a name="ln4653">fail_detach:</a>
<a name="ln4654">	ether_ifdetach(ctx-&gt;ifc_ifp);</a>
<a name="ln4655">fail_intr_free:</a>
<a name="ln4656">	iflib_free_intr_mem(ctx);</a>
<a name="ln4657">fail_queues:</a>
<a name="ln4658">	iflib_tx_structures_free(ctx);</a>
<a name="ln4659">	iflib_rx_structures_free(ctx);</a>
<a name="ln4660">fail_iflib_detach:</a>
<a name="ln4661">	IFDI_DETACH(ctx);</a>
<a name="ln4662">fail_unlock:</a>
<a name="ln4663">	CTX_UNLOCK(ctx);</a>
<a name="ln4664">fail_ctx_free:</a>
<a name="ln4665">        if (ctx-&gt;ifc_flags &amp; IFC_SC_ALLOCATED)</a>
<a name="ln4666">                free(ctx-&gt;ifc_softc, M_IFLIB);</a>
<a name="ln4667">        free(ctx, M_IFLIB);</a>
<a name="ln4668">	return (err);</a>
<a name="ln4669">}</a>
<a name="ln4670"> </a>
<a name="ln4671">int</a>
<a name="ln4672">iflib_pseudo_register(device_t dev, if_shared_ctx_t sctx, if_ctx_t *ctxp,</a>
<a name="ln4673">					  struct iflib_cloneattach_ctx *clctx)</a>
<a name="ln4674">{</a>
<a name="ln4675">	int err;</a>
<a name="ln4676">	if_ctx_t ctx;</a>
<a name="ln4677">	if_t ifp;</a>
<a name="ln4678">	if_softc_ctx_t scctx;</a>
<a name="ln4679">	int i;</a>
<a name="ln4680">	void *sc;</a>
<a name="ln4681">	uint16_t main_txq;</a>
<a name="ln4682">	uint16_t main_rxq;</a>
<a name="ln4683"> </a>
<a name="ln4684">	ctx = malloc(sizeof(*ctx), M_IFLIB, M_WAITOK|M_ZERO);</a>
<a name="ln4685">	sc = malloc(sctx-&gt;isc_driver-&gt;size, M_IFLIB, M_WAITOK|M_ZERO);</a>
<a name="ln4686">	ctx-&gt;ifc_flags |= IFC_SC_ALLOCATED;</a>
<a name="ln4687">	if (sctx-&gt;isc_flags &amp; (IFLIB_PSEUDO|IFLIB_VIRTUAL))</a>
<a name="ln4688">		ctx-&gt;ifc_flags |= IFC_PSEUDO;</a>
<a name="ln4689"> </a>
<a name="ln4690">	ctx-&gt;ifc_sctx = sctx;</a>
<a name="ln4691">	ctx-&gt;ifc_softc = sc;</a>
<a name="ln4692">	ctx-&gt;ifc_dev = dev;</a>
<a name="ln4693"> </a>
<a name="ln4694">	if ((err = iflib_register(ctx)) != 0) {</a>
<a name="ln4695">		device_printf(dev, &quot;%s: iflib_register failed %d\n&quot;, __func__, err);</a>
<a name="ln4696">		goto fail_ctx_free;</a>
<a name="ln4697">	}</a>
<a name="ln4698">	iflib_add_device_sysctl_pre(ctx);</a>
<a name="ln4699"> </a>
<a name="ln4700">	scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln4701">	ifp = ctx-&gt;ifc_ifp;</a>
<a name="ln4702"> </a>
<a name="ln4703">	/*</a>
<a name="ln4704">	 * XXX sanity check that ntxd &amp; nrxd are a power of 2</a>
<a name="ln4705">	 */</a>
<a name="ln4706">	iflib_reset_qvalues(ctx);</a>
<a name="ln4707">	CTX_LOCK(ctx);</a>
<a name="ln4708">	if ((err = IFDI_ATTACH_PRE(ctx)) != 0) {</a>
<a name="ln4709">		device_printf(dev, &quot;IFDI_ATTACH_PRE failed %d\n&quot;, err);</a>
<a name="ln4710">		goto fail_unlock;</a>
<a name="ln4711">	}</a>
<a name="ln4712">#ifndef __HAIKU__</a>
<a name="ln4713">	if (sctx-&gt;isc_flags &amp; IFLIB_GEN_MAC)</a>
<a name="ln4714">		ether_gen_addr(ifp, &amp;ctx-&gt;ifc_mac);</a>
<a name="ln4715">#endif</a>
<a name="ln4716">	if ((err = IFDI_CLONEATTACH(ctx, clctx-&gt;cc_ifc, clctx-&gt;cc_name,</a>
<a name="ln4717">								clctx-&gt;cc_params)) != 0) {</a>
<a name="ln4718">		device_printf(dev, &quot;IFDI_CLONEATTACH failed %d\n&quot;, err);</a>
<a name="ln4719">		goto fail_ctx_free;</a>
<a name="ln4720">	}</a>
<a name="ln4721">	ifmedia_add(&amp;ctx-&gt;ifc_media, IFM_ETHER | IFM_1000_T | IFM_FDX, 0, NULL);</a>
<a name="ln4722">	ifmedia_add(&amp;ctx-&gt;ifc_media, IFM_ETHER | IFM_AUTO, 0, NULL);</a>
<a name="ln4723">	ifmedia_set(&amp;ctx-&gt;ifc_media, IFM_ETHER | IFM_AUTO);</a>
<a name="ln4724"> </a>
<a name="ln4725">#ifdef INVARIANTS</a>
<a name="ln4726">	MPASS(scctx-&gt;isc_capabilities);</a>
<a name="ln4727">	if (scctx-&gt;isc_capabilities &amp; IFCAP_TXCSUM)</a>
<a name="ln4728">		MPASS(scctx-&gt;isc_tx_csum_flags);</a>
<a name="ln4729">#endif</a>
<a name="ln4730"> </a>
<a name="ln4731">	if_setcapabilities(ifp, scctx-&gt;isc_capabilities | IFCAP_HWSTATS | IFCAP_LINKSTATE);</a>
<a name="ln4732">	if_setcapenable(ifp, scctx-&gt;isc_capenable | IFCAP_HWSTATS | IFCAP_LINKSTATE);</a>
<a name="ln4733"> </a>
<a name="ln4734">	ifp-&gt;if_flags |= IFF_NOGROUP;</a>
<a name="ln4735">	if (sctx-&gt;isc_flags &amp; IFLIB_PSEUDO) {</a>
<a name="ln4736">		ether_ifattach(ctx-&gt;ifc_ifp, ctx-&gt;ifc_mac.octet);</a>
<a name="ln4737"> </a>
<a name="ln4738">		if ((err = IFDI_ATTACH_POST(ctx)) != 0) {</a>
<a name="ln4739">			device_printf(dev, &quot;IFDI_ATTACH_POST failed %d\n&quot;, err);</a>
<a name="ln4740">			goto fail_detach;</a>
<a name="ln4741">		}</a>
<a name="ln4742">		*ctxp = ctx;</a>
<a name="ln4743"> </a>
<a name="ln4744">		/*</a>
<a name="ln4745">		 * Tell the upper layer(s) if IFCAP_VLAN_MTU is supported.</a>
<a name="ln4746">		 * This must appear after the call to ether_ifattach() because</a>
<a name="ln4747">		 * ether_ifattach() sets if_hdrlen to the default value.</a>
<a name="ln4748">		 */</a>
<a name="ln4749">		if (if_getcapabilities(ifp) &amp; IFCAP_VLAN_MTU)</a>
<a name="ln4750">			if_setifheaderlen(ifp,</a>
<a name="ln4751">			    sizeof(struct ether_vlan_header));</a>
<a name="ln4752"> </a>
<a name="ln4753">		if_setgetcounterfn(ctx-&gt;ifc_ifp, iflib_if_get_counter);</a>
<a name="ln4754">		iflib_add_device_sysctl_post(ctx);</a>
<a name="ln4755">		ctx-&gt;ifc_flags |= IFC_INIT_DONE;</a>
<a name="ln4756">		return (0);</a>
<a name="ln4757">	}</a>
<a name="ln4758">	_iflib_pre_assert(scctx);</a>
<a name="ln4759">	ctx-&gt;ifc_txrx = *scctx-&gt;isc_txrx;</a>
<a name="ln4760"> </a>
<a name="ln4761">	if (scctx-&gt;isc_ntxqsets == 0 || (scctx-&gt;isc_ntxqsets_max &amp;&amp; scctx-&gt;isc_ntxqsets_max &lt; scctx-&gt;isc_ntxqsets))</a>
<a name="ln4762">		scctx-&gt;isc_ntxqsets = scctx-&gt;isc_ntxqsets_max;</a>
<a name="ln4763">	if (scctx-&gt;isc_nrxqsets == 0 || (scctx-&gt;isc_nrxqsets_max &amp;&amp; scctx-&gt;isc_nrxqsets_max &lt; scctx-&gt;isc_nrxqsets))</a>
<a name="ln4764">		scctx-&gt;isc_nrxqsets = scctx-&gt;isc_nrxqsets_max;</a>
<a name="ln4765"> </a>
<a name="ln4766">	main_txq = (sctx-&gt;isc_flags &amp; IFLIB_HAS_TXCQ) ? 1 : 0;</a>
<a name="ln4767">	main_rxq = (sctx-&gt;isc_flags &amp; IFLIB_HAS_RXCQ) ? 1 : 0;</a>
<a name="ln4768"> </a>
<a name="ln4769">	/* XXX change for per-queue sizes */</a>
<a name="ln4770">	device_printf(dev, &quot;Using %d tx descriptors and %d rx descriptors\n&quot;,</a>
<a name="ln4771">	    scctx-&gt;isc_ntxd[main_txq], scctx-&gt;isc_nrxd[main_rxq]);</a>
<a name="ln4772">	for (i = 0; i &lt; sctx-&gt;isc_nrxqs; i++) {</a>
<a name="ln4773">		if (!powerof2(scctx-&gt;isc_nrxd[i])) {</a>
<a name="ln4774">			/* round down instead? */</a>
<a name="ln4775">			device_printf(dev, &quot;# rx descriptors must be a power of 2\n&quot;);</a>
<a name="ln4776">			err = EINVAL;</a>
<a name="ln4777">			goto fail_iflib_detach;</a>
<a name="ln4778">		}</a>
<a name="ln4779">	}</a>
<a name="ln4780">	for (i = 0; i &lt; sctx-&gt;isc_ntxqs; i++) {</a>
<a name="ln4781">		if (!powerof2(scctx-&gt;isc_ntxd[i])) {</a>
<a name="ln4782">			device_printf(dev,</a>
<a name="ln4783">			    &quot;# tx descriptors must be a power of 2&quot;);</a>
<a name="ln4784">			err = EINVAL;</a>
<a name="ln4785">			goto fail_iflib_detach;</a>
<a name="ln4786">		}</a>
<a name="ln4787">	}</a>
<a name="ln4788"> </a>
<a name="ln4789">	if (scctx-&gt;isc_tx_nsegments &gt; scctx-&gt;isc_ntxd[main_txq] /</a>
<a name="ln4790">	    MAX_SINGLE_PACKET_FRACTION)</a>
<a name="ln4791">		scctx-&gt;isc_tx_nsegments = max(1, scctx-&gt;isc_ntxd[main_txq] /</a>
<a name="ln4792">		    MAX_SINGLE_PACKET_FRACTION);</a>
<a name="ln4793">	if (scctx-&gt;isc_tx_tso_segments_max &gt; scctx-&gt;isc_ntxd[main_txq] /</a>
<a name="ln4794">	    MAX_SINGLE_PACKET_FRACTION)</a>
<a name="ln4795">		scctx-&gt;isc_tx_tso_segments_max = max(1,</a>
<a name="ln4796">		    scctx-&gt;isc_ntxd[main_txq] / MAX_SINGLE_PACKET_FRACTION);</a>
<a name="ln4797"> </a>
<a name="ln4798">	/* TSO parameters - dig these out of the data sheet - simply correspond to tag setup */</a>
<a name="ln4799">	if (if_getcapabilities(ifp) &amp; IFCAP_TSO) {</a>
<a name="ln4800">#ifndef __HAIKU__</a>
<a name="ln4801">		/*</a>
<a name="ln4802">		 * The stack can't handle a TSO size larger than IP_MAXPACKET,</a>
<a name="ln4803">		 * but some MACs do.</a>
<a name="ln4804">		 */</a>
<a name="ln4805">		if_sethwtsomax(ifp, min(scctx-&gt;isc_tx_tso_size_max,</a>
<a name="ln4806">		    IP_MAXPACKET));</a>
<a name="ln4807">		/*</a>
<a name="ln4808">		 * Take maximum number of m_pullup(9)'s in iflib_parse_header()</a>
<a name="ln4809">		 * into account.  In the worst case, each of these calls will</a>
<a name="ln4810">		 * add another mbuf and, thus, the requirement for another DMA</a>
<a name="ln4811">		 * segment.  So for best performance, it doesn't make sense to</a>
<a name="ln4812">		 * advertize a maximum of TSO segments that typically will</a>
<a name="ln4813">		 * require defragmentation in iflib_encap().</a>
<a name="ln4814">		 */</a>
<a name="ln4815">		if_sethwtsomaxsegcount(ifp, scctx-&gt;isc_tx_tso_segments_max - 3);</a>
<a name="ln4816">		if_sethwtsomaxsegsize(ifp, scctx-&gt;isc_tx_tso_segsize_max);</a>
<a name="ln4817">#endif</a>
<a name="ln4818">	}</a>
<a name="ln4819">	if (scctx-&gt;isc_rss_table_size == 0)</a>
<a name="ln4820">		scctx-&gt;isc_rss_table_size = 64;</a>
<a name="ln4821">	scctx-&gt;isc_rss_table_mask = scctx-&gt;isc_rss_table_size-1;</a>
<a name="ln4822"> </a>
<a name="ln4823">	GROUPTASK_INIT(&amp;ctx-&gt;ifc_admin_task, 0, _task_fn_admin, ctx);</a>
<a name="ln4824">	/* XXX format name */</a>
<a name="ln4825">	taskqgroup_attach(qgroup_if_config_tqg, &amp;ctx-&gt;ifc_admin_task, ctx,</a>
<a name="ln4826">	    NULL, NULL, &quot;admin&quot;);</a>
<a name="ln4827"> </a>
<a name="ln4828">	/* XXX --- can support &gt; 1 -- but keep it simple for now */</a>
<a name="ln4829">	scctx-&gt;isc_intr = IFLIB_INTR_LEGACY;</a>
<a name="ln4830"> </a>
<a name="ln4831">	/* Get memory for the station queues */</a>
<a name="ln4832">	if ((err = iflib_queues_alloc(ctx))) {</a>
<a name="ln4833">		device_printf(dev, &quot;Unable to allocate queue memory\n&quot;);</a>
<a name="ln4834">		goto fail_iflib_detach;</a>
<a name="ln4835">	}</a>
<a name="ln4836"> </a>
<a name="ln4837">	if ((err = iflib_qset_structures_setup(ctx))) {</a>
<a name="ln4838">		device_printf(dev, &quot;qset structure setup failed %d\n&quot;, err);</a>
<a name="ln4839">		goto fail_queues;</a>
<a name="ln4840">	}</a>
<a name="ln4841"> </a>
<a name="ln4842">	/*</a>
<a name="ln4843">	 * XXX What if anything do we want to do about interrupts?</a>
<a name="ln4844">	 */</a>
<a name="ln4845">	ether_ifattach(ctx-&gt;ifc_ifp, ctx-&gt;ifc_mac.octet);</a>
<a name="ln4846">	if ((err = IFDI_ATTACH_POST(ctx)) != 0) {</a>
<a name="ln4847">		device_printf(dev, &quot;IFDI_ATTACH_POST failed %d\n&quot;, err);</a>
<a name="ln4848">		goto fail_detach;</a>
<a name="ln4849">	}</a>
<a name="ln4850"> </a>
<a name="ln4851">	/*</a>
<a name="ln4852">	 * Tell the upper layer(s) if IFCAP_VLAN_MTU is supported.</a>
<a name="ln4853">	 * This must appear after the call to ether_ifattach() because</a>
<a name="ln4854">	 * ether_ifattach() sets if_hdrlen to the default value.</a>
<a name="ln4855">	 */</a>
<a name="ln4856">	if (if_getcapabilities(ifp) &amp; IFCAP_VLAN_MTU)</a>
<a name="ln4857">		if_setifheaderlen(ifp, sizeof(struct ether_vlan_header));</a>
<a name="ln4858"> </a>
<a name="ln4859">	/* XXX handle more than one queue */</a>
<a name="ln4860">	for (i = 0; i &lt; scctx-&gt;isc_nrxqsets; i++)</a>
<a name="ln4861">		IFDI_RX_CLSET(ctx, 0, i, ctx-&gt;ifc_rxqs[i].ifr_fl[0].ifl_sds.ifsd_cl);</a>
<a name="ln4862"> </a>
<a name="ln4863">	*ctxp = ctx;</a>
<a name="ln4864"> </a>
<a name="ln4865">	if_setgetcounterfn(ctx-&gt;ifc_ifp, iflib_if_get_counter);</a>
<a name="ln4866">	iflib_add_device_sysctl_post(ctx);</a>
<a name="ln4867">	ctx-&gt;ifc_flags |= IFC_INIT_DONE;</a>
<a name="ln4868">	CTX_UNLOCK(ctx);</a>
<a name="ln4869">	return (0);</a>
<a name="ln4870">fail_detach:</a>
<a name="ln4871">	ether_ifdetach(ctx-&gt;ifc_ifp);</a>
<a name="ln4872">fail_queues:</a>
<a name="ln4873">	iflib_tx_structures_free(ctx);</a>
<a name="ln4874">	iflib_rx_structures_free(ctx);</a>
<a name="ln4875">fail_iflib_detach:</a>
<a name="ln4876">	IFDI_DETACH(ctx);</a>
<a name="ln4877">fail_unlock:</a>
<a name="ln4878">	CTX_UNLOCK(ctx);</a>
<a name="ln4879">fail_ctx_free:</a>
<a name="ln4880">	free(ctx-&gt;ifc_softc, M_IFLIB);</a>
<a name="ln4881">	free(ctx, M_IFLIB);</a>
<a name="ln4882">	return (err);</a>
<a name="ln4883">}</a>
<a name="ln4884"> </a>
<a name="ln4885">int</a>
<a name="ln4886">iflib_pseudo_deregister(if_ctx_t ctx)</a>
<a name="ln4887">{</a>
<a name="ln4888">	if_t ifp = ctx-&gt;ifc_ifp;</a>
<a name="ln4889">	iflib_txq_t txq;</a>
<a name="ln4890">	iflib_rxq_t rxq;</a>
<a name="ln4891">	int i, j;</a>
<a name="ln4892">	struct taskqgroup *tqg;</a>
<a name="ln4893">	iflib_fl_t fl;</a>
<a name="ln4894"> </a>
<a name="ln4895">	/* Unregister VLAN events */</a>
<a name="ln4896">	if (ctx-&gt;ifc_vlan_attach_event != NULL)</a>
<a name="ln4897">		EVENTHANDLER_DEREGISTER(vlan_config, ctx-&gt;ifc_vlan_attach_event);</a>
<a name="ln4898">	if (ctx-&gt;ifc_vlan_detach_event != NULL)</a>
<a name="ln4899">		EVENTHANDLER_DEREGISTER(vlan_unconfig, ctx-&gt;ifc_vlan_detach_event);</a>
<a name="ln4900"> </a>
<a name="ln4901">	ether_ifdetach(ifp);</a>
<a name="ln4902">	/* ether_ifdetach calls if_qflush - lock must be destroy afterwards*/</a>
<a name="ln4903">	CTX_LOCK_DESTROY(ctx);</a>
<a name="ln4904">	/* XXX drain any dependent tasks */</a>
<a name="ln4905">	tqg = qgroup_if_io_tqg;</a>
<a name="ln4906">	for (txq = ctx-&gt;ifc_txqs, i = 0; i &lt; NTXQSETS(ctx); i++, txq++) {</a>
<a name="ln4907">		callout_drain(&amp;txq-&gt;ift_timer);</a>
<a name="ln4908">		if (txq-&gt;ift_task.gt_uniq != NULL)</a>
<a name="ln4909">			taskqgroup_detach(tqg, &amp;txq-&gt;ift_task);</a>
<a name="ln4910">	}</a>
<a name="ln4911">	for (i = 0, rxq = ctx-&gt;ifc_rxqs; i &lt; NRXQSETS(ctx); i++, rxq++) {</a>
<a name="ln4912">		if (rxq-&gt;ifr_task.gt_uniq != NULL)</a>
<a name="ln4913">			taskqgroup_detach(tqg, &amp;rxq-&gt;ifr_task);</a>
<a name="ln4914"> </a>
<a name="ln4915">		for (j = 0, fl = rxq-&gt;ifr_fl; j &lt; rxq-&gt;ifr_nfl; j++, fl++)</a>
<a name="ln4916">			free(fl-&gt;ifl_rx_bitmap, M_IFLIB);</a>
<a name="ln4917">	}</a>
<a name="ln4918">	tqg = qgroup_if_config_tqg;</a>
<a name="ln4919">	if (ctx-&gt;ifc_admin_task.gt_uniq != NULL)</a>
<a name="ln4920">		taskqgroup_detach(tqg, &amp;ctx-&gt;ifc_admin_task);</a>
<a name="ln4921">	if (ctx-&gt;ifc_vflr_task.gt_uniq != NULL)</a>
<a name="ln4922">		taskqgroup_detach(tqg, &amp;ctx-&gt;ifc_vflr_task);</a>
<a name="ln4923"> </a>
<a name="ln4924">	if_free(ifp);</a>
<a name="ln4925"> </a>
<a name="ln4926">	iflib_tx_structures_free(ctx);</a>
<a name="ln4927">	iflib_rx_structures_free(ctx);</a>
<a name="ln4928">	if (ctx-&gt;ifc_flags &amp; IFC_SC_ALLOCATED)</a>
<a name="ln4929">		free(ctx-&gt;ifc_softc, M_IFLIB);</a>
<a name="ln4930">	free(ctx, M_IFLIB);</a>
<a name="ln4931">	return (0);</a>
<a name="ln4932">}</a>
<a name="ln4933"> </a>
<a name="ln4934">int</a>
<a name="ln4935">iflib_device_attach(device_t dev)</a>
<a name="ln4936">{</a>
<a name="ln4937">	if_ctx_t ctx;</a>
<a name="ln4938">	if_shared_ctx_t sctx;</a>
<a name="ln4939"> </a>
<a name="ln4940">	if ((sctx = DEVICE_REGISTER(dev)) == NULL || sctx-&gt;isc_magic != IFLIB_MAGIC)</a>
<a name="ln4941">		return (ENOTSUP);</a>
<a name="ln4942"> </a>
<a name="ln4943">	pci_enable_busmaster(dev);</a>
<a name="ln4944"> </a>
<a name="ln4945">	return (iflib_device_register(dev, NULL, sctx, &amp;ctx));</a>
<a name="ln4946">}</a>
<a name="ln4947"> </a>
<a name="ln4948">int</a>
<a name="ln4949">iflib_device_deregister(if_ctx_t ctx)</a>
<a name="ln4950">{</a>
<a name="ln4951">	if_t ifp = ctx-&gt;ifc_ifp;</a>
<a name="ln4952">	iflib_txq_t txq;</a>
<a name="ln4953">	iflib_rxq_t rxq;</a>
<a name="ln4954">	device_t dev = ctx-&gt;ifc_dev;</a>
<a name="ln4955">	int i, j;</a>
<a name="ln4956">	struct taskqgroup *tqg;</a>
<a name="ln4957">	iflib_fl_t fl;</a>
<a name="ln4958"> </a>
<a name="ln4959">	/* Make sure VLANS are not using driver */</a>
<a name="ln4960">	if (if_vlantrunkinuse(ifp)) {</a>
<a name="ln4961">		device_printf(dev, &quot;Vlan in use, detach first\n&quot;);</a>
<a name="ln4962">		return (EBUSY);</a>
<a name="ln4963">	}</a>
<a name="ln4964">#ifdef PCI_IOV</a>
<a name="ln4965">	if (!CTX_IS_VF(ctx) &amp;&amp; pci_iov_detach(dev) != 0) {</a>
<a name="ln4966">		device_printf(dev, &quot;SR-IOV in use; detach first.\n&quot;);</a>
<a name="ln4967">		return (EBUSY);</a>
<a name="ln4968">	}</a>
<a name="ln4969">#endif</a>
<a name="ln4970"> </a>
<a name="ln4971">	STATE_LOCK(ctx);</a>
<a name="ln4972">	ctx-&gt;ifc_flags |= IFC_IN_DETACH;</a>
<a name="ln4973">	STATE_UNLOCK(ctx);</a>
<a name="ln4974"> </a>
<a name="ln4975">	CTX_LOCK(ctx);</a>
<a name="ln4976">	iflib_stop(ctx);</a>
<a name="ln4977">	CTX_UNLOCK(ctx);</a>
<a name="ln4978"> </a>
<a name="ln4979">	/* Unregister VLAN events */</a>
<a name="ln4980">	if (ctx-&gt;ifc_vlan_attach_event != NULL)</a>
<a name="ln4981">		EVENTHANDLER_DEREGISTER(vlan_config, ctx-&gt;ifc_vlan_attach_event);</a>
<a name="ln4982">	if (ctx-&gt;ifc_vlan_detach_event != NULL)</a>
<a name="ln4983">		EVENTHANDLER_DEREGISTER(vlan_unconfig, ctx-&gt;ifc_vlan_detach_event);</a>
<a name="ln4984"> </a>
<a name="ln4985">	iflib_netmap_detach(ifp);</a>
<a name="ln4986">	ether_ifdetach(ifp);</a>
<a name="ln4987">	if (ctx-&gt;ifc_led_dev != NULL)</a>
<a name="ln4988">		led_destroy(ctx-&gt;ifc_led_dev);</a>
<a name="ln4989">	/* XXX drain any dependent tasks */</a>
<a name="ln4990">	tqg = qgroup_if_io_tqg;</a>
<a name="ln4991">	for (txq = ctx-&gt;ifc_txqs, i = 0; i &lt; NTXQSETS(ctx); i++, txq++) {</a>
<a name="ln4992">		callout_drain(&amp;txq-&gt;ift_timer);</a>
<a name="ln4993">		if (txq-&gt;ift_task.gt_uniq != NULL)</a>
<a name="ln4994">			taskqgroup_detach(tqg, &amp;txq-&gt;ift_task);</a>
<a name="ln4995">	}</a>
<a name="ln4996">	for (i = 0, rxq = ctx-&gt;ifc_rxqs; i &lt; NRXQSETS(ctx); i++, rxq++) {</a>
<a name="ln4997">		if (rxq-&gt;ifr_task.gt_uniq != NULL)</a>
<a name="ln4998">			taskqgroup_detach(tqg, &amp;rxq-&gt;ifr_task);</a>
<a name="ln4999"> </a>
<a name="ln5000">		for (j = 0, fl = rxq-&gt;ifr_fl; j &lt; rxq-&gt;ifr_nfl; j++, fl++)</a>
<a name="ln5001">			free(fl-&gt;ifl_rx_bitmap, M_IFLIB);</a>
<a name="ln5002">	}</a>
<a name="ln5003">	tqg = qgroup_if_config_tqg;</a>
<a name="ln5004">	if (ctx-&gt;ifc_admin_task.gt_uniq != NULL)</a>
<a name="ln5005">		taskqgroup_detach(tqg, &amp;ctx-&gt;ifc_admin_task);</a>
<a name="ln5006">	if (ctx-&gt;ifc_vflr_task.gt_uniq != NULL)</a>
<a name="ln5007">		taskqgroup_detach(tqg, &amp;ctx-&gt;ifc_vflr_task);</a>
<a name="ln5008">	CTX_LOCK(ctx);</a>
<a name="ln5009">	IFDI_DETACH(ctx);</a>
<a name="ln5010">	CTX_UNLOCK(ctx);</a>
<a name="ln5011"> </a>
<a name="ln5012">	/* ether_ifdetach calls if_qflush - lock must be destroy afterwards*/</a>
<a name="ln5013">	CTX_LOCK_DESTROY(ctx);</a>
<a name="ln5014">	device_set_softc(ctx-&gt;ifc_dev, NULL);</a>
<a name="ln5015">	iflib_free_intr_mem(ctx);</a>
<a name="ln5016"> </a>
<a name="ln5017">	bus_generic_detach(dev);</a>
<a name="ln5018">	if_free(ifp);</a>
<a name="ln5019"> </a>
<a name="ln5020">	iflib_tx_structures_free(ctx);</a>
<a name="ln5021">	iflib_rx_structures_free(ctx);</a>
<a name="ln5022">	if (ctx-&gt;ifc_flags &amp; IFC_SC_ALLOCATED)</a>
<a name="ln5023">		free(ctx-&gt;ifc_softc, M_IFLIB);</a>
<a name="ln5024">	STATE_LOCK_DESTROY(ctx);</a>
<a name="ln5025">	free(ctx, M_IFLIB);</a>
<a name="ln5026">	return (0);</a>
<a name="ln5027">}</a>
<a name="ln5028"> </a>
<a name="ln5029">static void</a>
<a name="ln5030">iflib_free_intr_mem(if_ctx_t ctx)</a>
<a name="ln5031">{</a>
<a name="ln5032"> </a>
<a name="ln5033">	if (ctx-&gt;ifc_softc_ctx.isc_intr != IFLIB_INTR_MSIX) {</a>
<a name="ln5034">		iflib_irq_free(ctx, &amp;ctx-&gt;ifc_legacy_irq);</a>
<a name="ln5035">	}</a>
<a name="ln5036">	if (ctx-&gt;ifc_softc_ctx.isc_intr != IFLIB_INTR_LEGACY) {</a>
<a name="ln5037">		pci_release_msi(ctx-&gt;ifc_dev);</a>
<a name="ln5038">	}</a>
<a name="ln5039">	if (ctx-&gt;ifc_msix_mem != NULL) {</a>
<a name="ln5040">		bus_release_resource(ctx-&gt;ifc_dev, SYS_RES_MEMORY,</a>
<a name="ln5041">		    rman_get_rid(ctx-&gt;ifc_msix_mem), ctx-&gt;ifc_msix_mem);</a>
<a name="ln5042">		ctx-&gt;ifc_msix_mem = NULL;</a>
<a name="ln5043">	}</a>
<a name="ln5044">}</a>
<a name="ln5045"> </a>
<a name="ln5046">int</a>
<a name="ln5047">iflib_device_detach(device_t dev)</a>
<a name="ln5048">{</a>
<a name="ln5049">	if_ctx_t ctx = device_get_softc(dev);</a>
<a name="ln5050"> </a>
<a name="ln5051">	return (iflib_device_deregister(ctx));</a>
<a name="ln5052">}</a>
<a name="ln5053"> </a>
<a name="ln5054">int</a>
<a name="ln5055">iflib_device_suspend(device_t dev)</a>
<a name="ln5056">{</a>
<a name="ln5057">	if_ctx_t ctx = device_get_softc(dev);</a>
<a name="ln5058"> </a>
<a name="ln5059">	CTX_LOCK(ctx);</a>
<a name="ln5060">	IFDI_SUSPEND(ctx);</a>
<a name="ln5061">	CTX_UNLOCK(ctx);</a>
<a name="ln5062"> </a>
<a name="ln5063">	return bus_generic_suspend(dev);</a>
<a name="ln5064">}</a>
<a name="ln5065">int</a>
<a name="ln5066">iflib_device_shutdown(device_t dev)</a>
<a name="ln5067">{</a>
<a name="ln5068">	if_ctx_t ctx = device_get_softc(dev);</a>
<a name="ln5069"> </a>
<a name="ln5070">	CTX_LOCK(ctx);</a>
<a name="ln5071">	IFDI_SHUTDOWN(ctx);</a>
<a name="ln5072">	CTX_UNLOCK(ctx);</a>
<a name="ln5073"> </a>
<a name="ln5074">	return bus_generic_suspend(dev);</a>
<a name="ln5075">}</a>
<a name="ln5076"> </a>
<a name="ln5077"> </a>
<a name="ln5078">int</a>
<a name="ln5079">iflib_device_resume(device_t dev)</a>
<a name="ln5080">{</a>
<a name="ln5081">	if_ctx_t ctx = device_get_softc(dev);</a>
<a name="ln5082">	iflib_txq_t txq = ctx-&gt;ifc_txqs;</a>
<a name="ln5083">	int i;</a>
<a name="ln5084"> </a>
<a name="ln5085">	CTX_LOCK(ctx);</a>
<a name="ln5086">	IFDI_RESUME(ctx);</a>
<a name="ln5087">	iflib_if_init_locked(ctx);</a>
<a name="ln5088">	CTX_UNLOCK(ctx);</a>
<a name="ln5089">	for (i = 0; i &lt; NTXQSETS(ctx); i++, txq++)</a>
<a name="ln5090">		iflib_txq_check_drain(txq, IFLIB_RESTART_BUDGET);</a>
<a name="ln5091"> </a>
<a name="ln5092">	return (bus_generic_resume(dev));</a>
<a name="ln5093">}</a>
<a name="ln5094"> </a>
<a name="ln5095">int</a>
<a name="ln5096">iflib_device_iov_init(device_t dev, uint16_t num_vfs, const nvlist_t *params)</a>
<a name="ln5097">{</a>
<a name="ln5098">	int error;</a>
<a name="ln5099">	if_ctx_t ctx = device_get_softc(dev);</a>
<a name="ln5100"> </a>
<a name="ln5101">	CTX_LOCK(ctx);</a>
<a name="ln5102">	error = IFDI_IOV_INIT(ctx, num_vfs, params);</a>
<a name="ln5103">	CTX_UNLOCK(ctx);</a>
<a name="ln5104"> </a>
<a name="ln5105">	return (error);</a>
<a name="ln5106">}</a>
<a name="ln5107"> </a>
<a name="ln5108">void</a>
<a name="ln5109">iflib_device_iov_uninit(device_t dev)</a>
<a name="ln5110">{</a>
<a name="ln5111">	if_ctx_t ctx = device_get_softc(dev);</a>
<a name="ln5112"> </a>
<a name="ln5113">	CTX_LOCK(ctx);</a>
<a name="ln5114">	IFDI_IOV_UNINIT(ctx);</a>
<a name="ln5115">	CTX_UNLOCK(ctx);</a>
<a name="ln5116">}</a>
<a name="ln5117"> </a>
<a name="ln5118">int</a>
<a name="ln5119">iflib_device_iov_add_vf(device_t dev, uint16_t vfnum, const nvlist_t *params)</a>
<a name="ln5120">{</a>
<a name="ln5121">	int error;</a>
<a name="ln5122">	if_ctx_t ctx = device_get_softc(dev);</a>
<a name="ln5123"> </a>
<a name="ln5124">	CTX_LOCK(ctx);</a>
<a name="ln5125">	error = IFDI_IOV_VF_ADD(ctx, vfnum, params);</a>
<a name="ln5126">	CTX_UNLOCK(ctx);</a>
<a name="ln5127"> </a>
<a name="ln5128">	return (error);</a>
<a name="ln5129">}</a>
<a name="ln5130"> </a>
<a name="ln5131">/*********************************************************************</a>
<a name="ln5132"> *</a>
<a name="ln5133"> *  MODULE FUNCTION DEFINITIONS</a>
<a name="ln5134"> *</a>
<a name="ln5135"> **********************************************************************/</a>
<a name="ln5136"> </a>
<a name="ln5137">/*</a>
<a name="ln5138"> * - Start a fast taskqueue thread for each core</a>
<a name="ln5139"> * - Start a taskqueue for control operations</a>
<a name="ln5140"> */</a>
<a name="ln5141">static int</a>
<a name="ln5142">iflib_module_init(void)</a>
<a name="ln5143">{</a>
<a name="ln5144">	return (0);</a>
<a name="ln5145">}</a>
<a name="ln5146"> </a>
<a name="ln5147">static int</a>
<a name="ln5148">iflib_module_event_handler(module_t mod, int what, void *arg)</a>
<a name="ln5149">{</a>
<a name="ln5150">	int err;</a>
<a name="ln5151"> </a>
<a name="ln5152">	switch (what) {</a>
<a name="ln5153">	case MOD_LOAD:</a>
<a name="ln5154">		if ((err = iflib_module_init()) != 0)</a>
<a name="ln5155">			return (err);</a>
<a name="ln5156">		break;</a>
<a name="ln5157">	case MOD_UNLOAD:</a>
<a name="ln5158">		return (EBUSY);</a>
<a name="ln5159">	default:</a>
<a name="ln5160">		return (EOPNOTSUPP);</a>
<a name="ln5161">	}</a>
<a name="ln5162"> </a>
<a name="ln5163">	return (0);</a>
<a name="ln5164">}</a>
<a name="ln5165"> </a>
<a name="ln5166">/*********************************************************************</a>
<a name="ln5167"> *</a>
<a name="ln5168"> *  PUBLIC FUNCTION DEFINITIONS</a>
<a name="ln5169"> *     ordered as in iflib.h</a>
<a name="ln5170"> *</a>
<a name="ln5171"> **********************************************************************/</a>
<a name="ln5172"> </a>
<a name="ln5173"> </a>
<a name="ln5174">static void</a>
<a name="ln5175">_iflib_assert(if_shared_ctx_t sctx)</a>
<a name="ln5176">{</a>
<a name="ln5177">	MPASS(sctx-&gt;isc_tx_maxsize);</a>
<a name="ln5178">	MPASS(sctx-&gt;isc_tx_maxsegsize);</a>
<a name="ln5179"> </a>
<a name="ln5180">	MPASS(sctx-&gt;isc_rx_maxsize);</a>
<a name="ln5181">	MPASS(sctx-&gt;isc_rx_nsegments);</a>
<a name="ln5182">	MPASS(sctx-&gt;isc_rx_maxsegsize);</a>
<a name="ln5183"> </a>
<a name="ln5184">	MPASS(sctx-&gt;isc_nrxd_min[0]);</a>
<a name="ln5185">	MPASS(sctx-&gt;isc_nrxd_max[0]);</a>
<a name="ln5186">	MPASS(sctx-&gt;isc_nrxd_default[0]);</a>
<a name="ln5187">	MPASS(sctx-&gt;isc_ntxd_min[0]);</a>
<a name="ln5188">	MPASS(sctx-&gt;isc_ntxd_max[0]);</a>
<a name="ln5189">	MPASS(sctx-&gt;isc_ntxd_default[0]);</a>
<a name="ln5190">}</a>
<a name="ln5191"> </a>
<a name="ln5192">static void</a>
<a name="ln5193">_iflib_pre_assert(if_softc_ctx_t scctx)</a>
<a name="ln5194">{</a>
<a name="ln5195"> </a>
<a name="ln5196">	MPASS(scctx-&gt;isc_txrx-&gt;ift_txd_encap);</a>
<a name="ln5197">	MPASS(scctx-&gt;isc_txrx-&gt;ift_txd_flush);</a>
<a name="ln5198">	MPASS(scctx-&gt;isc_txrx-&gt;ift_txd_credits_update);</a>
<a name="ln5199">	MPASS(scctx-&gt;isc_txrx-&gt;ift_rxd_available);</a>
<a name="ln5200">	MPASS(scctx-&gt;isc_txrx-&gt;ift_rxd_pkt_get);</a>
<a name="ln5201">	MPASS(scctx-&gt;isc_txrx-&gt;ift_rxd_refill);</a>
<a name="ln5202">	MPASS(scctx-&gt;isc_txrx-&gt;ift_rxd_flush);</a>
<a name="ln5203">}</a>
<a name="ln5204"> </a>
<a name="ln5205">static int</a>
<a name="ln5206">iflib_register(if_ctx_t ctx)</a>
<a name="ln5207">{</a>
<a name="ln5208">	if_shared_ctx_t sctx = ctx-&gt;ifc_sctx;</a>
<a name="ln5209">	driver_t *driver = sctx-&gt;isc_driver;</a>
<a name="ln5210">	device_t dev = ctx-&gt;ifc_dev;</a>
<a name="ln5211">	if_t ifp;</a>
<a name="ln5212"> </a>
<a name="ln5213">	_iflib_assert(sctx);</a>
<a name="ln5214"> </a>
<a name="ln5215">	CTX_LOCK_INIT(ctx);</a>
<a name="ln5216">	STATE_LOCK_INIT(ctx, device_get_nameunit(ctx-&gt;ifc_dev));</a>
<a name="ln5217">	ifp = ctx-&gt;ifc_ifp = if_alloc(IFT_ETHER);</a>
<a name="ln5218">	if (ifp == NULL) {</a>
<a name="ln5219">		device_printf(dev, &quot;can not allocate ifnet structure\n&quot;);</a>
<a name="ln5220">		return (ENOMEM);</a>
<a name="ln5221">	}</a>
<a name="ln5222"> </a>
<a name="ln5223">	/*</a>
<a name="ln5224">	 * Initialize our context's device specific methods</a>
<a name="ln5225">	 */</a>
<a name="ln5226">	kobj_init((kobj_t) ctx, (kobj_class_t) driver);</a>
<a name="ln5227">	kobj_class_compile((kobj_class_t) driver);</a>
<a name="ln5228">#ifndef __HAIKU__</a>
<a name="ln5229">	driver-&gt;refs++;</a>
<a name="ln5230">#endif</a>
<a name="ln5231"> </a>
<a name="ln5232">	if_initname(ifp, device_get_name(dev), device_get_unit(dev));</a>
<a name="ln5233">	if_setsoftc(ifp, ctx);</a>
<a name="ln5234">	if_setdev(ifp, dev);</a>
<a name="ln5235">	if_setinitfn(ifp, iflib_if_init);</a>
<a name="ln5236">	if_setioctlfn(ifp, iflib_if_ioctl);</a>
<a name="ln5237">#ifdef ALTQ</a>
<a name="ln5238">	if_setstartfn(ifp, iflib_altq_if_start);</a>
<a name="ln5239">	if_settransmitfn(ifp, iflib_altq_if_transmit);</a>
<a name="ln5240">	if_setsendqready(ifp);</a>
<a name="ln5241">#else</a>
<a name="ln5242">	if_settransmitfn(ifp, iflib_if_transmit);</a>
<a name="ln5243">#endif</a>
<a name="ln5244">	if_setqflushfn(ifp, iflib_if_qflush);</a>
<a name="ln5245">	if_setflags(ifp, IFF_BROADCAST | IFF_SIMPLEX | IFF_MULTICAST);</a>
<a name="ln5246"> </a>
<a name="ln5247">	ctx-&gt;ifc_vlan_attach_event =</a>
<a name="ln5248">		EVENTHANDLER_REGISTER(vlan_config, iflib_vlan_register, ctx,</a>
<a name="ln5249">							  EVENTHANDLER_PRI_FIRST);</a>
<a name="ln5250">	ctx-&gt;ifc_vlan_detach_event =</a>
<a name="ln5251">		EVENTHANDLER_REGISTER(vlan_unconfig, iflib_vlan_unregister, ctx,</a>
<a name="ln5252">							  EVENTHANDLER_PRI_FIRST);</a>
<a name="ln5253"> </a>
<a name="ln5254">	ifmedia_init(&amp;ctx-&gt;ifc_media, IFM_IMASK,</a>
<a name="ln5255">					 iflib_media_change, iflib_media_status);</a>
<a name="ln5256"> </a>
<a name="ln5257">	return (0);</a>
<a name="ln5258">}</a>
<a name="ln5259"> </a>
<a name="ln5260"> </a>
<a name="ln5261">static int</a>
<a name="ln5262">iflib_queues_alloc(if_ctx_t ctx)</a>
<a name="ln5263">{</a>
<a name="ln5264">	if_shared_ctx_t sctx = ctx-&gt;ifc_sctx;</a>
<a name="ln5265">	if_softc_ctx_t scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln5266">	device_t dev = ctx-&gt;ifc_dev;</a>
<a name="ln5267">	int nrxqsets = scctx-&gt;isc_nrxqsets;</a>
<a name="ln5268">	int ntxqsets = scctx-&gt;isc_ntxqsets;</a>
<a name="ln5269">	iflib_txq_t txq;</a>
<a name="ln5270">	iflib_rxq_t rxq;</a>
<a name="ln5271">	iflib_fl_t fl = NULL;</a>
<a name="ln5272">	int i, j, cpu, err, txconf, rxconf;</a>
<a name="ln5273">	iflib_dma_info_t ifdip;</a>
<a name="ln5274">	uint32_t *rxqsizes = scctx-&gt;isc_rxqsizes;</a>
<a name="ln5275">	uint32_t *txqsizes = scctx-&gt;isc_txqsizes;</a>
<a name="ln5276">	uint8_t nrxqs = sctx-&gt;isc_nrxqs;</a>
<a name="ln5277">	uint8_t ntxqs = sctx-&gt;isc_ntxqs;</a>
<a name="ln5278">	int nfree_lists = sctx-&gt;isc_nfl ? sctx-&gt;isc_nfl : 1;</a>
<a name="ln5279">	caddr_t *vaddrs;</a>
<a name="ln5280">	uint64_t *paddrs;</a>
<a name="ln5281"> </a>
<a name="ln5282">	KASSERT(ntxqs &gt; 0, (&quot;number of queues per qset must be at least 1&quot;));</a>
<a name="ln5283">	KASSERT(nrxqs &gt; 0, (&quot;number of queues per qset must be at least 1&quot;));</a>
<a name="ln5284"> </a>
<a name="ln5285">	/* Allocate the TX ring struct memory */</a>
<a name="ln5286">	if (!(ctx-&gt;ifc_txqs =</a>
<a name="ln5287">	    (iflib_txq_t) malloc(sizeof(struct iflib_txq) *</a>
<a name="ln5288">	    ntxqsets, M_IFLIB, M_NOWAIT | M_ZERO))) {</a>
<a name="ln5289">		device_printf(dev, &quot;Unable to allocate TX ring memory\n&quot;);</a>
<a name="ln5290">		err = ENOMEM;</a>
<a name="ln5291">		goto fail;</a>
<a name="ln5292">	}</a>
<a name="ln5293"> </a>
<a name="ln5294">	/* Now allocate the RX */</a>
<a name="ln5295">	if (!(ctx-&gt;ifc_rxqs =</a>
<a name="ln5296">	    (iflib_rxq_t) malloc(sizeof(struct iflib_rxq) *</a>
<a name="ln5297">	    nrxqsets, M_IFLIB, M_NOWAIT | M_ZERO))) {</a>
<a name="ln5298">		device_printf(dev, &quot;Unable to allocate RX ring memory\n&quot;);</a>
<a name="ln5299">		err = ENOMEM;</a>
<a name="ln5300">		goto rx_fail;</a>
<a name="ln5301">	}</a>
<a name="ln5302"> </a>
<a name="ln5303">	txq = ctx-&gt;ifc_txqs;</a>
<a name="ln5304">	rxq = ctx-&gt;ifc_rxqs;</a>
<a name="ln5305"> </a>
<a name="ln5306">	/*</a>
<a name="ln5307">	 * XXX handle allocation failure</a>
<a name="ln5308">	 */</a>
<a name="ln5309">	for (txconf = i = 0, cpu = CPU_FIRST(); i &lt; ntxqsets; i++, txconf++, txq++, cpu = CPU_NEXT(cpu)) {</a>
<a name="ln5310">		/* Set up some basics */</a>
<a name="ln5311"> </a>
<a name="ln5312">		if ((ifdip = malloc(sizeof(struct iflib_dma_info) * ntxqs,</a>
<a name="ln5313">		    M_IFLIB, M_NOWAIT | M_ZERO)) == NULL) {</a>
<a name="ln5314">			device_printf(dev,</a>
<a name="ln5315">			    &quot;Unable to allocate TX DMA info memory\n&quot;);</a>
<a name="ln5316">			err = ENOMEM;</a>
<a name="ln5317">			goto err_tx_desc;</a>
<a name="ln5318">		}</a>
<a name="ln5319">		txq-&gt;ift_ifdi = ifdip;</a>
<a name="ln5320">		for (j = 0; j &lt; ntxqs; j++, ifdip++) {</a>
<a name="ln5321">			if (iflib_dma_alloc(ctx, txqsizes[j], ifdip, 0)) {</a>
<a name="ln5322">				device_printf(dev,</a>
<a name="ln5323">				    &quot;Unable to allocate TX descriptors\n&quot;);</a>
<a name="ln5324">				err = ENOMEM;</a>
<a name="ln5325">				goto err_tx_desc;</a>
<a name="ln5326">			}</a>
<a name="ln5327">			txq-&gt;ift_txd_size[j] = scctx-&gt;isc_txd_size[j];</a>
<a name="ln5328">			bzero((void *)ifdip-&gt;idi_vaddr, txqsizes[j]);</a>
<a name="ln5329">		}</a>
<a name="ln5330">		txq-&gt;ift_ctx = ctx;</a>
<a name="ln5331">		txq-&gt;ift_id = i;</a>
<a name="ln5332">		if (sctx-&gt;isc_flags &amp; IFLIB_HAS_TXCQ) {</a>
<a name="ln5333">			txq-&gt;ift_br_offset = 1;</a>
<a name="ln5334">		} else {</a>
<a name="ln5335">			txq-&gt;ift_br_offset = 0;</a>
<a name="ln5336">		}</a>
<a name="ln5337">#ifndef __HAIKU__</a>
<a name="ln5338">		/* XXX fix this */</a>
<a name="ln5339">		txq-&gt;ift_timer.c_cpu = cpu;</a>
<a name="ln5340">#endif</a>
<a name="ln5341"> </a>
<a name="ln5342">		if (iflib_txsd_alloc(txq)) {</a>
<a name="ln5343">			device_printf(dev, &quot;Critical Failure setting up TX buffers\n&quot;);</a>
<a name="ln5344">			err = ENOMEM;</a>
<a name="ln5345">			goto err_tx_desc;</a>
<a name="ln5346">		}</a>
<a name="ln5347"> </a>
<a name="ln5348">		/* Initialize the TX lock */</a>
<a name="ln5349">		snprintf(txq-&gt;ift_mtx_name, MTX_NAME_LEN, &quot;%s:tx(%d):callout&quot;,</a>
<a name="ln5350">		    device_get_nameunit(dev), txq-&gt;ift_id);</a>
<a name="ln5351">		mtx_init(&amp;txq-&gt;ift_mtx, txq-&gt;ift_mtx_name, NULL, MTX_DEF);</a>
<a name="ln5352">		callout_init_mtx(&amp;txq-&gt;ift_timer, &amp;txq-&gt;ift_mtx, 0);</a>
<a name="ln5353"> </a>
<a name="ln5354">		snprintf(txq-&gt;ift_db_mtx_name, MTX_NAME_LEN, &quot;%s:tx(%d):db&quot;,</a>
<a name="ln5355">			 device_get_nameunit(dev), txq-&gt;ift_id);</a>
<a name="ln5356"> </a>
<a name="ln5357">		err = ifmp_ring_alloc(&amp;txq-&gt;ift_br, 2048, txq, iflib_txq_drain,</a>
<a name="ln5358">				      iflib_txq_can_drain, M_IFLIB, M_WAITOK);</a>
<a name="ln5359">		if (err) {</a>
<a name="ln5360">			/* XXX free any allocated rings */</a>
<a name="ln5361">			device_printf(dev, &quot;Unable to allocate buf_ring\n&quot;);</a>
<a name="ln5362">			goto err_tx_desc;</a>
<a name="ln5363">		}</a>
<a name="ln5364">	}</a>
<a name="ln5365"> </a>
<a name="ln5366">	for (rxconf = i = 0; i &lt; nrxqsets; i++, rxconf++, rxq++) {</a>
<a name="ln5367">		/* Set up some basics */</a>
<a name="ln5368"> </a>
<a name="ln5369">		if ((ifdip = malloc(sizeof(struct iflib_dma_info) * nrxqs,</a>
<a name="ln5370">		   M_IFLIB, M_NOWAIT | M_ZERO)) == NULL) {</a>
<a name="ln5371">			device_printf(dev,</a>
<a name="ln5372">			    &quot;Unable to allocate RX DMA info memory\n&quot;);</a>
<a name="ln5373">			err = ENOMEM;</a>
<a name="ln5374">			goto err_tx_desc;</a>
<a name="ln5375">		}</a>
<a name="ln5376"> </a>
<a name="ln5377">		rxq-&gt;ifr_ifdi = ifdip;</a>
<a name="ln5378">		/* XXX this needs to be changed if #rx queues != #tx queues */</a>
<a name="ln5379">		rxq-&gt;ifr_ntxqirq = 1;</a>
<a name="ln5380">		rxq-&gt;ifr_txqid[0] = i;</a>
<a name="ln5381">		for (j = 0; j &lt; nrxqs; j++, ifdip++) {</a>
<a name="ln5382">			if (iflib_dma_alloc(ctx, rxqsizes[j], ifdip, 0)) {</a>
<a name="ln5383">				device_printf(dev,</a>
<a name="ln5384">				    &quot;Unable to allocate RX descriptors\n&quot;);</a>
<a name="ln5385">				err = ENOMEM;</a>
<a name="ln5386">				goto err_tx_desc;</a>
<a name="ln5387">			}</a>
<a name="ln5388">			bzero((void *)ifdip-&gt;idi_vaddr, rxqsizes[j]);</a>
<a name="ln5389">		}</a>
<a name="ln5390">		rxq-&gt;ifr_ctx = ctx;</a>
<a name="ln5391">		rxq-&gt;ifr_id = i;</a>
<a name="ln5392">		if (sctx-&gt;isc_flags &amp; IFLIB_HAS_RXCQ) {</a>
<a name="ln5393">			rxq-&gt;ifr_fl_offset = 1;</a>
<a name="ln5394">		} else {</a>
<a name="ln5395">			rxq-&gt;ifr_fl_offset = 0;</a>
<a name="ln5396">		}</a>
<a name="ln5397">		rxq-&gt;ifr_nfl = nfree_lists;</a>
<a name="ln5398">		if (!(fl =</a>
<a name="ln5399">			  (iflib_fl_t) malloc(sizeof(struct iflib_fl) * nfree_lists, M_IFLIB, M_NOWAIT | M_ZERO))) {</a>
<a name="ln5400">			device_printf(dev, &quot;Unable to allocate free list memory\n&quot;);</a>
<a name="ln5401">			err = ENOMEM;</a>
<a name="ln5402">			goto err_tx_desc;</a>
<a name="ln5403">		}</a>
<a name="ln5404">		rxq-&gt;ifr_fl = fl;</a>
<a name="ln5405">		for (j = 0; j &lt; nfree_lists; j++) {</a>
<a name="ln5406">			fl[j].ifl_rxq = rxq;</a>
<a name="ln5407">			fl[j].ifl_id = j;</a>
<a name="ln5408">			fl[j].ifl_ifdi = &amp;rxq-&gt;ifr_ifdi[j + rxq-&gt;ifr_fl_offset];</a>
<a name="ln5409">			fl[j].ifl_rxd_size = scctx-&gt;isc_rxd_size[j];</a>
<a name="ln5410">		}</a>
<a name="ln5411">		/* Allocate receive buffers for the ring */</a>
<a name="ln5412">		if (iflib_rxsd_alloc(rxq)) {</a>
<a name="ln5413">			device_printf(dev,</a>
<a name="ln5414">			    &quot;Critical Failure setting up receive buffers\n&quot;);</a>
<a name="ln5415">			err = ENOMEM;</a>
<a name="ln5416">			goto err_rx_desc;</a>
<a name="ln5417">		}</a>
<a name="ln5418"> </a>
<a name="ln5419">		for (j = 0, fl = rxq-&gt;ifr_fl; j &lt; rxq-&gt;ifr_nfl; j++, fl++) </a>
<a name="ln5420">			fl-&gt;ifl_rx_bitmap = bit_alloc(fl-&gt;ifl_size, M_IFLIB,</a>
<a name="ln5421">			    M_WAITOK);</a>
<a name="ln5422">	}</a>
<a name="ln5423"> </a>
<a name="ln5424">	/* TXQs */</a>
<a name="ln5425">	vaddrs = malloc(sizeof(caddr_t)*ntxqsets*ntxqs, M_IFLIB, M_WAITOK);</a>
<a name="ln5426">	paddrs = malloc(sizeof(uint64_t)*ntxqsets*ntxqs, M_IFLIB, M_WAITOK);</a>
<a name="ln5427">	for (i = 0; i &lt; ntxqsets; i++) {</a>
<a name="ln5428">		iflib_dma_info_t di = ctx-&gt;ifc_txqs[i].ift_ifdi;</a>
<a name="ln5429"> </a>
<a name="ln5430">		for (j = 0; j &lt; ntxqs; j++, di++) {</a>
<a name="ln5431">			vaddrs[i*ntxqs + j] = di-&gt;idi_vaddr;</a>
<a name="ln5432">			paddrs[i*ntxqs + j] = di-&gt;idi_paddr;</a>
<a name="ln5433">		}</a>
<a name="ln5434">	}</a>
<a name="ln5435">	if ((err = IFDI_TX_QUEUES_ALLOC(ctx, vaddrs, paddrs, ntxqs, ntxqsets)) != 0) {</a>
<a name="ln5436">		device_printf(ctx-&gt;ifc_dev,</a>
<a name="ln5437">		    &quot;Unable to allocate device TX queue\n&quot;);</a>
<a name="ln5438">		iflib_tx_structures_free(ctx);</a>
<a name="ln5439">		free(vaddrs, M_IFLIB);</a>
<a name="ln5440">		free(paddrs, M_IFLIB);</a>
<a name="ln5441">		goto err_rx_desc;</a>
<a name="ln5442">	}</a>
<a name="ln5443">	free(vaddrs, M_IFLIB);</a>
<a name="ln5444">	free(paddrs, M_IFLIB);</a>
<a name="ln5445"> </a>
<a name="ln5446">	/* RXQs */</a>
<a name="ln5447">	vaddrs = malloc(sizeof(caddr_t)*nrxqsets*nrxqs, M_IFLIB, M_WAITOK);</a>
<a name="ln5448">	paddrs = malloc(sizeof(uint64_t)*nrxqsets*nrxqs, M_IFLIB, M_WAITOK);</a>
<a name="ln5449">	for (i = 0; i &lt; nrxqsets; i++) {</a>
<a name="ln5450">		iflib_dma_info_t di = ctx-&gt;ifc_rxqs[i].ifr_ifdi;</a>
<a name="ln5451"> </a>
<a name="ln5452">		for (j = 0; j &lt; nrxqs; j++, di++) {</a>
<a name="ln5453">			vaddrs[i*nrxqs + j] = di-&gt;idi_vaddr;</a>
<a name="ln5454">			paddrs[i*nrxqs + j] = di-&gt;idi_paddr;</a>
<a name="ln5455">		}</a>
<a name="ln5456">	}</a>
<a name="ln5457">	if ((err = IFDI_RX_QUEUES_ALLOC(ctx, vaddrs, paddrs, nrxqs, nrxqsets)) != 0) {</a>
<a name="ln5458">		device_printf(ctx-&gt;ifc_dev,</a>
<a name="ln5459">		    &quot;Unable to allocate device RX queue\n&quot;);</a>
<a name="ln5460">		iflib_tx_structures_free(ctx);</a>
<a name="ln5461">		free(vaddrs, M_IFLIB);</a>
<a name="ln5462">		free(paddrs, M_IFLIB);</a>
<a name="ln5463">		goto err_rx_desc;</a>
<a name="ln5464">	}</a>
<a name="ln5465">	free(vaddrs, M_IFLIB);</a>
<a name="ln5466">	free(paddrs, M_IFLIB);</a>
<a name="ln5467"> </a>
<a name="ln5468">	return (0);</a>
<a name="ln5469"> </a>
<a name="ln5470">/* XXX handle allocation failure changes */</a>
<a name="ln5471">err_rx_desc:</a>
<a name="ln5472">err_tx_desc:</a>
<a name="ln5473">rx_fail:</a>
<a name="ln5474">	if (ctx-&gt;ifc_rxqs != NULL)</a>
<a name="ln5475">		free(ctx-&gt;ifc_rxqs, M_IFLIB);</a>
<a name="ln5476">	ctx-&gt;ifc_rxqs = NULL;</a>
<a name="ln5477">	if (ctx-&gt;ifc_txqs != NULL)</a>
<a name="ln5478">		free(ctx-&gt;ifc_txqs, M_IFLIB);</a>
<a name="ln5479">	ctx-&gt;ifc_txqs = NULL;</a>
<a name="ln5480">fail:</a>
<a name="ln5481">	return (err);</a>
<a name="ln5482">}</a>
<a name="ln5483"> </a>
<a name="ln5484">static int</a>
<a name="ln5485">iflib_tx_structures_setup(if_ctx_t ctx)</a>
<a name="ln5486">{</a>
<a name="ln5487">	iflib_txq_t txq = ctx-&gt;ifc_txqs;</a>
<a name="ln5488">	int i;</a>
<a name="ln5489"> </a>
<a name="ln5490">	for (i = 0; i &lt; NTXQSETS(ctx); i++, txq++)</a>
<a name="ln5491">		iflib_txq_setup(txq);</a>
<a name="ln5492"> </a>
<a name="ln5493">	return (0);</a>
<a name="ln5494">}</a>
<a name="ln5495"> </a>
<a name="ln5496">static void</a>
<a name="ln5497">iflib_tx_structures_free(if_ctx_t ctx)</a>
<a name="ln5498">{</a>
<a name="ln5499">	iflib_txq_t txq = ctx-&gt;ifc_txqs;</a>
<a name="ln5500">	if_shared_ctx_t sctx = ctx-&gt;ifc_sctx;</a>
<a name="ln5501">	int i, j;</a>
<a name="ln5502"> </a>
<a name="ln5503">	for (i = 0; i &lt; NTXQSETS(ctx); i++, txq++) {</a>
<a name="ln5504">		iflib_txq_destroy(txq);</a>
<a name="ln5505">		for (j = 0; j &lt; sctx-&gt;isc_ntxqs; j++)</a>
<a name="ln5506">			iflib_dma_free(&amp;txq-&gt;ift_ifdi[j]);</a>
<a name="ln5507">	}</a>
<a name="ln5508">	free(ctx-&gt;ifc_txqs, M_IFLIB);</a>
<a name="ln5509">	ctx-&gt;ifc_txqs = NULL;</a>
<a name="ln5510">	IFDI_QUEUES_FREE(ctx);</a>
<a name="ln5511">}</a>
<a name="ln5512"> </a>
<a name="ln5513">/*********************************************************************</a>
<a name="ln5514"> *</a>
<a name="ln5515"> *  Initialize all receive rings.</a>
<a name="ln5516"> *</a>
<a name="ln5517"> **********************************************************************/</a>
<a name="ln5518">static int</a>
<a name="ln5519">iflib_rx_structures_setup(if_ctx_t ctx)</a>
<a name="ln5520">{</a>
<a name="ln5521">	iflib_rxq_t rxq = ctx-&gt;ifc_rxqs;</a>
<a name="ln5522">	int q;</a>
<a name="ln5523">#if defined(INET6) || defined(INET)</a>
<a name="ln5524">	int i, err;</a>
<a name="ln5525">#endif</a>
<a name="ln5526"> </a>
<a name="ln5527">	for (q = 0; q &lt; ctx-&gt;ifc_softc_ctx.isc_nrxqsets; q++, rxq++) {</a>
<a name="ln5528">#if defined(INET6) || defined(INET)</a>
<a name="ln5529">#ifndef __HAIKU__</a>
<a name="ln5530">		tcp_lro_free(&amp;rxq-&gt;ifr_lc);</a>
<a name="ln5531">		if ((err = tcp_lro_init_args(&amp;rxq-&gt;ifr_lc, ctx-&gt;ifc_ifp,</a>
<a name="ln5532">		    TCP_LRO_ENTRIES, min(1024,</a>
<a name="ln5533">		    ctx-&gt;ifc_softc_ctx.isc_nrxd[rxq-&gt;ifr_fl_offset]))) != 0) {</a>
<a name="ln5534">			device_printf(ctx-&gt;ifc_dev, &quot;LRO Initialization failed!\n&quot;);</a>
<a name="ln5535">			goto fail;</a>
<a name="ln5536">		}</a>
<a name="ln5537">		rxq-&gt;ifr_lro_enabled = TRUE;</a>
<a name="ln5538">#endif</a>
<a name="ln5539">#endif</a>
<a name="ln5540">		IFDI_RXQ_SETUP(ctx, rxq-&gt;ifr_id);</a>
<a name="ln5541">	}</a>
<a name="ln5542">	return (0);</a>
<a name="ln5543">#if defined(INET6) || defined(INET)</a>
<a name="ln5544">fail:</a>
<a name="ln5545">	/*</a>
<a name="ln5546">	 * Free RX software descriptors allocated so far, we will only handle</a>
<a name="ln5547">	 * the rings that completed, the failing case will have</a>
<a name="ln5548">	 * cleaned up for itself. 'q' failed, so its the terminus.</a>
<a name="ln5549">	 */</a>
<a name="ln5550">	rxq = ctx-&gt;ifc_rxqs;</a>
<a name="ln5551">	for (i = 0; i &lt; q; ++i, rxq++) {</a>
<a name="ln5552">		iflib_rx_sds_free(rxq);</a>
<a name="ln5553">		rxq-&gt;ifr_cq_gen = rxq-&gt;ifr_cq_cidx = rxq-&gt;ifr_cq_pidx = 0;</a>
<a name="ln5554">	}</a>
<a name="ln5555">	return (err);</a>
<a name="ln5556">#endif</a>
<a name="ln5557">}</a>
<a name="ln5558"> </a>
<a name="ln5559">/*********************************************************************</a>
<a name="ln5560"> *</a>
<a name="ln5561"> *  Free all receive rings.</a>
<a name="ln5562"> *</a>
<a name="ln5563"> **********************************************************************/</a>
<a name="ln5564">static void</a>
<a name="ln5565">iflib_rx_structures_free(if_ctx_t ctx)</a>
<a name="ln5566">{</a>
<a name="ln5567">	int i;</a>
<a name="ln5568">	iflib_rxq_t rxq = ctx-&gt;ifc_rxqs;</a>
<a name="ln5569"> </a>
<a name="ln5570">	for (i = 0; i &lt; ctx-&gt;ifc_softc_ctx.isc_nrxqsets; i++, rxq++) {</a>
<a name="ln5571">		iflib_rx_sds_free(rxq);</a>
<a name="ln5572">	}</a>
<a name="ln5573">	free(ctx-&gt;ifc_rxqs, M_IFLIB);</a>
<a name="ln5574">	ctx-&gt;ifc_rxqs = NULL;</a>
<a name="ln5575">}</a>
<a name="ln5576"> </a>
<a name="ln5577">static int</a>
<a name="ln5578">iflib_qset_structures_setup(if_ctx_t ctx)</a>
<a name="ln5579">{</a>
<a name="ln5580">	int err;</a>
<a name="ln5581"> </a>
<a name="ln5582">	/*</a>
<a name="ln5583">	 * It is expected that the caller takes care of freeing queues if this</a>
<a name="ln5584">	 * fails.</a>
<a name="ln5585">	 */</a>
<a name="ln5586">	if ((err = iflib_tx_structures_setup(ctx)) != 0) {</a>
<a name="ln5587">		device_printf(ctx-&gt;ifc_dev, &quot;iflib_tx_structures_setup failed: %d\n&quot;, err);</a>
<a name="ln5588">		return (err);</a>
<a name="ln5589">	}</a>
<a name="ln5590"> </a>
<a name="ln5591">	if ((err = iflib_rx_structures_setup(ctx)) != 0)</a>
<a name="ln5592">		device_printf(ctx-&gt;ifc_dev, &quot;iflib_rx_structures_setup failed: %d\n&quot;, err);</a>
<a name="ln5593"> </a>
<a name="ln5594">	return (err);</a>
<a name="ln5595">}</a>
<a name="ln5596"> </a>
<a name="ln5597">int</a>
<a name="ln5598">iflib_irq_alloc(if_ctx_t ctx, if_irq_t irq, int rid,</a>
<a name="ln5599">		driver_filter_t filter, void *filter_arg, driver_intr_t handler, void *arg, const char *name)</a>
<a name="ln5600">{</a>
<a name="ln5601"> </a>
<a name="ln5602">	return (_iflib_irq_alloc(ctx, irq, rid, filter, handler, arg, name));</a>
<a name="ln5603">}</a>
<a name="ln5604"> </a>
<a name="ln5605">#ifdef SMP</a>
<a name="ln5606">static int</a>
<a name="ln5607">find_nth(if_ctx_t ctx, int qid)</a>
<a name="ln5608">{</a>
<a name="ln5609">	cpuset_t cpus;</a>
<a name="ln5610">	int i, cpuid, eqid, count;</a>
<a name="ln5611"> </a>
<a name="ln5612">	CPU_COPY(&amp;ctx-&gt;ifc_cpus, &amp;cpus);</a>
<a name="ln5613">	count = CPU_COUNT(&amp;cpus);</a>
<a name="ln5614">	eqid = qid % count;</a>
<a name="ln5615">	/* clear up to the qid'th bit */</a>
<a name="ln5616">	for (i = 0; i &lt; eqid; i++) {</a>
<a name="ln5617">		cpuid = CPU_FFS(&amp;cpus);</a>
<a name="ln5618">		MPASS(cpuid != 0);</a>
<a name="ln5619">		CPU_CLR(cpuid-1, &amp;cpus);</a>
<a name="ln5620">	}</a>
<a name="ln5621">	cpuid = CPU_FFS(&amp;cpus);</a>
<a name="ln5622">	MPASS(cpuid != 0);</a>
<a name="ln5623">	return (cpuid-1);</a>
<a name="ln5624">}</a>
<a name="ln5625"> </a>
<a name="ln5626">#ifdef SCHED_ULE</a>
<a name="ln5627">extern struct cpu_group *cpu_top;              /* CPU topology */</a>
<a name="ln5628"> </a>
<a name="ln5629">static int</a>
<a name="ln5630">find_child_with_core(int cpu, struct cpu_group *grp)</a>
<a name="ln5631">{</a>
<a name="ln5632">	int i;</a>
<a name="ln5633"> </a>
<a name="ln5634">	if (grp-&gt;cg_children == 0)</a>
<a name="ln5635">		return -1;</a>
<a name="ln5636"> </a>
<a name="ln5637">	MPASS(grp-&gt;cg_child);</a>
<a name="ln5638">	for (i = 0; i &lt; grp-&gt;cg_children; i++) {</a>
<a name="ln5639">		if (CPU_ISSET(cpu, &amp;grp-&gt;cg_child[i].cg_mask))</a>
<a name="ln5640">			return i;</a>
<a name="ln5641">	}</a>
<a name="ln5642"> </a>
<a name="ln5643">	return -1;</a>
<a name="ln5644">}</a>
<a name="ln5645"> </a>
<a name="ln5646">/*</a>
<a name="ln5647"> * Find the nth &quot;close&quot; core to the specified core</a>
<a name="ln5648"> * &quot;close&quot; is defined as the deepest level that shares</a>
<a name="ln5649"> * at least an L2 cache.  With threads, this will be</a>
<a name="ln5650"> * threads on the same core.  If the sahred cache is L3</a>
<a name="ln5651"> * or higher, simply returns the same core.</a>
<a name="ln5652"> */</a>
<a name="ln5653">static int</a>
<a name="ln5654">find_close_core(int cpu, int core_offset)</a>
<a name="ln5655">{</a>
<a name="ln5656">	struct cpu_group *grp;</a>
<a name="ln5657">	int i;</a>
<a name="ln5658">	int fcpu;</a>
<a name="ln5659">	cpuset_t cs;</a>
<a name="ln5660"> </a>
<a name="ln5661">	grp = cpu_top;</a>
<a name="ln5662">	if (grp == NULL)</a>
<a name="ln5663">		return cpu;</a>
<a name="ln5664">	i = 0;</a>
<a name="ln5665">	while ((i = find_child_with_core(cpu, grp)) != -1) {</a>
<a name="ln5666">		/* If the child only has one cpu, don't descend */</a>
<a name="ln5667">		if (grp-&gt;cg_child[i].cg_count &lt;= 1)</a>
<a name="ln5668">			break;</a>
<a name="ln5669">		grp = &amp;grp-&gt;cg_child[i];</a>
<a name="ln5670">	}</a>
<a name="ln5671"> </a>
<a name="ln5672">	/* If they don't share at least an L2 cache, use the same CPU */</a>
<a name="ln5673">	if (grp-&gt;cg_level &gt; CG_SHARE_L2 || grp-&gt;cg_level == CG_SHARE_NONE)</a>
<a name="ln5674">		return cpu;</a>
<a name="ln5675"> </a>
<a name="ln5676">	/* Now pick one */</a>
<a name="ln5677">	CPU_COPY(&amp;grp-&gt;cg_mask, &amp;cs);</a>
<a name="ln5678"> </a>
<a name="ln5679">	/* Add the selected CPU offset to core offset. */</a>
<a name="ln5680">	for (i = 0; (fcpu = CPU_FFS(&amp;cs)) != 0; i++) {</a>
<a name="ln5681">		if (fcpu - 1 == cpu)</a>
<a name="ln5682">			break;</a>
<a name="ln5683">		CPU_CLR(fcpu - 1, &amp;cs);</a>
<a name="ln5684">	}</a>
<a name="ln5685">	MPASS(fcpu);</a>
<a name="ln5686"> </a>
<a name="ln5687">	core_offset += i;</a>
<a name="ln5688"> </a>
<a name="ln5689">	CPU_COPY(&amp;grp-&gt;cg_mask, &amp;cs);</a>
<a name="ln5690">	for (i = core_offset % grp-&gt;cg_count; i &gt; 0; i--) {</a>
<a name="ln5691">		MPASS(CPU_FFS(&amp;cs));</a>
<a name="ln5692">		CPU_CLR(CPU_FFS(&amp;cs) - 1, &amp;cs);</a>
<a name="ln5693">	}</a>
<a name="ln5694">	MPASS(CPU_FFS(&amp;cs));</a>
<a name="ln5695">	return CPU_FFS(&amp;cs) - 1;</a>
<a name="ln5696">}</a>
<a name="ln5697">#else</a>
<a name="ln5698">static int</a>
<a name="ln5699">find_close_core(int cpu, int core_offset __unused)</a>
<a name="ln5700">{</a>
<a name="ln5701">	return cpu;</a>
<a name="ln5702">}</a>
<a name="ln5703">#endif</a>
<a name="ln5704"> </a>
<a name="ln5705">static int</a>
<a name="ln5706">get_core_offset(if_ctx_t ctx, iflib_intr_type_t type, int qid)</a>
<a name="ln5707">{</a>
<a name="ln5708">	switch (type) {</a>
<a name="ln5709">	case IFLIB_INTR_TX:</a>
<a name="ln5710">		/* TX queues get cores which share at least an L2 cache with the corresponding RX queue */</a>
<a name="ln5711">		/* XXX handle multiple RX threads per core and more than two core per L2 group */</a>
<a name="ln5712">		return qid / CPU_COUNT(&amp;ctx-&gt;ifc_cpus) + 1;</a>
<a name="ln5713">	case IFLIB_INTR_RX:</a>
<a name="ln5714">	case IFLIB_INTR_RXTX:</a>
<a name="ln5715">		/* RX queues get the specified core */</a>
<a name="ln5716">		return qid / CPU_COUNT(&amp;ctx-&gt;ifc_cpus);</a>
<a name="ln5717">	default:</a>
<a name="ln5718">		return -1;</a>
<a name="ln5719">	}</a>
<a name="ln5720">}</a>
<a name="ln5721">#else</a>
<a name="ln5722">#define get_core_offset(ctx, type, qid)	CPU_FIRST()</a>
<a name="ln5723">#define find_close_core(cpuid, tid)	CPU_FIRST()</a>
<a name="ln5724">#define find_nth(ctx, gid)		CPU_FIRST()</a>
<a name="ln5725">#endif</a>
<a name="ln5726"> </a>
<a name="ln5727">/* Just to avoid copy/paste */</a>
<a name="ln5728">static inline int</a>
<a name="ln5729">iflib_irq_set_affinity(if_ctx_t ctx, if_irq_t irq, iflib_intr_type_t type,</a>
<a name="ln5730">    int qid, struct grouptask *gtask, struct taskqgroup *tqg, void *uniq,</a>
<a name="ln5731">    const char *name)</a>
<a name="ln5732">{</a>
<a name="ln5733">	device_t dev;</a>
<a name="ln5734">	int err, cpuid, tid;</a>
<a name="ln5735"> </a>
<a name="ln5736">	dev = ctx-&gt;ifc_dev;</a>
<a name="ln5737">	cpuid = find_nth(ctx, qid);</a>
<a name="ln5738">	tid = get_core_offset(ctx, type, qid);</a>
<a name="ln5739">	MPASS(tid &gt;= 0);</a>
<a name="ln5740">	cpuid = find_close_core(cpuid, tid);</a>
<a name="ln5741">	err = taskqgroup_attach_cpu(tqg, gtask, uniq, cpuid, dev, irq-&gt;ii_res,</a>
<a name="ln5742">	    name);</a>
<a name="ln5743">	if (err) {</a>
<a name="ln5744">		device_printf(dev, &quot;taskqgroup_attach_cpu failed %d\n&quot;, err);</a>
<a name="ln5745">		return (err);</a>
<a name="ln5746">	}</a>
<a name="ln5747">#ifdef notyet</a>
<a name="ln5748">	if (cpuid &gt; ctx-&gt;ifc_cpuid_highest)</a>
<a name="ln5749">		ctx-&gt;ifc_cpuid_highest = cpuid;</a>
<a name="ln5750">#endif</a>
<a name="ln5751">	return 0;</a>
<a name="ln5752">}</a>
<a name="ln5753"> </a>
<a name="ln5754">int</a>
<a name="ln5755">iflib_irq_alloc_generic(if_ctx_t ctx, if_irq_t irq, int rid,</a>
<a name="ln5756">			iflib_intr_type_t type, driver_filter_t *filter,</a>
<a name="ln5757">			void *filter_arg, int qid, const char *name)</a>
<a name="ln5758">{</a>
<a name="ln5759">	device_t dev;</a>
<a name="ln5760">	struct grouptask *gtask;</a>
<a name="ln5761">	struct taskqgroup *tqg;</a>
<a name="ln5762">	iflib_filter_info_t info;</a>
<a name="ln5763">	gtask_fn_t *fn;</a>
<a name="ln5764">	int tqrid, err;</a>
<a name="ln5765">	driver_filter_t *intr_fast;</a>
<a name="ln5766">	void *q;</a>
<a name="ln5767"> </a>
<a name="ln5768">	info = &amp;ctx-&gt;ifc_filter_info;</a>
<a name="ln5769">	tqrid = rid;</a>
<a name="ln5770"> </a>
<a name="ln5771">	switch (type) {</a>
<a name="ln5772">	/* XXX merge tx/rx for netmap? */</a>
<a name="ln5773">	case IFLIB_INTR_TX:</a>
<a name="ln5774">		q = &amp;ctx-&gt;ifc_txqs[qid];</a>
<a name="ln5775">		info = &amp;ctx-&gt;ifc_txqs[qid].ift_filter_info;</a>
<a name="ln5776">		gtask = &amp;ctx-&gt;ifc_txqs[qid].ift_task;</a>
<a name="ln5777">		tqg = qgroup_if_io_tqg;</a>
<a name="ln5778">		fn = _task_fn_tx;</a>
<a name="ln5779">		intr_fast = iflib_fast_intr;</a>
<a name="ln5780">		GROUPTASK_INIT(gtask, 0, fn, q);</a>
<a name="ln5781">		ctx-&gt;ifc_flags |= IFC_NETMAP_TX_IRQ;</a>
<a name="ln5782">		break;</a>
<a name="ln5783">	case IFLIB_INTR_RX:</a>
<a name="ln5784">		q = &amp;ctx-&gt;ifc_rxqs[qid];</a>
<a name="ln5785">		info = &amp;ctx-&gt;ifc_rxqs[qid].ifr_filter_info;</a>
<a name="ln5786">		gtask = &amp;ctx-&gt;ifc_rxqs[qid].ifr_task;</a>
<a name="ln5787">		tqg = qgroup_if_io_tqg;</a>
<a name="ln5788">		fn = _task_fn_rx;</a>
<a name="ln5789">		intr_fast = iflib_fast_intr;</a>
<a name="ln5790">		GROUPTASK_INIT(gtask, 0, fn, q);</a>
<a name="ln5791">		break;</a>
<a name="ln5792">	case IFLIB_INTR_RXTX:</a>
<a name="ln5793">		q = &amp;ctx-&gt;ifc_rxqs[qid];</a>
<a name="ln5794">		info = &amp;ctx-&gt;ifc_rxqs[qid].ifr_filter_info;</a>
<a name="ln5795">		gtask = &amp;ctx-&gt;ifc_rxqs[qid].ifr_task;</a>
<a name="ln5796">		tqg = qgroup_if_io_tqg;</a>
<a name="ln5797">		fn = _task_fn_rx;</a>
<a name="ln5798">		intr_fast = iflib_fast_intr_rxtx;</a>
<a name="ln5799">		GROUPTASK_INIT(gtask, 0, fn, q);</a>
<a name="ln5800">		break;</a>
<a name="ln5801">	case IFLIB_INTR_ADMIN:</a>
<a name="ln5802">		q = ctx;</a>
<a name="ln5803">		tqrid = -1;</a>
<a name="ln5804">		info = &amp;ctx-&gt;ifc_filter_info;</a>
<a name="ln5805">		gtask = &amp;ctx-&gt;ifc_admin_task;</a>
<a name="ln5806">		tqg = qgroup_if_config_tqg;</a>
<a name="ln5807">		fn = _task_fn_admin;</a>
<a name="ln5808">		intr_fast = iflib_fast_intr_ctx;</a>
<a name="ln5809">		break;</a>
<a name="ln5810">	default:</a>
<a name="ln5811">		panic(&quot;unknown net intr type&quot;);</a>
<a name="ln5812">	}</a>
<a name="ln5813"> </a>
<a name="ln5814">	info-&gt;ifi_filter = filter;</a>
<a name="ln5815">	info-&gt;ifi_filter_arg = filter_arg;</a>
<a name="ln5816">	info-&gt;ifi_task = gtask;</a>
<a name="ln5817">	info-&gt;ifi_ctx = q;</a>
<a name="ln5818"> </a>
<a name="ln5819">	dev = ctx-&gt;ifc_dev;</a>
<a name="ln5820">	err = _iflib_irq_alloc(ctx, irq, rid, intr_fast, NULL, info,  name);</a>
<a name="ln5821">	if (err != 0) {</a>
<a name="ln5822">		device_printf(dev, &quot;_iflib_irq_alloc failed %d\n&quot;, err);</a>
<a name="ln5823">		return (err);</a>
<a name="ln5824">	}</a>
<a name="ln5825">	if (type == IFLIB_INTR_ADMIN)</a>
<a name="ln5826">		return (0);</a>
<a name="ln5827"> </a>
<a name="ln5828">	if (tqrid != -1) {</a>
<a name="ln5829">		err = iflib_irq_set_affinity(ctx, irq, type, qid, gtask, tqg,</a>
<a name="ln5830">		    q, name);</a>
<a name="ln5831">		if (err)</a>
<a name="ln5832">			return (err);</a>
<a name="ln5833">	} else {</a>
<a name="ln5834">		taskqgroup_attach(tqg, gtask, q, dev, irq-&gt;ii_res, name);</a>
<a name="ln5835">	}</a>
<a name="ln5836"> </a>
<a name="ln5837">	return (0);</a>
<a name="ln5838">}</a>
<a name="ln5839"> </a>
<a name="ln5840">void</a>
<a name="ln5841">iflib_softirq_alloc_generic(if_ctx_t ctx, if_irq_t irq, iflib_intr_type_t type, void *arg, int qid, const char *name)</a>
<a name="ln5842">{</a>
<a name="ln5843">	struct grouptask *gtask;</a>
<a name="ln5844">	struct taskqgroup *tqg;</a>
<a name="ln5845">	gtask_fn_t *fn;</a>
<a name="ln5846">	void *q;</a>
<a name="ln5847">	int err;</a>
<a name="ln5848"> </a>
<a name="ln5849">	switch (type) {</a>
<a name="ln5850">	case IFLIB_INTR_TX:</a>
<a name="ln5851">		q = &amp;ctx-&gt;ifc_txqs[qid];</a>
<a name="ln5852">		gtask = &amp;ctx-&gt;ifc_txqs[qid].ift_task;</a>
<a name="ln5853">		tqg = qgroup_if_io_tqg;</a>
<a name="ln5854">		fn = _task_fn_tx;</a>
<a name="ln5855">		break;</a>
<a name="ln5856">	case IFLIB_INTR_RX:</a>
<a name="ln5857">		q = &amp;ctx-&gt;ifc_rxqs[qid];</a>
<a name="ln5858">		gtask = &amp;ctx-&gt;ifc_rxqs[qid].ifr_task;</a>
<a name="ln5859">		tqg = qgroup_if_io_tqg;</a>
<a name="ln5860">		fn = _task_fn_rx;</a>
<a name="ln5861">		break;</a>
<a name="ln5862">	case IFLIB_INTR_IOV:</a>
<a name="ln5863">		q = ctx;</a>
<a name="ln5864">		gtask = &amp;ctx-&gt;ifc_vflr_task;</a>
<a name="ln5865">		tqg = qgroup_if_config_tqg;</a>
<a name="ln5866">		fn = _task_fn_iov;</a>
<a name="ln5867">		break;</a>
<a name="ln5868">	default:</a>
<a name="ln5869">		panic(&quot;unknown net intr type&quot;);</a>
<a name="ln5870">	}</a>
<a name="ln5871">	GROUPTASK_INIT(gtask, 0, fn, q);</a>
<a name="ln5872">	if (irq != NULL) {</a>
<a name="ln5873">		err = iflib_irq_set_affinity(ctx, irq, type, qid, gtask, tqg,</a>
<a name="ln5874">		    q, name);</a>
<a name="ln5875">		if (err)</a>
<a name="ln5876">			taskqgroup_attach(tqg, gtask, q, ctx-&gt;ifc_dev,</a>
<a name="ln5877">			    irq-&gt;ii_res, name);</a>
<a name="ln5878">	} else {</a>
<a name="ln5879">		taskqgroup_attach(tqg, gtask, q, NULL, NULL, name);</a>
<a name="ln5880">	}</a>
<a name="ln5881">}</a>
<a name="ln5882"> </a>
<a name="ln5883">void</a>
<a name="ln5884">iflib_irq_free(if_ctx_t ctx, if_irq_t irq)</a>
<a name="ln5885">{</a>
<a name="ln5886"> </a>
<a name="ln5887">	if (irq-&gt;ii_tag)</a>
<a name="ln5888">		bus_teardown_intr(ctx-&gt;ifc_dev, irq-&gt;ii_res, irq-&gt;ii_tag);</a>
<a name="ln5889"> </a>
<a name="ln5890">	if (irq-&gt;ii_res)</a>
<a name="ln5891">		bus_release_resource(ctx-&gt;ifc_dev, SYS_RES_IRQ,</a>
<a name="ln5892">		    rman_get_rid(irq-&gt;ii_res), irq-&gt;ii_res);</a>
<a name="ln5893">}</a>
<a name="ln5894"> </a>
<a name="ln5895">static int</a>
<a name="ln5896">iflib_legacy_setup(if_ctx_t ctx, driver_filter_t filter, void *filter_arg, int *rid, const char *name)</a>
<a name="ln5897">{</a>
<a name="ln5898">	iflib_txq_t txq = ctx-&gt;ifc_txqs;</a>
<a name="ln5899">	iflib_rxq_t rxq = ctx-&gt;ifc_rxqs;</a>
<a name="ln5900">	if_irq_t irq = &amp;ctx-&gt;ifc_legacy_irq;</a>
<a name="ln5901">	iflib_filter_info_t info;</a>
<a name="ln5902">	device_t dev;</a>
<a name="ln5903">	struct grouptask *gtask;</a>
<a name="ln5904">	struct resource *res;</a>
<a name="ln5905">	struct taskqgroup *tqg;</a>
<a name="ln5906">	gtask_fn_t *fn;</a>
<a name="ln5907">	int tqrid;</a>
<a name="ln5908">	void *q;</a>
<a name="ln5909">	int err;</a>
<a name="ln5910"> </a>
<a name="ln5911">	q = &amp;ctx-&gt;ifc_rxqs[0];</a>
<a name="ln5912">	info = &amp;rxq[0].ifr_filter_info;</a>
<a name="ln5913">	gtask = &amp;rxq[0].ifr_task;</a>
<a name="ln5914">	tqg = qgroup_if_io_tqg;</a>
<a name="ln5915">	tqrid = irq-&gt;ii_rid = *rid;</a>
<a name="ln5916">	fn = _task_fn_rx;</a>
<a name="ln5917"> </a>
<a name="ln5918">	ctx-&gt;ifc_flags |= IFC_LEGACY;</a>
<a name="ln5919">	info-&gt;ifi_filter = filter;</a>
<a name="ln5920">	info-&gt;ifi_filter_arg = filter_arg;</a>
<a name="ln5921">	info-&gt;ifi_task = gtask;</a>
<a name="ln5922">	info-&gt;ifi_ctx = ctx;</a>
<a name="ln5923"> </a>
<a name="ln5924">	dev = ctx-&gt;ifc_dev;</a>
<a name="ln5925">	/* We allocate a single interrupt resource */</a>
<a name="ln5926">	if ((err = _iflib_irq_alloc(ctx, irq, tqrid, iflib_fast_intr_ctx, NULL, info, name)) != 0)</a>
<a name="ln5927">		return (err);</a>
<a name="ln5928">	GROUPTASK_INIT(gtask, 0, fn, q);</a>
<a name="ln5929">	res = irq-&gt;ii_res;</a>
<a name="ln5930">	taskqgroup_attach(tqg, gtask, q, dev, res, name);</a>
<a name="ln5931"> </a>
<a name="ln5932">	GROUPTASK_INIT(&amp;txq-&gt;ift_task, 0, _task_fn_tx, txq);</a>
<a name="ln5933">	taskqgroup_attach(qgroup_if_io_tqg, &amp;txq-&gt;ift_task, txq, dev, res,</a>
<a name="ln5934">	    &quot;tx&quot;);</a>
<a name="ln5935">	return (0);</a>
<a name="ln5936">}</a>
<a name="ln5937"> </a>
<a name="ln5938">void</a>
<a name="ln5939">iflib_led_create(if_ctx_t ctx)</a>
<a name="ln5940">{</a>
<a name="ln5941"> </a>
<a name="ln5942">	ctx-&gt;ifc_led_dev = led_create(iflib_led_func, ctx,</a>
<a name="ln5943">	    device_get_nameunit(ctx-&gt;ifc_dev));</a>
<a name="ln5944">}</a>
<a name="ln5945"> </a>
<a name="ln5946">void</a>
<a name="ln5947">iflib_tx_intr_deferred(if_ctx_t ctx, int txqid)</a>
<a name="ln5948">{</a>
<a name="ln5949"> </a>
<a name="ln5950">	GROUPTASK_ENQUEUE(&amp;ctx-&gt;ifc_txqs[txqid].ift_task);</a>
<a name="ln5951">}</a>
<a name="ln5952"> </a>
<a name="ln5953">void</a>
<a name="ln5954">iflib_rx_intr_deferred(if_ctx_t ctx, int rxqid)</a>
<a name="ln5955">{</a>
<a name="ln5956"> </a>
<a name="ln5957">	GROUPTASK_ENQUEUE(&amp;ctx-&gt;ifc_rxqs[rxqid].ifr_task);</a>
<a name="ln5958">}</a>
<a name="ln5959"> </a>
<a name="ln5960">void</a>
<a name="ln5961">iflib_admin_intr_deferred(if_ctx_t ctx)</a>
<a name="ln5962">{</a>
<a name="ln5963">#ifdef INVARIANTS</a>
<a name="ln5964">	struct grouptask *gtask;</a>
<a name="ln5965"> </a>
<a name="ln5966">	gtask = &amp;ctx-&gt;ifc_admin_task;</a>
<a name="ln5967">	MPASS(gtask != NULL &amp;&amp; gtask-&gt;gt_taskqueue != NULL);</a>
<a name="ln5968">#endif</a>
<a name="ln5969"> </a>
<a name="ln5970">	GROUPTASK_ENQUEUE(&amp;ctx-&gt;ifc_admin_task);</a>
<a name="ln5971">}</a>
<a name="ln5972"> </a>
<a name="ln5973">void</a>
<a name="ln5974">iflib_iov_intr_deferred(if_ctx_t ctx)</a>
<a name="ln5975">{</a>
<a name="ln5976"> </a>
<a name="ln5977">	GROUPTASK_ENQUEUE(&amp;ctx-&gt;ifc_vflr_task);</a>
<a name="ln5978">}</a>
<a name="ln5979"> </a>
<a name="ln5980">void</a>
<a name="ln5981">iflib_io_tqg_attach(struct grouptask *gt, void *uniq, int cpu, char *name)</a>
<a name="ln5982">{</a>
<a name="ln5983"> </a>
<a name="ln5984">	taskqgroup_attach_cpu(qgroup_if_io_tqg, gt, uniq, cpu, NULL, NULL,</a>
<a name="ln5985">	    name);</a>
<a name="ln5986">}</a>
<a name="ln5987"> </a>
<a name="ln5988">void</a>
<a name="ln5989">iflib_config_gtask_init(void *ctx, struct grouptask *gtask, gtask_fn_t *fn,</a>
<a name="ln5990">	const char *name)</a>
<a name="ln5991">{</a>
<a name="ln5992"> </a>
<a name="ln5993">	GROUPTASK_INIT(gtask, 0, fn, ctx);</a>
<a name="ln5994">	taskqgroup_attach(qgroup_if_config_tqg, gtask, gtask, NULL, NULL,</a>
<a name="ln5995">	    name);</a>
<a name="ln5996">}</a>
<a name="ln5997"> </a>
<a name="ln5998">void</a>
<a name="ln5999">iflib_config_gtask_deinit(struct grouptask *gtask)</a>
<a name="ln6000">{</a>
<a name="ln6001"> </a>
<a name="ln6002">	taskqgroup_detach(qgroup_if_config_tqg, gtask);	</a>
<a name="ln6003">}</a>
<a name="ln6004"> </a>
<a name="ln6005">void</a>
<a name="ln6006">iflib_link_state_change(if_ctx_t ctx, int link_state, uint64_t baudrate)</a>
<a name="ln6007">{</a>
<a name="ln6008">	if_t ifp = ctx-&gt;ifc_ifp;</a>
<a name="ln6009">	iflib_txq_t txq = ctx-&gt;ifc_txqs;</a>
<a name="ln6010"> </a>
<a name="ln6011">	if_setbaudrate(ifp, baudrate);</a>
<a name="ln6012">	if (baudrate &gt;= IF_Gbps(10)) {</a>
<a name="ln6013">		STATE_LOCK(ctx);</a>
<a name="ln6014">		ctx-&gt;ifc_flags |= IFC_PREFETCH;</a>
<a name="ln6015">		STATE_UNLOCK(ctx);</a>
<a name="ln6016">	}</a>
<a name="ln6017">	/* If link down, disable watchdog */</a>
<a name="ln6018">	if ((ctx-&gt;ifc_link_state == LINK_STATE_UP) &amp;&amp; (link_state == LINK_STATE_DOWN)) {</a>
<a name="ln6019">		int i;</a>
<a name="ln6020">		for (i = 0; i &lt; ctx-&gt;ifc_softc_ctx.isc_ntxqsets; i++, txq++)</a>
<a name="ln6021">			txq-&gt;ift_qstatus = IFLIB_QUEUE_IDLE;</a>
<a name="ln6022">	}</a>
<a name="ln6023">	ctx-&gt;ifc_link_state = link_state;</a>
<a name="ln6024">	if_link_state_change(ifp, link_state);</a>
<a name="ln6025">}</a>
<a name="ln6026"> </a>
<a name="ln6027">static int</a>
<a name="ln6028">iflib_tx_credits_update(if_ctx_t ctx, iflib_txq_t txq)</a>
<a name="ln6029">{</a>
<a name="ln6030">	int credits;</a>
<a name="ln6031">#ifdef INVARIANTS</a>
<a name="ln6032">	int credits_pre = txq-&gt;ift_cidx_processed;</a>
<a name="ln6033">#endif</a>
<a name="ln6034"> </a>
<a name="ln6035">	if (ctx-&gt;isc_txd_credits_update == NULL)</a>
<a name="ln6036">		return (0);</a>
<a name="ln6037"> </a>
<a name="ln6038">	bus_dmamap_sync(txq-&gt;ift_ifdi-&gt;idi_tag, txq-&gt;ift_ifdi-&gt;idi_map,</a>
<a name="ln6039">	    BUS_DMASYNC_POSTREAD);</a>
<a name="ln6040">	if ((credits = ctx-&gt;isc_txd_credits_update(ctx-&gt;ifc_softc, txq-&gt;ift_id, true)) == 0)</a>
<a name="ln6041">		return (0);</a>
<a name="ln6042"> </a>
<a name="ln6043">	txq-&gt;ift_processed += credits;</a>
<a name="ln6044">	txq-&gt;ift_cidx_processed += credits;</a>
<a name="ln6045"> </a>
<a name="ln6046">	MPASS(credits_pre + credits == txq-&gt;ift_cidx_processed);</a>
<a name="ln6047">	if (txq-&gt;ift_cidx_processed &gt;= txq-&gt;ift_size)</a>
<a name="ln6048">		txq-&gt;ift_cidx_processed -= txq-&gt;ift_size;</a>
<a name="ln6049">	return (credits);</a>
<a name="ln6050">}</a>
<a name="ln6051"> </a>
<a name="ln6052">static int</a>
<a name="ln6053">iflib_rxd_avail(if_ctx_t ctx, iflib_rxq_t rxq, qidx_t cidx, qidx_t budget)</a>
<a name="ln6054">{</a>
<a name="ln6055">	iflib_fl_t fl;</a>
<a name="ln6056">	u_int i;</a>
<a name="ln6057"> </a>
<a name="ln6058">	for (i = 0, fl = &amp;rxq-&gt;ifr_fl[0]; i &lt; rxq-&gt;ifr_nfl; i++, fl++)</a>
<a name="ln6059">		bus_dmamap_sync(fl-&gt;ifl_ifdi-&gt;idi_tag, fl-&gt;ifl_ifdi-&gt;idi_map,</a>
<a name="ln6060">		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);</a>
<a name="ln6061">	return (ctx-&gt;isc_rxd_available(ctx-&gt;ifc_softc, rxq-&gt;ifr_id, cidx,</a>
<a name="ln6062">	    budget));</a>
<a name="ln6063">}</a>
<a name="ln6064"> </a>
<a name="ln6065">void</a>
<a name="ln6066">iflib_add_int_delay_sysctl(if_ctx_t ctx, const char *name,</a>
<a name="ln6067">	const char *description, if_int_delay_info_t info,</a>
<a name="ln6068">	int offset, int value)</a>
<a name="ln6069">{</a>
<a name="ln6070">	info-&gt;iidi_ctx = ctx;</a>
<a name="ln6071">	info-&gt;iidi_offset = offset;</a>
<a name="ln6072">	info-&gt;iidi_value = value;</a>
<a name="ln6073">	SYSCTL_ADD_PROC(device_get_sysctl_ctx(ctx-&gt;ifc_dev),</a>
<a name="ln6074">	    SYSCTL_CHILDREN(device_get_sysctl_tree(ctx-&gt;ifc_dev)),</a>
<a name="ln6075">	    OID_AUTO, name, CTLTYPE_INT|CTLFLAG_RW,</a>
<a name="ln6076">	    info, 0, iflib_sysctl_int_delay, &quot;I&quot;, description);</a>
<a name="ln6077">}</a>
<a name="ln6078"> </a>
<a name="ln6079">struct sx *</a>
<a name="ln6080">iflib_ctx_lock_get(if_ctx_t ctx)</a>
<a name="ln6081">{</a>
<a name="ln6082"> </a>
<a name="ln6083">	return (&amp;ctx-&gt;ifc_ctx_sx);</a>
<a name="ln6084">}</a>
<a name="ln6085"> </a>
<a name="ln6086">static int</a>
<a name="ln6087">iflib_msix_init(if_ctx_t ctx)</a>
<a name="ln6088">{</a>
<a name="ln6089">	device_t dev = ctx-&gt;ifc_dev;</a>
<a name="ln6090">	if_shared_ctx_t sctx = ctx-&gt;ifc_sctx;</a>
<a name="ln6091">	if_softc_ctx_t scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln6092">	int vectors, queues, rx_queues, tx_queues, queuemsgs, msgs;</a>
<a name="ln6093">	int iflib_num_tx_queues, iflib_num_rx_queues;</a>
<a name="ln6094">	int err, admincnt, bar;</a>
<a name="ln6095"> </a>
<a name="ln6096">	iflib_num_tx_queues = ctx-&gt;ifc_sysctl_ntxqs;</a>
<a name="ln6097">	iflib_num_rx_queues = ctx-&gt;ifc_sysctl_nrxqs;</a>
<a name="ln6098"> </a>
<a name="ln6099">	if (bootverbose)</a>
<a name="ln6100">		device_printf(dev, &quot;msix_init qsets capped at %d\n&quot;,</a>
<a name="ln6101">		    imax(scctx-&gt;isc_ntxqsets, scctx-&gt;isc_nrxqsets));</a>
<a name="ln6102"> </a>
<a name="ln6103">	bar = ctx-&gt;ifc_softc_ctx.isc_msix_bar;</a>
<a name="ln6104">	admincnt = sctx-&gt;isc_admin_intrcnt;</a>
<a name="ln6105">	/* Override by tuneable */</a>
<a name="ln6106">	if (scctx-&gt;isc_disable_msix)</a>
<a name="ln6107">		goto msi;</a>
<a name="ln6108"> </a>
<a name="ln6109">	/* First try MSI-X */</a>
<a name="ln6110">	if ((msgs = pci_msix_count(dev)) == 0) {</a>
<a name="ln6111">		if (bootverbose)</a>
<a name="ln6112">			device_printf(dev, &quot;MSI-X not supported or disabled\n&quot;);</a>
<a name="ln6113">		goto msi;</a>
<a name="ln6114">	}</a>
<a name="ln6115">	/*</a>
<a name="ln6116">	 * bar == -1 =&gt; &quot;trust me I know what I'm doing&quot;</a>
<a name="ln6117">	 * Some drivers are for hardware that is so shoddily</a>
<a name="ln6118">	 * documented that no one knows which bars are which</a>
<a name="ln6119">	 * so the developer has to map all bars. This hack</a>
<a name="ln6120">	 * allows shoddy garbage to use MSI-X in this framework.</a>
<a name="ln6121">	 */</a>
<a name="ln6122">	if (bar != -1) {</a>
<a name="ln6123">		ctx-&gt;ifc_msix_mem = bus_alloc_resource_any(dev,</a>
<a name="ln6124">	            SYS_RES_MEMORY, &amp;bar, RF_ACTIVE);</a>
<a name="ln6125">		if (ctx-&gt;ifc_msix_mem == NULL) {</a>
<a name="ln6126">			device_printf(dev, &quot;Unable to map MSI-X table\n&quot;);</a>
<a name="ln6127">			goto msi;</a>
<a name="ln6128">		}</a>
<a name="ln6129">	}</a>
<a name="ln6130">#if IFLIB_DEBUG</a>
<a name="ln6131">	/* use only 1 qset in debug mode */</a>
<a name="ln6132">	queuemsgs = min(msgs - admincnt, 1);</a>
<a name="ln6133">#else</a>
<a name="ln6134">	queuemsgs = msgs - admincnt;</a>
<a name="ln6135">#endif</a>
<a name="ln6136">#ifdef RSS</a>
<a name="ln6137">	queues = imin(queuemsgs, rss_getnumbuckets());</a>
<a name="ln6138">#else</a>
<a name="ln6139">	queues = queuemsgs;</a>
<a name="ln6140">#endif</a>
<a name="ln6141">#ifndef __HAIKU__</a>
<a name="ln6142">	queues = imin(CPU_COUNT(&amp;ctx-&gt;ifc_cpus), queues);</a>
<a name="ln6143">	if (bootverbose)</a>
<a name="ln6144">		device_printf(dev,</a>
<a name="ln6145">		    &quot;intr CPUs: %d queue msgs: %d admincnt: %d\n&quot;,</a>
<a name="ln6146">		    CPU_COUNT(&amp;ctx-&gt;ifc_cpus), queuemsgs, admincnt);</a>
<a name="ln6147">#endif</a>
<a name="ln6148">#ifdef  RSS</a>
<a name="ln6149">	/* If we're doing RSS, clamp at the number of RSS buckets */</a>
<a name="ln6150">	if (queues &gt; rss_getnumbuckets())</a>
<a name="ln6151">		queues = rss_getnumbuckets();</a>
<a name="ln6152">#endif</a>
<a name="ln6153">	if (iflib_num_rx_queues &gt; 0 &amp;&amp; iflib_num_rx_queues &lt; queuemsgs - admincnt)</a>
<a name="ln6154">		rx_queues = iflib_num_rx_queues;</a>
<a name="ln6155">	else</a>
<a name="ln6156">		rx_queues = queues;</a>
<a name="ln6157"> </a>
<a name="ln6158">	if (rx_queues &gt; scctx-&gt;isc_nrxqsets)</a>
<a name="ln6159">		rx_queues = scctx-&gt;isc_nrxqsets;</a>
<a name="ln6160"> </a>
<a name="ln6161">	/*</a>
<a name="ln6162">	 * We want this to be all logical CPUs by default</a>
<a name="ln6163">	 */</a>
<a name="ln6164">	if (iflib_num_tx_queues &gt; 0 &amp;&amp; iflib_num_tx_queues &lt; queues)</a>
<a name="ln6165">		tx_queues = iflib_num_tx_queues;</a>
<a name="ln6166">	else</a>
<a name="ln6167">		tx_queues = mp_ncpus;</a>
<a name="ln6168"> </a>
<a name="ln6169">	if (tx_queues &gt; scctx-&gt;isc_ntxqsets)</a>
<a name="ln6170">		tx_queues = scctx-&gt;isc_ntxqsets;</a>
<a name="ln6171"> </a>
<a name="ln6172">	if (ctx-&gt;ifc_sysctl_qs_eq_override == 0) {</a>
<a name="ln6173">#ifdef INVARIANTS</a>
<a name="ln6174">		if (tx_queues != rx_queues)</a>
<a name="ln6175">			device_printf(dev,</a>
<a name="ln6176">			    &quot;queue equality override not set, capping rx_queues at %d and tx_queues at %d\n&quot;,</a>
<a name="ln6177">			    min(rx_queues, tx_queues), min(rx_queues, tx_queues));</a>
<a name="ln6178">#endif</a>
<a name="ln6179">		tx_queues = min(rx_queues, tx_queues);</a>
<a name="ln6180">		rx_queues = min(rx_queues, tx_queues);</a>
<a name="ln6181">	}</a>
<a name="ln6182"> </a>
<a name="ln6183">	device_printf(dev, &quot;Using %d rx queues %d tx queues\n&quot;,</a>
<a name="ln6184">	    rx_queues, tx_queues);</a>
<a name="ln6185"> </a>
<a name="ln6186">	vectors = rx_queues + admincnt;</a>
<a name="ln6187">	if ((err = pci_alloc_msix(dev, &amp;vectors)) == 0) {</a>
<a name="ln6188">		device_printf(dev, &quot;Using MSI-X interrupts with %d vectors\n&quot;,</a>
<a name="ln6189">		    vectors);</a>
<a name="ln6190">		scctx-&gt;isc_vectors = vectors;</a>
<a name="ln6191">		scctx-&gt;isc_nrxqsets = rx_queues;</a>
<a name="ln6192">		scctx-&gt;isc_ntxqsets = tx_queues;</a>
<a name="ln6193">		scctx-&gt;isc_intr = IFLIB_INTR_MSIX;</a>
<a name="ln6194"> </a>
<a name="ln6195">		return (vectors);</a>
<a name="ln6196">	} else {</a>
<a name="ln6197">		device_printf(dev,</a>
<a name="ln6198">		    &quot;failed to allocate %d MSI-X vectors, err: %d - using MSI\n&quot;,</a>
<a name="ln6199">		    vectors, err);</a>
<a name="ln6200">		bus_release_resource(dev, SYS_RES_MEMORY, bar,</a>
<a name="ln6201">		    ctx-&gt;ifc_msix_mem);</a>
<a name="ln6202">		ctx-&gt;ifc_msix_mem = NULL;</a>
<a name="ln6203">	}</a>
<a name="ln6204">msi:</a>
<a name="ln6205">	vectors = pci_msi_count(dev);</a>
<a name="ln6206">	scctx-&gt;isc_nrxqsets = 1;</a>
<a name="ln6207">	scctx-&gt;isc_ntxqsets = 1;</a>
<a name="ln6208">	scctx-&gt;isc_vectors = vectors;</a>
<a name="ln6209">	if (vectors == 1 &amp;&amp; pci_alloc_msi(dev, &amp;vectors) == 0) {</a>
<a name="ln6210">		device_printf(dev,&quot;Using an MSI interrupt\n&quot;);</a>
<a name="ln6211">		scctx-&gt;isc_intr = IFLIB_INTR_MSI;</a>
<a name="ln6212">	} else {</a>
<a name="ln6213">		scctx-&gt;isc_vectors = 1;</a>
<a name="ln6214">		device_printf(dev,&quot;Using a Legacy interrupt\n&quot;);</a>
<a name="ln6215">		scctx-&gt;isc_intr = IFLIB_INTR_LEGACY;</a>
<a name="ln6216">	}</a>
<a name="ln6217"> </a>
<a name="ln6218">	return (vectors);</a>
<a name="ln6219">}</a>
<a name="ln6220"> </a>
<a name="ln6221">static const char *ring_states[] = { &quot;IDLE&quot;, &quot;BUSY&quot;, &quot;STALLED&quot;, &quot;ABDICATED&quot; };</a>
<a name="ln6222"> </a>
<a name="ln6223">#ifndef __HAIKU__</a>
<a name="ln6224">static int</a>
<a name="ln6225">mp_ring_state_handler(SYSCTL_HANDLER_ARGS)</a>
<a name="ln6226">{</a>
<a name="ln6227">	int rc;</a>
<a name="ln6228">	uint16_t *state = ((uint16_t *)oidp-&gt;oid_arg1);</a>
<a name="ln6229">	struct sbuf *sb;</a>
<a name="ln6230">	const char *ring_state = &quot;UNKNOWN&quot;;</a>
<a name="ln6231"> </a>
<a name="ln6232">	/* XXX needed ? */</a>
<a name="ln6233">	rc = sysctl_wire_old_buffer(req, 0);</a>
<a name="ln6234">	MPASS(rc == 0);</a>
<a name="ln6235">	if (rc != 0)</a>
<a name="ln6236">		return (rc);</a>
<a name="ln6237">	sb = sbuf_new_for_sysctl(NULL, NULL, 80, req);</a>
<a name="ln6238">	MPASS(sb != NULL);</a>
<a name="ln6239">	if (sb == NULL)</a>
<a name="ln6240">		return (ENOMEM);</a>
<a name="ln6241">	if (state[3] &lt;= 3)</a>
<a name="ln6242">		ring_state = ring_states[state[3]];</a>
<a name="ln6243"> </a>
<a name="ln6244">	sbuf_printf(sb, &quot;pidx_head: %04hd pidx_tail: %04hd cidx: %04hd state: %s&quot;,</a>
<a name="ln6245">		    state[0], state[1], state[2], ring_state);</a>
<a name="ln6246">	rc = sbuf_finish(sb);</a>
<a name="ln6247">	sbuf_delete(sb);</a>
<a name="ln6248">        return(rc);</a>
<a name="ln6249">}</a>
<a name="ln6250">#endif</a>
<a name="ln6251"> </a>
<a name="ln6252">enum iflib_ndesc_handler {</a>
<a name="ln6253">	IFLIB_NTXD_HANDLER,</a>
<a name="ln6254">	IFLIB_NRXD_HANDLER,</a>
<a name="ln6255">};</a>
<a name="ln6256"> </a>
<a name="ln6257">static int</a>
<a name="ln6258">mp_ndesc_handler(SYSCTL_HANDLER_ARGS)</a>
<a name="ln6259">{</a>
<a name="ln6260">	if_ctx_t ctx = (void *)arg1;</a>
<a name="ln6261">	enum iflib_ndesc_handler type = arg2;</a>
<a name="ln6262">	char buf[256] = {0};</a>
<a name="ln6263">	qidx_t *ndesc;</a>
<a name="ln6264">	char *p, *next;</a>
<a name="ln6265">	int nqs, rc, i;</a>
<a name="ln6266"> </a>
<a name="ln6267">	MPASS(type == IFLIB_NTXD_HANDLER || type == IFLIB_NRXD_HANDLER);</a>
<a name="ln6268"> </a>
<a name="ln6269">	nqs = 8;</a>
<a name="ln6270">	switch(type) {</a>
<a name="ln6271">	case IFLIB_NTXD_HANDLER:</a>
<a name="ln6272">		ndesc = ctx-&gt;ifc_sysctl_ntxds;</a>
<a name="ln6273">		if (ctx-&gt;ifc_sctx)</a>
<a name="ln6274">			nqs = ctx-&gt;ifc_sctx-&gt;isc_ntxqs;</a>
<a name="ln6275">		break;</a>
<a name="ln6276">	case IFLIB_NRXD_HANDLER:</a>
<a name="ln6277">		ndesc = ctx-&gt;ifc_sysctl_nrxds;</a>
<a name="ln6278">		if (ctx-&gt;ifc_sctx)</a>
<a name="ln6279">			nqs = ctx-&gt;ifc_sctx-&gt;isc_nrxqs;</a>
<a name="ln6280">		break;</a>
<a name="ln6281">	default:</a>
<a name="ln6282">			panic(&quot;unhandled type&quot;);</a>
<a name="ln6283">	}</a>
<a name="ln6284">	if (nqs == 0)</a>
<a name="ln6285">		nqs = 8;</a>
<a name="ln6286"> </a>
<a name="ln6287">	for (i=0; i&lt;8; i++) {</a>
<a name="ln6288">		if (i &gt;= nqs)</a>
<a name="ln6289">			break;</a>
<a name="ln6290">		if (i)</a>
<a name="ln6291">			strcat(buf, &quot;,&quot;);</a>
<a name="ln6292">		sprintf(strchr(buf, 0), &quot;%d&quot;, ndesc[i]);</a>
<a name="ln6293">	}</a>
<a name="ln6294"> </a>
<a name="ln6295">	rc = sysctl_handle_string(oidp, buf, sizeof(buf), req);</a>
<a name="ln6296">	if (rc || req-&gt;newptr == NULL)</a>
<a name="ln6297">		return rc;</a>
<a name="ln6298"> </a>
<a name="ln6299">	for (i = 0, next = buf, p = strsep(&amp;next, &quot; ,&quot;); i &lt; 8 &amp;&amp; p;</a>
<a name="ln6300">	    i++, p = strsep(&amp;next, &quot; ,&quot;)) {</a>
<a name="ln6301">		ndesc[i] = strtoul(p, NULL, 10);</a>
<a name="ln6302">	}</a>
<a name="ln6303"> </a>
<a name="ln6304">	return(rc);</a>
<a name="ln6305">}</a>
<a name="ln6306"> </a>
<a name="ln6307">#define NAME_BUFLEN 32</a>
<a name="ln6308">static void</a>
<a name="ln6309">iflib_add_device_sysctl_pre(if_ctx_t ctx)</a>
<a name="ln6310">{</a>
<a name="ln6311">#ifndef __HAIKU__</a>
<a name="ln6312">        device_t dev = iflib_get_dev(ctx);</a>
<a name="ln6313">	struct sysctl_oid_list *child, *oid_list;</a>
<a name="ln6314">	struct sysctl_ctx_list *ctx_list;</a>
<a name="ln6315">	struct sysctl_oid *node;</a>
<a name="ln6316"> </a>
<a name="ln6317">	ctx_list = device_get_sysctl_ctx(dev);</a>
<a name="ln6318">	child = SYSCTL_CHILDREN(device_get_sysctl_tree(dev));</a>
<a name="ln6319">	ctx-&gt;ifc_sysctl_node = node = SYSCTL_ADD_NODE(ctx_list, child, OID_AUTO, &quot;iflib&quot;,</a>
<a name="ln6320">						      CTLFLAG_RD, NULL, &quot;IFLIB fields&quot;);</a>
<a name="ln6321">	oid_list = SYSCTL_CHILDREN(node);</a>
<a name="ln6322"> </a>
<a name="ln6323">	SYSCTL_ADD_CONST_STRING(ctx_list, oid_list, OID_AUTO, &quot;driver_version&quot;,</a>
<a name="ln6324">		       CTLFLAG_RD, ctx-&gt;ifc_sctx-&gt;isc_driver_version,</a>
<a name="ln6325">		       &quot;driver version&quot;);</a>
<a name="ln6326"> </a>
<a name="ln6327">	SYSCTL_ADD_U16(ctx_list, oid_list, OID_AUTO, &quot;override_ntxqs&quot;,</a>
<a name="ln6328">		       CTLFLAG_RWTUN, &amp;ctx-&gt;ifc_sysctl_ntxqs, 0,</a>
<a name="ln6329">			&quot;# of txqs to use, 0 =&gt; use default #&quot;);</a>
<a name="ln6330">	SYSCTL_ADD_U16(ctx_list, oid_list, OID_AUTO, &quot;override_nrxqs&quot;,</a>
<a name="ln6331">		       CTLFLAG_RWTUN, &amp;ctx-&gt;ifc_sysctl_nrxqs, 0,</a>
<a name="ln6332">			&quot;# of rxqs to use, 0 =&gt; use default #&quot;);</a>
<a name="ln6333">	SYSCTL_ADD_U16(ctx_list, oid_list, OID_AUTO, &quot;override_qs_enable&quot;,</a>
<a name="ln6334">		       CTLFLAG_RWTUN, &amp;ctx-&gt;ifc_sysctl_qs_eq_override, 0,</a>
<a name="ln6335">                       &quot;permit #txq != #rxq&quot;);</a>
<a name="ln6336">	SYSCTL_ADD_INT(ctx_list, oid_list, OID_AUTO, &quot;disable_msix&quot;,</a>
<a name="ln6337">                      CTLFLAG_RWTUN, &amp;ctx-&gt;ifc_softc_ctx.isc_disable_msix, 0,</a>
<a name="ln6338">                      &quot;disable MSI-X (default 0)&quot;);</a>
<a name="ln6339">	SYSCTL_ADD_U16(ctx_list, oid_list, OID_AUTO, &quot;rx_budget&quot;,</a>
<a name="ln6340">		       CTLFLAG_RWTUN, &amp;ctx-&gt;ifc_sysctl_rx_budget, 0,</a>
<a name="ln6341">                       &quot;set the rx budget&quot;);</a>
<a name="ln6342">	SYSCTL_ADD_U16(ctx_list, oid_list, OID_AUTO, &quot;tx_abdicate&quot;,</a>
<a name="ln6343">		       CTLFLAG_RWTUN, &amp;ctx-&gt;ifc_sysctl_tx_abdicate, 0,</a>
<a name="ln6344">		       &quot;cause tx to abdicate instead of running to completion&quot;);</a>
<a name="ln6345"> </a>
<a name="ln6346">	/* XXX change for per-queue sizes */</a>
<a name="ln6347">	SYSCTL_ADD_PROC(ctx_list, oid_list, OID_AUTO, &quot;override_ntxds&quot;,</a>
<a name="ln6348">		       CTLTYPE_STRING|CTLFLAG_RWTUN, ctx, IFLIB_NTXD_HANDLER,</a>
<a name="ln6349">                       mp_ndesc_handler, &quot;A&quot;,</a>
<a name="ln6350">                       &quot;list of # of tx descriptors to use, 0 = use default #&quot;);</a>
<a name="ln6351">	SYSCTL_ADD_PROC(ctx_list, oid_list, OID_AUTO, &quot;override_nrxds&quot;,</a>
<a name="ln6352">		       CTLTYPE_STRING|CTLFLAG_RWTUN, ctx, IFLIB_NRXD_HANDLER,</a>
<a name="ln6353">                       mp_ndesc_handler, &quot;A&quot;,</a>
<a name="ln6354">                       &quot;list of # of rx descriptors to use, 0 = use default #&quot;);</a>
<a name="ln6355">#endif</a>
<a name="ln6356">}</a>
<a name="ln6357"> </a>
<a name="ln6358">static void</a>
<a name="ln6359">iflib_add_device_sysctl_post(if_ctx_t ctx)</a>
<a name="ln6360">{</a>
<a name="ln6361">#ifndef __HAIKU__</a>
<a name="ln6362">	if_shared_ctx_t sctx = ctx-&gt;ifc_sctx;</a>
<a name="ln6363">	if_softc_ctx_t scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln6364">        device_t dev = iflib_get_dev(ctx);</a>
<a name="ln6365">	struct sysctl_oid_list *child;</a>
<a name="ln6366">	struct sysctl_ctx_list *ctx_list;</a>
<a name="ln6367">	iflib_fl_t fl;</a>
<a name="ln6368">	iflib_txq_t txq;</a>
<a name="ln6369">	iflib_rxq_t rxq;</a>
<a name="ln6370">	int i, j;</a>
<a name="ln6371">	char namebuf[NAME_BUFLEN];</a>
<a name="ln6372">	char *qfmt;</a>
<a name="ln6373">	struct sysctl_oid *queue_node, *fl_node, *node;</a>
<a name="ln6374">	struct sysctl_oid_list *queue_list, *fl_list;</a>
<a name="ln6375">	ctx_list = device_get_sysctl_ctx(dev);</a>
<a name="ln6376"> </a>
<a name="ln6377">	node = ctx-&gt;ifc_sysctl_node;</a>
<a name="ln6378">	child = SYSCTL_CHILDREN(node);</a>
<a name="ln6379"> </a>
<a name="ln6380">	if (scctx-&gt;isc_ntxqsets &gt; 100)</a>
<a name="ln6381">		qfmt = &quot;txq%03d&quot;;</a>
<a name="ln6382">	else if (scctx-&gt;isc_ntxqsets &gt; 10)</a>
<a name="ln6383">		qfmt = &quot;txq%02d&quot;;</a>
<a name="ln6384">	else</a>
<a name="ln6385">		qfmt = &quot;txq%d&quot;;</a>
<a name="ln6386">	for (i = 0, txq = ctx-&gt;ifc_txqs; i &lt; scctx-&gt;isc_ntxqsets; i++, txq++) {</a>
<a name="ln6387">		snprintf(namebuf, NAME_BUFLEN, qfmt, i);</a>
<a name="ln6388">		queue_node = SYSCTL_ADD_NODE(ctx_list, child, OID_AUTO, namebuf,</a>
<a name="ln6389">					     CTLFLAG_RD, NULL, &quot;Queue Name&quot;);</a>
<a name="ln6390">		queue_list = SYSCTL_CHILDREN(queue_node);</a>
<a name="ln6391">#if MEMORY_LOGGING</a>
<a name="ln6392">		SYSCTL_ADD_QUAD(ctx_list, queue_list, OID_AUTO, &quot;txq_dequeued&quot;,</a>
<a name="ln6393">				CTLFLAG_RD,</a>
<a name="ln6394">				&amp;txq-&gt;ift_dequeued, &quot;total mbufs freed&quot;);</a>
<a name="ln6395">		SYSCTL_ADD_QUAD(ctx_list, queue_list, OID_AUTO, &quot;txq_enqueued&quot;,</a>
<a name="ln6396">				CTLFLAG_RD,</a>
<a name="ln6397">				&amp;txq-&gt;ift_enqueued, &quot;total mbufs enqueued&quot;);</a>
<a name="ln6398">#endif</a>
<a name="ln6399">		SYSCTL_ADD_QUAD(ctx_list, queue_list, OID_AUTO, &quot;mbuf_defrag&quot;,</a>
<a name="ln6400">				   CTLFLAG_RD,</a>
<a name="ln6401">				   &amp;txq-&gt;ift_mbuf_defrag, &quot;# of times m_defrag was called&quot;);</a>
<a name="ln6402">		SYSCTL_ADD_QUAD(ctx_list, queue_list, OID_AUTO, &quot;m_pullups&quot;,</a>
<a name="ln6403">				   CTLFLAG_RD,</a>
<a name="ln6404">				   &amp;txq-&gt;ift_pullups, &quot;# of times m_pullup was called&quot;);</a>
<a name="ln6405">		SYSCTL_ADD_QUAD(ctx_list, queue_list, OID_AUTO, &quot;mbuf_defrag_failed&quot;,</a>
<a name="ln6406">				   CTLFLAG_RD,</a>
<a name="ln6407">				   &amp;txq-&gt;ift_mbuf_defrag_failed, &quot;# of times m_defrag failed&quot;);</a>
<a name="ln6408">		SYSCTL_ADD_QUAD(ctx_list, queue_list, OID_AUTO, &quot;no_desc_avail&quot;,</a>
<a name="ln6409">				   CTLFLAG_RD,</a>
<a name="ln6410">				   &amp;txq-&gt;ift_no_desc_avail, &quot;# of times no descriptors were available&quot;);</a>
<a name="ln6411">		SYSCTL_ADD_QUAD(ctx_list, queue_list, OID_AUTO, &quot;tx_map_failed&quot;,</a>
<a name="ln6412">				   CTLFLAG_RD,</a>
<a name="ln6413">				   &amp;txq-&gt;ift_map_failed, &quot;# of times dma map failed&quot;);</a>
<a name="ln6414">		SYSCTL_ADD_QUAD(ctx_list, queue_list, OID_AUTO, &quot;txd_encap_efbig&quot;,</a>
<a name="ln6415">				   CTLFLAG_RD,</a>
<a name="ln6416">				   &amp;txq-&gt;ift_txd_encap_efbig, &quot;# of times txd_encap returned EFBIG&quot;);</a>
<a name="ln6417">		SYSCTL_ADD_QUAD(ctx_list, queue_list, OID_AUTO, &quot;no_tx_dma_setup&quot;,</a>
<a name="ln6418">				   CTLFLAG_RD,</a>
<a name="ln6419">				   &amp;txq-&gt;ift_no_tx_dma_setup, &quot;# of times map failed for other than EFBIG&quot;);</a>
<a name="ln6420">		SYSCTL_ADD_U16(ctx_list, queue_list, OID_AUTO, &quot;txq_pidx&quot;,</a>
<a name="ln6421">				   CTLFLAG_RD,</a>
<a name="ln6422">				   &amp;txq-&gt;ift_pidx, 1, &quot;Producer Index&quot;);</a>
<a name="ln6423">		SYSCTL_ADD_U16(ctx_list, queue_list, OID_AUTO, &quot;txq_cidx&quot;,</a>
<a name="ln6424">				   CTLFLAG_RD,</a>
<a name="ln6425">				   &amp;txq-&gt;ift_cidx, 1, &quot;Consumer Index&quot;);</a>
<a name="ln6426">		SYSCTL_ADD_U16(ctx_list, queue_list, OID_AUTO, &quot;txq_cidx_processed&quot;,</a>
<a name="ln6427">				   CTLFLAG_RD,</a>
<a name="ln6428">				   &amp;txq-&gt;ift_cidx_processed, 1, &quot;Consumer Index seen by credit update&quot;);</a>
<a name="ln6429">		SYSCTL_ADD_U16(ctx_list, queue_list, OID_AUTO, &quot;txq_in_use&quot;,</a>
<a name="ln6430">				   CTLFLAG_RD,</a>
<a name="ln6431">				   &amp;txq-&gt;ift_in_use, 1, &quot;descriptors in use&quot;);</a>
<a name="ln6432">		SYSCTL_ADD_QUAD(ctx_list, queue_list, OID_AUTO, &quot;txq_processed&quot;,</a>
<a name="ln6433">				   CTLFLAG_RD,</a>
<a name="ln6434">				   &amp;txq-&gt;ift_processed, &quot;descriptors procesed for clean&quot;);</a>
<a name="ln6435">		SYSCTL_ADD_QUAD(ctx_list, queue_list, OID_AUTO, &quot;txq_cleaned&quot;,</a>
<a name="ln6436">				   CTLFLAG_RD,</a>
<a name="ln6437">				   &amp;txq-&gt;ift_cleaned, &quot;total cleaned&quot;);</a>
<a name="ln6438">		SYSCTL_ADD_PROC(ctx_list, queue_list, OID_AUTO, &quot;ring_state&quot;,</a>
<a name="ln6439">				CTLTYPE_STRING | CTLFLAG_RD, __DEVOLATILE(uint64_t *, &amp;txq-&gt;ift_br-&gt;state),</a>
<a name="ln6440">				0, mp_ring_state_handler, &quot;A&quot;, &quot;soft ring state&quot;);</a>
<a name="ln6441">		SYSCTL_ADD_COUNTER_U64(ctx_list, queue_list, OID_AUTO, &quot;r_enqueues&quot;,</a>
<a name="ln6442">				       CTLFLAG_RD, &amp;txq-&gt;ift_br-&gt;enqueues,</a>
<a name="ln6443">				       &quot;# of enqueues to the mp_ring for this queue&quot;);</a>
<a name="ln6444">		SYSCTL_ADD_COUNTER_U64(ctx_list, queue_list, OID_AUTO, &quot;r_drops&quot;,</a>
<a name="ln6445">				       CTLFLAG_RD, &amp;txq-&gt;ift_br-&gt;drops,</a>
<a name="ln6446">				       &quot;# of drops in the mp_ring for this queue&quot;);</a>
<a name="ln6447">		SYSCTL_ADD_COUNTER_U64(ctx_list, queue_list, OID_AUTO, &quot;r_starts&quot;,</a>
<a name="ln6448">				       CTLFLAG_RD, &amp;txq-&gt;ift_br-&gt;starts,</a>
<a name="ln6449">				       &quot;# of normal consumer starts in the mp_ring for this queue&quot;);</a>
<a name="ln6450">		SYSCTL_ADD_COUNTER_U64(ctx_list, queue_list, OID_AUTO, &quot;r_stalls&quot;,</a>
<a name="ln6451">				       CTLFLAG_RD, &amp;txq-&gt;ift_br-&gt;stalls,</a>
<a name="ln6452">					       &quot;# of consumer stalls in the mp_ring for this queue&quot;);</a>
<a name="ln6453">		SYSCTL_ADD_COUNTER_U64(ctx_list, queue_list, OID_AUTO, &quot;r_restarts&quot;,</a>
<a name="ln6454">			       CTLFLAG_RD, &amp;txq-&gt;ift_br-&gt;restarts,</a>
<a name="ln6455">				       &quot;# of consumer restarts in the mp_ring for this queue&quot;);</a>
<a name="ln6456">		SYSCTL_ADD_COUNTER_U64(ctx_list, queue_list, OID_AUTO, &quot;r_abdications&quot;,</a>
<a name="ln6457">				       CTLFLAG_RD, &amp;txq-&gt;ift_br-&gt;abdications,</a>
<a name="ln6458">				       &quot;# of consumer abdications in the mp_ring for this queue&quot;);</a>
<a name="ln6459">	}</a>
<a name="ln6460"> </a>
<a name="ln6461">	if (scctx-&gt;isc_nrxqsets &gt; 100)</a>
<a name="ln6462">		qfmt = &quot;rxq%03d&quot;;</a>
<a name="ln6463">	else if (scctx-&gt;isc_nrxqsets &gt; 10)</a>
<a name="ln6464">		qfmt = &quot;rxq%02d&quot;;</a>
<a name="ln6465">	else</a>
<a name="ln6466">		qfmt = &quot;rxq%d&quot;;</a>
<a name="ln6467">	for (i = 0, rxq = ctx-&gt;ifc_rxqs; i &lt; scctx-&gt;isc_nrxqsets; i++, rxq++) {</a>
<a name="ln6468">		snprintf(namebuf, NAME_BUFLEN, qfmt, i);</a>
<a name="ln6469">		queue_node = SYSCTL_ADD_NODE(ctx_list, child, OID_AUTO, namebuf,</a>
<a name="ln6470">					     CTLFLAG_RD, NULL, &quot;Queue Name&quot;);</a>
<a name="ln6471">		queue_list = SYSCTL_CHILDREN(queue_node);</a>
<a name="ln6472">		if (sctx-&gt;isc_flags &amp; IFLIB_HAS_RXCQ) {</a>
<a name="ln6473">			SYSCTL_ADD_U16(ctx_list, queue_list, OID_AUTO, &quot;rxq_cq_pidx&quot;,</a>
<a name="ln6474">				       CTLFLAG_RD,</a>
<a name="ln6475">				       &amp;rxq-&gt;ifr_cq_pidx, 1, &quot;Producer Index&quot;);</a>
<a name="ln6476">			SYSCTL_ADD_U16(ctx_list, queue_list, OID_AUTO, &quot;rxq_cq_cidx&quot;,</a>
<a name="ln6477">				       CTLFLAG_RD,</a>
<a name="ln6478">				       &amp;rxq-&gt;ifr_cq_cidx, 1, &quot;Consumer Index&quot;);</a>
<a name="ln6479">		}</a>
<a name="ln6480"> </a>
<a name="ln6481">		for (j = 0, fl = rxq-&gt;ifr_fl; j &lt; rxq-&gt;ifr_nfl; j++, fl++) {</a>
<a name="ln6482">			snprintf(namebuf, NAME_BUFLEN, &quot;rxq_fl%d&quot;, j);</a>
<a name="ln6483">			fl_node = SYSCTL_ADD_NODE(ctx_list, queue_list, OID_AUTO, namebuf,</a>
<a name="ln6484">						     CTLFLAG_RD, NULL, &quot;freelist Name&quot;);</a>
<a name="ln6485">			fl_list = SYSCTL_CHILDREN(fl_node);</a>
<a name="ln6486">			SYSCTL_ADD_U16(ctx_list, fl_list, OID_AUTO, &quot;pidx&quot;,</a>
<a name="ln6487">				       CTLFLAG_RD,</a>
<a name="ln6488">				       &amp;fl-&gt;ifl_pidx, 1, &quot;Producer Index&quot;);</a>
<a name="ln6489">			SYSCTL_ADD_U16(ctx_list, fl_list, OID_AUTO, &quot;cidx&quot;,</a>
<a name="ln6490">				       CTLFLAG_RD,</a>
<a name="ln6491">				       &amp;fl-&gt;ifl_cidx, 1, &quot;Consumer Index&quot;);</a>
<a name="ln6492">			SYSCTL_ADD_U16(ctx_list, fl_list, OID_AUTO, &quot;credits&quot;,</a>
<a name="ln6493">				       CTLFLAG_RD,</a>
<a name="ln6494">				       &amp;fl-&gt;ifl_credits, 1, &quot;credits available&quot;);</a>
<a name="ln6495">#if MEMORY_LOGGING</a>
<a name="ln6496">			SYSCTL_ADD_QUAD(ctx_list, fl_list, OID_AUTO, &quot;fl_m_enqueued&quot;,</a>
<a name="ln6497">					CTLFLAG_RD,</a>
<a name="ln6498">					&amp;fl-&gt;ifl_m_enqueued, &quot;mbufs allocated&quot;);</a>
<a name="ln6499">			SYSCTL_ADD_QUAD(ctx_list, fl_list, OID_AUTO, &quot;fl_m_dequeued&quot;,</a>
<a name="ln6500">					CTLFLAG_RD,</a>
<a name="ln6501">					&amp;fl-&gt;ifl_m_dequeued, &quot;mbufs freed&quot;);</a>
<a name="ln6502">			SYSCTL_ADD_QUAD(ctx_list, fl_list, OID_AUTO, &quot;fl_cl_enqueued&quot;,</a>
<a name="ln6503">					CTLFLAG_RD,</a>
<a name="ln6504">					&amp;fl-&gt;ifl_cl_enqueued, &quot;clusters allocated&quot;);</a>
<a name="ln6505">			SYSCTL_ADD_QUAD(ctx_list, fl_list, OID_AUTO, &quot;fl_cl_dequeued&quot;,</a>
<a name="ln6506">					CTLFLAG_RD,</a>
<a name="ln6507">					&amp;fl-&gt;ifl_cl_dequeued, &quot;clusters freed&quot;);</a>
<a name="ln6508">#endif</a>
<a name="ln6509"> </a>
<a name="ln6510">		}</a>
<a name="ln6511">	}</a>
<a name="ln6512">#endif</a>
<a name="ln6513">}</a>
<a name="ln6514"> </a>
<a name="ln6515">void</a>
<a name="ln6516">iflib_request_reset(if_ctx_t ctx)</a>
<a name="ln6517">{</a>
<a name="ln6518"> </a>
<a name="ln6519">	STATE_LOCK(ctx);</a>
<a name="ln6520">	ctx-&gt;ifc_flags |= IFC_DO_RESET;</a>
<a name="ln6521">	STATE_UNLOCK(ctx);</a>
<a name="ln6522">}</a>
<a name="ln6523"> </a>
<a name="ln6524">#ifndef __NO_STRICT_ALIGNMENT</a>
<a name="ln6525">static struct mbuf *</a>
<a name="ln6526">iflib_fixup_rx(struct mbuf *m)</a>
<a name="ln6527">{</a>
<a name="ln6528">	struct mbuf *n;</a>
<a name="ln6529"> </a>
<a name="ln6530">	if (m-&gt;m_len &lt;= (MCLBYTES - ETHER_HDR_LEN)) {</a>
<a name="ln6531">		bcopy(m-&gt;m_data, m-&gt;m_data + ETHER_HDR_LEN, m-&gt;m_len);</a>
<a name="ln6532">		m-&gt;m_data += ETHER_HDR_LEN;</a>
<a name="ln6533">		n = m;</a>
<a name="ln6534">	} else {</a>
<a name="ln6535">		MGETHDR(n, M_NOWAIT, MT_DATA);</a>
<a name="ln6536">		if (n == NULL) {</a>
<a name="ln6537">			m_freem(m);</a>
<a name="ln6538">			return (NULL);</a>
<a name="ln6539">		}</a>
<a name="ln6540">		bcopy(m-&gt;m_data, n-&gt;m_data, ETHER_HDR_LEN);</a>
<a name="ln6541">		m-&gt;m_data += ETHER_HDR_LEN;</a>
<a name="ln6542">		m-&gt;m_len -= ETHER_HDR_LEN;</a>
<a name="ln6543">		n-&gt;m_len = ETHER_HDR_LEN;</a>
<a name="ln6544">		M_MOVE_PKTHDR(n, m);</a>
<a name="ln6545">		n-&gt;m_next = m;</a>
<a name="ln6546">	}</a>
<a name="ln6547">	return (n);</a>
<a name="ln6548">}</a>
<a name="ln6549">#endif</a>
<a name="ln6550"> </a>
<a name="ln6551">#ifdef NETDUMP</a>
<a name="ln6552">static void</a>
<a name="ln6553">iflib_netdump_init(struct ifnet *ifp, int *nrxr, int *ncl, int *clsize)</a>
<a name="ln6554">{</a>
<a name="ln6555">	if_ctx_t ctx;</a>
<a name="ln6556"> </a>
<a name="ln6557">	ctx = if_getsoftc(ifp);</a>
<a name="ln6558">	CTX_LOCK(ctx);</a>
<a name="ln6559">	*nrxr = NRXQSETS(ctx);</a>
<a name="ln6560">	*ncl = ctx-&gt;ifc_rxqs[0].ifr_fl-&gt;ifl_size;</a>
<a name="ln6561">	*clsize = ctx-&gt;ifc_rxqs[0].ifr_fl-&gt;ifl_buf_size;</a>
<a name="ln6562">	CTX_UNLOCK(ctx);</a>
<a name="ln6563">}</a>
<a name="ln6564"> </a>
<a name="ln6565">static void</a>
<a name="ln6566">iflib_netdump_event(struct ifnet *ifp, enum netdump_ev event)</a>
<a name="ln6567">{</a>
<a name="ln6568">	if_ctx_t ctx;</a>
<a name="ln6569">	if_softc_ctx_t scctx;</a>
<a name="ln6570">	iflib_fl_t fl;</a>
<a name="ln6571">	iflib_rxq_t rxq;</a>
<a name="ln6572">	int i, j;</a>
<a name="ln6573"> </a>
<a name="ln6574">	ctx = if_getsoftc(ifp);</a>
<a name="ln6575">	scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln6576"> </a>
<a name="ln6577">	switch (event) {</a>
<a name="ln6578">#ifndef __HAIKU__</a>
<a name="ln6579">	case NETDUMP_START:</a>
<a name="ln6580">		for (i = 0; i &lt; scctx-&gt;isc_nrxqsets; i++) {</a>
<a name="ln6581">			rxq = &amp;ctx-&gt;ifc_rxqs[i];</a>
<a name="ln6582">			for (j = 0; j &lt; rxq-&gt;ifr_nfl; j++) {</a>
<a name="ln6583">				fl = rxq-&gt;ifr_fl;</a>
<a name="ln6584">				fl-&gt;ifl_zone = m_getzone(fl-&gt;ifl_buf_size);</a>
<a name="ln6585">			}</a>
<a name="ln6586">		}</a>
<a name="ln6587">		iflib_no_tx_batch = 1;</a>
<a name="ln6588">		break;</a>
<a name="ln6589">#endif</a>
<a name="ln6590">	default:</a>
<a name="ln6591">		break;</a>
<a name="ln6592">	}</a>
<a name="ln6593">}</a>
<a name="ln6594"> </a>
<a name="ln6595">static int</a>
<a name="ln6596">iflib_netdump_transmit(struct ifnet *ifp, struct mbuf *m)</a>
<a name="ln6597">{</a>
<a name="ln6598">	if_ctx_t ctx;</a>
<a name="ln6599">	iflib_txq_t txq;</a>
<a name="ln6600">	int error;</a>
<a name="ln6601"> </a>
<a name="ln6602">	ctx = if_getsoftc(ifp);</a>
<a name="ln6603">	if ((if_getdrvflags(ifp) &amp; (IFF_DRV_RUNNING | IFF_DRV_OACTIVE)) !=</a>
<a name="ln6604">	    IFF_DRV_RUNNING)</a>
<a name="ln6605">		return (EBUSY);</a>
<a name="ln6606"> </a>
<a name="ln6607">	txq = &amp;ctx-&gt;ifc_txqs[0];</a>
<a name="ln6608">	error = iflib_encap(txq, &amp;m);</a>
<a name="ln6609">	if (error == 0)</a>
<a name="ln6610">		(void)iflib_txd_db_check(ctx, txq, true, txq-&gt;ift_in_use);</a>
<a name="ln6611">	return (error);</a>
<a name="ln6612">}</a>
<a name="ln6613"> </a>
<a name="ln6614">static int</a>
<a name="ln6615">iflib_netdump_poll(struct ifnet *ifp, int count)</a>
<a name="ln6616">{</a>
<a name="ln6617">	if_ctx_t ctx;</a>
<a name="ln6618">	if_softc_ctx_t scctx;</a>
<a name="ln6619">	iflib_txq_t txq;</a>
<a name="ln6620">	int i;</a>
<a name="ln6621"> </a>
<a name="ln6622">	ctx = if_getsoftc(ifp);</a>
<a name="ln6623">	scctx = &amp;ctx-&gt;ifc_softc_ctx;</a>
<a name="ln6624"> </a>
<a name="ln6625">	if ((if_getdrvflags(ifp) &amp; (IFF_DRV_RUNNING | IFF_DRV_OACTIVE)) !=</a>
<a name="ln6626">	    IFF_DRV_RUNNING)</a>
<a name="ln6627">		return (EBUSY);</a>
<a name="ln6628"> </a>
<a name="ln6629">	txq = &amp;ctx-&gt;ifc_txqs[0];</a>
<a name="ln6630">	(void)iflib_completed_tx_reclaim(txq, RECLAIM_THRESH(ctx));</a>
<a name="ln6631"> </a>
<a name="ln6632">	for (i = 0; i &lt; scctx-&gt;isc_nrxqsets; i++)</a>
<a name="ln6633">		(void)iflib_rxeof(&amp;ctx-&gt;ifc_rxqs[i], 16 /* XXX */);</a>
<a name="ln6634">	return (0);</a>
<a name="ln6635">}</a>
<a name="ln6636">#endif /* NETDUMP */</a>

</code></pre>
<div class="balloon" rel="6292"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v614/" target="_blank">V614</a> Potentially uninitialized pointer 'ndesc' used.</p></div>
<div class="balloon" rel="5873"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v614/" target="_blank">V614</a> Potentially uninitialized pointer 'tqg' used. Consider checking the sixth actual argument of the 'iflib_irq_set_affinity' function.</p></div>
<div class="balloon" rel="5871"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v614/" target="_blank">V614</a> Potentially uninitialized pointer 'q' used.</p></div>
<div class="balloon" rel="5871"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v614/" target="_blank">V614</a> Potentially uninitialized pointer 'fn' used.</p></div>
<div class="balloon" rel="5871"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v614/" target="_blank">V614</a> Potentially uninitialized pointer 'gtask' used.</p></div>
<div class="balloon" rel="5820"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v614/" target="_blank">V614</a> Potentially uninitialized pointer 'intr_fast' used. Consider checking the fourth actual argument of the '_iflib_irq_alloc' function.</p></div>
<div class="balloon" rel="5817"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v614/" target="_blank">V614</a> Potentially uninitialized pointer 'q' used.</p></div>
<div class="balloon" rel="5816"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v614/" target="_blank">V614</a> Potentially uninitialized pointer 'gtask' used.</p></div>
<div class="balloon" rel="3518"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v576/" target="_blank">V576</a> Incorrect format. Consider checking the fourth actual argument of the 'freebsd_printf' function. The intmax_t/uintmax_t type argument is expected.</p></div>
<div class="balloon" rel="3518"><p><span style="font-size:18px">&uarr;</span> <a href="https://www.viva64.com/en/w/v576/" target="_blank">V576</a> Incorrect format. Consider checking the third actual argument of the 'freebsd_printf' function. The intmax_t/uintmax_t type argument is expected.</p></div>

<link rel="stylesheet" href="highlight.css">
<script src="highlight.pack.js"></script>
<script src="highlightjs-line-numbers.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>hljs.initLineNumbersOnLoad();</script>
<script>
  $(document).ready(function() {
      $('.balloon').each(function () {
          var bl = $(this);
          var line = bl.attr('rel');
          var text = $('a[name="ln'+line+'"]').text();

          var space_count = 0;
          for(var i = 0; i<text.length; i++){
              var char = text[i];
              if((char !== ' ')&&(char !== '\t'))break;
              if(char === '\t')space_count++;
              space_count++;
          }

          bl.css('margin-left', space_count*8);
          $('a[name="ln'+line+'"]').after(bl);
      });

      window.location = window.location;
  });
</script>
</body>
</html>
